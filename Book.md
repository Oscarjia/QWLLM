# ã€Šåƒé—®LLMå¤§è¯­è¨€æ¨¡å‹-å…¥é—¨ç¯‡ã€‹

> è®©æ¯ä¸ªäººéƒ½èƒ½å¬æ‡‚çš„AIæŠ€æœ¯æŒ‡å—

---

## ğŸ“– å…³äºæœ¬ä¹¦

æ¬¢è¿æ¥åˆ°å¤§è¯­è¨€æ¨¡å‹çš„å¥‡å¦™ä¸–ç•Œï¼å¦‚æœä½ æ›¾ç»å¯¹ChatGPTã€æ–‡å¿ƒä¸€è¨€è¿™äº›AIåŠ©æ‰‹æ„Ÿåˆ°å¥½å¥‡ï¼Œæƒ³çŸ¥é“å®ƒä»¬èƒŒåçš„æŠ€æœ¯åŸç†ï¼Œåˆæ‹…å¿ƒè‡ªå·±æ²¡æœ‰æ·±åšçš„æŠ€æœ¯èƒŒæ™¯çœ‹ä¸æ‡‚â€”â€”åˆ«æ‹…å¿ƒï¼Œè¿™æœ¬ä¹¦å°±æ˜¯ä¸ºä½ å‡†å¤‡çš„ï¼

æˆ‘ä»¬ç”¨æœ€æ¥åœ°æ°”çš„è¯­è¨€ï¼Œé…ä¸Šç”Ÿæ´»åŒ–çš„æ¯”å–»ï¼Œå¸¦ä½ æ­å¼€LLMï¼ˆLarge Language Modelï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼‰çš„ç¥ç§˜é¢çº±ã€‚ä»æœ€åŸºç¡€çš„æ¦‚å¿µå¼€å§‹ï¼Œä¸€æ­¥æ­¥æ·±å…¥åˆ°å‰æ²¿æŠ€æœ¯ï¼Œè®©ä½ åœ¨è½»æ¾æ„‰å¿«çš„é˜…è¯»ä¸­æŒæ¡AIçš„æ ¸å¿ƒçŸ¥è¯†ã€‚

### ğŸ“š æœ¬ä¹¦ç‰¹è‰²

- **é›¶åŸºç¡€å‹å¥½**ï¼šä¸éœ€è¦æœºå™¨å­¦ä¹ èƒŒæ™¯ï¼Œæˆ‘ä»¬ä»é›¶å¼€å§‹
- **å¹½é»˜é£è¶£**ï¼šæŠ€æœ¯ä¹¦ä¹Ÿå¯ä»¥å¾ˆæœ‰è¶£ï¼Œæ‹’ç»æ¯ç‡¥è¯´æ•™
- **å®æˆ˜å¯¼å‘**ï¼šä¸ä»…è®²åŸç†ï¼Œæ›´æ³¨é‡å®é™…åº”ç”¨
- **ç´§è·Ÿå‰æ²¿**ï¼šåŒ…å«DeepSeek R1ã€MCPåè®®ç­‰æœ€æ–°æŠ€æœ¯

---

## ğŸ¯ å‰è¨€ï¼šAIæ—¶ä»£ï¼Œä½ å‡†å¤‡å¥½äº†å—ï¼Ÿ

è¿˜è®°å¾—ç¬¬ä¸€æ¬¡å’ŒChatGPTå¯¹è¯æ—¶çš„éœ‡æ’¼å—ï¼Ÿ

"å†™ä¸€é¦–å…³äºç¨‹åºå‘˜çš„è¯—ã€‚"
"å¸®æˆ‘è§£é‡Šä»€ä¹ˆæ˜¯é‡å­è®¡ç®—ã€‚"
"ç”¨Pythonå†™ä¸€ä¸ªè´ªåƒè›‡æ¸¸æˆã€‚"

å‡ ç§’é’Ÿåï¼Œå±å¹•ä¸Šå°±å‡ºç°äº†è®©äººæƒŠå¹çš„å›ç­”ã€‚é‚£ä¸€åˆ»ï¼Œä½ æ˜¯å¦æƒ³è¿‡ï¼šè¿™ç©æ„å„¿åˆ°åº•æ˜¯æ€ä¹ˆåšåˆ°çš„ï¼Ÿ

å¦‚æœè¯´äº’è”ç½‘æ”¹å˜äº†ä¿¡æ¯çš„ä¼ æ’­æ–¹å¼ï¼Œé‚£ä¹ˆå¤§è¯­è¨€æ¨¡å‹æ­£åœ¨æ”¹å˜ä¿¡æ¯çš„ç”Ÿäº§æ–¹å¼ã€‚ä»å†™ä½œã€ç¼–ç¨‹åˆ°å®¢æœã€æ•™è‚²ï¼ŒAIæ­£åœ¨é‡å¡‘å„è¡Œå„ä¸šã€‚ä½œä¸ºè¿™ä¸ªæ—¶ä»£çš„è§è¯è€…å’Œå‚ä¸è€…ï¼Œäº†è§£AIçš„å·¥ä½œåŸç†ï¼Œä¸ä»…èƒ½æ»¡è¶³å¥½å¥‡å¿ƒï¼Œæ›´èƒ½å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ä¸AIåä½œï¼Œåœ¨è¿™åœºæŠ€æœ¯é©å‘½ä¸­å æ®ä¸»åŠ¨ã€‚

è¿™æœ¬ä¹¦ï¼Œå°±æ˜¯ä½ è¿›å…¥AIä¸–ç•Œçš„æ•²é—¨ç –ã€‚è®©æˆ‘ä»¬å…ˆä»ä¸€ä¸ªæœ‰è¶£çš„è§’åº¦ï¼Œæ¥çœ‹çœ‹AIçš„å‘å±•å†ç¨‹ã€‚

# AIç•Œçš„"ä¸‰å›½æ¼”ä¹‰"â€”â€”è¯­è¨€æ¨¡å‹å‘å±•å²

> **å¼€ç¯‡è¯­ï¼šAIç•Œçš„"ä¸‰å›½æ¼”ä¹‰"**
>
> åœ¨äººå·¥æ™ºèƒ½çš„å†å²é•¿æ²³ä¸­ï¼Œè¯­è¨€æ¨¡å‹çš„å‘å±•å ªæ¯”ä¸€éƒ¨æ³¢æ¾œå£®é˜”çš„"ä¸‰å›½æ¼”ä¹‰"ã€‚ä»æœ€åˆå„è·¯ç®—æ³•ç¾¤é›„å‰²æ®ï¼Œåˆ°Transformerç»Ÿä¸€æ±Ÿæ¹–ï¼Œå†åˆ°å¦‚ä»ŠGPTã€BERTã€å¼€æºæ¨¡å‹ä¸‰è¶³é¼ç«‹ï¼Œè¿™æ˜¯ä¸€åœºè·¨è¶ŠäºŒåå¤šå¹´çš„æŠ€æœ¯äº‰éœ¸å²ã€‚
>
> è®©æˆ‘ä»¬ç©¿è¶Šæ—¶ç©ºï¼Œçœ‹çœ‹è¿™åœºAIç‰ˆ"ä¸‰å›½æ¼”ä¹‰"æ˜¯å¦‚ä½•ä¸Šæ¼”çš„â€”â€”

## ğŸº ç¬¬ä¸€å¹•ï¼šç¾¤é›„å‰²æ®æ—¶ä»£ï¼ˆ2000-2017ï¼‰
**ä»£è¡¨äººç‰©ï¼šè¯å‘é‡è¯¸ä¾¯ä»¬**

åœ¨æ·±åº¦å­¦ä¹ çš„æ˜¥ç§‹æˆ˜å›½æ—¶æœŸï¼ŒAIæ±Ÿæ¹–é¢ä¸´çš„æœ€å¤§æŒ‘æˆ˜æ˜¯ï¼šå¦‚ä½•è®©å†°å†·çš„æœºå™¨"è¯»æ‡‚"äººç±»æ¸©æš–çš„è¯­è¨€ï¼Ÿ

è¿™æ—¶çš„æ¨¡å‹å°±åƒæ˜¯æˆ˜å›½ä¸ƒé›„ï¼Œå„è‡ªä¸ºæ”¿ã€äº’ä¸å…¼å®¹ï¼š

```python
# é‚£ä¸ªæ—¶ä»£çš„"æ­¦å™¨è£…å¤‡"
class æ—©æœŸæ­¦å™¨åº“:
    def __init__(self):
        self.weapons = {
            "Bag-of-Words": "ç»Ÿè®¡æ´¾æŒé—¨ï¼Œç®€å•ç²—æš´æ•°è¯é¢‘",
            "TF-IDF": "æƒé‡å¤§å¸ˆï¼ŒçŸ¥é“å“ªäº›è¯æ›´é‡è¦", 
            "Word2Vec": "å‘é‡ç©ºé—´çš„å¼€æ‹“è€…ï¼Œè®©è¯è¯­æœ‰äº†'è·ç¦»'",
            "GloVe": "å…¨å±€ç»Ÿè®¡ä¸å±€éƒ¨ä¸Šä¸‹æ–‡çš„è°ƒå’Œè€…"
        }
```

**Word2Vecçš„ä¼ å¥‡**ï¼š2013å¹´ï¼Œè°·æ­Œçš„Mikolovå›¢é˜Ÿæå‡ºWord2Vecï¼Œå°±åƒåˆ˜å¤‡å¾—åˆ°äº†è¯¸è‘›äº®çš„éš†ä¸­å¯¹ã€‚çªç„¶é—´ï¼Œæœºå™¨èƒ½ç†è§£"å›½ç‹-ç”·äºº+å¥³äºº=ç‹å"è¿™ç§ç¥å¥‡çš„ç±»æ¯”å…³ç³»ï¼

```python
# Word2Vecçš„é­”æ³•æ—¶åˆ»
def word_analogy_demo():
    """
    Word2Vecæœ€è‘—åçš„åº”ç”¨ï¼šè¯è¯­ç±»æ¯”
    è¿™ä¸ªå‘ç°éœ‡æƒŠäº†æ•´ä¸ªAIç•Œ
    """
    examples = [
        "å›½ç‹ - ç”·äºº + å¥³äºº = ç‹å",
        "åŒ—äº¬ - ä¸­å›½ + ç¾å›½ = åç››é¡¿", 
        "è‹¹æœ - æ°´æœ + åŠ¨ç‰© = ï¼Ÿ"  # æ¨¡å‹èƒ½æ¨ç†å—ï¼Ÿ
    ]
    return examples
```

**è¿™ä¸ªæ—¶ä»£çš„ç‰¹ç‚¹**ï¼šå„è·¯ç®—æ³•å°æ‰“å°é—¹ï¼Œè§£å†³å±€éƒ¨é—®é¢˜ï¼Œä½†ç¼ºä¹ç»Ÿä¸€çš„æ¶æ„ã€‚å°±åƒä¸‰å›½å‰çš„ç¾¤é›„å‰²æ®ï¼Œè™½ç„¶ç™¾èŠ±é½æ”¾ï¼Œä½†åŠ›é‡åˆ†æ•£ã€‚

## âš¡ ç¬¬äºŒå¹•ï¼šå¤©ä¸‹ä¸‰åˆ†å‰å¤œï¼ˆ2017-2018ï¼‰  
**å…³é”®äººç‰©ï¼šTransformerï¼ˆè¯¸è‘›äº®ï¼‰**

2017å¹´ï¼Œä¸€ç¯‡åä¸ºã€ŠAttention is All You Needã€‹çš„è®ºæ–‡æ¨ªç©ºå‡ºä¸–ï¼Œå°±åƒè¯¸è‘›äº®çš„ã€Šå‡ºå¸ˆè¡¨ã€‹ï¼Œå½»åº•æ”¹å†™äº†AIæ±Ÿæ¹–çš„æ¸¸æˆè§„åˆ™ã€‚

```python
class AttentionRevolution:
    """
    æ³¨æ„åŠ›æœºåˆ¶çš„é©å‘½
    å°±åƒè¯¸è‘›äº®çš„å…«å¦é˜µï¼Œèƒ½åŒæ—¶å…³æ³¨å…¨å±€
    """
    def __init__(self):
        self.æ ¸å¿ƒåˆ›æ–° = [
            "è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼šè®©æ¯ä¸ªè¯éƒ½èƒ½'çœ‹åˆ°'æ‰€æœ‰å…¶ä»–è¯",
            "å¤šå¤´æ³¨æ„åŠ›ï¼šä»ä¸åŒè§’åº¦ç†è§£è¯­è¨€",
            "å¹¶è¡Œè®¡ç®—ï¼šå‘Šåˆ«RNNçš„ä¸²è¡Œé™åˆ¶",
            "ä½ç½®ç¼–ç ï¼šåœ¨å¹¶è¡Œä¸­ä¿æŒåºåˆ—ä¿¡æ¯"
        ]
    
    def why_revolutionary(self):
        """ä¸ºä»€ä¹ˆTransformeræ˜¯é©å‘½æ€§çš„ï¼Ÿ"""
        old_way = "RNN: åªèƒ½çœ‹å‰é¢å‡ ä¸ªè¯ï¼Œä¸²è¡Œè®¡ç®—æ…¢"
        new_way = "Transformer: å…¨å±€è§†é‡ï¼Œå¹¶è¡Œè®¡ç®—å¿«"
        
        return f"ä» {old_way} åˆ° {new_way}"
```

**BERTçš„å´›èµ·**ï¼š2018å¹´ï¼Œè°·æ­ŒåŸºäºTransformeræ¨å‡ºBERTï¼Œå°±åƒè¯¸è‘›äº®è¾…ä½åˆ˜å¤‡å»ºç«‹èœ€æ±‰ã€‚BERTç”¨"é®è”½è¯­è¨€æ¨¡å‹"çš„è®­ç»ƒæ–¹å¼ï¼Œè®©æœºå™¨çœŸæ­£å­¦ä¼šäº†"ä¸Šä¸‹æ–‡ç†è§£"ã€‚

## ğŸ›ï¸ ç¬¬ä¸‰å¹•ï¼šä¸‰å›½é¼ç«‹æ—¶ä»£ï¼ˆ2018-è‡³ä»Šï¼‰
**å¤©ä¸‹ä¸‰åˆ†ï¼šGPTç³»ï¼ˆæ›¹é­ï¼‰ã€BERTç³»ï¼ˆèœ€æ±‰ï¼‰ã€å¼€æºè”ç›Ÿï¼ˆä¸œå´ï¼‰**

### ğŸ”¸ æ›¹é­é˜µè¥ï¼šGPTç‹æœ
**ä»£è¡¨äººç‰©ï¼šGPTç³»åˆ—ï¼ˆæ›¹æ“çˆ¶å­ï¼‰**

OpenAIçš„GPTç³»åˆ—å°±åƒæ›¹æ“â€”â€”é‡å¿ƒå‹ƒå‹ƒï¼Œå®åŠ›å¼ºå¤§ï¼Œå¿—åœ¨ç»Ÿä¸€å¤©ä¸‹ã€‚

```python
class GPTDynasty:
    """GPTç‹æœçš„å‘å±•å²"""
    def __init__(self):
        self.rulers = {
            "GPT-1": "å¼€å›½çš‡å¸ï¼Œè¯æ˜äº†ç”Ÿæˆå¼é¢„è®­ç»ƒçš„å¯è¡Œæ€§",
            "GPT-2": "æ–‡å¸æ›¹ä¸•ï¼Œå±•ç¤ºäº†è§„æ¨¡çš„åŠ›é‡ï¼ˆ15äº¿å‚æ•°ï¼‰",
            "GPT-3": "æ­¦å¸æ›¹å¡ï¼Œéœ‡æƒŠä¸–ç•Œï¼ˆ1750äº¿å‚æ•°ï¼‰",
            "ChatGPT": "æ˜­çƒˆå¸ï¼Œè®©AIèµ°å‘æ°‘é—´",
            "GPT-4": "å½“ä»Šåœ£ä¸Šï¼Œå¤šæ¨¡æ€ç»Ÿä¸€æ±Ÿæ¹–"
        }
    
    def core_philosophy(self):
        """GPTçš„æ ¸å¿ƒç†å¿µ"""
        return """
        åªç”¨Decoderï¼Œä¸“æ³¨ç”Ÿæˆ
        å¤§åŠ›å‡ºå¥‡è¿¹ï¼šå‚æ•°è¶Šå¤šè¶Šå¼º
        è‡ªå›å½’ï¼šä¸€ä¸ªè¯ä¸€ä¸ªè¯åœ°ç”Ÿæˆ
        ç®€å•å°±æ˜¯ç¾ï¼šæ¶æ„ç®€æ´ä½†æœ‰æ•ˆ
        """
```

**GPTçš„ç§°éœ¸ä¹‹è·¯**ï¼š
- GPT â†’ GPT-2 â†’ GPT-3ï¼šå‚æ•°è§„æ¨¡æŒ‡æ•°çº§å¢é•¿
- ChatGPTï¼šåŠ å…¥äººç±»åé¦ˆï¼Œå­¦ä¼šå¯¹è¯
- GPT-4ï¼šå¤šæ¨¡æ€èƒ½åŠ›ï¼Œå›¾æ–‡å¹¶èŒ‚

### ğŸ”¹ èœ€æ±‰é˜µè¥ï¼šBERTè”ç›Ÿ
**ä»£è¡¨äººç‰©ï¼šBERTåŠå…¶å˜ä½“ï¼ˆåˆ˜å¤‡é›†å›¢ï¼‰**

BERTå°±åƒåˆ˜å¤‡â€”â€”ä»¥ä»ä¹‰è‘—ç§°ï¼Œä¸“æ³¨ç†è§£ï¼Œæ·±å¾—å­¦æœ¯ç•Œäººå¿ƒã€‚

```python
class BERTAlliance:
    """BERTè”ç›Ÿçš„ç‰¹è‰²"""
    def __init__(self):
        self.members = {
            "BERT": "å¼€å›½å›ä¸»ï¼ŒåŒå‘ç†è§£çš„å…ˆé©±",
            "RoBERTa": "å…³ç¾½ï¼Œä¼˜åŒ–è®­ç»ƒç­–ç•¥çš„çŒ›å°†",
            "ALBERT": "å¼ é£ï¼Œå‚æ•°å…±äº«çš„å‹‡å£«", 
            "DeBERTa": "è¯¸è‘›äº®ï¼Œè§£è€¦æ³¨æ„åŠ›çš„å†›å¸ˆ",
            "ELECTRA": "èµµäº‘ï¼Œåˆ¤åˆ«å¼è®­ç»ƒçš„å°‘å¹´è‹±é›„"
        }
    
    def core_strength(self):
        """BERTç³»çš„æ ¸å¿ƒä¼˜åŠ¿"""
        return """
        Encoder-onlyæ¶æ„ï¼Œä¸“ç²¾ç†è§£ä»»åŠ¡
        æ©ç è¯­è¨€æ¨¡å‹ï¼šå­¦ä¼šåŒå‘ç†è§£
        åœ¨ç†è§£ç±»ä»»åŠ¡ä¸Šè¡¨ç°å“è¶Š
        å­¦æœ¯ç•Œæœ€çˆ±ï¼Œè®ºæ–‡å¼•ç”¨æ— æ•°
        """
```

### ğŸ”º ä¸œå´é˜µè¥ï¼šå¼€æºè”ç›Ÿ
**ä»£è¡¨äººç‰©ï¼šå„è·¯å¼€æºè‹±é›„ï¼ˆå­™æƒè”ç›Ÿï¼‰**

å¼€æºæ¨¡å‹å°±åƒä¸œå´â€”â€”å–„äºè”åˆï¼Œå€ŸåŠ›æ‰“åŠ›ï¼Œä»¥å°åšå¤§ã€‚

```python
class OpenSourceAlliance:
    """å¼€æºè”ç›Ÿçš„è‹±é›„è°±"""
    def __init__(self):
        self.heroes = {
            "T5": "å­™æƒï¼Œç»Ÿä¸€æ ¼å¼çš„è‹±ä¸»ï¼ˆText-to-Textï¼‰",
            "LLaMA": "å‘¨ç‘œï¼ŒMetaçš„æ°ä½œï¼Œå¼€æºç•Œçš„ç¾ç”·å­",
            "Alpaca": "é™†é€Šï¼Œæ–¯å¦ç¦çš„åèµ·ä¹‹ç§€", 
            "Vicuna": "å¤ªå²æ…ˆï¼ŒåŠ å·å¤§å­¦çš„éªå°†",
            "åƒé—®Qwen": "ç”˜å®ï¼Œé˜¿é‡Œçš„é”¦å¸†è´¼",
            "ChatGLM": "å‡Œç»Ÿï¼Œæ¸…åçš„å­¦é™¢æ´¾",
            "Mistral": "å•è’™ï¼Œæ¬§æ´²çš„å¥‡å…µ"
        }
    
    def strategy(self):
        """å¼€æºè”ç›Ÿçš„æˆ˜ç•¥"""
        return """
        ç”¨å¼€æºå¯¹æŠ—é—­æºå„æ–­
        è½»é‡åŒ–æ¨¡å‹ï¼Œé™ä½ä½¿ç”¨é—¨æ§›  
        ç¤¾åŒºé©±åŠ¨ï¼Œç™¾èŠ±é½æ”¾
        äº§å­¦ç ”ç»“åˆï¼Œæ¨åŠ¨åˆ›æ–°
        """
```

## ğŸ”¥ èµ¤å£ä¹‹æˆ˜ï¼šScaling Lawä¹‹äº‰

å°±åƒå†å²ä¸Šçš„èµ¤å£ä¹‹æˆ˜ï¼ŒAIç•Œä¹Ÿæœ‰è‡ªå·±çš„"èµ¤å£ä¹‹æˆ˜"â€”â€”å…³äºScaling Lawï¼ˆè§„æ¨¡å®šå¾‹ï¼‰çš„å¤§è¾©è®ºï¼š

```python
class ScalingWarDebate:
    """è§„æ¨¡å®šå¾‹å¤§è¾©è®º"""
    def __init__(self):
        self.camps = {
            "è§„æ¨¡æ´¾ï¼ˆæ›¹æ“ï¼‰": {
                "è§‚ç‚¹": "å¤§åŠ›å‡ºå¥‡è¿¹ï¼Œå‚æ•°è¶Šå¤šæ€§èƒ½è¶Šå¼º",
                "è¯æ®": "GPT-3çš„1750äº¿å‚æ•°å¸¦æ¥è´¨çš„é£è·ƒ",
                "ç­–ç•¥": "ä¸æ–­å¢å¤§æ¨¡å‹è§„æ¨¡"
            },
            
            "æ•ˆç‡æ´¾ï¼ˆå‘¨ç‘œï¼‰": {
                "è§‚ç‚¹": "æ•ˆç‡ä¼˜äºè§„æ¨¡ï¼Œå°æ¨¡å‹ä¹Ÿèƒ½åšå¤§äº‹", 
                "è¯æ®": "Phiã€Gemmaç­‰å°æ¨¡å‹è¡¨ç°ä¼˜å¼‚",
                "ç­–ç•¥": "ä¼˜åŒ–è®­ç»ƒæ–¹æ³•ï¼Œæå‡æ•°æ®è´¨é‡"
            },
            
            "å¤šæ ·åŒ–æ´¾ï¼ˆå­™æƒï¼‰": {
                "è§‚ç‚¹": "ç™¾èŠ±é½æ”¾ï¼Œä¸åŒåœºæ™¯éœ€è¦ä¸åŒæ¨¡å‹",
                "è¯æ®": "MoEã€ç¨€ç–æ¿€æ´»ç­‰æ–°æ¶æ„",
                "ç­–ç•¥": "æ¢ç´¢æ–°çš„æ¨¡å‹æ¶æ„"
            }
        }
```

## ğŸ­ å½“å‰æˆ˜å±€ï¼š2024å¹´çš„"ä¸‰å›½"æ ¼å±€

**é—­æºä¸‰å·¨å¤´**ï¼š
- OpenAIï¼ˆGPTç³»ï¼‰ï¼šç”Ÿæˆèƒ½åŠ›æœ€å¼ºï¼Œå•†ä¸šåŒ–é¢†å…ˆ
- Googleï¼ˆGeminiï¼‰ï¼šæœç´¢+AIçš„ç»„åˆæ‹³
- Anthropicï¼ˆClaudeï¼‰ï¼šå®‰å…¨å¯¹é½çš„æ ‡æ†

**å¼€æºå››å¤§å®¶æ—**ï¼š
- DeepSeekï¼šç›®å‰å¼€æ”¾ç”Ÿæ€çš„é¢†å¯¼è€…ï¼Œé—­æºç”Ÿæ€çš„æŒ‘æˆ˜è€…ã€‚
- Metaï¼ˆLLaMAç³»ï¼‰ï¼šæ›¾ç»å¼€æ”¾ç”Ÿæ€çš„é¢†å¯¼è€…
- é˜¿é‡Œï¼ˆåƒé—®ç³»ï¼‰ï¼šå¼€æ”¾ç”Ÿæ€çš„æ–°æ˜Ÿ
- æ™ºè°±ï¼ˆChatGLMç³»ï¼‰ï¼šå­¦æœ¯ç•Œçš„å® å„¿  

```python
def current_battle_field():
    """2024å¹´çš„AIæˆ˜åœº"""
    metrics = {
        "æ¨¡å‹è§„æ¨¡ç«èµ›": "ä»åƒäº¿åˆ°ä¸‡äº¿å‚æ•°",
        "æ¨ç†é€Ÿåº¦ä¼˜åŒ–": "ä»ç§’çº§åˆ°æ¯«ç§’çº§å“åº”", 
        "æˆæœ¬æ§åˆ¶": "ä»å¤©ä»·åˆ°å¹³æ°‘åŒ–",
        "å¤šæ¨¡æ€èåˆ": "ä»å•ä¸€åˆ°å…¨èƒ½",
        "é¢†åŸŸä¸“ä¸šåŒ–": "ä»é€šæ‰åˆ°ä¸“å®¶"
    }
    
    new_frontiers = [
        "Agentèƒ½åŠ›ï¼šä»å¯¹è¯åˆ°è¡ŒåŠ¨",
        "é•¿ä¸Šä¸‹æ–‡ï¼šä»4Kåˆ°100ä¸‡token",
        "MoEæ¶æ„ï¼šä¸“å®¶æ··åˆçš„æ™ºæ…§",
        "ç«¯ä¾§éƒ¨ç½²ï¼šä»äº‘ç«¯åˆ°æ‰‹æœº"
    ]
    
    return metrics, new_frontiers
```

## ğŸ”® æœªæ¥å±•æœ›ï¼šè°å°†ç»Ÿä¸€"AIå¤©ä¸‹"ï¼Ÿ

å†å²å‘Šè¯‰æˆ‘ä»¬ï¼ŒçœŸæ­£çš„ç»Ÿä¸€å¾€å¾€æ¥è‡ªæ„æƒ³ä¸åˆ°çš„æ–¹å‘ã€‚ä¹Ÿè®¸æœªæ¥çš„"å¸é©¬æ‡¿"æ­£åœ¨æŸä¸ªå®éªŒå®¤é‡Œé…é…¿ç€ä¸‹ä¸€åœºé©å‘½ï¼š

**å¯èƒ½çš„å˜é©æ–¹å‘**ï¼š
1. **æ–°æ¶æ„çªç ´**ï¼šMambaã€RWKVç­‰æŒ‘æˆ˜Transformer
2. **å¤šæ¨¡æ€èåˆ**ï¼šçœŸæ­£çš„é€šç”¨äººå·¥æ™ºèƒ½
3. **ç¥ç»ç¬¦å·ç»“åˆ**ï¼šé€»è¾‘æ¨ç†+æ·±åº¦å­¦ä¹ 
4. **é‡å­è®¡ç®—åŠ æŒ**ï¼šç®—åŠ›çš„æŒ‡æ•°çº§æå‡

**ä¸å˜çš„çœŸç†**ï¼š
- æ•°æ®æ˜¯ç‡ƒæ–™ï¼Œç®—æ³•æ˜¯å¼•æ“
- ç†è§£æ¯”ç”Ÿæˆæ›´éš¾ï¼Œæ¨ç†æ¯”è®°å¿†æ›´é‡è¦
- æœ€ç»ˆèƒœåˆ©è€…ä¸æ˜¯æœ€å¼ºçš„ï¼Œè€Œæ˜¯æœ€é€‚åº”çš„

## ğŸ“š æœ¬èŠ‚å¯ç¤º

è¿™åœºAIç‰ˆ"ä¸‰å›½æ¼”ä¹‰"å‘Šè¯‰æˆ‘ä»¬ï¼š

1. **æŠ€æœ¯å‘å±•çš„èºæ—‹å¼ä¸Šå‡**ï¼šä»ç»Ÿè®¡åˆ°ç¥ç»ç½‘ç»œï¼Œå†åˆ°å¤§æ¨¡å‹
2. **æ¶æ„åˆ›æ–°çš„é‡è¦æ€§**ï¼šTransformeræ”¹å˜ä¸€åˆ‡
3. **è§„æ¨¡ä¸æ•ˆç‡çš„å¹³è¡¡**ï¼šä¸æ˜¯è¶Šå¤§è¶Šå¥½ï¼Œè€Œæ˜¯è¶Šåˆé€‚è¶Šå¥½
4. **å¼€æºvsé—­æºçš„åšå¼ˆ**ï¼šæ¨åŠ¨æ•´ä¸ªè¡Œä¸šçš„è¿›æ­¥
5. **åº”ç”¨åœºæ™¯çš„å¤šå…ƒåŒ–**ï¼šä¸åŒçš„æ¨¡å‹é€‚åˆä¸åŒçš„ä»»åŠ¡

æ­£å¦‚ã€Šä¸‰å›½æ¼”ä¹‰ã€‹çš„å¼€ç¯‡æ‰€è¨€ï¼š"å¤©ä¸‹å¤§åŠ¿ï¼Œåˆ†ä¹…å¿…åˆï¼Œåˆä¹…å¿…åˆ†ã€‚"AIçš„ä¸–ç•Œä¹Ÿåœ¨ä¸æ–­åˆ†åŒ–ä¸æ•´åˆä¸­å‰è¿›ï¼Œè€Œæˆ‘ä»¬ï¼Œæ­£å¤„åœ¨è¿™ä¸ªæ¿€åŠ¨äººå¿ƒçš„æ—¶ä»£ï¼

äº†è§£äº†AIçš„å‘å±•å†ç¨‹ï¼Œç›¸ä¿¡ä½ å·²ç»å¯¹è¿™ä¸ªé¢†åŸŸæœ‰äº†åˆæ­¥çš„è®¤è¯†ã€‚æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å¸¦ç€è¿™ä»½å¯¹å†å²çš„ç†è§£ï¼Œä¸€èµ·æ·±å…¥æ¢ç´¢AIæŠ€æœ¯çš„æ ¸å¿ƒçŸ¥è¯†ã€‚

## ğŸ“‘ ç›®å½•ï¼ˆåŸºäºç¬¬ä¸€æ€§åŸç†é‡æ–°æ•´ç†ï¼‰

### ç¬¬ä¸€éƒ¨åˆ†ï¼šè¯­è¨€ä¸è®¡ç®—çš„ç¬¬ä¸€æ€§åŸç†ï¼ˆç¬¬1-12ç« ï¼‰

#### ç¬¬1ç« ï¼šè¯­è¨€çš„æœ¬è´¨â€”â€”ä»äººç±»è¯­è¨€åˆ°æœºå™¨è¯­è¨€
#### ç¬¬2ç« ï¼šæ¦‚ç‡ä¸è¯­è¨€â€”â€”ä¸ºä»€ä¹ˆLLMæœ¬è´¨ä¸Šæ˜¯æ¦‚ç‡æ¨¡å‹ï¼Ÿ
#### ç¬¬3ç« ï¼šç¥ç»ç½‘ç»œåŸºç¡€â€”â€”ä»æ„ŸçŸ¥æœºåˆ°æ·±åº¦å­¦ä¹ 
#### ç¬¬4ç« ï¼šæ¢¯åº¦ä¸‹é™â€”â€”AIæ˜¯å¦‚ä½•å­¦ä¹ çš„ï¼Ÿ
#### ç¬¬5ç« ï¼šåå‘ä¼ æ’­â€”â€”è®©AIçŸ¥é”™å°±æ”¹çš„é­”æ³•
#### ç¬¬6ç« ï¼šæŸå¤±å‡½æ•°â€”â€”å¦‚ä½•è¡¡é‡AIçš„è¡¨ç°ï¼Ÿ
#### ç¬¬7ç« ï¼šä¼˜åŒ–å™¨â€”â€”Adamä¸ºä»€ä¹ˆè¿™ä¹ˆæµè¡Œï¼Ÿ
#### ç¬¬8ç« ï¼šè¿‡æ‹Ÿåˆä¸æ­£åˆ™åŒ–â€”â€”è®©AIå­¦ä¼šä¸¾ä¸€åä¸‰
#### ç¬¬9ç« ï¼šBatchå¤„ç†ä¸Paddingâ€”â€”ä¸ºä»€ä¹ˆè¦æŠŠæ•°æ®æ‰“åŒ…ï¼Ÿ
#### ç¬¬10ç« ï¼šå¹¶è¡Œè®¡ç®—åŸºç¡€â€”â€”GPUä¸ºä»€ä¹ˆé€‚åˆè®­ç»ƒAIï¼Ÿ
#### ç¬¬11ç« ï¼šè‡ªåŠ¨å¾®åˆ†â€”â€”è®©æ¢¯åº¦è®¡ç®—å˜å¾—ç®€å•
#### ç¬¬12ç« ï¼šä»ç»Ÿè®¡è¯­è¨€æ¨¡å‹åˆ°ç¥ç»è¯­è¨€æ¨¡å‹

### ç¬¬äºŒéƒ¨åˆ†ï¼šè¯­è¨€çš„è¡¨ç¤ºä¸ç¼–ç ï¼ˆç¬¬13-20ç« ï¼‰

#### ç¬¬13ç« ï¼šTokenizationâ€”â€”å¦‚ä½•æŠŠæ–‡å­—åˆ‡æˆç§¯æœ¨ï¼Ÿ
#### ç¬¬14ç« ï¼šè¯è¡¨è®¾è®¡â€”â€”BPEã€WordPieceå’ŒSentencePiece
#### ç¬¬15ç« ï¼šEmbeddingåŸºç¡€â€”â€”ç»™è¯è¯­è´´ä¸Šå¤šç»´æ ‡ç­¾
#### ç¬¬16ç« ï¼šWord2Vecâ€”â€”è¯å‘é‡çš„å¼€å±±ä¹‹ä½œ
#### ç¬¬17ç« ï¼šä½ç½®ç¼–ç â€”â€”è®©AIç†è§£è¯è¯­çš„é¡ºåº
#### ç¬¬18ç« ï¼šä¸Šä¸‹æ–‡è¡¨ç¤ºâ€”â€”ä¸ºä»€ä¹ˆBERTçš„Embeddingæ›´èªæ˜ï¼Ÿ
#### ç¬¬19ç« ï¼šå¤šè¯­è¨€è¡¨ç¤ºâ€”â€”ä¸åŒè¯­è¨€å¦‚ä½•å…±äº«è¯å‘é‡ç©ºé—´ï¼Ÿ
#### ç¬¬20ç« ï¼šEmbeddingçš„æ•°å­¦æœ¬è´¨â€”â€”ä»ç¨€ç–åˆ°ç¨ å¯†

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šç†è§£è¯­è¨€çš„æ ¸å¿ƒæœºåˆ¶ï¼ˆç¬¬21-35ç« ï¼‰

#### ç¬¬21ç« ï¼šæ³¨æ„åŠ›æœºåˆ¶â€”â€”è®©AIå­¦ä¼š"ä¸“æ³¨"
#### ç¬¬22ç« ï¼šè‡ªæ³¨æ„åŠ›â€”â€”"æˆ‘æ€æ•…æˆ‘åœ¨"çš„AIç‰ˆæœ¬
#### ç¬¬23ç« ï¼šå¤šå¤´æ³¨æ„åŠ›â€”â€”ä»ä¸åŒè§’åº¦ç†è§£è¯­è¨€
#### ç¬¬24ç« ï¼šTransformeræ¶æ„â€”â€”æ”¹å˜ä¸€åˆ‡çš„åˆ›æ–°
#### ç¬¬25ç« ï¼šEncoderè¯¦è§£â€”â€”ç†è§£è¾“å…¥çš„ä¸“å®¶
#### ç¬¬26ç« ï¼šDecoderè¯¦è§£â€”â€”ç”Ÿæˆè¾“å‡ºçš„é­”æœ¯å¸ˆ
#### ç¬¬27ç« ï¼šEncoder-Decoderâ€”â€”ç¿»è¯‘ä»»åŠ¡çš„é»„é‡‘æ­æ¡£
#### ç¬¬28ç« ï¼šLayer Normalizationâ€”â€”ä¿æŒè®­ç»ƒç¨³å®šçš„ç§˜è¯€
#### ç¬¬29ç« ï¼šæ®‹å·®è¿æ¥â€”â€”è®©æ·±å±‚ç½‘ç»œæˆä¸ºå¯èƒ½
#### ç¬¬30ç« ï¼šå‰é¦ˆç½‘ç»œâ€”â€”Transformerä¸­çš„"æ€è€ƒ"æ¨¡å—
#### ç¬¬31ç« ï¼šä¸ºä»€ä¹ˆTransformeræ¯”RNNæ›´å¼ºå¤§ï¼Ÿ
#### ç¬¬32ç« ï¼šæ³¨æ„åŠ›å¯è§†åŒ–â€”â€”çœ‹çœ‹AIåœ¨å…³æ³¨ä»€ä¹ˆ
#### ç¬¬33ç« ï¼šä½ç½®ç¼–ç çš„å„ç§å˜ä½“â€”â€”ç»å¯¹ä½ç½®vsç›¸å¯¹ä½ç½®
#### ç¬¬34ç« ï¼šTransformerçš„è®¡ç®—å¤æ‚åº¦åˆ†æ
#### ç¬¬35ç« ï¼šé•¿åºåˆ—å¤„ç†â€”â€”çªç ´ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶

### ç¬¬å››éƒ¨åˆ†ï¼šè¯­è¨€æ¨¡å‹çš„æ¼”è¿›å²ï¼ˆç¬¬36-50ç« ï¼‰

#### ç¬¬36ç« ï¼šä»N-gramåˆ°ç¥ç»ç½‘ç»œâ€”â€”è¯­è¨€æ¨¡å‹ç®€å²
#### ç¬¬37ç« ï¼šRNNå®¶æ—â€”â€”LSTMå’ŒGRUçš„å…´è¡°
#### ç¬¬38ç« ï¼šSeq2Seqâ€”â€”æœºå™¨ç¿»è¯‘çš„é‡Œç¨‹ç¢‘
#### ç¬¬39ç« ï¼šGPTçš„è¯ç”Ÿâ€”â€”è‡ªå›å½’è¯­è¨€æ¨¡å‹
#### ç¬¬40ç« ï¼šBERTæ¨ªç©ºå‡ºä¸–â€”â€”åŒå‘ç†è§£çš„é©å‘½
#### ç¬¬41ç« ï¼šGPT-2â€”â€”è¯æ˜è§„æ¨¡çš„åŠ›é‡
#### ç¬¬42ç« ï¼šT5â€”â€”ç»Ÿä¸€çš„æ–‡æœ¬åˆ°æ–‡æœ¬æ¡†æ¶
#### ç¬¬43ç« ï¼šGPT-3â€”â€”å¤§åŠ›å‡ºå¥‡è¿¹
#### ç¬¬44ç« ï¼šChatGPTâ€”â€”å¯¹è¯å¼AIçš„çªç ´
#### ç¬¬45ç« ï¼šGPT-4â€”â€”å¤šæ¨¡æ€çš„æ–°çºªå…ƒ
#### ç¬¬46ç« ï¼šå¼€æºæ¨¡å‹çš„å´›èµ·â€”â€”LLaMAã€Mistralã€Qwen
#### ç¬¬47ç« ï¼šä¸­æ–‡å¤§æ¨¡å‹â€”â€”æ–‡å¿ƒã€é€šä¹‰ã€æ™ºè°±
#### ç¬¬48ç« ï¼šä¸“ä¸šé¢†åŸŸæ¨¡å‹â€”â€”åŒ»ç–—ã€æ³•å¾‹ã€é‡‘è
#### ç¬¬49ç« ï¼šå°æ¨¡å‹çš„é€†è¢­â€”â€”Phiã€Gemmaç­‰
#### ç¬¬50ç« ï¼šæ¨¡å‹æ¶æ„çš„åˆ›æ–°â€”â€”Mambaã€RWKVç­‰

### ç¬¬äº”éƒ¨åˆ†ï¼šè®­ç»ƒçš„è‰ºæœ¯ä¸ç§‘å­¦ï¼ˆç¬¬51-70ç« ï¼‰

#### ç¬¬51ç« ï¼šé¢„è®­ç»ƒâ€”â€”è®©AIè¯»éå¤©ä¸‹ä¹¦
#### ç¬¬52ç« ï¼šæ•°æ®çš„é‡è¦æ€§â€”â€”åƒåœ¾è¿›ï¼Œåƒåœ¾å‡º
#### ç¬¬53ç« ï¼šè®­ç»ƒç›®æ ‡â€”â€”MLMã€CLMå’Œæ›´å¤š
#### ç¬¬54ç« ï¼šå¾®è°ƒæŠ€æœ¯â€”â€”è®©é€šç”¨æ¨¡å‹å˜ä¸“ä¸š
#### ç¬¬55ç« ï¼šLoRAâ€”â€”å‚æ•°é«˜æ•ˆå¾®è°ƒçš„æ°ä½œ
#### ç¬¬56ç« ï¼šQLoRAâ€”â€”è®©å¾®è°ƒæ›´çœèµ„æº
#### ç¬¬57ç« ï¼šæŒ‡ä»¤å¾®è°ƒâ€”â€”è®©AIå¬æ‡‚äººè¯
#### ç¬¬58ç« ï¼šRLHFåŸºç¡€â€”â€”ç”¨äººç±»åé¦ˆè®­ç»ƒAI
#### ç¬¬59ç« ï¼šPPOç®—æ³•â€”â€”å¼ºåŒ–å­¦ä¹ åœ¨LLMä¸­çš„åº”ç”¨
#### ç¬¬60ç« ï¼šDPOâ€”â€”ç›´æ¥åå¥½ä¼˜åŒ–
#### ç¬¬61ç« ï¼šConstitutional AIâ€”â€”è®©AIå­¦ä¼šè‡ªæˆ‘çº¦æŸ
#### ç¬¬62ç« ï¼šæ•°æ®å¹¶è¡Œâ€”â€”å¤šå¡è®­ç»ƒçš„åŸºç¡€
#### ç¬¬63ç« ï¼šæ¨¡å‹å¹¶è¡Œâ€”â€”è®­ç»ƒè¶…å¤§æ¨¡å‹çš„å…³é”®
#### ç¬¬64ç« ï¼šZeROä¼˜åŒ–â€”â€”å†…å­˜æ•ˆç‡çš„æè‡´è¿½æ±‚
#### ç¬¬65ç« ï¼šæ¢¯åº¦ç´¯ç§¯ä¸æ£€æŸ¥ç‚¹â€”â€”ç”¨æ—¶é—´æ¢ç©ºé—´
#### ç¬¬66ç« ï¼šæ··åˆç²¾åº¦è®­ç»ƒâ€”â€”FP16/BF16çš„ä½¿ç”¨
#### ç¬¬67ç« ï¼šè®­ç»ƒçš„ç¨³å®šæ€§â€”â€”æ¢¯åº¦çˆ†ç‚¸å’Œæ¶ˆå¤±
#### ç¬¬68ç« ï¼šå­¦ä¹ ç‡è°ƒåº¦â€”â€”è®­ç»ƒçš„èŠ‚å¥å¤§å¸ˆ
#### ç¬¬69ç« ï¼šè¯„ä¼°æŒ‡æ ‡â€”â€”å¦‚ä½•è¡¡é‡æ¨¡å‹å¥½åï¼Ÿ
#### ç¬¬70ç« ï¼šè®­ç»ƒæˆæœ¬ä¼°ç®—â€”â€”ç®—åŠ›ã€æ—¶é—´å’Œé‡‘é’±

### ç¬¬å…­éƒ¨åˆ†ï¼šå·¥ç¨‹åŒ–ä¸éƒ¨ç½²å®è·µï¼ˆç¬¬71-90ç« ï¼‰

#### ç¬¬71ç« ï¼šæ¨¡å‹é‡åŒ–â€”â€”INT8/INT4é‡åŒ–æŠ€æœ¯
#### ç¬¬72ç« ï¼šçŸ¥è¯†è’¸é¦â€”â€”è®©å°æ¨¡å‹å­¦ä¹ å¤§æ¨¡å‹
#### ç¬¬73ç« ï¼šæ¨ç†ä¼˜åŒ–â€”â€”vLLMåŸç†ä¸å®è·µ
#### ç¬¬74ç« ï¼šKV Cacheâ€”â€”åŠ é€Ÿè‡ªå›å½’ç”Ÿæˆ
#### ç¬¬75ç« ï¼šFlash Attentionâ€”â€”æ³¨æ„åŠ›è®¡ç®—çš„é©å‘½
#### ç¬¬76ç« ï¼šContinuous Batchingâ€”â€”æé«˜ååé‡
#### ç¬¬77ç« ï¼šæ¨¡å‹å‹ç¼©â€”â€”å‰ªæã€é‡åŒ–ã€è’¸é¦
#### ç¬¬78ç« ï¼šONNXâ€”â€”æ¨¡å‹çš„é€šç”¨æ ¼å¼
#### ç¬¬79ç« ï¼šTensorRTâ€”â€”NVIDIAçš„æ¨ç†åŠ é€Ÿå™¨
#### ç¬¬80ç« ï¼šTritonâ€”â€”ç®€åŒ–GPUç¼–ç¨‹
#### ç¬¬81ç« ï¼šæ¨¡å‹æœåŠ¡åŒ–â€”â€”ä»æ¨¡å‹åˆ°API
#### ç¬¬82ç« ï¼šè´Ÿè½½å‡è¡¡â€”â€”åº”å¯¹é«˜å¹¶å‘è¯·æ±‚
#### ç¬¬83ç« ï¼šA/Bæµ‹è¯•â€”â€”æ¨¡å‹æ•ˆæœè¯„ä¼°
#### ç¬¬84ç« ï¼šç›‘æ§ä¸æ—¥å¿—â€”â€”ä¿éšœæœåŠ¡ç¨³å®š
#### ç¬¬85ç« ï¼šæˆæœ¬ä¼˜åŒ–â€”â€”çœé’±å°±æ˜¯èµšé’±
#### ç¬¬86ç« ï¼šè¾¹ç¼˜éƒ¨ç½²â€”â€”è®©AIè·‘åœ¨æ‰‹æœºä¸Š
#### ç¬¬87ç« ï¼šå®‰å…¨ä¸éšç§â€”â€”ä¿æŠ¤ç”¨æˆ·æ•°æ®
#### ç¬¬88ç« ï¼šæç¤ºå·¥ç¨‹â€”â€”å¦‚ä½•å’ŒAIå¯¹è¯ï¼Ÿ
#### ç¬¬89ç« ï¼šRAGåŸºç¡€â€”â€”æ£€ç´¢å¢å¼ºç”Ÿæˆ
#### ç¬¬90ç« ï¼šå‘é‡æ•°æ®åº“â€”â€”RAGçš„æ ¸å¿ƒç»„ä»¶

### ç¬¬ä¸ƒéƒ¨åˆ†ï¼šå¤šæ¨¡æ€ä¸è·¨ç•Œèåˆï¼ˆç¬¬91-105ç« ï¼‰

#### ç¬¬91ç« ï¼šå¤šæ¨¡æ€åŸºç¡€â€”â€”æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘çš„ç»Ÿä¸€
#### ç¬¬92ç« ï¼šVision Transformerâ€”â€”ç”¨Transformerå¤„ç†å›¾åƒ
#### ç¬¬93ç« ï¼šCLIPåŸç†â€”â€”è¿æ¥æ–‡æœ¬å’Œå›¾åƒ
#### ç¬¬94ç« ï¼šStable Diffusionâ€”â€”æ–‡ç”Ÿå›¾çš„é­”æ³•
#### ç¬¬95ç« ï¼šDALL-Eç³»åˆ—â€”â€”OpenAIçš„è§†è§‰åˆ›é€ åŠ›
#### ç¬¬96ç« ï¼šMidjourneyâ€”â€”è‰ºæœ¯åˆ›ä½œçš„æ–°å·¥å…·
#### ç¬¬97ç« ï¼šè§†é¢‘ç†è§£â€”â€”ä»å›¾åƒåˆ°åŠ¨æ€
#### ç¬¬98ç« ï¼šè¯­éŸ³è¯†åˆ«â€”â€”Whisperç­‰æ¨¡å‹
#### ç¬¬99ç« ï¼šè¯­éŸ³åˆæˆâ€”â€”è®©AIå¼€å£è¯´è¯
#### ç¬¬100ç« ï¼šéŸ³ä¹ç”Ÿæˆâ€”â€”AIä½œæ›²å®¶
#### ç¬¬101ç« ï¼š3Dç”Ÿæˆâ€”â€”ä»æ–‡æœ¬åˆ°ç«‹ä½“æ¨¡å‹
#### ç¬¬102ç« ï¼šå…·èº«æ™ºèƒ½â€”â€”AIä¸æœºå™¨äººçš„ç»“åˆ
#### ç¬¬103ç« ï¼šVQAâ€”â€”è§†è§‰é—®ç­”ç³»ç»Ÿ
#### ç¬¬104ç« ï¼šOCRä¸æ–‡æ¡£ç†è§£â€”â€”è®©AIè¯»æ‡‚æ–‡æ¡£
#### ç¬¬105ç« ï¼šå¤šæ¨¡æ€å¤§ä¸€ç»Ÿâ€”â€”GPT-4Vçš„å¯ç¤º

### ç¬¬å…«éƒ¨åˆ†ï¼šå‰æ²¿æ¢ç´¢ä¸æœªæ¥å±•æœ›ï¼ˆç¬¬106-120ç« ï¼‰

#### ç¬¬106ç« ï¼šAgentåŸºç¡€â€”â€”ä»å·¥å…·ä½¿ç”¨åˆ°è‡ªä¸»å†³ç­–
#### ç¬¬107ç« ï¼šFunction Callingâ€”â€”è®©AIè°ƒç”¨å¤–éƒ¨å·¥å…·
#### ç¬¬108ç« ï¼šMCPåè®®â€”â€”AIä¸å¤–ç•Œäº¤äº’çš„æ–°æ ‡å‡†
#### ç¬¬109ç« ï¼šLangChainâ€”â€”æ„å»ºAIåº”ç”¨çš„æ¡†æ¶
#### ç¬¬110ç« ï¼šAutoGPTâ€”â€”è‡ªä¸»AIçš„å°è¯•
#### ç¬¬111ç« ï¼šMoEæ¶æ„â€”â€”ä¸“å®¶æ··åˆæ¨¡å‹
#### ç¬¬112ç« ï¼šDeepSeekçš„åˆ›æ–°â€”â€”ç¨€ç–æ¿€æ´»çš„å¨åŠ›
#### ç¬¬113ç« ï¼šé•¿ä¸Šä¸‹æ–‡å¤„ç†â€”â€”ç™¾ä¸‡tokenä¸æ˜¯æ¢¦
#### ç¬¬114ç« ï¼šæ€ç»´é“¾â€”â€”è®©AIå±•ç¤ºæ¨ç†è¿‡ç¨‹
#### ç¬¬115ç« ï¼šå®ªæ³•AIâ€”â€”ä»·å€¼å¯¹é½çš„æ–°æ–¹æ³•
#### ç¬¬116ç« ï¼šå¯è§£é‡Šæ€§â€”â€”æ‰“å¼€AIçš„é»‘ç›’å­
#### ç¬¬117ç« ï¼šAIå®‰å…¨â€”â€”å¯¹é½ã€é²æ£’æ€§ä¸å¯æ§æ€§
#### ç¬¬118ç« ï¼šAGIä¹‹è·¯â€”â€”é€šç”¨äººå·¥æ™ºèƒ½çš„æŒ‘æˆ˜
#### ç¬¬119ç« ï¼šAIä¼¦ç†â€”â€”æŠ€æœ¯å‘å±•çš„è¾¹ç•Œ
#### ç¬¬120ç« ï¼šæœªæ¥å·²æ¥â€”â€”LLMå°†å¦‚ä½•æ”¹å˜ä¸–ç•Œ

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šè¯­è¨€ä¸è®¡ç®—çš„ç¬¬ä¸€æ€§åŸç†

### ç¬¬1ç« ï¼šè¯­è¨€çš„æœ¬è´¨â€”â€”ä»äººç±»è¯­è¨€åˆ°æœºå™¨è¯­è¨€

#### ğŸ¯ æœ¬ç« å¯¼è¯»

åœ¨å¼€å§‹æˆ‘ä»¬çš„LLMä¹‹æ—…å‰ï¼Œè®©æˆ‘ä»¬å…ˆæ€è€ƒä¸€ä¸ªæ ¹æœ¬é—®é¢˜ï¼šè¯­è¨€åˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿ

å½“ä½ å¼ å£æ¥ä¸€å¥ã€Œæˆ‘é¥¿äº†ã€ï¼Œå…¶å®å°±æ˜¯æŠŠè‚šå­é‡Œçš„é¦‹è™«è£…è¿›ä¸‰é¢—éŸ³èŠ‚çš„å°ç«ç®­ï¼Œå—–åœ°å°„å‘ç©ºæ°”ã€‚å£°æ³¢æˆ–é”®ç›˜ç”µä¿¡å·ä¸€è·¯è¹¦è·¶ï¼Œåˆ°è¾¾å¯¹æ–¹è€³æœµæˆ–å±å¹•åï¼Œè¢«å¤§è„‘ç¿»è¯‘æˆä¸€æ¡æ¸…æ™°æŒ‡ä»¤ï¼šæ‰“æ‰°äº†ï¼Œæˆ‘æœ‰ç‚¹é¥¿äº†ï¼Œå¯ä»¥ç»™æˆ‘åƒçš„å—ï¼Ÿ  


çŸ­çŸ­ä¸‰ä¸ªå­—ï¼Œå´èƒ½è®©å¯¹æ–¹ç§’æ‡‚ä½ çš„éœ€æ±‚ï¼Œè¿™å°±æ˜¯è¯­è¨€çš„é­”æœ¯ï¼šç”¨æœ‰é™çš„ç¬¦å·äº¤æ¢æ— é™çš„æ„æ€ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨ç»ƒä¹ çš„ï¼Œæ­£æ˜¯è¿™é—¨è®©æœºå™¨ä¹Ÿèƒ½å˜é­”æœ¯çš„æ‰‹è‰ºã€‚

#### ğŸ¤” è¯­è¨€çš„ä¸‰ä¸ªå±‚æ¬¡

##### 1. ç¬¦å·å±‚ï¼ˆSymbolic Levelï¼‰
è¿™æ˜¯è¯­è¨€æœ€è¡¨é¢çš„å±‚æ¬¡â€”â€”æˆ‘ä»¬çœ‹åˆ°çš„å­—ã€å¬åˆ°çš„éŸ³ã€‚

```python
# åŒæ ·çš„æ„æ€ï¼Œä¸åŒçš„ç¬¦å·
ä¸­æ–‡ = "æˆ‘çˆ±äººå·¥æ™ºèƒ½"
English = "I love AI"  
æ—¥æœ¬èª = "ç§ã¯AIãŒå¤§å¥½ãã§ã™"
Emoji = "ğŸ‘ï¸ â¤ï¸ ğŸ¤–"

# å¯¹è®¡ç®—æœºæ¥è¯´ï¼Œè¿™äº›éƒ½åªæ˜¯ä¸åŒçš„ç¬¦å·åºåˆ—
print(f"ä¸­æ–‡å­—ç¬¦æ•°: {len(ä¸­æ–‡)}")      # 6
print(f"è‹±æ–‡å­—ç¬¦æ•°: {len(English)}")   # 9
print(f"æ—¥æ–‡å­—ç¬¦æ•°: {len(æ—¥æœ¬èª)}")    # 10
print(f"Emojiå­—ç¬¦æ•°: {len(Emoji)}")    # 7
```

##### 2. è¯­æ³•å±‚ï¼ˆSyntactic Levelï¼‰
ç¬¦å·å¦‚ä½•ç»„åˆæ‰æœ‰æ„ä¹‰ï¼Ÿè¿™å°±æ˜¯è¯­æ³•çš„ä½œç”¨ã€‚

```python
# è¯åºå¾ˆé‡è¦
å¥å­1 = "ç‹—å’¬äºº"    # æ­£å¸¸æ–°é—»
å¥å­2 = "äººå’¬ç‹—"    # å¤§æ–°é—»ï¼

# è¯­æ³•æ ‘ç¤ºä¾‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
è¯­æ³•æ ‘ = {
    "å¥å­": {
        "ä¸»è¯­": "ç‹—",
        "è°“è¯­": "å’¬", 
        "å®¾è¯­": "äºº"
    }
}

# åŒæ ·çš„è¯ï¼Œä¸åŒçš„ç»“æ„ï¼Œæ„æ€å®Œå…¨ä¸åŒ
```

##### 3. è¯­ä¹‰å±‚ï¼ˆSemantic Levelï¼‰
è¿™æ˜¯è¯­è¨€çš„æ ¸å¿ƒâ€”â€”æ„ä¹‰ã€‚åŒæ ·çš„è¯åœ¨ä¸åŒåœºæ™¯ä¸‹å¯èƒ½æœ‰å®Œå…¨ä¸åŒçš„å«ä¹‰ã€‚

```python
# ä¸Šä¸‹æ–‡å†³å®šè¯­ä¹‰
def ç†è§£è¯­ä¹‰(å¥å­, ä¸Šä¸‹æ–‡):
    if å¥å­ == "çœŸå‡‰å¿«":
        if ä¸Šä¸‹æ–‡ == "å¤å¤©å¹ç©ºè°ƒ":
            return "æ¸©åº¦èˆ’é€‚"
        elif ä¸Šä¸‹æ–‡ == "æœ‹å‹æ²¡å¸®å¿™":
            return "è®½åˆºï¼Œè¡¨ç¤ºå¤±æœ›"
    
    elif å¥å­ == "ä½ çœŸæ˜¯ä¸ªå¤©æ‰":
        if ä¸Šä¸‹æ–‡ == "è§£å†³éš¾é¢˜":
            return "çœŸå¿ƒèµç¾"
        elif ä¸Šä¸‹æ–‡ == "åšé”™äº‹":
            return "åè®½"
```

#### ğŸ’¡ ä»è§„åˆ™åˆ°æ¦‚ç‡ï¼šè¯­è¨€æ¨¡å‹çš„æ¼”è¿›

##### 1. è§„åˆ™æ—¶ä»£ï¼ˆ1950s-1980sï¼‰
æ—©æœŸçš„äººä»¬è¯•å›¾ç”¨è§„åˆ™æ¥æè¿°è¯­è¨€ï¼š

```python
# æ—©æœŸçš„è§„åˆ™ç³»ç»Ÿç¤ºä¾‹
class è§„åˆ™è¯­æ³•:
    def __init__(self):
        self.è§„åˆ™ = {
            "å¥å­": ["ä¸»è¯­", "è°“è¯­", "å®¾è¯­"],
            "ä¸»è¯­": ["æˆ‘", "ä½ ", "ä»–", "å°æ˜"],
            "è°“è¯­": ["åƒ", "å–", "å­¦ä¹ "],
            "å®¾è¯­": ["é¥­", "æ°´", "æ•°å­¦"]
        }
    
    def ç”Ÿæˆå¥å­(self):
        import random
        ä¸»è¯­ = random.choice(self.è§„åˆ™["ä¸»è¯­"])
        è°“è¯­ = random.choice(self.è§„åˆ™["è°“è¯­"]) 
        å®¾è¯­ = random.choice(self.è§„åˆ™["å®¾è¯­"])
        return f"{ä¸»è¯­}{è°“è¯­}{å®¾è¯­}"

# é—®é¢˜ï¼šåªèƒ½ç”Ÿæˆæœ‰é™çš„ã€æ­»æ¿çš„å¥å­
# "å°æ˜åƒæ•°å­¦" â€”â€” è¯­æ³•å¯¹ï¼Œä½†è¯­ä¹‰é”™è¯¯
```

##### 2. ç»Ÿè®¡æ—¶ä»£ï¼ˆ1980s-2010sï¼‰
äººä»¬å‘ç°ï¼šä¸å…¶å®šè§„åˆ™ï¼Œä¸å¦‚çœ‹æ¦‚ç‡ï¼

```python
# N-gramæ¨¡å‹ï¼šæ ¹æ®å‰é¢çš„è¯é¢„æµ‹ä¸‹ä¸€ä¸ªè¯
class BigramModel:
    def __init__(self):
        self.ç»Ÿè®¡ = {
            "æˆ‘": {"çˆ±": 0.3, "åƒ": 0.2, "æ˜¯": 0.5},
            "çˆ±": {"ä½ ": 0.4, "å­¦ä¹ ": 0.3, "åƒ": 0.3},
            "åƒ": {"é¥­": 0.6, "è‹¹æœ": 0.3, "é¥­äº†": 0.1}
        }
    
    def é¢„æµ‹ä¸‹ä¸€ä¸ªè¯(self, å½“å‰è¯):
        if current_word not in self.ç»Ÿè®¡:
            return "æ²¡æœ‰æ•°æ®"
        
        next_words = self.ç»Ÿè®¡[current_word]
        total = sum(next_words.values())
        
        # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
        prob_dist = {}
        for word, count in next_words.items():
            prob_dist[word] = count / total
            
        return prob_dist

# ä¼˜ç‚¹ï¼šä»æ•°æ®ä¸­å­¦ä¹ ï¼Œæ›´çµæ´»
# ç¼ºç‚¹ï¼šåªèƒ½çœ‹åˆ°å±€éƒ¨ä¿¡æ¯
```

##### 3. æ·±åº¦å­¦ä¹ æ—¶ä»£ï¼ˆ2010s-ç°åœ¨ï¼‰
ç¥ç»ç½‘ç»œå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ï¼š

```python
# ç°ä»£è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒæ€æƒ³ï¼ˆä¼ªä»£ç ï¼‰
class ModernLM:
    def __init__(self):
        self.ç†è§£æ•´ä¸ªä¸Šä¸‹æ–‡ = True
        self.å­¦ä¹ æ·±å±‚è¯­ä¹‰ = True
        self.å¤„ç†é•¿è·ç¦»ä¾èµ– = True
    
    def predict_next_token(self, context):
        # 1. æŠŠæ‰€æœ‰å†å²ä¿¡æ¯ç¼–ç æˆå‘é‡
        context_vector = self.encode(context)
        
        # 2. åŸºäºæ·±åº¦ç†è§£é¢„æµ‹
        prediction = self.decode(context_vector)
        
        # 3. è¿”å›æ¦‚ç‡åˆ†å¸ƒï¼Œè€Œä¸æ˜¯å•ä¸€ç­”æ¡ˆ
        return probability_distribution
```

#### ğŸ­ ä¸ºä»€ä¹ˆè¯´LLMæœ¬è´¨ä¸Šæ˜¯"éšæœºé¹¦é¹‰"ï¼Ÿ

è¿™ä¸ªè¯´æ³•æ—¢å¯¹åˆä¸å¯¹ã€‚è®©æˆ‘ç”¨ä¸€ä¸ªå®éªŒæ¥è§£é‡Šï¼š

```python
import numpy as np

class ç®€åŒ–ç‰ˆLLM:
    def __init__(self):
        # è¿™æ˜¯ä¸€ä¸ªæç®€çš„"è¯è¡¨"
        self.è¯è¡¨ = ["æˆ‘", "çˆ±", "åƒ", "è‹¹æœ", "å­¦ä¹ ", "AI"]
        
        # ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆéšæœºåˆå§‹åŒ–ï¼‰
        self.è½¬ç§»æ¦‚ç‡ = np.random.rand(6, 6)  # åˆ›å»º6Ã—6çš„éšæœºçŸ©é˜µï¼Œè¡¨ç¤ºä»æ¯ä¸ªè¯åˆ°å…¶ä»–è¯çš„è½¬ç§»æ¦‚ç‡
        # å½’ä¸€åŒ–ï¼Œaxis=1 è¡¨ç¤ºæ²¿ç€çŸ©é˜µçš„è¡Œæ–¹å‘è¿›è¡Œæ±‚å’Œæ“ä½œã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å°†æ¯ä¸€è¡Œçš„æ¦‚ç‡å€¼å½’ä¸€åŒ–ï¼Œä½¿å¾—æ¯è¡Œçš„æ€»å’Œç­‰äº1ã€‚
        self.è½¬ç§»æ¦‚ç‡ = self.è½¬ç§»æ¦‚ç‡ / self.è½¬ç§»æ¦‚ç‡.sum(axis=1, keepdims=True)
    
    def ç”Ÿæˆæ–‡æœ¬(self, å¼€å§‹è¯="æˆ‘", é•¿åº¦=5):
        ç»“æœ = [å¼€å§‹è¯]
        å½“å‰è¯ç´¢å¼• = self.è¯è¡¨.index(å¼€å§‹è¯)
        
        for _ in range(é•¿åº¦-1):
            # æ ¹æ®æ¦‚ç‡åˆ†å¸ƒéšæœºé€‰æ‹©ä¸‹ä¸€ä¸ªè¯
            æ¦‚ç‡åˆ†å¸ƒ = self.è½¬ç§»æ¦‚ç‡[å½“å‰è¯ç´¢å¼•]
            
            # np.random.choice(6, p=æ¦‚ç‡åˆ†å¸ƒ) ä»0-5ä¸­æŒ‰ç…§æ¦‚ç‡åˆ†å¸ƒéšæœºé€‰æ‹©ä¸€ä¸ªæ•°
            # 6: å¯é€‰å€¼çš„èŒƒå›´æ˜¯0-5å…±6ä¸ªæ•°
            # p=æ¦‚ç‡åˆ†å¸ƒ: æ¯ä¸ªæ•°è¢«é€‰ä¸­çš„æ¦‚ç‡ç”±æ¦‚ç‡åˆ†å¸ƒæŒ‡å®š
            # è¿™æ ·åšçš„å¥½å¤„æ˜¯è®©è¾“å‡ºæ›´æœ‰è§„å¾‹æ€§ï¼ˆé«˜æ¦‚ç‡çš„è¯ç»å¸¸å‡ºç°ï¼‰ï¼Œåˆæœ‰åˆ›é€ æ€§ï¼ˆä½æ¦‚ç‡çš„è¯å¶å°”ä¹Ÿä¼šè¢«é€‰ä¸­ï¼‰
            ä¸‹ä¸€ä¸ªè¯ç´¢å¼• = np.random.choice(6, p=æ¦‚ç‡åˆ†å¸ƒ)
            
            ç»“æœ.append(self.è¯è¡¨[ä¸‹ä¸€ä¸ªè¯ç´¢å¼•])
            å½“å‰è¯ç´¢å¼• =ä¸‹ä¸€ä¸ªè¯ç´¢å¼•
        
        return "".join(ç»“æœ)

# è¯•è¯•çœ‹
model = ç®€åŒ–ç‰ˆLLM()
for i in range(3):
    print(f"ç”Ÿæˆ{i+1}: {model.ç”Ÿæˆæ–‡æœ¬()}")

# è¾“å‡ºå¯èƒ½æ˜¯ï¼š
# ç”Ÿæˆ1: æˆ‘çˆ±AIå­¦ä¹ åƒ
# ç”Ÿæˆ2: æˆ‘åƒè‹¹æœçˆ±æˆ‘  
# ç”Ÿæˆ3: æˆ‘å­¦ä¹ AIçˆ±è‹¹æœ
```

çœ‹èµ·æ¥ç¡®å®åƒ"éšæœºé¹¦é¹‰"ï¼Œä½†ç°ä»£LLMçš„"éšæœº"æ˜¯åŸºäºå¯¹è¯­è¨€æ·±åˆ»ç†è§£åçš„"æ™ºèƒ½éšæœº"ã€‚

#### ğŸš€ è¯­è¨€çš„æ•°å­¦æœ¬è´¨

åœ¨è®¡ç®—æœºçš„ä¸–ç•Œé‡Œï¼Œä¸€åˆ‡éƒ½æ˜¯æ•°å­—ã€‚è¯­è¨€ä¹Ÿä¸ä¾‹å¤–ï¼š

```python
# è¯­è¨€çš„å‘é‡ç©ºé—´è¡¨ç¤º
class è¯­è¨€ç©ºé—´:
    def __init__(self):
        # æ¯ä¸ªè¯éƒ½æ˜¯é«˜ç»´ç©ºé—´ä¸­çš„ä¸€ä¸ªç‚¹
        self.è¯å‘é‡ = {
            "å›½ç‹": [0.8, 0.2, 0.9, 0.1],
            "ç‹å": [0.7, 0.8, 0.9, 0.1],
            "ç”·äºº": [0.9, 0.1, 0.2, 0.1],
            "å¥³äºº": [0.8, 0.9, 0.2, 0.1]
        }
    
    def è¯è¯­è¿ç®—(self):
        # è‘—åçš„ä¾‹å­ï¼šå›½ç‹ - ç”·äºº + å¥³äºº â‰ˆ ç‹å
        å›½ç‹ = np.array(self.è¯å‘é‡["å›½ç‹"])
        ç”·äºº = np.array(self.è¯å‘é‡["ç”·äºº"])
        å¥³äºº = np.array(self.è¯å‘é‡["å¥³äºº"])
        
        ç»“æœ = å›½ç‹ - ç”·äºº + å¥³äºº
        print(f"å›½ç‹ - ç”·äºº + å¥³äºº = {ç»“æœ}")
        print(f"ç‹å = {self.è¯å‘é‡['ç‹å']}")
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        ç‹å = np.array(self.è¯å‘é‡["ç‹å"])
        ç›¸ä¼¼åº¦ = np.dot(ç»“æœ, ç‹å) / (np.linalg.norm(ç»“æœ) * np.linalg.norm(ç‹å))
        print(f"ç›¸ä¼¼åº¦: {ç›¸ä¼¼åº¦:.3f}")
```

#### ğŸ“Š ä»è¯­è¨€åˆ°æ¦‚ç‡åˆ†å¸ƒ

LLMçš„æ ¸å¿ƒæ´å¯Ÿï¼š**è¯­è¨€ç”Ÿæˆå°±æ˜¯åœ¨æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·**ã€‚

```python
import matplotlib.pyplot as plt
# è®¾ç½®æ”¯æŒä¸­æ–‡æ˜¾ç¤ºçš„å­—ä½“
#plt.rcParams['font.sans-serif'] = ['SimHei']  #Windows ä½¿ç”¨é»‘ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS'] #Mac ä½¿ç”¨å­—ä½“
plt.rcParams['axes.unicode_minus'] = False 
# å¯è§†åŒ–ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒ
def å¯è§†åŒ–æ¦‚ç‡åˆ†å¸ƒ():
    # å‡è®¾å½“å‰è¾“å…¥æ˜¯"ä»Šå¤©å¤©æ°”"
    ä¸‹ä¸€ä¸ªè¯å€™é€‰ = ["å¾ˆ", "çœŸ", "éå¸¸", "ä¸", "ç‰¹åˆ«", "æœ‰ç‚¹"]
    æ¦‚ç‡ = [0.3, 0.25, 0.2, 0.1, 0.1, 0.05]
    
    plt.figure(figsize=(10, 6))
    # ä½¿ç”¨plt.bar()ç»˜åˆ¶æŸ±çŠ¶å›¾
    # å‚æ•°è¯´æ˜:
    # - ä¸‹ä¸€ä¸ªè¯å€™é€‰: xè½´çš„æ ‡ç­¾
    # - æ¦‚ç‡: yè½´çš„æ•°å€¼
    # - color='skyblue': è®¾ç½®æŸ±çŠ¶å›¾é¢œè‰²ä¸ºå¤©è“è‰²
    # è®¾ç½® x è½´å’Œ y è½´æ•°æ®æ¥æº
    bars = plt.bar(ä¸‹ä¸€ä¸ªè¯å€™é€‰, æ¦‚ç‡, color='skyblue')
    plt.xlabel('ä¸‹ä¸€ä¸ªè¯')
    plt.ylabel('æ¦‚ç‡')
    plt.title('ç»™å®š"ä»Šå¤©å¤©æ°”"åï¼Œä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒ')
    
    # æ ‡æ³¨æ¦‚ç‡å€¼
    for bar, prob in zip(bars, æ¦‚ç‡):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{prob:.2f}', ha='center')
    
    plt.ylim(0, 0.4)
    plt.show()

# Temperatureå‚æ•°çš„å½±å“
def temperature_effect(logits, temperature):
    """
    Temperatureæ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§
    - é«˜æ¸©åº¦(>1)ï¼šæ›´éšæœºï¼Œæ›´æœ‰åˆ›é€ æ€§
    - ä½æ¸©åº¦(<1)ï¼šæ›´ç¡®å®šï¼Œæ›´ä¿å®ˆ
    """
    # åº”ç”¨temperature
    # temperature å‚æ•°çš„ä½œç”¨:
    # 1. è°ƒèŠ‚ç”Ÿæˆæ–‡æœ¬çš„"åˆ›é€ æ€§":
    #    - temperature é«˜ (>1): æ¦‚ç‡åˆ†å¸ƒæ›´å¹³å¦,ç”Ÿæˆæ›´æœ‰åˆ›æ„ä½†å¯èƒ½ä¸å¤ªè¿è´¯
    #    - temperature ä½ (<1): æ¦‚ç‡åˆ†å¸ƒæ›´å°–é”,ç”Ÿæˆæ›´ä¿å®ˆä½†æ›´å¯é 
    # 2. æ•°å­¦åŸç†:
    #    - temperature è¶Šå¤§,logitsé™¤ä»¥æ›´å¤§çš„æ•°,scaled_logitså˜å°,æ¦‚ç‡åˆ†å¸ƒè¶‹äºå¹³å‡
    #    - temperature è¶Šå°,logitsé™¤ä»¥æ›´å°çš„æ•°,scaled_logitså˜å¤§,æ¦‚ç‡åˆ†å¸ƒæ›´é›†ä¸­
    # 3. ä¸¾ä¾‹:
    #    - logit=2, temperature=0.5æ—¶: scaled_logits=4 (æ›´å°–é”)
    #    - logit=2, temperature=2æ—¶: scaled_logits=1 (æ›´å¹³å¦)
    scaled_logits = logits / temperature
    
    # Softmaxè½¬æ¢ä¸ºæ¦‚ç‡
    # å‡å»æœ€å¤§å€¼æ˜¯ä¸ºäº†é˜²æ­¢æŒ‡æ•°è¿ç®—æ—¶æ•°å€¼æº¢å‡º
    # å› ä¸º exp(å¤§æ•°) ä¼šäº§ç”Ÿéå¸¸å¤§çš„æ•°å€¼ï¼Œå¯èƒ½è¶…å‡ºè®¡ç®—æœºçš„è¡¨ç¤ºèŒƒå›´
    # è¿™ä¸ªæŠ€å·§å«åš log-sum-exp trickï¼Œä¸å½±å“æœ€ç»ˆçš„ softmax ç»“æœ
    exp_logits = np.exp(scaled_logits - np.max(scaled_logits))
    # å½’ä¸€åŒ–:å°†æ‰€æœ‰æ¦‚ç‡å€¼ç›¸åŠ ç­‰äº1
    probabilities = exp_logits / exp_logits.sum()
    
    return probabilities

# æ¼”ç¤ºä¸åŒtemperatureçš„æ•ˆæœ
logits = np.array([2.0, 1.5, 1.0, 0.5, 0.0, -0.5])
temps = [0.5, 1.0, 2.0]

plt.figure(figsize=(15, 5))
for i, temp in enumerate(temps):
    plt.subplot(1, 3, i+1)
    probs = temperature_effect(logits, temp)
    plt.bar(range(len(probs)), probs)
    plt.title(f'Temperature = {temp}')
    plt.ylabel('æ¦‚ç‡')
    plt.ylim(0, 1.0)
```
<div align="center">
  <img src="./figures/Figure_1.png" alt="ç»™å®š'ä»Šå¤©å¤©æ°”'åï¼Œä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒ" width="80%" />
  <p><em>ç»™å®š"ä»Šå¤©å¤©æ°”"åï¼Œä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒ</em></p>
</div>

<div align="center">
  <img src="./figures/Figure_2.png" alt="ä¸åŒtemperatureçš„æ•ˆæœ" width="80%" />
  <p><em>ä¸åŒ temperature å¯¹ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡å½±å“æ•ˆæœ</em></p>
</div>


#### ğŸ“ æœ¬ç« å°ç»“

1. **è¯­è¨€æ˜¯ç¬¦å·ç³»ç»Ÿ**ï¼šæœ‰é™çš„ç¬¦å·ï¼Œæ— é™çš„è¡¨è¾¾
2. **è¯­è¨€æ˜¯æ¦‚ç‡æ¸¸æˆ**ï¼šæ¯ä¸ªè¯çš„å‡ºç°éƒ½æœ‰å…¶æ¦‚ç‡
3. **è¯­è¨€æ˜¯å‘é‡ç©ºé—´**ï¼šè¯è¯­ä¹‹é—´çš„å…³ç³»å¯ä»¥ç”¨æ•°å­¦æè¿°
4. **LLMå­¦ä¹ è¯­è¨€çš„ç»Ÿè®¡è§„å¾‹**ï¼šä¸æ˜¯æ­»è®°ç¡¬èƒŒï¼Œè€Œæ˜¯ç†è§£æ¨¡å¼

è®°ä½ï¼šLLMä¸æ˜¯åœ¨"ç†è§£"è¯­è¨€çš„æ„æ€ï¼ˆåƒäººç±»é‚£æ ·ï¼‰ï¼Œè€Œæ˜¯åœ¨å­¦ä¹ è¯­è¨€çš„ç»Ÿè®¡æ¨¡å¼ã€‚ä½†å½“è¿™ç§å­¦ä¹ è¶³å¤Ÿæ·±å…¥ã€è§„æ¨¡è¶³å¤Ÿå¤§æ—¶ï¼Œå°±äº§ç”Ÿäº†"æ¶Œç°"â€”â€”çœ‹èµ·æ¥åƒæ˜¯çœŸæ­£çš„ç†è§£ã€‚

#### ğŸ’­ æ€è€ƒé¢˜

1. å¦‚æœè¯­è¨€æœ¬è´¨ä¸Šæ˜¯æ¦‚ç‡çš„ï¼Œé‚£ä¹ˆè¯—æ­Œçš„ç¾ä»ä½•è€Œæ¥ï¼Ÿ
2. ä¸ºä»€ä¹ˆåŒæ ·çš„è®­ç»ƒæ•°æ®ï¼Œä¸åŒçš„æ¨¡å‹ä¼šæœ‰ä¸åŒçš„"è¯­è¨€é£æ ¼"ï¼Ÿ
3. æœºå™¨çœŸçš„èƒ½"ç†è§£"è¯­è¨€å—ï¼Ÿè¿˜æ˜¯åªæ˜¯é«˜çº§çš„æ¨¡å¼åŒ¹é…ï¼Ÿ

ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨æ¦‚ç‡ä¸è¯­è¨€çš„å…³ç³»ï¼Œçœ‹çœ‹ä¸ºä»€ä¹ˆè¯´"LLMæœ¬è´¨ä¸Šæ˜¯æ¦‚ç‡æ¨¡å‹"ã€‚

---


### ç¬¬2ç« ï¼šæ¦‚ç‡ä¸è¯­è¨€â€”â€”ä¸ºä»€ä¹ˆLLMæœ¬è´¨ä¸Šæ˜¯æ¦‚ç‡æ¨¡å‹ï¼Ÿ

#### ğŸ¯ æœ¬ç« å¯¼è¯»

æƒ³è±¡ä½ åœ¨ç©ä¸€ä¸ªå¡«è¯æ¸¸æˆï¼š"ä»Šå¤©çš„å¤©æ°”çœŸ____"ã€‚

ä½ ä¼šå¡«ä»€ä¹ˆï¼Ÿ"å¥½"ã€"ç³Ÿç³•"ã€"å¥‡æ€ª"ï¼Ÿä½ çš„å¤§è„‘åœ¨ç¬é—´å°±ç»™å‡ºäº†ç­”æ¡ˆï¼Œä½†ä½ æœ‰æ²¡æœ‰æƒ³è¿‡ï¼Œè¿™ä¸ªé€‰æ‹©çš„è¿‡ç¨‹å…¶å®æ˜¯ä¸€ä¸ªæ¦‚ç‡è®¡ç®—ï¼Ÿ

LLMåšçš„äº‹æƒ…æœ¬è´¨ä¸Šå°±æ˜¯è¿™ä¸ªï¼šç»™å®šå‰é¢çš„æ–‡å­—ï¼Œè®¡ç®—ä¸‹ä¸€ä¸ªè¯å‡ºç°çš„æ¦‚ç‡ã€‚å¬èµ·æ¥ç®€å•ï¼Œä½†è¿™ä¸ªç®€å•çš„æƒ³æ³•ï¼Œå´è•´å«ç€è¯­è¨€æ™ºèƒ½çš„å¥¥ç§˜ã€‚

#### ğŸ² ä¸€åˆ‡éƒ½æ˜¯æ¦‚ç‡

è®©æˆ‘ä»¬ä»ä¸€ä¸ªç®€å•çš„å®éªŒå¼€å§‹ï¼š

```python
import random
from collections import defaultdict, Counter

class è¯­è¨€æ¦‚ç‡å®éªŒ:
    def __init__(self):
        # æ”¶é›†ä¸€äº›å¥å­
        self.sentences = [
            "æˆ‘å–œæ¬¢åƒè‹¹æœ",
            "æˆ‘å–œæ¬¢åƒé¦™è•‰", 
            "æˆ‘å–œæ¬¢å­¦ä¹ ç¼–ç¨‹",
            "ä»–å–œæ¬¢åƒè‹¹æœ",
            "å¥¹å–œæ¬¢å­¦ä¹ æ•°å­¦",
            "æˆ‘ä»Šå¤©åƒè‹¹æœ",
            "æˆ‘æ˜¨å¤©åƒé¦™è•‰"
        ]
        
        # ç»Ÿè®¡è¯é¢‘
        self.word_freq = defaultdict(int)
        self.bigram_freq = defaultdict(lambda: defaultdict(int))
        
    def ç»Ÿè®¡æ¦‚ç‡(self):
        # ç»Ÿè®¡å•è¯å‡ºç°æ¬¡æ•°
        for sentence in self.sentences:
            words = list(sentence)
            
            # å•è¯é¢‘ç‡
            for word in words:
                self.word_freq[word] += 1
            
            # äºŒå…ƒç»„é¢‘ç‡ï¼ˆbigramï¼‰
            for i in range(len(words)-1):
                self.bigram_freq[words[i]][words[i+1]] += 1
    
    def é¢„æµ‹ä¸‹ä¸€ä¸ªå­—(self, current_word):
        """æ ¹æ®å½“å‰å­—é¢„æµ‹ä¸‹ä¸€ä¸ªå­—çš„æ¦‚ç‡åˆ†å¸ƒ"""
        if current_word not in self.bigram_freq:
            return "æ²¡æœ‰æ•°æ®"
        
        next_words = self.bigram_freq[current_word]
        total = sum(next_words.values())
        
        # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
        prob_dist = {}
        for word, count in next_words.items():
            prob_dist[word] = count / total
            
        return prob_dist

# è¿è¡Œå®éªŒ
exp = è¯­è¨€æ¦‚ç‡å®éªŒ()
exp.ç»Ÿè®¡æ¦‚ç‡()

# çœ‹çœ‹"æˆ‘"åé¢æœ€å¯èƒ½å‡ºç°ä»€ä¹ˆ
print("'æˆ‘'åé¢çš„æ¦‚ç‡åˆ†å¸ƒ:")
for word, prob in exp.é¢„æµ‹ä¸‹ä¸€ä¸ªå­—("æˆ‘").items():
    print(f"  {word}: {prob:.2%}")
```

è¿™å°±æ˜¯æœ€ç®€å•çš„è¯­è¨€æ¨¡å‹â€”â€”åŸºäºç»Ÿè®¡çš„N-gramæ¨¡å‹ï¼

#### ğŸ“ˆ ä»è®¡æ•°åˆ°æ¦‚ç‡ï¼šè´å¶æ–¯è§†è§’

è¯­è¨€æ¨¡å‹çš„æ•°å­¦åŸºç¡€æ˜¯æ¡ä»¶æ¦‚ç‡ï¼š

```python
# è¯­è¨€ç”Ÿæˆçš„æ¦‚ç‡é“¾
def å¥å­æ¦‚ç‡(sentence):
    """
    P(æˆ‘å–œæ¬¢åƒè‹¹æœ) = P(æˆ‘) Ã— P(å–œ|æˆ‘) Ã— P(æ¬¢|æˆ‘å–œ) Ã— P(åƒ|å–œæ¬¢) Ã— P(è‹¹|æ¬¢åƒ) Ã— P(æœ|åƒè‹¹)
    
    ä½†å®é™…ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ç®€åŒ–ä¸ºï¼š
    P(æˆ‘å–œæ¬¢åƒè‹¹æœ) = P(æˆ‘) Ã— P(å–œæ¬¢|æˆ‘) Ã— P(åƒ|æˆ‘å–œæ¬¢) Ã— P(è‹¹æœ|æˆ‘å–œæ¬¢åƒ)
    """
    
    # ç”¨å¯¹æ•°æ¦‚ç‡é¿å…æ•°å€¼ä¸‹æº¢
    log_prob = 0
    
    # è¿™é‡Œç”¨ä¼ªä»£ç è¡¨ç¤º
    # log_prob += math.log(P("æˆ‘"))
    # log_prob += math.log(P("å–œæ¬¢"|"æˆ‘"))
    # log_prob += math.log(P("åƒ"|"æˆ‘å–œæ¬¢"))
    # log_prob += math.log(P("è‹¹æœ"|"æˆ‘å–œæ¬¢åƒ"))
    
    return math.exp(log_prob)

# è´å¶æ–¯å…¬å¼çš„åº”ç”¨
class è´å¶æ–¯è¯­è¨€ç†è§£:
    def __init__(self):
        self.å…ˆéªŒçŸ¥è¯† = {
            "æƒ…æ„Ÿ": {"æ­£é¢": 0.6, "è´Ÿé¢": 0.4},
            "ä¸»é¢˜": {"ç¾é£Ÿ": 0.3, "ç§‘æŠ€": 0.2, "å¨±ä¹": 0.5}
        }
    
    def ç†è§£å¥å­(self, sentence):
        """
        åéªŒæ¦‚ç‡ = (ä¼¼ç„¶åº¦ Ã— å…ˆéªŒæ¦‚ç‡) / è¯æ®
        P(æƒ…æ„Ÿ|å¥å­) = P(å¥å­|æƒ…æ„Ÿ) Ã— P(æƒ…æ„Ÿ) / P(å¥å­)
        """
        # è¿™é‡Œå±•ç¤ºæ¦‚å¿µï¼Œå®é™…è®¡ç®—ä¼šæ›´å¤æ‚
        if "å–œæ¬¢" in sentence or "æ£’" in sentence:
            ä¼¼ç„¶_æ­£é¢ = 0.8
            ä¼¼ç„¶_è´Ÿé¢ = 0.2
        else:
            ä¼¼ç„¶_æ­£é¢ = 0.3
            ä¼¼ç„¶_è´Ÿé¢ = 0.7
            
        # è®¡ç®—åéªŒæ¦‚ç‡
        P_æ­£é¢ = ä¼¼ç„¶_æ­£é¢ * self.å…ˆéªŒçŸ¥è¯†["æƒ…æ„Ÿ"]["æ­£é¢"]
        P_è´Ÿé¢ = ä¼¼ç„¶_è´Ÿé¢ * self.å…ˆéªŒçŸ¥è¯†["æƒ…æ„Ÿ"]["è´Ÿé¢"]
        
        # å½’ä¸€åŒ–
        æ€»å’Œ = P_æ­£é¢ + P_è´Ÿé¢
        return {"æ­£é¢": P_æ­£é¢/æ€»å’Œ, "è´Ÿé¢": P_è´Ÿé¢/æ€»å’Œ}
```

#### ğŸ° è¯­è¨€ç”Ÿæˆ=æ¦‚ç‡é‡‡æ ·

LLMç”Ÿæˆæ–‡æœ¬çš„è¿‡ç¨‹ï¼Œæœ¬è´¨ä¸Šå°±æ˜¯ä¸æ–­åœ°ä»æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ï¼š

```python
import numpy as np
import matplotlib.pyplot as plt

class æ¦‚ç‡é‡‡æ ·æ¼”ç¤º:
    def __init__(self):
        self.vocab = ["æˆ‘", "å–œæ¬¢", "åƒ", "è‹¹æœ", "ç¼–ç¨‹", "å­¦ä¹ ", 
                     "ä»Šå¤©", "å¤©æ°”", "å¾ˆ", "å¥½", "ã€‚"]
        
    def softmax(self, logits, temperature=1.0):
        """Softmax with temperature"""
        # Temperatureæ§åˆ¶éšæœºæ€§
        logits = np.array(logits) / temperature
        exp_logits = np.exp(logits - np.max(logits))
        return exp_logits / exp_logits.sum()
    
    def ä¸åŒé‡‡æ ·ç­–ç•¥(self, logits):
        """å±•ç¤ºä¸åŒçš„é‡‡æ ·ç­–ç•¥"""
        probs = self.softmax(logits)
        
        strategies = {
            "è´ªå¿ƒé‡‡æ ·": self.greedy_sampling,
            "éšæœºé‡‡æ ·": self.random_sampling,
            "Top-ké‡‡æ ·": self.top_k_sampling,
            "Top-pé‡‡æ ·": self.nucleus_sampling
        }
        
        results = {}
        for name, method in strategies.items():
            results[name] = method(probs)
            
        return results
    
    def greedy_sampling(self, probs):
        """æ€»æ˜¯é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„"""
        return self.vocab[np.argmax(probs)]
    
    def random_sampling(self, probs):
        """æŒ‰æ¦‚ç‡åˆ†å¸ƒéšæœºé‡‡æ ·"""
        return np.random.choice(self.vocab, p=probs)
    
    def top_k_sampling(self, probs, k=3):
        """åªä»æ¦‚ç‡æœ€é«˜çš„kä¸ªä¸­é‡‡æ ·"""
        top_k_idx = np.argsort(probs)[-k:]
        top_k_probs = probs[top_k_idx]
        top_k_probs = top_k_probs / top_k_probs.sum()
        
        idx = np.random.choice(top_k_idx, p=top_k_probs)
        return self.vocab[idx]
    
    def nucleus_sampling(self, probs, p=0.9):
        """åªä»ç´¯ç§¯æ¦‚ç‡è¾¾åˆ°pçš„è¯ä¸­é‡‡æ ·"""
        sorted_idx = np.argsort(probs)[::-1]
        sorted_probs = probs[sorted_idx]
        
        cumsum = np.cumsum(sorted_probs)
        mask = cumsum <= p
        if not mask.any():
            mask[0] = True
            
        nucleus_probs = sorted_probs[mask]
        nucleus_probs = nucleus_probs / nucleus_probs.sum()
        
        idx = np.random.choice(np.where(mask)[0], p=nucleus_probs)
        return self.vocab[sorted_idx[idx]]
    
    def å¯è§†åŒ–é‡‡æ ·ç­–ç•¥(self):
        """å¯è§†åŒ–ä¸åŒé‡‡æ ·ç­–ç•¥çš„æ•ˆæœ"""
        # æ¨¡æ‹Ÿä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ
        logits = np.random.randn(len(self.vocab)) * 2
        probs = self.softmax(logits)
        
        # æ’åºç”¨äºå±•ç¤º
        sorted_idx = np.argsort(probs)[::-1]
        sorted_vocab = [self.vocab[i] for i in sorted_idx]
        sorted_probs = probs[sorted_idx]
        
        # ç»˜å›¾
        plt.figure(figsize=(12, 8))
        
        # åŸå§‹æ¦‚ç‡åˆ†å¸ƒ
        plt.subplot(2, 2, 1)
        plt.bar(sorted_vocab, sorted_probs)
        plt.title('åŸå§‹æ¦‚ç‡åˆ†å¸ƒ')
        plt.xticks(rotation=45)
        
        # Top-k (k=3)
        plt.subplot(2, 2, 2)
        colors = ['red' if i < 3 else 'gray' for i in range(len(sorted_vocab))]
        plt.bar(sorted_vocab, sorted_probs, color=colors)
        plt.title('Top-3é‡‡æ ·ï¼ˆçº¢è‰²éƒ¨åˆ†ï¼‰')
        plt.xticks(rotation=45)
        
        # Top-p (p=0.9)
        plt.subplot(2, 2, 3)
        cumsum = np.cumsum(sorted_probs)
        colors = ['blue' if c <= 0.9 else 'gray' for c in cumsum]
        plt.bar(sorted_vocab, sorted_probs, color=colors)
        plt.title('Top-pé‡‡æ · (p=0.9)ï¼ˆè“è‰²éƒ¨åˆ†ï¼‰')
        plt.xticks(rotation=45)
        
        # Temperatureæ•ˆæœ
        plt.subplot(2, 2, 4)
        temps = [0.5, 1.0, 1.5]
        x = np.arange(len(sorted_vocab))
        width = 0.25
        
        for i, temp in enumerate(temps):
            temp_probs = self.softmax(logits[sorted_idx], temperature=temp)
            plt.bar(x + i*width, temp_probs, width, label=f'T={temp}')
        
        plt.title('Temperatureçš„å½±å“')
        plt.xticks(x + width, sorted_vocab, rotation=45)
        plt.legend()
        
        plt.tight_layout()
        plt.show()

# è¿è¡Œæ¼”ç¤º
demo = æ¦‚ç‡é‡‡æ ·æ¼”ç¤º()
demo.å¯è§†åŒ–é‡‡æ ·ç­–ç•¥()
```

#### ğŸŒ¡ï¸ Temperatureï¼šåˆ›é€ åŠ›çš„è°ƒèŠ‚å™¨

Temperatureæ˜¯æ§åˆ¶LLM"åˆ›é€ åŠ›"çš„å…³é”®å‚æ•°ï¼š

```python
def temperature_effects_demo():
    """æ¼”ç¤ºtemperatureå¯¹ç”Ÿæˆç»“æœçš„å½±å“"""
    
    # å‡è®¾è¿™æ˜¯æ¨¡å‹å¯¹ä¸‹ä¸€ä¸ªè¯çš„åŸå§‹é¢„æµ‹åˆ†æ•°
    vocab = ["å¥½", "æ£’", "ç³Ÿç³•", "æ™®é€š", "å¥‡æ€ª"]
    logits = np.array([2.0, 1.8, 0.1, 0.5, 0.3])
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    temperatures = [0.5, 1.0, 2.0]
    descriptions = ["ä¿å®ˆ(T=0.5)", "å¹³è¡¡(T=1.0)", "åˆ›æ–°(T=2.0)"]
    
    for ax, temp, desc in zip(axes, temperatures, descriptions):
        # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
        probs = np.exp(logits / temp)
        probs = probs / probs.sum()
        
        # å¯è§†åŒ–
        bars = ax.bar(vocab, probs, color=['green', 'blue', 'red', 'gray', 'orange'])
        ax.set_title(f'{desc}')
        ax.set_ylabel('æ¦‚ç‡')
        ax.set_ylim(0, 1)
        
        # æ ‡æ³¨æ¦‚ç‡å€¼
        for bar, prob in zip(bars, probs):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                   f'{prob:.2%}', ha='center', va='bottom')
    
    plt.suptitle('Temperatureå¯¹æ¦‚ç‡åˆ†å¸ƒçš„å½±å“', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    # æ¨¡æ‹Ÿå¤šæ¬¡é‡‡æ ·çš„ç»“æœ
    print("\næ¨¡æ‹Ÿ100æ¬¡é‡‡æ ·çš„ç»“æœåˆ†å¸ƒï¼š")
    for temp in temperatures:
        probs = np.exp(logits / temp)
        probs = probs / probs.sum()
        
        # é‡‡æ ·100æ¬¡
        samples = np.random.choice(vocab, size=100, p=probs)
        counts = Counter(samples)
        
        print(f"\nTemperature = {temp}:")
        for word, count in counts.most_common():
            print(f"  {word}: {count}æ¬¡ ({count}%)")

temperature_effects_demo()
```


### ç¬¬2ç« ï¼šæ¦‚ç‡ä¸è¯­è¨€â€”â€”ä¸ºä»€ä¹ˆLLMæœ¬è´¨ä¸Šæ˜¯æ¦‚ç‡æ¨¡å‹ï¼Ÿ

#### ğŸ¯ æœ¬ç« å¯¼è¯»

æƒ³è±¡ä½ åœ¨ç©ä¸€ä¸ªå¡«è¯æ¸¸æˆï¼š"ä»Šå¤©çš„å¤©æ°”çœŸ____"ã€‚

ä½ ä¼šå¡«ä»€ä¹ˆï¼Ÿ"å¥½"ã€"ç³Ÿç³•"ã€"å¥‡æ€ª"ï¼Ÿä½ çš„å¤§è„‘åœ¨ç¬é—´å°±ç»™å‡ºäº†ç­”æ¡ˆï¼Œä½†ä½ æœ‰æ²¡æœ‰æƒ³è¿‡ï¼Œè¿™ä¸ªé€‰æ‹©çš„è¿‡ç¨‹å…¶å®æ˜¯ä¸€ä¸ªæ¦‚ç‡è®¡ç®—ï¼Ÿ

LLMåšçš„äº‹æƒ…æœ¬è´¨ä¸Šå°±æ˜¯è¿™ä¸ªï¼šç»™å®šå‰é¢çš„æ–‡å­—ï¼Œè®¡ç®—ä¸‹ä¸€ä¸ªè¯å‡ºç°çš„æ¦‚ç‡ã€‚å¬èµ·æ¥ç®€å•ï¼Œä½†è¿™ä¸ªç®€å•çš„æƒ³æ³•ï¼Œå´è•´å«ç€è¯­è¨€æ™ºèƒ½çš„å¥¥ç§˜ã€‚

#### ğŸ² ä¸€åˆ‡éƒ½æ˜¯æ¦‚ç‡

è®©æˆ‘ä»¬ä»ä¸€ä¸ªç®€å•çš„å®éªŒå¼€å§‹ï¼š

```python
import random
from collections import defaultdict, Counter

class è¯­è¨€æ¦‚ç‡å®éªŒ:
    def __init__(self):
        # æ”¶é›†ä¸€äº›å¥å­
        self.sentences = [
            "æˆ‘å–œæ¬¢åƒè‹¹æœ",
            "æˆ‘å–œæ¬¢åƒé¦™è•‰", 
            "æˆ‘å–œæ¬¢å­¦ä¹ ç¼–ç¨‹",
            "ä»–å–œæ¬¢åƒè‹¹æœ",
            "å¥¹å–œæ¬¢å­¦ä¹ æ•°å­¦",
            "æˆ‘ä»Šå¤©åƒè‹¹æœ",
            "æˆ‘æ˜¨å¤©åƒé¦™è•‰"
        ]
        
        # ç»Ÿè®¡è¯é¢‘
        self.word_freq = defaultdict(int)
        self.bigram_freq = defaultdict(lambda: defaultdict(int))
        
    def ç»Ÿè®¡æ¦‚ç‡(self):
        # ç»Ÿè®¡å•è¯å‡ºç°æ¬¡æ•°
        for sentence in self.sentences:
            words = list(sentence)
            
            # å•è¯é¢‘ç‡
            for word in words:
                self.word_freq[word] += 1
            
            # äºŒå…ƒç»„é¢‘ç‡ï¼ˆbigramï¼‰
            for i in range(len(words)-1):
                self.bigram_freq[words[i]][words[i+1]] += 1
    
    def é¢„æµ‹ä¸‹ä¸€ä¸ªå­—(self, current_word):
        """æ ¹æ®å½“å‰å­—é¢„æµ‹ä¸‹ä¸€ä¸ªå­—çš„æ¦‚ç‡åˆ†å¸ƒ"""
        if current_word not in self.bigram_freq:
            return "æ²¡æœ‰æ•°æ®"
        
        next_words = self.bigram_freq[current_word]
        total = sum(next_words.values())
        
        # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
        prob_dist = {}
        for word, count in next_words.items():
            prob_dist[word] = count / total
            
        return prob_dist

# è¿è¡Œå®éªŒ
exp = è¯­è¨€æ¦‚ç‡å®éªŒ()
exp.ç»Ÿè®¡æ¦‚ç‡()

# çœ‹çœ‹"æˆ‘"åé¢æœ€å¯èƒ½å‡ºç°ä»€ä¹ˆ
print("'æˆ‘'åé¢çš„æ¦‚ç‡åˆ†å¸ƒ:")
for word, prob in exp.é¢„æµ‹ä¸‹ä¸€ä¸ªå­—("æˆ‘").items():
    print(f"  {word}: {prob:.2%}")
```

è¿™å°±æ˜¯æœ€ç®€å•çš„è¯­è¨€æ¨¡å‹â€”â€”åŸºäºç»Ÿè®¡çš„N-gramæ¨¡å‹ï¼

#### ğŸ“ˆ ä»è®¡æ•°åˆ°æ¦‚ç‡ï¼šè´å¶æ–¯è§†è§’

è¯­è¨€æ¨¡å‹çš„æ•°å­¦åŸºç¡€æ˜¯æ¡ä»¶æ¦‚ç‡ï¼š

```python
# è¯­è¨€ç”Ÿæˆçš„æ¦‚ç‡é“¾
def å¥å­æ¦‚ç‡(sentence):
    """
    P(æˆ‘å–œæ¬¢åƒè‹¹æœ) = P(æˆ‘) Ã— P(å–œ|æˆ‘) Ã— P(æ¬¢|æˆ‘å–œ) Ã— P(åƒ|å–œæ¬¢) Ã— P(è‹¹|æ¬¢åƒ) Ã— P(æœ|åƒè‹¹)
    
    ä½†å®é™…ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ç®€åŒ–ä¸ºï¼š
    P(æˆ‘å–œæ¬¢åƒè‹¹æœ) = P(æˆ‘) Ã— P(å–œæ¬¢|æˆ‘) Ã— P(åƒ|æˆ‘å–œæ¬¢) Ã— P(è‹¹æœ|æˆ‘å–œæ¬¢åƒ)
    """
    
    # ç”¨å¯¹æ•°æ¦‚ç‡é¿å…æ•°å€¼ä¸‹æº¢
    log_prob = 0
    
    # è¿™é‡Œç”¨ä¼ªä»£ç è¡¨ç¤º
    # log_prob += math.log(P("æˆ‘"))
    # log_prob += math.log(P("å–œæ¬¢"|"æˆ‘"))
    # log_prob += math.log(P("åƒ"|"æˆ‘å–œæ¬¢"))
    # log_prob += math.log(P("è‹¹æœ"|"æˆ‘å–œæ¬¢åƒ"))
    
    return math.exp(log_prob)

# è´å¶æ–¯å…¬å¼çš„åº”ç”¨
class è´å¶æ–¯è¯­è¨€ç†è§£:
    def __init__(self):
        self.å…ˆéªŒçŸ¥è¯† = {
            "æƒ…æ„Ÿ": {"æ­£é¢": 0.6, "è´Ÿé¢": 0.4},
            "ä¸»é¢˜": {"ç¾é£Ÿ": 0.3, "ç§‘æŠ€": 0.2, "å¨±ä¹": 0.5}
        }
    
    def ç†è§£å¥å­(self, sentence):
        """
        åéªŒæ¦‚ç‡ = (ä¼¼ç„¶åº¦ Ã— å…ˆéªŒæ¦‚ç‡) / è¯æ®
        P(æƒ…æ„Ÿ|å¥å­) = P(å¥å­|æƒ…æ„Ÿ) Ã— P(æƒ…æ„Ÿ) / P(å¥å­)
        """
        # è¿™é‡Œå±•ç¤ºæ¦‚å¿µï¼Œå®é™…è®¡ç®—ä¼šæ›´å¤æ‚
        if "å–œæ¬¢" in sentence or "æ£’" in sentence:
            ä¼¼ç„¶_æ­£é¢ = 0.8
            ä¼¼ç„¶_è´Ÿé¢ = 0.2
        else:
            ä¼¼ç„¶_æ­£é¢ = 0.3
            ä¼¼ç„¶_è´Ÿé¢ = 0.7
            
        # è®¡ç®—åéªŒæ¦‚ç‡
        P_æ­£é¢ = ä¼¼ç„¶_æ­£é¢ * self.å…ˆéªŒçŸ¥è¯†["æƒ…æ„Ÿ"]["æ­£é¢"]
        P_è´Ÿé¢ = ä¼¼ç„¶_è´Ÿé¢ * self.å…ˆéªŒçŸ¥è¯†["æƒ…æ„Ÿ"]["è´Ÿé¢"]
        
        # å½’ä¸€åŒ–
        æ€»å’Œ = P_æ­£é¢ + P_è´Ÿé¢
        return {"æ­£é¢": P_æ­£é¢/æ€»å’Œ, "è´Ÿé¢": P_è´Ÿé¢/æ€»å’Œ}
```

#### ğŸ° è¯­è¨€ç”Ÿæˆ=æ¦‚ç‡é‡‡æ ·

LLMç”Ÿæˆæ–‡æœ¬çš„è¿‡ç¨‹ï¼Œæœ¬è´¨ä¸Šå°±æ˜¯ä¸æ–­åœ°ä»æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ï¼š

```python
import numpy as np
import matplotlib.pyplot as plt

class æ¦‚ç‡é‡‡æ ·æ¼”ç¤º:
    def __init__(self):
        self.vocab = ["æˆ‘", "å–œæ¬¢", "åƒ", "è‹¹æœ", "ç¼–ç¨‹", "å­¦ä¹ ", 
                     "ä»Šå¤©", "å¤©æ°”", "å¾ˆ", "å¥½", "ã€‚"]
        
    def softmax(self, logits, temperature=1.0):
        """Softmax with temperature"""
        # Temperatureæ§åˆ¶éšæœºæ€§
        logits = np.array(logits) / temperature
        exp_logits = np.exp(logits - np.max(logits))
        return exp_logits / exp_logits.sum()
    
    def ä¸åŒé‡‡æ ·ç­–ç•¥(self, logits):
        """å±•ç¤ºä¸åŒçš„é‡‡æ ·ç­–ç•¥"""
        probs = self.softmax(logits)
        
        strategies = {
            "è´ªå¿ƒé‡‡æ ·": self.greedy_sampling,
            "éšæœºé‡‡æ ·": self.random_sampling,
            "Top-ké‡‡æ ·": self.top_k_sampling,
            "Top-pé‡‡æ ·": self.nucleus_sampling
        }
        
        results = {}
        for name, method in strategies.items():
            results[name] = method(probs)
            
        return results
    
    def greedy_sampling(self, probs):
        """æ€»æ˜¯é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„"""
        return self.vocab[np.argmax(probs)]
    
    def random_sampling(self, probs):
        """æŒ‰æ¦‚ç‡åˆ†å¸ƒéšæœºé‡‡æ ·"""
        return np.random.choice(self.vocab, p=probs)
    
    def top_k_sampling(self, probs, k=3):
        """åªä»æ¦‚ç‡æœ€é«˜çš„kä¸ªä¸­é‡‡æ ·"""
        top_k_idx = np.argsort(probs)[-k:]
        top_k_probs = probs[top_k_idx]
        top_k_probs = top_k_probs / top_k_probs.sum()
        
        idx = np.random.choice(top_k_idx, p=top_k_probs)
        return self.vocab[idx]
    
    def nucleus_sampling(self, probs, p=0.9):
        """åªä»ç´¯ç§¯æ¦‚ç‡è¾¾åˆ°pçš„è¯ä¸­é‡‡æ ·"""
        sorted_idx = np.argsort(probs)[::-1]
        sorted_probs = probs[sorted_idx]
        
        cumsum = np.cumsum(sorted_probs)
        mask = cumsum <= p
        if not mask.any():
            mask[0] = True
            
        nucleus_probs = sorted_probs[mask]
        nucleus_probs = nucleus_probs / nucleus_probs.sum()
        
        idx = np.random.choice(np.where(mask)[0], p=nucleus_probs)
        return self.vocab[sorted_idx[idx]]
    
    def å¯è§†åŒ–é‡‡æ ·ç­–ç•¥(self):
        """å¯è§†åŒ–ä¸åŒé‡‡æ ·ç­–ç•¥çš„æ•ˆæœ"""
        # æ¨¡æ‹Ÿä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ
        logits = np.random.randn(len(self.vocab)) * 2
        probs = self.softmax(logits)
        
        # æ’åºç”¨äºå±•ç¤º
        sorted_idx = np.argsort(probs)[::-1]
        sorted_vocab = [self.vocab[i] for i in sorted_idx]
        sorted_probs = probs[sorted_idx]
        
        # ç»˜å›¾
        plt.figure(figsize=(12, 8))
        
        # åŸå§‹æ¦‚ç‡åˆ†å¸ƒ
        plt.subplot(2, 2, 1)
        plt.bar(sorted_vocab, sorted_probs)
        plt.title('åŸå§‹æ¦‚ç‡åˆ†å¸ƒ')
        plt.xticks(rotation=45)
        
        # Top-k (k=3)
        plt.subplot(2, 2, 2)
        colors = ['red' if i < 3 else 'gray' for i in range(len(sorted_vocab))]
        plt.bar(sorted_vocab, sorted_probs, color=colors)
        plt.title('Top-3é‡‡æ ·ï¼ˆçº¢è‰²éƒ¨åˆ†ï¼‰')
        plt.xticks(rotation=45)
        
        # Top-p (p=0.9)
        plt.subplot(2, 2, 3)
        cumsum = np.cumsum(sorted_probs)
        colors = ['blue' if c <= 0.9 else 'gray' for c in cumsum]
        plt.bar(sorted_vocab, sorted_probs, color=colors)
        plt.title('Top-pé‡‡æ · (p=0.9)ï¼ˆè“è‰²éƒ¨åˆ†ï¼‰')
        plt.xticks(rotation=45)
        
        # Temperatureæ•ˆæœ
        plt.subplot(2, 2, 4)
        temps = [0.5, 1.0, 1.5]
        x = np.arange(len(sorted_vocab))
        width = 0.25
        
        for i, temp in enumerate(temps):
            temp_probs = self.softmax(logits[sorted_idx], temperature=temp)
            plt.bar(x + i*width, temp_probs, width, label=f'T={temp}')
        
        plt.title('Temperatureçš„å½±å“')
        plt.xticks(x + width, sorted_vocab, rotation=45)
        plt.legend()
        
        plt.tight_layout()
        plt.show()

# è¿è¡Œæ¼”ç¤º
demo = æ¦‚ç‡é‡‡æ ·æ¼”ç¤º()
demo.å¯è§†åŒ–é‡‡æ ·ç­–ç•¥()
```

#### ğŸŒ¡ï¸ Temperatureï¼šåˆ›é€ åŠ›çš„è°ƒèŠ‚å™¨

Temperatureæ˜¯æ§åˆ¶LLM"åˆ›é€ åŠ›"çš„å…³é”®å‚æ•°ï¼š

```python
def temperature_effects_demo():
    """æ¼”ç¤ºtemperatureå¯¹ç”Ÿæˆç»“æœçš„å½±å“"""
    
    # å‡è®¾è¿™æ˜¯æ¨¡å‹å¯¹ä¸‹ä¸€ä¸ªè¯çš„åŸå§‹é¢„æµ‹åˆ†æ•°
    vocab = ["å¥½", "æ£’", "ç³Ÿç³•", "æ™®é€š", "å¥‡æ€ª"]
    logits = np.array([2.0, 1.8, 0.1, 0.5, 0.3])
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    temperatures = [0.5, 1.0, 2.0]
    descriptions = ["ä¿å®ˆ(T=0.5)", "å¹³è¡¡(T=1.0)", "åˆ›æ–°(T=2.0)"]
    
    for ax, temp, desc in zip(axes, temperatures, descriptions):
        # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
        probs = np.exp(logits / temp)
        probs = probs / probs.sum()
        
        # å¯è§†åŒ–
        bars = ax.bar(vocab, probs, color=['green', 'blue', 'red', 'gray', 'orange'])
        ax.set_title(f'{desc}')
        ax.set_ylabel('æ¦‚ç‡')
        ax.set_ylim(0, 1)
        
        # æ ‡æ³¨æ¦‚ç‡å€¼
        for bar, prob in zip(bars, probs):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                   f'{prob:.2%}', ha='center', va='bottom')
    
    plt.suptitle('Temperatureå¯¹æ¦‚ç‡åˆ†å¸ƒçš„å½±å“', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    # æ¨¡æ‹Ÿå¤šæ¬¡é‡‡æ ·çš„ç»“æœ
    print("\næ¨¡æ‹Ÿ100æ¬¡é‡‡æ ·çš„ç»“æœåˆ†å¸ƒï¼š")
    for temp in temperatures:
        probs = np.exp(logits / temp)
        probs = probs / probs.sum()
        
        # é‡‡æ ·100æ¬¡
        samples = np.random.choice(vocab, size=100, p=probs)
        counts = Counter(samples)
        
        print(f"\nTemperature = {temp}:")
        for word, count in counts.most_common():
            print(f"  {word}: {count}æ¬¡ ({count}%)")

temperature_effects_demo()
```

#### ğŸ¯ å›°æƒ‘åº¦(Perplexity)ï¼šè¯­è¨€æ¨¡å‹çš„"è€ƒè¯•åˆ†æ•°"

å¦‚ä½•è¡¡é‡ä¸€ä¸ªè¯­è¨€æ¨¡å‹çš„å¥½åï¼Ÿå›°æƒ‘åº¦æ˜¯å…³é”®æŒ‡æ ‡ï¼š

```python
import math

class PerplexityDemo:
    def __init__(self):
        self.vocab = ["æˆ‘", "å–œæ¬¢", "åƒ", "è‹¹æœ", "é¦™è•‰", "ç¼–ç¨‹"]
        
    def calculate_perplexity(self, model_probs, true_sequence):
        """
        å›°æƒ‘åº¦ = 2^(-å¹³å‡å¯¹æ•°æ¦‚ç‡)
        
        ç›´è§‚ç†è§£ï¼š
        - å›°æƒ‘åº¦=2: æ¨¡å‹åœ¨æ¯ä¸€æ­¥å¹³å‡åœ¨2ä¸ªè¯ä¸­çŠ¹è±«
        - å›°æƒ‘åº¦=10: æ¨¡å‹åœ¨æ¯ä¸€æ­¥å¹³å‡åœ¨10ä¸ªè¯ä¸­çŠ¹è±«
        - å›°æƒ‘åº¦è¶Šä½ï¼Œæ¨¡å‹è¶Šç¡®å®šï¼Œé¢„æµ‹è¶Šå‡†ç¡®
        """
        total_log_prob = 0
        count = 0
        
        for i in range(len(true_sequence)-1):
            current_word = true_sequence[i]
            next_word = true_sequence[i+1]
            
            # è·å–æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡
            if current_word in model_probs and next_word in model_probs[current_word]:
                prob = model_probs[current_word][next_word]
                total_log_prob += math.log2(prob)
                count += 1
        
        # è®¡ç®—å¹³å‡å¯¹æ•°æ¦‚ç‡
        avg_log_prob = total_log_prob / count if count > 0 else float('-inf')
        
        # è®¡ç®—å›°æƒ‘åº¦
        perplexity = 2 ** (-avg_log_prob)
        
        return perplexity
    
    def compare_models(self):
        """æ¯”è¾ƒä¸åŒæ¨¡å‹çš„å›°æƒ‘åº¦"""
        test_sequence = ["æˆ‘", "å–œæ¬¢", "åƒ", "è‹¹æœ"]
        
        # æ¨¡å‹1ï¼šå‡åŒ€åˆ†å¸ƒï¼ˆæœ€å·®çš„æ¨¡å‹ï¼‰
        uniform_model = {}
        for word in self.vocab:
            uniform_model[word] = {w: 1/len(self.vocab) for w in self.vocab}
        
        # æ¨¡å‹2ï¼šæœ‰ä¸€å®šè§„å¾‹çš„æ¨¡å‹
        smart_model = {
            "æˆ‘": {"å–œæ¬¢": 0.6, "åƒ": 0.3, "è‹¹æœ": 0.05, "é¦™è•‰": 0.05},
            "å–œæ¬¢": {"åƒ": 0.5, "ç¼–ç¨‹": 0.4, "è‹¹æœ": 0.05, "é¦™è•‰": 0.05},
            "åƒ": {"è‹¹æœ": 0.4, "é¦™è•‰": 0.4, "æˆ‘": 0.1, "å–œæ¬¢": 0.1}
        }
        
        # è®¡ç®—å›°æƒ‘åº¦
        pp_uniform = self.calculate_perplexity(uniform_model, test_sequence)
        pp_smart = self.calculate_perplexity(smart_model, test_sequence)
        
        print(f"å‡åŒ€åˆ†å¸ƒæ¨¡å‹çš„å›°æƒ‘åº¦: {pp_uniform:.2f}")
        print(f"æ™ºèƒ½æ¨¡å‹çš„å›°æƒ‘åº¦: {pp_smart:.2f}")
        print(f"\nè§£é‡Šï¼šæ™ºèƒ½æ¨¡å‹çš„å›°æƒ‘åº¦æ›´ä½ï¼Œè¯´æ˜å®ƒå¯¹è¯­è¨€çš„ç†è§£æ›´å¥½")
        
        # å¯è§†åŒ–
        self.visualize_perplexity_meaning()
    
    def visualize_perplexity_meaning(self):
        """å¯è§†åŒ–å›°æƒ‘åº¦çš„å«ä¹‰"""
        perplexities = [2, 5, 10, 50, 100]
        
        plt.figure(figsize=(12, 6))
        
        # å­å›¾1ï¼šå›°æƒ‘åº¦vså¹³å‡é€‰æ‹©æ•°
        plt.subplot(1, 2, 1)
        plt.bar([str(p) for p in perplexities], perplexities, 
               color=['green', 'yellow', 'orange', 'red', 'darkred'])
        plt.xlabel('å›°æƒ‘åº¦')
        plt.ylabel('å¹³å‡é€‰æ‹©æ•°')
        plt.title('å›°æƒ‘åº¦çš„ç›´è§‚å«ä¹‰')
        
        # æ·»åŠ æ ‡æ³¨
        for i, p in enumerate(perplexities):
            plt.text(i, p + 2, f'å¹³å‡åœ¨{p}ä¸ªè¯ä¸­é€‰æ‹©', ha='center')
        
        # å­å›¾2ï¼šå›°æƒ‘åº¦vsæ¨¡å‹è´¨é‡
        plt.subplot(1, 2, 2)
        quality = [95, 80, 60, 30, 10]  # å‡è®¾çš„è´¨é‡åˆ†æ•°
        plt.plot(perplexities, quality, 'o-', linewidth=2, markersize=10)
        plt.xlabel('å›°æƒ‘åº¦')
        plt.ylabel('æ¨¡å‹è´¨é‡ (%)')
        plt.title('å›°æƒ‘åº¦ä¸æ¨¡å‹è´¨é‡çš„å…³ç³»')
        plt.gca().invert_xaxis()  # åè½¬xè½´ï¼Œå› ä¸ºå›°æƒ‘åº¦è¶Šä½è¶Šå¥½
        
        plt.tight_layout()
        plt.show()

# è¿è¡Œæ¼”ç¤º
demo = PerplexityDemo()
demo.compare_models()
```

#### ğŸ”® ä»æ¦‚ç‡åˆ°æ™ºèƒ½ï¼šæ¶Œç°çš„é­”æ³•

å½“æ¨¡å‹è§„æ¨¡è¶³å¤Ÿå¤§æ—¶ï¼Œç®€å•çš„"é¢„æµ‹ä¸‹ä¸€ä¸ªè¯"ç«Ÿç„¶èƒ½äº§ç”Ÿæ™ºèƒ½ï¼

```python
class æ¶Œç°ç°è±¡æ¼”ç¤º:
    def __init__(self):
        self.å°æ¨¡å‹èƒ½åŠ› = ["å®Œæˆå¥å­", "ç®€å•é—®ç­”"]
        self.ä¸­æ¨¡å‹èƒ½åŠ› = ["ç†è§£ä¸Šä¸‹æ–‡", "åŸºç¡€æ¨ç†", "ç®€å•ç¿»è¯‘"]
        self.å¤§æ¨¡å‹èƒ½åŠ› = ["å¤æ‚æ¨ç†", "åˆ›ä½œ", "ä»£ç ç”Ÿæˆ", "å¤šè¯­è¨€ç†è§£"]
        
    def å±•ç¤ºèƒ½åŠ›æ¶Œç°(self):
        """å±•ç¤ºæ¨¡å‹è§„æ¨¡ä¸èƒ½åŠ›çš„å…³ç³»"""
        import numpy as np
        
        # æ¨¡å‹å‚æ•°é‡ï¼ˆå•ä½ï¼šç™¾ä¸‡ï¼‰
        model_sizes = [10, 100, 1000, 10000, 100000]
        
        # ä¸åŒèƒ½åŠ›åœ¨ä¸åŒè§„æ¨¡ä¸‹çš„è¡¨ç°
        abilities = {
            "åŸºç¡€è¯­è¨€ç†è§£": [30, 60, 85, 95, 98],
            "é€»è¾‘æ¨ç†": [5, 15, 40, 80, 95],
            "åˆ›é€ æ€§å†™ä½œ": [2, 10, 30, 70, 90],
            "ä»£ç ç”Ÿæˆ": [0, 5, 25, 75, 95],
            "è·¨è¯­è¨€ç†è§£": [0, 0, 20, 60, 85]
        }
        
        plt.figure(figsize=(12, 8))
        
        for ability, scores in abilities.items():
            plt.plot(model_sizes, scores, 'o-', label=ability, linewidth=2, markersize=8)
        
        plt.xscale('log')
        plt.xlabel('æ¨¡å‹å‚æ•°é‡ï¼ˆç™¾ä¸‡ï¼‰')
        plt.ylabel('èƒ½åŠ›å¾—åˆ† (%)')
        plt.title('æ¨¡å‹è§„æ¨¡ä¸èƒ½åŠ›æ¶Œç°')
        plt.legend(loc='lower right')
        plt.grid(True, alpha=0.3)
        
        # æ ‡æ³¨æ¶Œç°ç‚¹
        plt.axvline(x=1000, color='red', linestyle='--', alpha=0.5)
        plt.text(1000, 50, 'èƒ½åŠ›æ¶Œç°ç‚¹', rotation=90, va='bottom', ha='right')
        
        plt.show()
    
    def æ¦‚ç‡çš„å“²å­¦(self):
        """æ¢è®¨æ¦‚ç‡æ¨¡å‹ä¸ºä½•èƒ½äº§ç”Ÿæ™ºèƒ½"""
        print("ğŸ¤” æ·±åº¦æ€è€ƒï¼šä¸ºä»€ä¹ˆæ¦‚ç‡æ¨¡å‹èƒ½äº§ç”Ÿæ™ºèƒ½ï¼Ÿ\n")
        
        insights = [
            "1. è¯­è¨€æœ¬èº«å°±æ˜¯æ¦‚ç‡çš„ - æˆ‘ä»¬è¯´è¯æ—¶ä¹Ÿåœ¨æ— æ„è¯†åœ°é€‰æ‹©æœ€å¯èƒ½çš„è¯",
            "2. è¶³å¤Ÿçš„æ•°æ®åŒ…å«äº†äººç±»çŸ¥è¯† - æ¨¡å‹ä»ä¸­å­¦ä¹ æ¨¡å¼",
            "3. æ·±åº¦ç½‘ç»œèƒ½æ•æ‰å¤æ‚å…³ç³» - ä¸åªæ˜¯è¡¨é¢çš„è¯åº",
            "4. è§„æ¨¡å¸¦æ¥è´¨å˜ - é‡å˜å¼•èµ·è´¨å˜çš„å“²å­¦åŸç†",
            "5. æ³¨æ„åŠ›æœºåˆ¶æ¨¡æ‹Ÿäººç±»æ€è€ƒ - å…³æ³¨ç›¸å…³ä¿¡æ¯"
        ]
        
        for insight in insights:
            print(f"ğŸ’¡ {insight}")
        
        print("\nğŸ“Š ä¸€ä¸ªæ€æƒ³å®éªŒï¼š")
        print("å¦‚æœä¸€ä¸ªç³»ç»Ÿèƒ½å¤Ÿå®Œç¾é¢„æµ‹äººç±»çš„ä¸‹ä¸€ä¸ªè¯ï¼Œ")
        print("é‚£å®ƒæ˜¯å¦å°±'ç†è§£'äº†äººç±»çš„è¯­è¨€ï¼Ÿ")
        print("è¿™å°±æ˜¯è¯­è¨€æ¨¡å‹æ™ºèƒ½çš„å“²å­¦åŸºç¡€ã€‚")

# è¿è¡Œæ¼”ç¤º
emergence = æ¶Œç°ç°è±¡æ¼”ç¤º()
emergence.å±•ç¤ºèƒ½åŠ›æ¶Œç°()
emergence.æ¦‚ç‡çš„å“²å­¦()
```

#### ğŸ“ æœ¬ç« å°ç»“

1. **LLMçš„æœ¬è´¨æ˜¯æ¦‚ç‡æ¨¡å‹**ï¼šç»™å®šä¸Šæ–‡ï¼Œé¢„æµ‹ä¸‹æ–‡çš„æ¦‚ç‡åˆ†å¸ƒ
2. **ç”Ÿæˆå³é‡‡æ ·**ï¼šä»æ¦‚ç‡åˆ†å¸ƒä¸­é€‰æ‹©ä¸‹ä¸€ä¸ªtoken
3. **Temperatureæ§åˆ¶åˆ›é€ åŠ›**ï¼šé«˜æ¸©åº¦æ›´éšæœºï¼Œä½æ¸©åº¦æ›´ç¡®å®š
4. **å›°æƒ‘åº¦è¡¡é‡æ¨¡å‹è´¨é‡**ï¼šè¶Šä½è¶Šå¥½ï¼Œè¡¨ç¤ºæ¨¡å‹è¶Š"ä¸å›°æƒ‘"
5. **è§„æ¨¡å¸¦æ¥æ¶Œç°**ï¼šç®€å•çš„æ¦‚ç‡é¢„æµ‹åœ¨å¤§è§„æ¨¡ä¸‹äº§ç”Ÿæ™ºèƒ½

#### ğŸ’­ æ€è€ƒé¢˜

1. å¦‚æœLLMåªæ˜¯åœ¨åšæ¦‚ç‡é¢„æµ‹ï¼Œä¸ºä»€ä¹ˆå®ƒèƒ½å†™è¯—ã€ç¼–ç¨‹ã€ç”šè‡³æ¨ç†ï¼Ÿ
2. Temperature=0ï¼ˆå®Œå…¨ç¡®å®šï¼‰çš„æ¨¡å‹æ˜¯å¦æ€»æ˜¯æœ€å¥½çš„ï¼Ÿ
3. äººç±»çš„è¯­è¨€ä½¿ç”¨ä¹Ÿæ˜¯æ¦‚ç‡æ€§çš„å—ï¼Ÿæˆ‘ä»¬å’ŒLLMæœ‰ä»€ä¹ˆæœ¬è´¨åŒºåˆ«ï¼Ÿ

#### ğŸ” åŠ¨æ‰‹å®éªŒ

```python
# å®éªŒï¼šæ„å»ºä¸€ä¸ªè¿·ä½ è¯­è¨€æ¨¡å‹
class MiniLM:
    """ä¸€ä¸ªæç®€çš„è¯­è¨€æ¨¡å‹ï¼Œå¸®åŠ©ç†è§£æ ¸å¿ƒæ¦‚å¿µ"""
    
    def __init__(self):
        # è®­ç»ƒæ•°æ®
        self.data = [
            "æˆ‘å–œæ¬¢å­¦ä¹ äººå·¥æ™ºèƒ½",
            "äººå·¥æ™ºèƒ½æ”¹å˜ä¸–ç•Œ",
            "å­¦ä¹ ä½¿äººè¿›æ­¥",
            "æˆ‘å–œæ¬¢äººå·¥æ™ºèƒ½"
        ]
        
        # æ„å»ºè¯è¡¨
        self.build_vocab()
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆç»Ÿè®¡æ¦‚ç‡ï¼‰
        self.train()
    
    def build_vocab(self):
        """æ„å»ºè¯è¡¨"""
        self.word_to_id = {}
        self.id_to_word = {}
        
        # æ·»åŠ ç‰¹æ®Šæ ‡è®°
        self.word_to_id["<START>"] = 0
        self.word_to_id["<END>"] = 1
        
        # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„è¯
        word_id = 2
        for sentence in self.data:
            for word in sentence:
                if word not in self.word_to_id:
                    self.word_to_id[word] = word_id
                    self.id_to_word[word_id] = word
                    word_id += 1
        
        self.id_to_word[0] = "<START>"
        self.id_to_word[1] = "<END>"
        self.vocab_size = len(self.word_to_id)
    
    def train(self):
        """è®­ç»ƒæ¨¡å‹ï¼ˆè®¡ç®—è½¬ç§»æ¦‚ç‡ï¼‰"""
        # åˆå§‹åŒ–è®¡æ•°çŸ©é˜µ
        self.counts = np.zeros((self.vocab_size, self.vocab_size))
        
        for sentence in self.data:
            # æ·»åŠ å¼€å§‹å’Œç»“æŸæ ‡è®°
            words = ["<START>"] + list(sentence) + ["<END>"]
            
            # ç»Ÿè®¡bigram
            for i in range(len(words)-1):
                current_id = self.word_to_id[words[i]]
                next_id = self.word_to_id[words[i+1]]
                self.counts[current_id, next_id] += 1
        
        # è½¬æ¢ä¸ºæ¦‚ç‡
        self.probs = self.counts / (self.counts.sum(axis=1, keepdims=True) + 1e-8)
    
    def generate(self, max_length=20, temperature=1.0):
        """ç”Ÿæˆæ–‡æœ¬"""
        result = []
        current_id = 0  # ä»<START>å¼€å§‹
        
        for _ in range(max_length):
            # è·å–ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒ
            prob_dist = self.probs[current_id]
            
            # åº”ç”¨temperature
            if temperature != 1.0:
                # è½¬æ¢å›logitsï¼Œåº”ç”¨temperatureï¼Œå†è½¬å›æ¦‚ç‡
                logits = np.log(prob_dist + 1e-8)
                logits = logits / temperature
                prob_dist = np.exp(logits) / np.exp(logits).sum()
            
            # é‡‡æ ·
            next_id = np.random.choice(self.vocab_size, p=prob_dist)
            
            # æ£€æŸ¥æ˜¯å¦ç»“æŸ
            if next_id == 1:  # <END>
                break
            
            # æ·»åŠ è¯åˆ°ç»“æœ
            if next_id > 1:  # è·³è¿‡ç‰¹æ®Šæ ‡è®°
                result.append(self.id_to_word[next_id])
            
            current_id = next_id
        
        return ''.join(result)
    
    def demo(self):
        """æ¼”ç¤ºä¸åŒtemperatureçš„ç”Ÿæˆæ•ˆæœ"""
        print("ğŸ¤– è¿·ä½ è¯­è¨€æ¨¡å‹æ¼”ç¤º\n")
        print("è®­ç»ƒæ•°æ®ï¼š")
        for s in self.data:
            print(f"  - {s}")
        
        print("\nç”Ÿæˆç»“æœï¼š")
        for temp in [0.5, 1.0, 1.5]:
            print(f"\nTemperature = {temp}:")
            for _ in range(3):
                generated = self.generate(temperature=temp)
                print(f"  - {generated}")

# è¿è¡Œè¿·ä½ è¯­è¨€æ¨¡å‹
mini_lm = MiniLM()
mini_lm.demo()
```

ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†å­¦ä¹ ç¥ç»ç½‘ç»œåŸºç¡€ï¼Œçœ‹çœ‹å¦‚ä½•ç”¨ç¥ç»ç½‘ç»œæ¥å®ç°æ›´å¼ºå¤§çš„æ¦‚ç‡æ¨¡å‹ï¼

---

### ç¬¬3ç« ï¼šç¥ç»ç½‘ç»œåŸºç¡€â€”â€”ä»æ„ŸçŸ¥æœºåˆ°æ·±åº¦å­¦ä¹ 

#### ğŸ¯ æœ¬ç« å¯¼è¯»

è¿˜è®°å¾—å°æ—¶å€™ç¬¬ä¸€æ¬¡å­¦éª‘è‡ªè¡Œè½¦å—ï¼Ÿä¸€å¼€å§‹ä½ æ‘‡æ‘‡æ™ƒæ™ƒï¼Œå¤§è„‘ç–¯ç‹‚è®¡ç®—ï¼š"å·¦è¾¹å€’äº†å¾€å³æ‰¶ï¼Œå³è¾¹å€’äº†å¾€å·¦æ‰¶"ã€‚æ‘”äº†å‡ æ¬¡åï¼Œç¥å¥‡çš„äº‹æƒ…å‘ç”Ÿäº†â€”â€”ä½ ä¸å†éœ€è¦æ€è€ƒï¼Œèº«ä½“è‡ªåŠ¨å°±çŸ¥é“è¯¥æ€ä¹ˆä¿æŒå¹³è¡¡ã€‚

è¿™å°±æ˜¯ç¥ç»ç½‘ç»œçš„é­…åŠ›ï¼šé€šè¿‡ä¸æ–­çš„"æ‘”è·¤"ï¼ˆè®­ç»ƒï¼‰ï¼Œå®ƒèƒ½å­¦ä¼šå¤æ‚çš„æ¨¡å¼ï¼Œæœ€ç»ˆåƒä½ éª‘è½¦ä¸€æ ·è‡ªå¦‚åœ°å¤„ç†å„ç§ä»»åŠ¡ã€‚

ä»Šå¤©ï¼Œè®©æˆ‘ä»¬ä»æœ€ç®€å•çš„"ç¥ç»å…ƒ"å¼€å§‹ï¼Œä¸€æ­¥æ­¥æ„å»ºèµ·æ·±åº¦å­¦ä¹ çš„æ‘©å¤©å¤§æ¥¼ã€‚

#### ğŸ§  ä»ç”Ÿç‰©ç¥ç»å…ƒåˆ°äººå·¥ç¥ç»å…ƒ

##### ç”Ÿç‰©ç¥ç»å…ƒï¼šå¤§è‡ªç„¶çš„æ°ä½œ

```python
# ç”¨ä»£ç æ¨¡æ‹Ÿç”Ÿç‰©ç¥ç»å…ƒçš„å·¥ä½œåŸç†
class ç”Ÿç‰©ç¥ç»å…ƒæ¨¡æ‹Ÿ:
    def __init__(self):
        self.name = "è§†è§‰ç¥ç»å…ƒ"
        self.threshold = 0.5  # æ¿€æ´»é˜ˆå€¼
        
    def æ¥æ”¶ä¿¡å·(self, inputs):
        """
        ç”Ÿç‰©ç¥ç»å…ƒçš„å·¥ä½œè¿‡ç¨‹ï¼š
        1. æ ‘çªæ¥æ”¶ä¿¡å·
        2. ç»†èƒä½“æ•´åˆä¿¡å·
        3. å¦‚æœè¶…è¿‡é˜ˆå€¼ï¼Œè½´çªå‘å‡ºä¿¡å·
        """
        # æ•´åˆæ‰€æœ‰è¾“å…¥ä¿¡å·
        æ€»ä¿¡å·å¼ºåº¦ = sum(inputs)
        
        # åˆ¤æ–­æ˜¯å¦æ¿€æ´»
        if æ€»ä¿¡å·å¼ºåº¦ > self.threshold:
            print(f"{self.name}è¢«æ¿€æ´»äº†ï¼çœ‹åˆ°äº†ä»€ä¹ˆä¸œè¥¿ï¼")
            return 1  # å‘å‡ºä¿¡å·
        else:
            print(f"{self.name}æ²¡ååº”ï¼Œä¿¡å·å¤ªå¼±")
            return 0  # ä¿æŒæ²‰é»˜

# æ¨¡æ‹Ÿè§†è§‰è¯†åˆ«
neuron = ç”Ÿç‰©ç¥ç»å…ƒæ¨¡æ‹Ÿ()
neuron.æ¥æ”¶ä¿¡å·([0.1, 0.2, 0.1])  # æ˜æš—çš„å…‰çº¿
neuron.æ¥æ”¶ä¿¡å·([0.3, 0.4, 0.5])  # æ˜äº®çš„å…‰çº¿
```

##### äººå·¥ç¥ç»å…ƒï¼šæ•°å­¦çš„æ¨¡ä»¿

ç”Ÿç‰©ç¥ç»å…ƒå¯å‘äº†äººå·¥ç¥ç»å…ƒçš„è®¾è®¡ï¼Œä½†æˆ‘ä»¬ç”¨æ›´ç®€æ´çš„æ•°å­¦æ¨¡å‹ï¼š

```python
import numpy as np
import matplotlib.pyplot as plt

class Perceptron:
    """æ„ŸçŸ¥æœºï¼šæœ€ç®€å•çš„äººå·¥ç¥ç»å…ƒ"""
    
    def __init__(self, n_inputs, learning_rate=0.1):
        # éšæœºåˆå§‹åŒ–æƒé‡ï¼ˆæƒ³è±¡æˆæ¯ä¸ªè¾“å…¥çš„"é‡è¦æ€§"ï¼‰
        self.weights = np.random.randn(n_inputs) * 0.01
        self.bias = 0  # åç½®ï¼ˆæƒ³è±¡æˆç¥ç»å…ƒçš„"æ•æ„Ÿåº¦"ï¼‰
        self.learning_rate = learning_rate
        
    def activate(self, x):
        """æ¿€æ´»å‡½æ•°ï¼šè¶…è¿‡0å°±è¾“å‡º1ï¼Œå¦åˆ™è¾“å‡º0"""
        return 1 if x > 0 else 0
    
    def predict(self, inputs):
        """é¢„æµ‹ï¼šè®¡ç®—åŠ æƒå’Œï¼Œç„¶åæ¿€æ´»"""
        # è¿™å°±åƒç¥ç»å…ƒåœ¨"æ•´åˆ"æ‰€æœ‰è¾“å…¥ä¿¡å·
        weighted_sum = np.dot(inputs, self.weights) + self.bias
        return self.activate(weighted_sum)
    
    def train(self, X, y, epochs=10):
        """è®­ç»ƒï¼šé€šè¿‡é”™è¯¯æ¥å­¦ä¹ """
        errors = []
        
        for epoch in range(epochs):
            total_error = 0
            for inputs, target in zip(X, y):
                # é¢„æµ‹
                prediction = self.predict(inputs)
                
                # è®¡ç®—è¯¯å·®
                error = target - prediction
                total_error += abs(error)
                
                # æ›´æ–°æƒé‡ï¼ˆè¿™å°±æ˜¯"å­¦ä¹ "çš„è¿‡ç¨‹ï¼‰
                self.weights += self.learning_rate * error * inputs
                self.bias += self.learning_rate * error
            
            errors.append(total_error)
            print(f"Epoch {epoch+1}, æ€»è¯¯å·®: {total_error}")
        
        return errors

# è®©æˆ‘ä»¬ç”¨æ„ŸçŸ¥æœºè§£å†³ä¸€ä¸ªç®€å•é—®é¢˜ï¼šANDé€»è¾‘
def æ„ŸçŸ¥æœºå­¦ä¹ ANDé€»è¾‘():
    # è®­ç»ƒæ•°æ®
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([0, 0, 0, 1])  # ANDçš„çœŸå€¼è¡¨
    
    # åˆ›å»ºå¹¶è®­ç»ƒæ„ŸçŸ¥æœº
    perceptron = Perceptron(n_inputs=2)
    errors = perceptron.train(X, y, epochs=10)
    
    # å¯è§†åŒ–å­¦ä¹ è¿‡ç¨‹
    plt.figure(figsize=(12, 5))
    
    # å­å›¾1ï¼šè¯¯å·®æ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(errors, 'b-o')
    plt.xlabel('è®­ç»ƒè½®æ¬¡')
    plt.ylabel('æ€»è¯¯å·®')
    plt.title('æ„ŸçŸ¥æœºå­¦ä¹ æ›²çº¿')
    plt.grid(True, alpha=0.3)
    
    # å­å›¾2ï¼šå†³ç­–è¾¹ç•Œ
    plt.subplot(1, 2, 2)
    # ç»˜åˆ¶æ•°æ®ç‚¹
    colors = ['red' if label == 0 else 'blue' for label in y]
    plt.scatter(X[:, 0], X[:, 1], c=colors, s=100, edgecolors='black')
    
    # ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
    x_min, x_max = -0.5, 1.5
    y_min, y_max = -0.5, 1.5
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                         np.linspace(y_min, y_max, 100))
    Z = np.array([perceptron.predict([x, y]) 
                  for x, y in zip(xx.ravel(), yy.ravel())])
    Z = Z.reshape(xx.shape)
    
    plt.contourf(xx, yy, Z, alpha=0.3, cmap='RdBu')
    plt.xlabel('è¾“å…¥1')
    plt.ylabel('è¾“å…¥2')
    plt.title('ANDé€»è¾‘çš„å†³ç­–è¾¹ç•Œ')
    plt.legend(['0 (False)', '1 (True)'])
    
    plt.tight_layout()
    plt.show()
    
    # æµ‹è¯•
    print("\næµ‹è¯•ç»“æœ:")
    for inputs in X:
        output = perceptron.predict(inputs)
        print(f"{inputs[0]} AND {inputs[1]} = {output}")

æ„ŸçŸ¥æœºå­¦ä¹ ANDé€»è¾‘()
```

#### âš¡ æ„ŸçŸ¥æœºçš„å±€é™ï¼šXORé—®é¢˜

æ„ŸçŸ¥æœºå¾ˆå¼ºå¤§ï¼Œä½†å®ƒæœ‰ä¸ªè‡´å‘½å¼±ç‚¹â€”â€”åªèƒ½è§£å†³çº¿æ€§å¯åˆ†çš„é—®é¢˜ã€‚è®©æˆ‘çœ‹çœ‹è‘—åçš„XORé—®é¢˜ï¼š

```python
def æ„ŸçŸ¥æœºçš„å±€é™æ€§():
    """æ¼”ç¤ºæ„ŸçŸ¥æœºæ— æ³•è§£å†³XORé—®é¢˜"""
    
    # XORæ•°æ®
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([0, 1, 1, 0])  # XORçš„çœŸå€¼è¡¨
    
    # å¯è§†åŒ–XORæ•°æ®
    plt.figure(figsize=(8, 6))
    colors = ['red' if label == 0 else 'blue' for label in y]
    plt.scatter(X[:, 0], X[:, 1], c=colors, s=200, edgecolors='black')
    
    # å°è¯•ç”»ä¸€æ¡ç›´çº¿åˆ†å¼€çº¢ç‚¹å’Œè“ç‚¹
    plt.plot([0, 1], [1, 0], 'g--', linewidth=2, label='å°è¯•çš„åˆ†å‰²çº¿')
    
    plt.xlabel('è¾“å…¥1', fontsize=12)
    plt.ylabel('è¾“å…¥2', fontsize=12)
    plt.title('XORé—®é¢˜ï¼šå•æ¡ç›´çº¿æ— æ³•åˆ†å‰²ï¼', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ æ ‡æ³¨
    for i, (x, y_val) in enumerate(zip(X, y)):
        plt.annotate(f'XOR={y_val}', (x[0], x[1]), 
                    xytext=(5, 5), textcoords='offset points')
    
    plt.show()
    
    print("ğŸ’¡ å…³é”®æ´å¯Ÿï¼š")
    print("XORé—®é¢˜éœ€è¦è‡³å°‘ä¸¤æ¡çº¿æ‰èƒ½åˆ†å‰²ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆéœ€è¦å¤šå±‚ç¥ç»ç½‘ç»œï¼")

æ„ŸçŸ¥æœºçš„å±€é™æ€§()
```

#### ğŸ—ï¸ ä»å•å±‚åˆ°å¤šå±‚ï¼šæ·±åº¦çš„åŠ›é‡

è§£å†³XORé—®é¢˜çš„å…³é”®æ˜¯å¢åŠ å±‚æ•°ã€‚è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªä¸¤å±‚ç¥ç»ç½‘ç»œï¼š

```python
class TwoLayerNetwork:
    """ä¸¤å±‚ç¥ç»ç½‘ç»œï¼šå¯ä»¥è§£å†³XORé—®é¢˜ï¼"""
    
    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.5):
        # ç¬¬ä¸€å±‚æƒé‡ï¼ˆè¾“å…¥å±‚ -> éšè—å±‚ï¼‰
        self.W1 = np.random.randn(input_size, hidden_size) * 0.5
        self.b1 = np.zeros((1, hidden_size))
        
        # ç¬¬äºŒå±‚æƒé‡ï¼ˆéšè—å±‚ -> è¾“å‡ºå±‚ï¼‰
        self.W2 = np.random.randn(hidden_size, output_size) * 0.5
        self.b2 = np.zeros((1, output_size))
        
        self.learning_rate = learning_rate
        
    def sigmoid(self, x):
        """Sigmoidæ¿€æ´»å‡½æ•°ï¼šæŠŠä»»æ„å€¼å‹ç¼©åˆ°0-1ä¹‹é—´"""
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        """Sigmoidçš„å¯¼æ•°ï¼šç”¨äºåå‘ä¼ æ’­"""
        return x * (1 - x)
    
    def forward(self, X):
        """å‰å‘ä¼ æ’­ï¼šä¿¡å·ä»è¾“å…¥å±‚æµå‘è¾“å‡ºå±‚"""
        # ç¬¬ä¸€å±‚
        self.z1 = np.dot(X, self.W1) + self.b1
        self.a1 = self.sigmoid(self.z1)
        
        # ç¬¬äºŒå±‚
        self.z2 = np.dot(self.a1, self.W2) + self.b2
        self.a2 = self.sigmoid(self.z2)
        
        return self.a2
    
    def backward(self, X, y, output):
        """åå‘ä¼ æ’­ï¼šè¯¯å·®ä»è¾“å‡ºå±‚æµå‘è¾“å…¥å±‚"""
        m = X.shape[0]
        
        # è®¡ç®—è¾“å‡ºå±‚çš„è¯¯å·®
        self.dz2 = output - y
        self.dW2 = (1/m) * np.dot(self.a1.T, self.dz2)
        self.db2 = (1/m) * np.sum(self.dz2, axis=0, keepdims=True)
        
        # è®¡ç®—éšè—å±‚çš„è¯¯å·®
        self.da1 = np.dot(self.dz2, self.W2.T)
        self.dz1 = self.da1 * self.sigmoid_derivative(self.a1)
        self.dW1 = (1/m) * np.dot(X.T, self.dz1)
        self.db1 = (1/m) * np.sum(self.dz1, axis=0, keepdims=True)
        
        # æ›´æ–°æƒé‡
        self.W2 -= self.learning_rate * self.dW2
        self.b2 -= self.learning_rate * self.db2
        self.W1 -= self.learning_rate * self.dW1
        self.b1 -= self.learning_rate * self.db1
    
    def train(self, X, y, epochs=1000):
        """è®­ç»ƒç½‘ç»œ"""
        losses = []
        
        for epoch in range(epochs):
            # å‰å‘ä¼ æ’­
            output = self.forward(X)
            
            # è®¡ç®—æŸå¤±
            loss = np.mean((output - y) ** 2)
            losses.append(loss)
            
            # åå‘ä¼ æ’­
            self.backward(X, y, output)
            
            # æ¯100è½®æ‰“å°ä¸€æ¬¡
            if epoch % 100 == 0:
                print(f"Epoch {epoch}, Loss: {loss:.4f}")
        
        return losses

def ç¥ç»ç½‘ç»œè§£å†³XOR():
    """ä½¿ç”¨ä¸¤å±‚ç¥ç»ç½‘ç»œè§£å†³XORé—®é¢˜"""
    
    # XORæ•°æ®
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([[0], [1], [1], [0]])
    
    # åˆ›å»ºå¹¶è®­ç»ƒç½‘ç»œ
    nn = TwoLayerNetwork(input_size=2, hidden_size=4, output_size=1)
    losses = nn.train(X, y, epochs=1000)
    
    # å¯è§†åŒ–ç»“æœ
    plt.figure(figsize=(15, 5))
    
    # å­å›¾1ï¼šæŸå¤±æ›²çº¿
    plt.subplot(1, 3, 1)
    plt.plot(losses)
    plt.xlabel('è®­ç»ƒè½®æ¬¡')
    plt.ylabel('æŸå¤±')
    plt.title('è®­ç»ƒæŸå¤±æ›²çº¿')
    plt.yscale('log')
    plt.grid(True, alpha=0.3)
    
    # å­å›¾2ï¼šç½‘ç»œç»“æ„å¯è§†åŒ–
    plt.subplot(1, 3, 2)
    visualize_network_architecture(nn)
    
    # å­å›¾3ï¼šå†³ç­–è¾¹ç•Œ
    plt.subplot(1, 3, 3)
    plot_decision_boundary(nn, X, y)
    
    plt.tight_layout()
    plt.show()
    
    # æµ‹è¯•
    print("\næµ‹è¯•ç»“æœ:")
    for inputs in X:
        output = nn.forward(inputs.reshape(1, -1))
        print(f"{inputs[0]} XOR {inputs[1]} = {output[0, 0]:.3f} â‰ˆ {int(output[0, 0] > 0.5)}")

def visualize_network_architecture(nn):
    """å¯è§†åŒ–ç¥ç»ç½‘ç»œç»“æ„"""
    # è¿™é‡Œç”»ä¸€ä¸ªç®€åŒ–çš„ç½‘ç»œç»“æ„å›¾
    ax = plt.gca()
    ax.set_xlim(-0.5, 2.5)
    ax.set_ylim(-0.5, 4.5)
    
    # è¾“å…¥å±‚
    input_neurons = [(0, 1), (0, 3)]
    # éšè—å±‚
    hidden_neurons = [(1, 0), (1, 1.5), (1, 2.5), (1, 4)]
    # è¾“å‡ºå±‚
    output_neurons = [(2, 2)]
    
    # ç”»ç¥ç»å…ƒ
    for x, y in input_neurons:
        circle = plt.Circle((x, y), 0.2, color='lightblue', ec='black')
        ax.add_patch(circle)
        ax.text(x, y, 'X', ha='center', va='center')
    
    for x, y in hidden_neurons:
        circle = plt.Circle((x, y), 0.2, color='lightgreen', ec='black')
        ax.add_patch(circle)
        ax.text(x, y, 'H', ha='center', va='center')
    
    for x, y in output_neurons:
        circle = plt.Circle((x, y), 0.2, color='lightcoral', ec='black')
        ax.add_patch(circle)
        ax.text(x, y, 'Y', ha='center', va='center')
    
    # ç”»è¿æ¥
    for in_n in input_neurons:
        for hid_n in hidden_neurons:
            ax.plot([in_n[0], hid_n[0]], [in_n[1], hid_n[1]], 
                   'gray', alpha=0.5, linewidth=1)
    
    for hid_n in hidden_neurons:
        for out_n in output_neurons:
            ax.plot([hid_n[0], out_n[0]], [hid_n[1], out_n[1]], 
                   'gray', alpha=0.5, linewidth=1)
    
    ax.set_title('ä¸¤å±‚ç¥ç»ç½‘ç»œç»“æ„')
    ax.axis('off')

def plot_decision_boundary(model, X, y):
    """ç»˜åˆ¶å†³ç­–è¾¹ç•Œ"""
    # åˆ›å»ºç½‘æ ¼
    x_min, x_max = -0.5, 1.5
    y_min, y_max = -0.5, 1.5
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                         np.linspace(y_min, y_max, 100))
    
    # é¢„æµ‹ç½‘æ ¼ä¸Šçš„æ¯ä¸ªç‚¹
    grid_points = np.c_[xx.ravel(), yy.ravel()]
    Z = model.forward(grid_points)
    Z = Z.reshape(xx.shape)
    
    # ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
    plt.contourf(xx, yy, Z, levels=[0, 0.5, 1], alpha=0.3, colors=['red', 'blue'])
    
    # ç»˜åˆ¶æ•°æ®ç‚¹
    colors = ['red' if label[0] == 0 else 'blue' for label in y]
    plt.scatter(X[:, 0], X[:, 1], c=colors, s=100, edgecolors='black')
    
    plt.xlabel('è¾“å…¥1')
    plt.ylabel('è¾“å…¥2')
    plt.title('XORé—®é¢˜çš„å†³ç­–è¾¹ç•Œ')
    plt.grid(True, alpha=0.3)

# è¿è¡Œæ¼”ç¤º
ç¥ç»ç½‘ç»œè§£å†³XOR()
```

#### ğŸ¨ æ¿€æ´»å‡½æ•°ï¼šç»™ç¥ç»ç½‘ç»œæ³¨å…¥"çµé­‚"

æ¿€æ´»å‡½æ•°æ˜¯ç¥ç»ç½‘ç»œçš„ç§˜å¯†æ­¦å™¨ï¼Œå®ƒè®©ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ éçº¿æ€§æ¨¡å¼ï¼š

```python
def æ¿€æ´»å‡½æ•°å¤§æ¯”æ‹¼():
    """å¯è§†åŒ–ä¸åŒçš„æ¿€æ´»å‡½æ•°"""
    
    x = np.linspace(-5, 5, 100)
    
    # å®šä¹‰å„ç§æ¿€æ´»å‡½æ•°
    def step(x):
        return np.where(x > 0, 1, 0)
    
    def sigmoid(x):
        return 1 / (1 + np.exp(-x))
    
    def tanh(x):
        return np.tanh(x)
    
    def relu(x):
        return np.maximum(0, x)
    
    def leaky_relu(x, alpha=0.1):
        return np.where(x > 0, x, alpha * x)
    
    # ç»˜å›¾
    plt.figure(figsize=(15, 10))
    
    functions = [
        ('Step Function', step, 'é˜¶è·ƒå‡½æ•°ï¼šæœ€ç®€å•ä½†ä¸å¯å¯¼'),
        ('Sigmoid', sigmoid, 'Sigmoidï¼šç»å…¸ä½†æœ‰æ¢¯åº¦æ¶ˆå¤±é—®é¢˜'),
        ('Tanh', tanh, 'Tanhï¼šé›¶ä¸­å¿ƒä½†ä»æœ‰æ¢¯åº¦æ¶ˆå¤±'),
        ('ReLU', relu, 'ReLUï¼šç®€å•æœ‰æ•ˆï¼Œç°ä»£ç½‘ç»œçš„æ ‡é…'),
        ('Leaky ReLU', leaky_relu, 'Leaky ReLUï¼šè§£å†³ReLUçš„"æ­»ç¥ç»å…ƒ"é—®é¢˜')
    ]
    
    for i, (name, func, description) in enumerate(functions):
        plt.subplot(2, 3, i+1)
        y = func(x)
        plt.plot(x, y, linewidth=2)
        plt.grid(True, alpha=0.3)
        plt.title(name, fontsize=12)
        plt.xlabel('x')
        plt.ylabel('f(x)')
        
        # æ·»åŠ æè¿°
        plt.text(0.5, 0.95, description, 
                transform=plt.gca().transAxes,
                ha='center', va='top', fontsize=10,
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    plt.tight_layout()
    plt.show()
    
    # æ¼”ç¤ºæ¿€æ´»å‡½æ•°çš„ä½œç”¨
    æ¼”ç¤ºæ¿€æ´»å‡½æ•°çš„éçº¿æ€§å˜æ¢()

def æ¼”ç¤ºæ¿€æ´»å‡½æ•°çš„éçº¿æ€§å˜æ¢():
    """å±•ç¤ºæ¿€æ´»å‡½æ•°å¦‚ä½•å¼•å…¥éçº¿æ€§"""
    
    # ç”Ÿæˆèºæ—‹æ•°æ®
    np.random.seed(42)
    n_points = 100
    n_classes = 2
    
    X = []
    y = []
    
    for class_num in range(n_classes):
        r = np.linspace(0.0, 1, n_points)
        t = np.linspace(class_num * np.pi, (class_num + 2) * np.pi, n_points) + np.random.randn(n_points) * 0.2
        
        X.append(np.c_[r * np.sin(t), r * np.cos(t)])
        y.append(np.full(n_points, class_num))
    
    X = np.vstack(X)
    y = np.hstack(y)
    
    plt.figure(figsize=(12, 5))
    
    # åŸå§‹æ•°æ®
    plt.subplot(1, 2, 1)
    plt.scatter(X[y==0, 0], X[y==0, 1], c='red', s=40, label='ç±»åˆ«0')
    plt.scatter(X[y==1, 0], X[y==1, 1], c='blue', s=40, label='ç±»åˆ«1')
    plt.title('èºæ—‹æ•°æ®ï¼šçº¿æ€§ä¸å¯åˆ†ï¼')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ç»è¿‡ReLUå˜æ¢å
    plt.subplot(1, 2, 2)
    # ç®€å•çš„éçº¿æ€§å˜æ¢
    X_transformed = np.c_[
        np.maximum(0, X[:, 0] - X[:, 1]),  # ReLU(x1 - x2)
        np.maximum(0, X[:, 0] + X[:, 1])   # ReLU(x1 + x2)
    ]
    
    plt.scatter(X_transformed[y==0, 0], X_transformed[y==0, 1], c='red', s=40, label='ç±»åˆ«0')
    plt.scatter(X_transformed[y==1, 0], X_transformed[y==1, 1], c='blue', s=40, label='ç±»åˆ«1')
    plt.title('ç»è¿‡éçº¿æ€§å˜æ¢åï¼šæ›´å®¹æ˜“åˆ†ç¦»ï¼')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

æ¿€æ´»å‡½æ•°å¤§æ¯”æ‹¼()
```

#### ğŸš€ æ·±åº¦å­¦ä¹ ï¼šå½“ç½‘ç»œå˜æ·±ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ

```python
class DeepNeuralNetwork:
    """æ·±åº¦ç¥ç»ç½‘ç»œï¼šå¤šä¸ªéšè—å±‚"""
    
    def __init__(self, layer_sizes, learning_rate=0.01):
        """
        layer_sizes: åˆ—è¡¨ï¼Œæ¯å±‚çš„ç¥ç»å…ƒæ•°é‡
        ä¾‹å¦‚ [2, 4, 4, 1] è¡¨ç¤ºï¼š2ä¸ªè¾“å…¥ï¼Œä¸¤ä¸ª4ç¥ç»å…ƒçš„éšè—å±‚ï¼Œ1ä¸ªè¾“å‡º
        """
        self.num_layers = len(layer_sizes)
        self.layer_sizes = layer_sizes
        self.learning_rate = learning_rate
        
        # åˆå§‹åŒ–æƒé‡å’Œåç½®
        self.weights = []
        self.biases = []
        
        for i in range(self.num_layers - 1):
            # Heåˆå§‹åŒ–ï¼šé€‚åˆReLUæ¿€æ´»å‡½æ•°
            w = np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2.0 / layer_sizes[i])
            b = np.zeros((1, layer_sizes[i+1]))
            
            self.weights.append(w)
            self.biases.append(b)
    
    def relu(self, x):
        return np.maximum(0, x)
    
    def relu_derivative(self, x):
        return (x > 0).astype(float)
    
    def forward(self, X):
        """å‰å‘ä¼ æ’­"""
        self.activations = [X]
        self.z_values = []
        
        activation = X
        for i in range(self.num_layers - 1):
            z = np.dot(activation, self.weights[i]) + self.biases[i]
            self.z_values.append(z)
            
            # æœ€åä¸€å±‚ç”¨sigmoidï¼Œå…¶ä»–å±‚ç”¨ReLU
            if i == self.num_layers - 2:
                activation = 1 / (1 + np.exp(-z))
            else:
                activation = self.relu(z)
            
            self.activations.append(activation)
        
        return activation
    
    def visualize_activations(self, X, layer_names=None):
        """å¯è§†åŒ–æ¯å±‚çš„æ¿€æ´»å€¼"""
        _ = self.forward(X[:1])  # åªç”¨ç¬¬ä¸€ä¸ªæ ·æœ¬
        
        if layer_names is None:
            layer_names = [f'Layer {i}' for i in range(len(self.activations))]
        
        fig, axes = plt.subplots(1, len(self.activations), figsize=(15, 3))
        
        for i, (activation, name) in enumerate(zip(self.activations, layer_names)):
            ax = axes[i] if len(self.activations) > 1 else axes
            
            # å°†æ¿€æ´»å€¼reshapeæˆæ–¹å½¢ï¼ˆå¦‚æœå¯èƒ½ï¼‰
            act = activation.flatten()
            size = int(np.sqrt(len(act)))
            if size * size == len(act):
                act = act.reshape(size, size)
            else:
                act = act.reshape(1, -1)
            
            im = ax.imshow(act, cmap='hot', aspect='auto')
            ax.set_title(f'{name}\nShape: {activation.shape}')
            ax.axis('off')
            
            # æ·»åŠ colorbar
            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        
        plt.tight_layout()
        plt.show()

def æ·±åº¦çš„åŠ›é‡æ¼”ç¤º():
    """æ¼”ç¤ºæ·±åº¦ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›"""
    
    # åˆ›å»ºä¸€ä¸ªå¤æ‚çš„åˆ†ç±»ä»»åŠ¡
    np.random.seed(42)
    n_samples = 200
    
    # ç”ŸæˆåŒå¿ƒåœ†æ•°æ®
    t = np.linspace(0, 4 * np.pi, n_samples)
    r1 = t / (4 * np.pi) + np.random.randn(n_samples) * 0.1
    r2 = t / (4 * np.pi) + 0.5 + np.random.randn(n_samples) * 0.1
    
    X1 = np.c_[r1 * np.cos(t), r1 * np.sin(t)]
    X2 = np.c_[r2 * np.cos(t), r2 * np.sin(t)]
    
    X = np.vstack([X1, X2])
    y = np.hstack([np.zeros(n_samples), np.ones(n_samples)]).reshape(-1, 1)
    
    # æ¯”è¾ƒä¸åŒæ·±åº¦çš„ç½‘ç»œ
    architectures = [
        ([2, 1], "æµ…å±‚ç½‘ç»œï¼š1å±‚"),
        ([2, 4, 1], "ä¸­ç­‰ç½‘ç»œï¼š2å±‚"),
        ([2, 8, 8, 1], "æ·±å±‚ç½‘ç»œï¼š3å±‚"),
        ([2, 8, 8, 8, 8, 1], "æ›´æ·±ç½‘ç»œï¼š5å±‚")
    ]
    
    plt.figure(figsize=(16, 4))
    
    for i, (arch, title) in enumerate(architectures):
        plt.subplot(1, 4, i+1)
        
        # è®­ç»ƒç½‘ç»œ
        nn = DeepNeuralNetwork(arch, learning_rate=0.1)
        
        # ç®€å•çš„è®­ç»ƒå¾ªç¯
        for epoch in range(1000):
            output = nn.forward(X)
            # è¿™é‡Œç®€åŒ–äº†åå‘ä¼ æ’­ï¼Œå®é™…å®ç°ä¼šæ›´å¤æ‚
        
        # ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
        xx, yy = np.meshgrid(np.linspace(-2, 2, 100),
                            np.linspace(-2, 2, 100))
        grid = np.c_[xx.ravel(), yy.ravel()]
        Z = nn.forward(grid)
        Z = Z.reshape(xx.shape)
        
        plt.contourf(xx, yy, Z, levels=20, alpha=0.3, cmap='RdBu')
        plt.scatter(X[y.ravel()==0, 0], X[y.ravel()==0, 1], c='red', s=20)
        plt.scatter(X[y.ravel()==1, 0], X[y.ravel()==1, 1], c='blue', s=20)
        
        plt.title(title)
        plt.xlabel('x1')
        plt.ylabel('x2')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ’¡ è§‚å¯Ÿï¼š")
    print("- æµ…å±‚ç½‘ç»œåªèƒ½å­¦ä¹ ç®€å•çš„å†³ç­–è¾¹ç•Œ")
    print("- éšç€æ·±åº¦å¢åŠ ï¼Œç½‘ç»œèƒ½å­¦ä¹ æ›´å¤æ‚çš„æ¨¡å¼")
    print("- ä½†å¤ªæ·±ä¹Ÿå¯èƒ½å¸¦æ¥è®­ç»ƒå›°éš¾ï¼ˆæ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ï¼‰")

æ·±åº¦çš„åŠ›é‡æ¼”ç¤º()
```

#### ğŸ§® é€šç”¨è¿‘ä¼¼å®šç†ï¼šç¥ç»ç½‘ç»œçš„"ä¸‡èƒ½é’¥åŒ™"

```python
def é€šç”¨è¿‘ä¼¼å®šç†æ¼”ç¤º():
    """æ¼”ç¤ºç¥ç»ç½‘ç»œå¯ä»¥è¿‘ä¼¼ä»»æ„å‡½æ•°"""
    
    # å®šä¹‰ä¸€ä¸ªå¤æ‚çš„ç›®æ ‡å‡½æ•°
    def target_function(x):
        return np.sin(x) * np.exp(-x/10) + 0.5 * np.cos(3*x)
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    x_train = np.linspace(-5, 5, 100).reshape(-1, 1)
    y_train = target_function(x_train)
    
    # ä¸åŒå®½åº¦çš„ç½‘ç»œ
    widths = [2, 5, 10, 50]
    
    plt.figure(figsize=(15, 10))
    
    for i, width in enumerate(widths):
        plt.subplot(2, 2, i+1)
        
        # åˆ›å»ºå¹¶"è®­ç»ƒ"ç½‘ç»œï¼ˆè¿™é‡Œç”¨éšæœºæƒé‡æ¨¡æ‹Ÿï¼‰
        nn = DeepNeuralNetwork([1, width, 1], learning_rate=0.01)
        
        # å‰å‘ä¼ æ’­
        y_pred = nn.forward(x_train)
        
        # ç»˜å›¾
        plt.plot(x_train, y_train, 'b-', linewidth=2, label='ç›®æ ‡å‡½æ•°')
        plt.plot(x_train, y_pred, 'r--', linewidth=2, label=f'ç¥ç»ç½‘ç»œ (å®½åº¦={width})')
        
        plt.xlabel('x')
        plt.ylabel('y')
        plt.title(f'éšè—å±‚å®½åº¦ = {width}')
        plt.legend()
        plt.grid(True, alpha=0.3)
    
    plt.suptitle('é€šç”¨è¿‘ä¼¼å®šç†ï¼šè¶³å¤Ÿå®½çš„å•å±‚ç½‘ç»œå¯ä»¥è¿‘ä¼¼ä»»æ„è¿ç»­å‡½æ•°', fontsize=14)
    plt.tight_layout()
    plt.show()
    
    print("\nğŸ“š é€šç”¨è¿‘ä¼¼å®šç†ï¼š")
    print("ä¸€ä¸ªå…·æœ‰è¶³å¤Ÿå¤šç¥ç»å…ƒçš„å•éšè—å±‚å‰é¦ˆç¥ç»ç½‘ç»œï¼Œ")
    print("å¯ä»¥ä»¥ä»»æ„ç²¾åº¦è¿‘ä¼¼ä»»æ„è¿ç»­å‡½æ•°ï¼")
    print("\nä½†æ˜¯ï¼š")
    print("- å¯èƒ½éœ€è¦æŒ‡æ•°çº§çš„ç¥ç»å…ƒæ•°é‡")
    print("- æ·±åº¦ç½‘ç»œé€šå¸¸æ›´æœ‰æ•ˆç‡")

é€šç”¨è¿‘ä¼¼å®šç†æ¼”ç¤º()
```

#### ğŸ¯ ç¥ç»ç½‘ç»œçš„ç›´è§‰ç†è§£

```python
def ç¥ç»ç½‘ç»œçš„å±‚æ¬¡åŒ–ç‰¹å¾å­¦ä¹ ():
    """å±•ç¤ºç¥ç»ç½‘ç»œå¦‚ä½•å±‚æ¬¡åŒ–åœ°å­¦ä¹ ç‰¹å¾"""
    
    print("ğŸ§  ç¥ç»ç½‘ç»œçš„å±‚æ¬¡åŒ–å­¦ä¹ ï¼š")
    print("\næƒ³è±¡ä½ åœ¨å­¦ä¹ è¯†åˆ«çŒ«ï¼š")
    print("\nç¬¬1å±‚ï¼šå­¦ä¹ è¾¹ç¼˜å’Œçº¿æ¡")
    print("  - æ¨ªçº¿æ£€æµ‹å™¨")
    print("  - ç«–çº¿æ£€æµ‹å™¨") 
    print("  - æ–œçº¿æ£€æµ‹å™¨")
    
    print("\nç¬¬2å±‚ï¼šç»„åˆæˆç®€å•å½¢çŠ¶")
    print("  - åœ†å½¢ï¼ˆçœ¼ç›ï¼‰")
    print("  - ä¸‰è§’å½¢ï¼ˆè€³æœµï¼‰")
    print("  - æ›²çº¿ï¼ˆå°¾å·´ï¼‰")
    
    print("\nç¬¬3å±‚ï¼šç»„åˆæˆéƒ¨ä»¶")
    print("  - çŒ«è„¸")
    print("  - çŒ«èº«")
    print("  - çŒ«çˆª")
    
    print("\nç¬¬4å±‚ï¼šå®Œæ•´çš„çŒ«ï¼")
    print("  - ä¸åŒå§¿åŠ¿çš„çŒ«")
    print("  - ä¸åŒå“ç§çš„çŒ«")
    print("  - ä¸åŒç¯å¢ƒä¸­çš„çŒ«")
    
    # ç”¨ç®€å•çš„å¯è§†åŒ–å±•ç¤ºè¿™ä¸ªæ¦‚å¿µ
    fig, axes = plt.subplots(1, 4, figsize=(15, 4))
    
    # æ¨¡æ‹Ÿæ¯å±‚å­¦åˆ°çš„ç‰¹å¾
    features = [
        ("ç¬¬1å±‚ï¼šè¾¹ç¼˜", ["â€”", "|", "/", "\\"]),
        ("ç¬¬2å±‚ï¼šå½¢çŠ¶", ["â—‹", "â–³", "â–¡", "â—‡"]),
        ("ç¬¬3å±‚ï¼šéƒ¨ä»¶", ["ğŸ‘ï¸", "ğŸ‘ƒ", "ğŸ‘‚", "ğŸ¦µ"]),
        ("ç¬¬4å±‚ï¼šå®Œæ•´", ["ğŸ±", "ğŸˆ", "ğŸ˜º", "ğŸ¦"])
    ]
    
    for ax, (title, symbols) in zip(axes, features):
        ax.text(0.5, 0.7, title, ha='center', va='center', fontsize=14, weight='bold')
        
        for i, symbol in enumerate(symbols):
            x = 0.2 + (i % 2) * 0.6
            y = 0.3 - (i // 2) * 0.2
            ax.text(x, y, symbol, ha='center', va='center', fontsize=20)
        
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)
        ax.axis('off')
    
    plt.suptitle('ç¥ç»ç½‘ç»œçš„å±‚æ¬¡åŒ–ç‰¹å¾å­¦ä¹ ', fontsize=16)
    plt.tight_layout()
    plt.show()

ç¥ç»ç½‘ç»œçš„å±‚æ¬¡åŒ–ç‰¹å¾å­¦ä¹ ()
```

#### ğŸ’¡ æœ¬ç« å°ç»“

1. **ç¥ç»å…ƒæ˜¯åŸºæœ¬å•å…ƒ**ï¼š
   - æ¥æ”¶è¾“å…¥ â†’ åŠ æƒæ±‚å’Œ â†’ æ¿€æ´»å‡½æ•° â†’ è¾“å‡º
   - æ¨¡ä»¿äº†ç”Ÿç‰©ç¥ç»å…ƒçš„å·¥ä½œåŸç†

2. **æ„ŸçŸ¥æœºçš„å±€é™**ï¼š
   - åªèƒ½è§£å†³çº¿æ€§å¯åˆ†é—®é¢˜
   - XORé—®é¢˜æš´éœ²äº†å•å±‚çš„ä¸è¶³

3. **å¤šå±‚ç½‘ç»œçš„å¨åŠ›**ï¼š
   - å¯ä»¥å­¦ä¹ éçº¿æ€§æ¨¡å¼
   - æ·±åº¦å¸¦æ¥æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›

4. **æ¿€æ´»å‡½æ•°çš„é‡è¦æ€§**ï¼š
   - å¼•å…¥éçº¿æ€§
   - ä¸åŒæ¿€æ´»å‡½æ•°æœ‰ä¸åŒç‰¹æ€§

5. **æ·±åº¦å­¦ä¹ çš„æœ¬è´¨**ï¼š
   - å±‚æ¬¡åŒ–çš„ç‰¹å¾å­¦ä¹ 
   - è‡ªåŠ¨å‘ç°æ•°æ®ä¸­çš„æ¨¡å¼

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆè¯´æ²¡æœ‰æ¿€æ´»å‡½æ•°çš„æ·±å±‚ç½‘ç»œç­‰ä»·äºå•å±‚ç½‘ç»œï¼Ÿ
2. æ—¢ç„¶å•å±‚ç½‘ç»œç†è®ºä¸Šå¯ä»¥è¿‘ä¼¼ä»»æ„å‡½æ•°ï¼Œä¸ºä»€ä¹ˆè¿˜éœ€è¦æ·±åº¦ç½‘ç»œï¼Ÿ
3. ç”Ÿç‰©ç¥ç»ç½‘ç»œæœ‰å¤§çº¦1000äº¿ä¸ªç¥ç»å…ƒï¼Œè€ŒGPT-3åªæœ‰1750äº¿å‚æ•°ï¼Œè¿™è¯´æ˜äº†ä»€ä¹ˆï¼Ÿ

#### ğŸ”¬ åŠ¨æ‰‹å®éªŒ

```python
# å°é¡¹ç›®ï¼šæ„å»ºä¸€ä¸ªè¯†åˆ«æ‰‹å†™æ•°å­—çš„ç¥ç»ç½‘ç»œ
def æ‰‹å†™æ•°å­—è¯†åˆ«é¡¹ç›®():
    """ä¸€ä¸ªå®Œæ•´çš„å°é¡¹ç›®ï¼šè¯†åˆ«ç®€åŒ–çš„æ‰‹å†™æ•°å­—"""
    
    # ç”Ÿæˆç®€åŒ–çš„"æ‰‹å†™"æ•°å­—æ•°æ®ï¼ˆ3x3åƒç´ ï¼‰
    digits = {
        '0': [[1,1,1],
              [1,0,1],
              [1,1,1]],
        
        '1': [[0,1,0],
              [0,1,0],
              [0,1,0]],
        
        '7': [[1,1,1],
              [0,0,1],
              [0,0,1]]
    }
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X = []
    y = []
    
    for digit, pattern in digits.items():
        # æ·»åŠ ä¸€äº›å™ªå£°ï¼Œæ¨¡æ‹Ÿä¸åŒçš„æ‰‹å†™é£æ ¼
        for _ in range(10):
            noisy_pattern = np.array(pattern).flatten() + np.random.randn(9) * 0.1
            X.append(noisy_pattern)
            
            # One-hotç¼–ç 
            label = [0, 0, 0]
            label[int(digit) if digit != '7' else 2] = 1
            y.append(label)
    
    X = np.array(X)
    y = np.array(y)
    
    # åˆ›å»ºå¹¶è®­ç»ƒç½‘ç»œ
    nn = DeepNeuralNetwork([9, 6, 3], learning_rate=0.1)
    
    print("å¼€å§‹è®­ç»ƒæ‰‹å†™æ•°å­—è¯†åˆ«ç½‘ç»œ...")
    # è¿™é‡Œçœç•¥äº†å®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹
    
    # æµ‹è¯•
    print("\næµ‹è¯•ç»“æœï¼š")
    test_cases = [
        ("æ¸…æ™°çš„0", [[1,1,1], [1,0,1], [1,1,1]]),
        ("æ¨¡ç³Šçš„1", [[0,0.8,0], [0.1,1,0.1], [0,0.9,0]]),
        ("æ­ªæ–œçš„7", [[0.9,1,0.8], [0.1,0,1], [0,0.1,0.9]])
    ]
    
    for name, pattern in test_cases:
        input_data = np.array(pattern).flatten().reshape(1, -1)
        output = nn.forward(input_data)
        predicted = np.argmax(output)
        
        # å¯è§†åŒ–
        plt.figure(figsize=(10, 3))
        
        plt.subplot(1, 3, 1)
        plt.imshow(np.array(pattern), cmap='gray')
        plt.title(f'è¾“å…¥: {name}')
        plt.axis('off')
        
        plt.subplot(1, 3, 2)
        plt.bar(['0', '1', '7'], output[0])
        plt.title('ç½‘ç»œè¾“å‡ºæ¦‚ç‡')
        plt.ylabel('æ¦‚ç‡')
        
        plt.subplot(1, 3, 3)
        plt.text(0.5, 0.5, f'é¢„æµ‹: {predicted}', 
                ha='center', va='center', fontsize=30)
        plt.title('æœ€ç»ˆé¢„æµ‹')
        plt.axis('off')
        
        plt.tight_layout()
        plt.show()

# è¿è¡Œé¡¹ç›®
æ‰‹å†™æ•°å­—è¯†åˆ«é¡¹ç›®()
```

ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†æ·±å…¥å­¦ä¹ æ¢¯åº¦ä¸‹é™â€”â€”ç¥ç»ç½‘ç»œæ˜¯å¦‚ä½•é€šè¿‡"è¯•é”™"æ¥å­¦ä¹ çš„ï¼

---

### ç¬¬4ç« ï¼šæ¢¯åº¦ä¸‹é™â€”â€”AIæ˜¯å¦‚ä½•å­¦ä¹ çš„ï¼Ÿ

#### ğŸ¯ æœ¬ç« å¯¼è¯»

æƒ³è±¡ä½ åœ¨ä¸€ä¸ªé›¾è’™è’™çš„å±±è°·é‡Œï¼Œæƒ³è¦æ‰¾åˆ°æœ€ä½ç‚¹ã€‚ä½ çœ‹ä¸æ¸…è¿œå¤„ï¼Œåªèƒ½æ„Ÿè§‰è„šä¸‹çš„å¡åº¦ã€‚æ€ä¹ˆåŠï¼Ÿæœ€ç®€å•çš„æ–¹æ³•å°±æ˜¯ï¼šå“ªè¾¹æ›´é™¡å°±å¾€å“ªè¾¹èµ°ï¼Œä¸€æ­¥ä¸€æ­¥ï¼Œæœ€ç»ˆå°±èƒ½åˆ°è¾¾è°·åº•ã€‚

è¿™å°±æ˜¯æ¢¯åº¦ä¸‹é™çš„æ ¸å¿ƒæ€æƒ³â€”â€”AIé€šè¿‡ä¸æ–­åœ°"ä¸‹å±±"æ¥æ‰¾åˆ°æœ€ä¼˜è§£ã€‚å¬èµ·æ¥ç®€å•ï¼Œä½†è¿™ä¸ªç®€å•çš„æƒ³æ³•å´æ˜¯æ•´ä¸ªæ·±åº¦å­¦ä¹ çš„åŸºçŸ³ã€‚

ä»Šå¤©ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ­å¼€AIå­¦ä¹ çš„ç§˜å¯†ï¼

#### ğŸ”ï¸ ç›´è§‚ç†è§£ï¼šä¸‹å±±çš„è‰ºæœ¯

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.animation import FuncAnimation
from IPython.display import HTML

def æ¢¯åº¦ä¸‹é™çš„ç›´è§‚ç†è§£():
    """ç”¨3Då¯è§†åŒ–å±•ç¤ºæ¢¯åº¦ä¸‹é™çš„è¿‡ç¨‹"""
    
    # å®šä¹‰ä¸€ä¸ªç®€å•çš„"å±±è°·"å‡½æ•°
    def valley_function(x, y):
        """ä¸€ä¸ªæœ‰è¶£çš„å±±è°·åœ°å½¢"""
        return x**2 + y**2 + 3*np.sin(2*x) + 2*np.cos(3*y)
    
    # è®¡ç®—æ¢¯åº¦
    def gradient(x, y):
        """è®¡ç®—å‡½æ•°åœ¨(x,y)ç‚¹çš„æ¢¯åº¦"""
        dx = 2*x + 6*np.cos(2*x)
        dy = 2*y - 6*np.sin(3*y)
        return dx, dy
    
    # åˆ›å»ºç½‘æ ¼
    x = np.linspace(-3, 3, 100)
    y = np.linspace(-3, 3, 100)
    X, Y = np.meshgrid(x, y)
    Z = valley_function(X, Y)
    
    # ç»˜åˆ¶3Dåœ°å½¢
    fig = plt.figure(figsize=(15, 5))
    
    # å­å›¾1ï¼š3Dè§†å›¾
    ax1 = fig.add_subplot(131, projection='3d')
    surf = ax1.plot_surface(X, Y, Z, cmap=cm.coolwarm, alpha=0.8)
    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_zlabel('é«˜åº¦')
    ax1.set_title('å±±è°·åœ°å½¢ï¼ˆ3Dè§†å›¾ï¼‰')
    
    # æ¢¯åº¦ä¸‹é™è·¯å¾„
    learning_rate = 0.1
    start_x, start_y = 2.5, 2.5
    path = [(start_x, start_y)]
    
    x_current, y_current = start_x, start_y
    for _ in range(50):
        dx, dy = gradient(x_current, y_current)
        x_current -= learning_rate * dx
        y_current -= learning_rate * dy
        path.append((x_current, y_current))
    
    # åœ¨3Då›¾ä¸Šç»˜åˆ¶è·¯å¾„
    path_array = np.array(path)
    z_path = [valley_function(x, y) for x, y in path]
    ax1.plot(path_array[:, 0], path_array[:, 1], z_path, 
             'r-o', markersize=3, linewidth=2, label='ä¸‹å±±è·¯å¾„')
    ax1.legend()
    
    # å­å›¾2ï¼šç­‰é«˜çº¿å›¾
    ax2 = fig.add_subplot(132)
    contour = ax2.contour(X, Y, Z, levels=20, cmap='coolwarm')
    ax2.clabel(contour, inline=True, fontsize=8)
    ax2.plot(path_array[:, 0], path_array[:, 1], 'r-o', 
             markersize=3, linewidth=2, label='æ¢¯åº¦ä¸‹é™è·¯å¾„')
    ax2.plot(start_x, start_y, 'go', markersize=10, label='èµ·ç‚¹')
    ax2.plot(path_array[-1, 0], path_array[-1, 1], 'rs', 
             markersize=10, label='ç»ˆç‚¹')
    ax2.set_xlabel('X')
    ax2.set_ylabel('Y')
    ax2.set_title('ç­‰é«˜çº¿è§†å›¾')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # å­å›¾3ï¼šæŸå¤±å˜åŒ–æ›²çº¿
    ax3 = fig.add_subplot(133)
    losses = [valley_function(x, y) for x, y in path]
    ax3.plot(losses, 'b-o', markersize=3)
    ax3.set_xlabel('è¿­ä»£æ¬¡æ•°')
    ax3.set_ylabel('æŸå¤±å€¼ï¼ˆé«˜åº¦ï¼‰')
    ax3.set_title('æŸå¤±ä¸‹é™æ›²çº¿')
    ax3.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ¯ å…³é”®è§‚å¯Ÿï¼š")
    print("1. æ¢¯åº¦æŒ‡å‘å‡½æ•°ä¸Šå‡æœ€å¿«çš„æ–¹å‘")
    print("2. è´Ÿæ¢¯åº¦æ–¹å‘å°±æ˜¯ä¸‹é™æœ€å¿«çš„æ–¹å‘")
    print("3. æ¯ä¸€æ­¥éƒ½åœ¨å±€éƒ¨å¯»æ‰¾æœ€é™¡çš„ä¸‹å¡è·¯")
    print("4. æœ€ç»ˆä¼šæ”¶æ•›åˆ°æŸä¸ªä½ç‚¹ï¼ˆå¯èƒ½æ˜¯å±€éƒ¨æœ€å°å€¼ï¼‰")

æ¢¯åº¦ä¸‹é™çš„ç›´è§‚ç†è§£()
```

#### ğŸ“ æ•°å­¦åŸç†ï¼šä¸ºä»€ä¹ˆæ¢¯åº¦ä¸‹é™æœ‰æ•ˆï¼Ÿ

```python
def æ¢¯åº¦ä¸‹é™çš„æ•°å­¦åŸç†():
    """æ·±å…¥ç†è§£æ¢¯åº¦ä¸‹é™çš„æ•°å­¦åŸºç¡€"""
    
    print("ğŸ“š æ¢¯åº¦ä¸‹é™çš„æ•°å­¦åŸç†ï¼š\n")
    
    print("1ï¸âƒ£ ä»€ä¹ˆæ˜¯æ¢¯åº¦ï¼Ÿ")
    print("   æ¢¯åº¦æ˜¯å‡½æ•°åœ¨æŸç‚¹çš„æ–¹å‘å¯¼æ•°çš„æœ€å¤§å€¼")
    print("   å®ƒæŒ‡å‘å‡½æ•°å¢é•¿æœ€å¿«çš„æ–¹å‘\n")
    
    print("2ï¸âƒ£ æ³°å‹’å±•å¼€ï¼ˆä¸€é˜¶è¿‘ä¼¼ï¼‰ï¼š")
    print("   f(x + Î”x) â‰ˆ f(x) + âˆ‡f(x)Â·Î”x")
    print("   å¦‚æœæˆ‘ä»¬é€‰æ‹© Î”x = -Î±Â·âˆ‡f(x)ï¼ˆÎ±æ˜¯å­¦ä¹ ç‡ï¼‰")
    print("   é‚£ä¹ˆ f(x + Î”x) â‰ˆ f(x) - Î±Â·||âˆ‡f(x)||Â²")
    print("   ç”±äº ||âˆ‡f(x)||Â² â‰¥ 0ï¼Œæ‰€ä»¥å‡½æ•°å€¼ä¼šä¸‹é™ï¼\n")
    
    # ä¸€ç»´å‡½æ•°çš„æ¢¯åº¦ä¸‹é™æ¼”ç¤º
    def f(x):
        return x**2 - 4*x + 4  # (x-2)Â²
    
    def df_dx(x):
        return 2*x - 4  # å¯¼æ•°
    
    # å¯è§†åŒ–ä¸€ç»´æ¢¯åº¦ä¸‹é™
    x = np.linspace(-1, 5, 100)
    y = f(x)
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # å·¦å›¾ï¼šå‡½æ•°å’Œæ¢¯åº¦
    ax1.plot(x, y, 'b-', linewidth=2, label='f(x) = (x-2)Â²')
    ax1.plot(x, df_dx(x), 'r--', linewidth=2, label="f'(x) = 2x-4")
    ax1.axhline(y=0, color='k', linestyle='-', alpha=0.3)
    ax1.axvline(x=2, color='k', linestyle='-', alpha=0.3)
    ax1.set_xlabel('x')
    ax1.set_ylabel('y')
    ax1.set_title('å‡½æ•°åŠå…¶å¯¼æ•°')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # å³å›¾ï¼šæ¢¯åº¦ä¸‹é™è¿‡ç¨‹
    ax2.plot(x, y, 'b-', linewidth=2, alpha=0.5)
    
    # æ¨¡æ‹Ÿæ¢¯åº¦ä¸‹é™
    x_start = 4.5
    learning_rate = 0.1
    x_history = [x_start]
    
    for i in range(10):
        x_current = x_history[-1]
        gradient = df_dx(x_current)
        x_new = x_current - learning_rate * gradient
        x_history.append(x_new)
        
        # ç”»å‡ºæ¯ä¸€æ­¥
        ax2.plot([x_current, x_current], [0, f(x_current)], 'k--', alpha=0.3)
        ax2.plot(x_current, f(x_current), 'ro', markersize=8)
        
        # ç”»å‡ºæ¢¯åº¦æ–¹å‘
        ax2.arrow(x_current, f(x_current), 
                 -learning_rate * gradient, 0,
                 head_width=0.3, head_length=0.1, 
                 fc='red', ec='red', alpha=0.7)
    
    ax2.plot(x_history[-1], f(x_history[-1]), 'gs', markersize=12, label='æœ€ç»ˆä½ç½®')
    ax2.set_xlabel('x')
    ax2.set_ylabel('f(x)')
    ax2.set_title('æ¢¯åº¦ä¸‹é™è¿‡ç¨‹')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # å±•ç¤ºæ”¶æ•›è¿‡ç¨‹
    print("\n3ï¸âƒ£ æ”¶æ•›è¿‡ç¨‹ï¼š")
    for i, x in enumerate(x_history[:5]):
        print(f"   ç¬¬{i}æ­¥: x = {x:.3f}, f(x) = {f(x):.3f}, æ¢¯åº¦ = {df_dx(x):.3f}")
    print("   ...")
    print(f"   æœ€ç»ˆ: x = {x_history[-1]:.3f}, f(x) = {f(x_history[-1]):.3f}")

æ¢¯åº¦ä¸‹é™çš„æ•°å­¦åŸç†()
```

#### ğŸª æ¢¯åº¦ä¸‹é™çš„å˜ä½“ï¼šå„æ˜¾ç¥é€š

```python
def æ¢¯åº¦ä¸‹é™å˜ä½“å¯¹æ¯”():
    """æ¯”è¾ƒä¸åŒçš„æ¢¯åº¦ä¸‹é™å˜ä½“"""
    
    # ç”Ÿæˆä¸€ä¸ªæœ‰å™ªå£°çš„æŸå¤±å‡½æ•°
    np.random.seed(42)
    n_samples = 100
    X = np.random.randn(n_samples, 2)
    true_weights = np.array([3, -2])
    y = X @ true_weights + np.random.randn(n_samples) * 0.5
    
    # æŸå¤±å‡½æ•°
    def loss(w):
        predictions = X @ w
        return np.mean((predictions - y) ** 2)
    
    # æ¢¯åº¦å‡½æ•°
    def gradient_full(w):
        predictions = X @ w
        return 2 * X.T @ (predictions - y) / n_samples
    
    # éšæœºæ¢¯åº¦
    def gradient_stochastic(w, i):
        prediction = X[i] @ w
        return 2 * X[i] * (prediction - y[i])
    
    # ä¸åŒçš„ä¼˜åŒ–å™¨
    class GradientDescent:
        def __init__(self, learning_rate=0.01):
            self.lr = learning_rate
            
        def update(self, w, grad):
            return w - self.lr * grad
    
    class MomentumGD:
        def __init__(self, learning_rate=0.01, momentum=0.9):
            self.lr = learning_rate
            self.momentum = momentum
            self.velocity = 0
            
        def update(self, w, grad):
            self.velocity = self.momentum * self.velocity - self.lr * grad
            return w + self.velocity
    
    class AdaGrad:
        def __init__(self, learning_rate=0.01, epsilon=1e-8):
            self.lr = learning_rate
            self.epsilon = epsilon
            self.accumulated_grad = 0
            
        def update(self, w, grad):
            self.accumulated_grad += grad ** 2
            adjusted_lr = self.lr / (np.sqrt(self.accumulated_grad) + self.epsilon)
            return w - adjusted_lr * grad
    
    class Adam:
        def __init__(self, learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):
            self.lr = learning_rate
            self.beta1 = beta1
            self.beta2 = beta2
            self.epsilon = epsilon
            self.m = 0
            self.v = 0
            self.t = 0
            
        def update(self, w, grad):
            self.t += 1
            self.m = self.beta1 * self.m + (1 - self.beta1) * grad
            self.v = self.beta2 * self.v + (1 - self.beta2) * grad ** 2
            
            m_hat = self.m / (1 - self.beta1 ** self.t)
            v_hat = self.v / (1 - self.beta2 ** self.t)
            
            return w - self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)
    
    # è®­ç»ƒä¸åŒçš„ä¼˜åŒ–å™¨
    optimizers = {
        'SGD': GradientDescent(0.01),
        'Momentum': MomentumGD(0.01, 0.9),
        'AdaGrad': AdaGrad(0.01),
        'Adam': Adam(0.01)
    }
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    axes = axes.ravel()
    
    for idx, (name, optimizer) in enumerate(optimizers.items()):
        w = np.array([0.0, 0.0])  # åˆå§‹æƒé‡
        history = [w.copy()]
        losses = [loss(w)]
        
        # è®­ç»ƒ
        for epoch in range(100):
            if name == 'SGD':
                # æ‰¹é‡æ¢¯åº¦ä¸‹é™
                grad = gradient_full(w)
            else:
                # å°æ‰¹é‡æ¢¯åº¦ä¸‹é™
                batch_size = 10
                batch_indices = np.random.choice(n_samples, batch_size)
                grad = np.mean([gradient_stochastic(w, i) for i in batch_indices], axis=0)
            
            w = optimizer.update(w, grad)
            history.append(w.copy())
            losses.append(loss(w))
        
        history = np.array(history)
        
        # ç»˜åˆ¶è½¨è¿¹
        ax = axes[idx]
        
        # åˆ›å»ºç­‰é«˜çº¿
        w1_range = np.linspace(-1, 4, 100)
        w2_range = np.linspace(-4, 1, 100)
        W1, W2 = np.meshgrid(w1_range, w2_range)
        Z = np.zeros_like(W1)
        
        for i in range(W1.shape[0]):
            for j in range(W1.shape[1]):
                Z[i, j] = loss(np.array([W1[i, j], W2[i, j]]))
        
        contour = ax.contour(W1, W2, Z, levels=30, alpha=0.4)
        ax.plot(history[:, 0], history[:, 1], 'r-o', markersize=3, 
                linewidth=2, label='ä¼˜åŒ–è·¯å¾„')
        ax.plot(true_weights[0], true_weights[1], 'g*', 
                markersize=15, label='çœŸå®æœ€ä¼˜è§£')
        ax.plot(history[0, 0], history[0, 1], 'bo', 
                markersize=10, label='èµ·ç‚¹')
        
        ax.set_xlabel('w1')
        ax.set_ylabel('w2')
        ax.set_title(f'{name} ä¼˜åŒ–å™¨')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # æ‰“å°æœ€ç»ˆç»“æœ
        print(f"{name}: æœ€ç»ˆæƒé‡ = [{history[-1, 0]:.3f}, {history[-1, 1]:.3f}], "
              f"æœ€ç»ˆæŸå¤± = {losses[-1]:.4f}")
    
    plt.tight_layout()
    plt.show()
    
    # æŸå¤±æ›²çº¿å¯¹æ¯”
    plt.figure(figsize=(10, 6))
    for name, optimizer in optimizers.items():
        w = np.array([0.0, 0.0])
        losses = []
        
        for epoch in range(100):
            grad = gradient_full(w)
            w = optimizer.update(w, grad)
            losses.append(loss(w))
        
        plt.plot(losses, linewidth=2, label=name)
    
    plt.xlabel('è¿­ä»£æ¬¡æ•°')
    plt.ylabel('æŸå¤±å€¼')
    plt.title('ä¸åŒä¼˜åŒ–å™¨çš„æ”¶æ•›é€Ÿåº¦å¯¹æ¯”')
    plt.legend()
    plt.yscale('log')
    plt.grid(True, alpha=0.3)
    plt.show()

æ¢¯åº¦ä¸‹é™å˜ä½“å¯¹æ¯”()
```

#### ğŸ¨ å­¦ä¹ ç‡ï¼šæ­¥ä¼çš„è‰ºæœ¯

```python
def å­¦ä¹ ç‡çš„é‡è¦æ€§():
    """æ¼”ç¤ºå­¦ä¹ ç‡å¯¹è®­ç»ƒçš„å½±å“"""
    
    # ç®€å•çš„äºŒæ¬¡å‡½æ•°
    def f(x):
        return (x - 2) ** 2 + 1
    
    def df_dx(x):
        return 2 * (x - 2)
    
    # ä¸åŒçš„å­¦ä¹ ç‡
    learning_rates = [0.01, 0.1, 0.5, 0.9, 1.1]
    colors = ['blue', 'green', 'orange', 'red', 'purple']
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.ravel()
    
    x_range = np.linspace(-2, 6, 100)
    
    for idx, (lr, color) in enumerate(zip(learning_rates, colors)):
        ax = axes[idx]
        
        # ç»˜åˆ¶å‡½æ•°
        ax.plot(x_range, f(x_range), 'k-', linewidth=2, alpha=0.5)
        
        # æ¢¯åº¦ä¸‹é™
        x = 5.0  # èµ·ç‚¹
        history = [x]
        
        for _ in range(20):
            grad = df_dx(x)
            x = x - lr * grad
            history.append(x)
            
            if abs(x) > 10:  # å‘æ•£äº†
                break
        
        # ç»˜åˆ¶è½¨è¿¹
        for i in range(len(history) - 1):
            ax.plot(history[i], f(history[i]), 'o', color=color, markersize=8)
            if i < 10:  # åªç”»å‰10æ­¥çš„ç®­å¤´
                ax.annotate('', xy=(history[i+1], f(history[i+1])),
                           xytext=(history[i], f(history[i])),
                           arrowprops=dict(arrowstyle='->', color=color, alpha=0.7))
        
        ax.set_xlim(-2, 6)
        ax.set_ylim(0, 20)
        ax.set_title(f'å­¦ä¹ ç‡ = {lr}')
        ax.grid(True, alpha=0.3)
        
        # åˆ¤æ–­æ”¶æ•›æƒ…å†µ
        if abs(history[-1] - 2) < 0.01:
            status = "âœ… æ”¶æ•›"
        elif abs(history[-1]) > 10:
            status = "ğŸ’¥ å‘æ•£"
        elif len(set(history[-5:])) > 1 and max(history[-5:]) - min(history[-5:]) > 2:
            status = "ğŸ”„ éœ‡è¡"
        else:
            status = "ğŸŒ æ”¶æ•›æ…¢"
        
        ax.text(0.95, 0.95, status, transform=ax.transAxes,
                ha='right', va='top', fontsize=14,
                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))
    
    # æœ€åä¸€ä¸ªå­å›¾ï¼šå­¦ä¹ ç‡è°ƒåº¦
    ax = axes[5]
    epochs = np.arange(100)
    
    # ä¸åŒçš„å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥
    constant_lr = np.ones(100) * 0.1
    step_lr = np.where(epochs < 30, 0.1, np.where(epochs < 60, 0.01, 0.001))
    exponential_lr = 0.1 * 0.95 ** epochs
    cosine_lr = 0.05 + 0.05 * np.cos(np.pi * epochs / 100)
    
    ax.plot(epochs, constant_lr, label='å¸¸æ•°å­¦ä¹ ç‡')
    ax.plot(epochs, step_lr, label='é˜¶æ¢¯ä¸‹é™')
    ax.plot(epochs, exponential_lr, label='æŒ‡æ•°è¡°å‡')
    ax.plot(epochs, cosine_lr, label='ä½™å¼¦é€€ç«')
    
    ax.set_xlabel('è®­ç»ƒè½®æ¬¡')
    ax.set_ylabel('å­¦ä¹ ç‡')
    ax.set_title('å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ’¡ å­¦ä¹ ç‡çš„å½±å“ï¼š")
    print("- å¤ªå°ï¼ˆ0.01ï¼‰ï¼šæ”¶æ•›å¤ªæ…¢ï¼Œè®­ç»ƒæ—¶é—´é•¿")
    print("- åˆé€‚ï¼ˆ0.1ï¼‰ï¼šç¨³å®šæ”¶æ•›")
    print("- è¾ƒå¤§ï¼ˆ0.5ï¼‰ï¼šå¿«é€Ÿä¸‹é™ä½†å¯èƒ½éœ‡è¡")
    print("- å¤ªå¤§ï¼ˆ>1ï¼‰ï¼šå¯èƒ½å‘æ•£ï¼Œæ— æ³•æ”¶æ•›")
    print("\nğŸ¯ å­¦ä¹ ç‡è°ƒåº¦çš„å¥½å¤„ï¼š")
    print("- å¼€å§‹æ—¶ç”¨å¤§å­¦ä¹ ç‡å¿«é€Ÿä¸‹é™")
    print("- åæœŸç”¨å°å­¦ä¹ ç‡ç²¾ç»†è°ƒæ•´")
    print("- é¿å…åœ¨æœ€ä¼˜ç‚¹é™„è¿‘éœ‡è¡")

å­¦ä¹ ç‡çš„é‡è¦æ€§()
```

#### ğŸ”ï¸ å±€éƒ¨æœ€å°å€¼ï¼šå±±è°·ä¸­çš„é™·é˜±

```python
def å±€éƒ¨æœ€å°å€¼é—®é¢˜():
    """æ¼”ç¤ºå±€éƒ¨æœ€å°å€¼å’Œå…¨å±€æœ€å°å€¼"""
    
    # ä¸€ä¸ªæœ‰å¤šä¸ªå±€éƒ¨æœ€å°å€¼çš„å‡½æ•°
    def complex_function(x):
        return np.sin(3*x) * np.exp(-0.1*x) + 0.1*x**2
    
    def gradient(x):
        # æ•°å€¼æ¢¯åº¦
        h = 1e-5
        return (complex_function(x + h) - complex_function(x - h)) / (2 * h)
    
    x = np.linspace(-5, 5, 1000)
    y = complex_function(x)
    
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # ä¸Šå›¾ï¼šå‡½æ•°å’Œä¸åŒèµ·ç‚¹çš„æ¢¯åº¦ä¸‹é™
    ax1.plot(x, y, 'b-', linewidth=2, label='æŸå¤±å‡½æ•°')
    
    # æ‰¾å‡ºå±€éƒ¨æœ€å°å€¼
    local_minima = []
    for i in range(1, len(x)-1):
        if y[i] < y[i-1] and y[i] < y[i+1]:
            local_minima.append((x[i], y[i]))
    
    # æ ‡è®°å±€éƒ¨æœ€å°å€¼
    for i, (x_min, y_min) in enumerate(local_minima):
        ax1.plot(x_min, y_min, 'ro', markersize=10)
        ax1.annotate(f'å±€éƒ¨æœ€å°å€¼{i+1}', (x_min, y_min), 
                    xytext=(x_min, y_min+0.5),
                    arrowprops=dict(arrowstyle='->', color='red'))
    
    # æ‰¾å‡ºå…¨å±€æœ€å°å€¼
    global_min_idx = np.argmin(y)
    ax1.plot(x[global_min_idx], y[global_min_idx], 'g*', 
            markersize=20, label='å…¨å±€æœ€å°å€¼')
    
    # ä»ä¸åŒèµ·ç‚¹å¼€å§‹æ¢¯åº¦ä¸‹é™
    starting_points = [-4.5, -2, 0, 2, 4.5]
    colors = ['purple', 'orange', 'brown', 'pink', 'cyan']
    
    for start, color in zip(starting_points, colors):
        x_current = start
        path_x = [x_current]
        path_y = [complex_function(x_current)]
        
        learning_rate = 0.1
        for _ in range(100):
            grad = gradient(x_current)
            x_current = x_current - learning_rate * grad
            path_x.append(x_current)
            path_y.append(complex_function(x_current))
            
            # æ£€æŸ¥æ”¶æ•›
            if abs(grad) < 0.001:
                break
        
        ax1.plot(path_x, path_y, 'o-', color=color, markersize=3, 
                alpha=0.7, label=f'èµ·ç‚¹ x={start:.1f}')
    
    ax1.set_xlabel('x')
    ax1.set_ylabel('f(x)')
    ax1.set_title('æ¢¯åº¦ä¸‹é™é™·å…¥ä¸åŒçš„å±€éƒ¨æœ€å°å€¼')
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax1.grid(True, alpha=0.3)
    
    # ä¸‹å›¾ï¼šè§£å†³æ–¹æ¡ˆæ¼”ç¤º
    ax2.plot(x, y, 'b-', linewidth=2, alpha=0.5)
    
    # æ¨¡æ‹Ÿå¸¦åŠ¨é‡çš„æ¢¯åº¦ä¸‹é™
    x_current = 4.5
    velocity = 0
    momentum = 0.9
    path_x = [x_current]
    path_y = [complex_function(x_current)]
    
    for i in range(200):
        grad = gradient(x_current)
        velocity = momentum * velocity - learning_rate * grad
        x_current = x_current + velocity
        
        path_x.append(x_current)
        path_y.append(complex_function(x_current))
    
    ax2.plot(path_x[:50], path_y[:50], 'ro-', markersize=3, 
            linewidth=2, label='å¸¦åŠ¨é‡çš„æ¢¯åº¦ä¸‹é™', alpha=0.8)
    
    # æ¨¡æ‹Ÿéšæœºæ‰°åŠ¨
    x_current = 4.5
    path_x_noise = [x_current]
    path_y_noise = [complex_function(x_current)]
    
    for i in range(200):
        grad = gradient(x_current)
        noise = np.random.randn() * 0.05  # æ·»åŠ éšæœºå™ªå£°
        x_current = x_current - learning_rate * grad + noise
        
        path_x_noise.append(x_current)
        path_y_noise.append(complex_function(x_current))
    
    ax2.plot(path_x_noise[:100], path_y_noise[:100], 'go-', 
            markersize=2, linewidth=1, label='å¸¦éšæœºæ‰°åŠ¨çš„æ¢¯åº¦ä¸‹é™', alpha=0.6)
    
    ax2.set_xlabel('x')
    ax2.set_ylabel('f(x)')
    ax2.set_title('è·³å‡ºå±€éƒ¨æœ€å°å€¼çš„ç­–ç•¥')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ¯ å±€éƒ¨æœ€å°å€¼é—®é¢˜ï¼š")
    print("1. æ¢¯åº¦ä¸‹é™åªèƒ½ä¿è¯æ‰¾åˆ°å±€éƒ¨æœ€å°å€¼")
    print("2. ä¸åŒçš„èµ·ç‚¹å¯èƒ½æ”¶æ•›åˆ°ä¸åŒçš„å±€éƒ¨æœ€å°å€¼")
    print("\nğŸ’¡ è§£å†³ç­–ç•¥ï¼š")
    print("- åŠ¨é‡ï¼ˆMomentumï¼‰ï¼šåƒå°çƒæ»šåŠ¨ï¼Œæœ‰æƒ¯æ€§èƒ½å†²è¿‡å°å‘")
    print("- éšæœºæ€§ï¼ˆSGDï¼‰ï¼šéšæœºæ‰°åŠ¨å¯èƒ½å¸®åŠ©è·³å‡ºå±€éƒ¨æœ€å°å€¼")
    print("- å­¦ä¹ ç‡è°ƒåº¦ï¼šå¤§å­¦ä¹ ç‡æœ‰åŠ©äºæ¢ç´¢ï¼Œå°å­¦ä¹ ç‡æœ‰åŠ©äºæ”¶æ•›")
    print("- å¤šæ¬¡éšæœºåˆå§‹åŒ–ï¼šä»ä¸åŒèµ·ç‚¹å¼€å§‹ï¼Œé€‰æœ€å¥½çš„ç»“æœ")

å±€éƒ¨æœ€å°å€¼é—®é¢˜()
```

#### ğŸ¯ å®æˆ˜ï¼šè®­ç»ƒä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œ

```python
class SimpleNN:
    """ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œï¼Œç”¨äºæ¼”ç¤ºæ¢¯åº¦ä¸‹é™"""
    
    def __init__(self, input_size, hidden_size, output_size):
        # Xavieråˆå§‹åŒ–
        self.W1 = np.random.randn(input_size, hidden_size) / np.sqrt(input_size)
        self.b1 = np.zeros((1, hidden_size))
        self.W2 = np.random.randn(hidden_size, output_size) / np.sqrt(hidden_size)
        self.b2 = np.zeros((1, output_size))
        
        # ä¿å­˜ä¸­é—´å€¼ç”¨äºåå‘ä¼ æ’­
        self.cache = {}
        
    def relu(self, x):
        return np.maximum(0, x)
    
    def relu_derivative(self, x):
        return (x > 0).astype(float)
    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        # ç¬¬ä¸€å±‚
        self.cache['z1'] = X @ self.W1 + self.b1
        self.cache['a1'] = self.relu(self.cache['z1'])
        
        # ç¬¬äºŒå±‚
        self.cache['z2'] = self.cache['a1'] @ self.W2 + self.b2
        self.cache['a2'] = self.softmax(self.cache['z2'])
        
        return self.cache['a2']
    
    def compute_loss(self, y_pred, y_true):
        # äº¤å‰ç†µæŸå¤±
        m = y_true.shape[0]
        log_likelihood = -np.log(y_pred[range(m), y_true])
        return np.sum(log_likelihood) / m
    
    def backward(self, X, y_true):
        m = X.shape[0]
        
        # è¾“å‡ºå±‚æ¢¯åº¦
        y_pred = self.cache['a2']
        dz2 = y_pred.copy()
        dz2[range(m), y_true] -= 1
        dz2 /= m
        
        dW2 = self.cache['a1'].T @ dz2
        db2 = np.sum(dz2, axis=0, keepdims=True)
        
        # éšè—å±‚æ¢¯åº¦
        da1 = dz2 @ self.W2.T
        dz1 = da1 * self.relu_derivative(self.cache['z1'])
        
        dW1 = X.T @ dz1
        db1 = np.sum(dz1, axis=0, keepdims=True)
        
        return {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2}

def è®­ç»ƒç¥ç»ç½‘ç»œæ¼”ç¤º():
    """æ¼”ç¤ºå¦‚ä½•ç”¨æ¢¯åº¦ä¸‹é™è®­ç»ƒç¥ç»ç½‘ç»œ"""
    
    # ç”Ÿæˆèºæ—‹æ•°æ®é›†
    np.random.seed(42)
    n_samples = 200
    n_classes = 3
    
    X = []
    y = []
    
    for class_id in range(n_classes):
        r = np.linspace(0.0, 1, n_samples // n_classes)
        t = np.linspace(class_id * 4, (class_id + 1) * 4, n_samples // n_classes) + np.random.randn(n_samples // n_classes) * 0.2
        X.append(np.c_[r * np.sin(t), r * np.cos(t)])
        y.extend([class_id] * (n_samples // n_classes))
    
    X = np.vstack(X)
    y = np.array(y)
    
    # åˆ›å»ºç½‘ç»œ
    nn = SimpleNN(input_size=2, hidden_size=10, output_size=3)
    
    # è®­ç»ƒå‚æ•°
    learning_rate = 1.0
    n_epochs = 1000
    
    # è®°å½•è®­ç»ƒè¿‡ç¨‹
    losses = []
    accuracies = []
    
    # åˆ›å»ºåŠ¨ç”»
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))
    
    # åˆå§‹å†³ç­–è¾¹ç•Œ
    xx, yy = np.meshgrid(np.linspace(-1.5, 1.5, 100),
                         np.linspace(-1.5, 1.5, 100))
    
    for epoch in range(n_epochs):
        # å‰å‘ä¼ æ’­
        y_pred = nn.forward(X)
        
        # è®¡ç®—æŸå¤±
        loss = nn.compute_loss(y_pred, y)
        losses.append(loss)
        
        # è®¡ç®—å‡†ç¡®ç‡
        predictions = np.argmax(y_pred, axis=1)
        accuracy = np.mean(predictions == y)
        accuracies.append(accuracy)
        
        # åå‘ä¼ æ’­
        gradients = nn.backward(X, y)
        
        # æ›´æ–°å‚æ•°ï¼ˆæ¢¯åº¦ä¸‹é™ï¼‰
        nn.W1 -= learning_rate * gradients['dW1']
        nn.b1 -= learning_rate * gradients['db1']
        nn.W2 -= learning_rate * gradients['dW2']
        nn.b2 -= learning_rate * gradients['db2']
        
        # æ¯100è½®æ›´æ–°å¯è§†åŒ–
        if epoch % 100 == 0:
            ax1.clear()
            ax2.clear()
            ax3.clear()
            
            # ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
            Z = nn.forward(np.c_[xx.ravel(), yy.ravel()])
            Z = np.argmax(Z, axis=1).reshape(xx.shape)
            
            ax1.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')
            scatter = ax1.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', 
                                 edgecolors='black', s=50)
            ax1.set_title(f'å†³ç­–è¾¹ç•Œ (Epoch {epoch})')
            ax1.set_xlabel('x1')
            ax1.set_ylabel('x2')
            
            # æŸå¤±æ›²çº¿
            ax2.plot(losses, 'b-', linewidth=2)
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('æŸå¤±')
            ax2.set_title('è®­ç»ƒæŸå¤±')
            ax2.grid(True, alpha=0.3)
            
            # å‡†ç¡®ç‡æ›²çº¿
            ax3.plot(accuracies, 'g-', linewidth=2)
            ax3.set_xlabel('Epoch')
            ax3.set_ylabel('å‡†ç¡®ç‡')
            ax3.set_title('è®­ç»ƒå‡†ç¡®ç‡')
            ax3.set_ylim(0, 1.1)
            ax3.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.pause(0.01)
    
    plt.show()
    
    print(f"\nè®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}")
    print(f"æœ€ç»ˆå‡†ç¡®ç‡: {accuracies[-1]:.2%}")
    
    # åˆ†ææ¢¯åº¦
    final_gradients = nn.backward(X, y)
    print(f"\næœ€ç»ˆæ¢¯åº¦å¤§å°ï¼š")
    for name, grad in final_gradients.items():
        print(f"{name}: {np.linalg.norm(grad):.6f}")
    
    print("\nğŸ’¡ è§‚å¯Ÿï¼š")
    print("1. æŸå¤±é€æ¸ä¸‹é™ï¼Œå‡†ç¡®ç‡é€æ¸ä¸Šå‡")
    print("2. å†³ç­–è¾¹ç•Œä»ç®€å•åˆ°å¤æ‚")
    print("3. æœ€ç»ˆæ¢¯åº¦æ¥è¿‘0ï¼Œè¯´æ˜æ”¶æ•›åˆ°äº†æŸä¸ªæå€¼ç‚¹")

è®­ç»ƒç¥ç»ç½‘ç»œæ¼”ç¤º()
```

#### ğŸ® æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸

```python
def æ¢¯åº¦æ¶ˆå¤±å’Œçˆ†ç‚¸é—®é¢˜():
    """æ¼”ç¤ºæ·±åº¦ç½‘ç»œä¸­çš„æ¢¯åº¦é—®é¢˜"""
    
    # åˆ›å»ºä¸åŒæ·±åº¦çš„ç½‘ç»œ
    depths = [2, 5, 10, 20]
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    axes = axes.ravel()
    
    for idx, depth in enumerate(depths):
        ax = axes[idx]
        
        # æ¨¡æ‹Ÿæ¢¯åº¦åœ¨ä¸åŒå±‚çš„ä¼ æ’­
        n_neurons = 10
        gradients_sigmoid = []
        gradients_relu = []
        gradients_tanh = []
        
        # Sigmoidçš„æ¢¯åº¦
        grad = 1.0
        for layer in range(depth):
            # sigmoidå¯¼æ•°çš„æœ€å¤§å€¼æ˜¯0.25
            grad *= 0.25 * np.random.rand()
            gradients_sigmoid.append(grad)
        
        # ReLUçš„æ¢¯åº¦
        grad = 1.0
        for layer in range(depth):
            # ReLUå¯¼æ•°æ˜¯0æˆ–1
            grad *= np.random.choice([0, 1], p=[0.3, 0.7])
            gradients_relu.append(grad)
        
        # Tanhçš„æ¢¯åº¦
        grad = 1.0
        for layer in range(depth):
            # tanhå¯¼æ•°çš„æœ€å¤§å€¼æ˜¯1
            grad *= 0.5 * np.random.rand()
            gradients_tanh.append(grad)
        
        layers = range(1, depth + 1)
        
        ax.semilogy(layers, gradients_sigmoid, 'b-o', label='Sigmoid', linewidth=2)
        ax.semilogy(layers, gradients_relu, 'g-s', label='ReLU', linewidth=2)
        ax.semilogy(layers, gradients_tanh, 'r-^', label='Tanh', linewidth=2)
        
        ax.set_xlabel('å±‚æ•°')
        ax.set_ylabel('æ¢¯åº¦å¤§å°ï¼ˆå¯¹æ•°å°ºåº¦ï¼‰')
        ax.set_title(f'æ·±åº¦ = {depth} å±‚')
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # æ ‡æ³¨æ¢¯åº¦æ¶ˆå¤±åŒºåŸŸ
        ax.axhline(y=1e-5, color='red', linestyle='--', alpha=0.5)
        ax.text(depth * 0.7, 1e-5, 'æ¢¯åº¦æ¶ˆå¤±é˜ˆå€¼', 
                color='red', fontsize=10)
    
    plt.suptitle('ä¸åŒæ¿€æ´»å‡½æ•°çš„æ¢¯åº¦ä¼ æ’­', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    # è§£å†³æ–¹æ¡ˆæ¼”ç¤º
    print("ğŸ”§ è§£å†³æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸çš„æ–¹æ³•ï¼š\n")
    
    methods = [
        ("1. ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°", "é¿å…æ¢¯åº¦é¥±å’Œ"),
        ("2. Batch Normalization", "å½’ä¸€åŒ–æ¯å±‚çš„è¾“å…¥"),
        ("3. æ®‹å·®è¿æ¥ï¼ˆResNetï¼‰", "è®©æ¢¯åº¦å¯ä»¥è·³è¿‡å±‚ç›´æ¥ä¼ æ’­"),
        ("4. æ¢¯åº¦è£å‰ª", "é™åˆ¶æ¢¯åº¦çš„æœ€å¤§å€¼"),
        ("5. æ›´å¥½çš„åˆå§‹åŒ–", "Xavieræˆ–Heåˆå§‹åŒ–"),
        ("6. ä½¿ç”¨LSTM/GRU", "åœ¨RNNä¸­ä½¿ç”¨é—¨æ§æœºåˆ¶")
    ]
    
    for method, description in methods:
        print(f"{method}")
        print(f"   â†’ {description}\n")

æ¢¯åº¦æ¶ˆå¤±å’Œçˆ†ç‚¸é—®é¢˜()
```

#### ğŸ’¡ æœ¬ç« å°ç»“

1. **æ¢¯åº¦ä¸‹é™çš„æœ¬è´¨**ï¼š
   - æ²¿ç€å‡½æ•°ä¸‹é™æœ€å¿«çš„æ–¹å‘èµ°
   - æ­¥é•¿ç”±å­¦ä¹ ç‡æ§åˆ¶
   - ç›®æ ‡æ˜¯æ‰¾åˆ°æŸå¤±å‡½æ•°çš„æœ€å°å€¼

2. **æ ¸å¿ƒå…¬å¼**ï¼š
   - å‚æ•°æ›´æ–°ï¼šÎ¸ = Î¸ - Î±Â·âˆ‡L(Î¸)
   - Î±æ˜¯å­¦ä¹ ç‡ï¼Œâˆ‡Læ˜¯æŸå¤±å‡½æ•°çš„æ¢¯åº¦

3. **æ¢¯åº¦ä¸‹é™çš„å˜ä½“**ï¼š
   - **æ‰¹é‡æ¢¯åº¦ä¸‹é™**ï¼šä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼Œç¨³å®šä½†æ…¢
   - **éšæœºæ¢¯åº¦ä¸‹é™**ï¼šä½¿ç”¨å•ä¸ªæ ·æœ¬ï¼Œå¿«ä½†ä¸ç¨³å®š
   - **å°æ‰¹é‡æ¢¯åº¦ä¸‹é™**ï¼šæŠ˜ä¸­æ–¹æ¡ˆï¼Œæœ€å¸¸ç”¨

4. **é«˜çº§ä¼˜åŒ–å™¨**ï¼š
   - **Momentum**ï¼šå¢åŠ æƒ¯æ€§ï¼ŒåŠ é€Ÿæ”¶æ•›
   - **AdaGrad**ï¼šè‡ªé€‚åº”å­¦ä¹ ç‡
   - **Adam**ï¼šç»“åˆMomentumå’Œè‡ªé€‚åº”å­¦ä¹ ç‡

5. **å¸¸è§é—®é¢˜**ï¼š
   - **å±€éƒ¨æœ€å°å€¼**ï¼šå¯èƒ½é™·å…¥æ¬¡ä¼˜è§£
   - **å­¦ä¹ ç‡é€‰æ‹©**ï¼šå¤ªå¤§å‘æ•£ï¼Œå¤ªå°æ”¶æ•›æ…¢
   - **æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸**ï¼šæ·±åº¦ç½‘ç»œçš„æŒ‘æˆ˜

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆæ¢¯åº¦çš„åæ–¹å‘æ˜¯å‡½æ•°ä¸‹é™æœ€å¿«çš„æ–¹å‘ï¼Ÿ
2. å¦‚æœæŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°ï¼Œæ¢¯åº¦ä¸‹é™èƒ½ä¿è¯æ‰¾åˆ°å…¨å±€æœ€ä¼˜å—ï¼Ÿ
3. ä¸ºä»€ä¹ˆç°ä»£æ·±åº¦å­¦ä¹ ä¸­Adamä¼˜åŒ–å™¨å¦‚æ­¤æµè¡Œï¼Ÿ

#### ğŸ”¬ åŠ¨æ‰‹å®éªŒ

```python
def æ¢¯åº¦ä¸‹é™å¤§æŒ‘æˆ˜():
    """ä¸€ä¸ªç»¼åˆæ€§çš„æ¢¯åº¦ä¸‹é™å®éªŒ"""
    
    print("ğŸ® æ¢¯åº¦ä¸‹é™å¤§æŒ‘æˆ˜ï¼\n")
    print("ä»»åŠ¡ï¼šä¼˜åŒ–ä¸€ä¸ªç¥ç§˜å‡½æ•°ï¼Œæ‰¾åˆ°éšè—çš„å®è—ï¼ˆæœ€å°å€¼ï¼‰\n")
    
    # ç¥ç§˜å‡½æ•°ï¼ˆRosenbrockå‡½æ•°ï¼‰
    def mystery_function(x, y):
        return (1 - x)**2 + 100 * (y - x**2)**2
    
    # æ¢¯åº¦
    def gradient(x, y):
        dx = -2 * (1 - x) - 400 * x * (y - x**2)
        dy = 200 * (y - x**2)
        return np.array([dx, dy])
    
    # è®©ç”¨æˆ·é€‰æ‹©ä¼˜åŒ–å™¨
    print("é€‰æ‹©ä½ çš„ä¼˜åŒ–å™¨ï¼š")
    print("1. æ™®é€šæ¢¯åº¦ä¸‹é™")
    print("2. å¸¦åŠ¨é‡çš„æ¢¯åº¦ä¸‹é™")
    print("3. Adamä¼˜åŒ–å™¨")
    
    # è¿™é‡Œç®€åŒ–ä¸ºè‡ªåŠ¨é€‰æ‹©
    optimizer_choice = 3  # Adam
    
    # åˆå§‹ä½ç½®
    position = np.array([-1.0, 1.0])
    learning_rate = 0.001
    
    # è®°å½•è·¯å¾„
    path = [position.copy()]
    
    # ä¼˜åŒ–è¿‡ç¨‹
    if optimizer_choice == 3:  # Adam
        m = np.zeros(2)
        v = np.zeros(2)
        beta1, beta2 = 0.9, 0.999
        epsilon = 1e-8
        
        for t in range(1, 1001):
            grad = gradient(position[0], position[1])
            
            m = beta1 * m + (1 - beta1) * grad
            v = beta2 * v + (1 - beta2) * grad**2
            
            m_hat = m / (1 - beta1**t)
            v_hat = v / (1 - beta2**t)
            
            position = position - learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)
            path.append(position.copy())
    
    path = np.array(path)
    
    # å¯è§†åŒ–ç»“æœ
    plt.figure(figsize=(12, 10))
    
    # åˆ›å»ºç­‰é«˜çº¿å›¾
    x = np.linspace(-2, 2, 100)
    y = np.linspace(-1, 3, 100)
    X, Y = np.meshgrid(x, y)
    Z = mystery_function(X, Y)
    
    plt.contour(X, Y, Z, levels=np.logspace(-1, 3, 20), alpha=0.6)
    plt.plot(path[:, 0], path[:, 1], 'r-o', markersize=3, 
             linewidth=2, label='ä¼˜åŒ–è·¯å¾„')
    plt.plot(1, 1, 'g*', markersize=20, label='å®è—ä½ç½®')
    plt.plot(path[0, 0], path[0, 1], 'bo', markersize=10, label='èµ·å§‹ä½ç½®')
    
    plt.xlabel('x')
    plt.ylabel('y')
    plt.title('æ¢¯åº¦ä¸‹é™å¯»å®è®°')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ æ–‡å­—è¯´æ˜
    final_value = mystery_function(path[-1, 0], path[-1, 1])
    plt.text(0.02, 0.98, f'æœ€ç»ˆä½ç½®: ({path[-1, 0]:.3f}, {path[-1, 1]:.3f})\n'
                        f'å‡½æ•°å€¼: {final_value:.6f}\n'
                        f'æ€»æ­¥æ•°: {len(path)-1}',
             transform=plt.gca().transAxes,
             verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    plt.show()
    
    print(f"\nğŸ‰ æ­å–œï¼ä½ æ‰¾åˆ°äº†å®è—ï¼")
    print(f"å®è—ä½ç½®åº”è¯¥åœ¨ (1, 1)ï¼Œä½ æ‰¾åˆ°çš„ä½ç½®æ˜¯ ({path[-1, 0]:.3f}, {path[-1, 1]:.3f})")
    print(f"è¯¯å·®åªæœ‰ {np.linalg.norm(path[-1] - np.array([1, 1])):.6f}ï¼")

æ¢¯åº¦ä¸‹é™å¤§æŒ‘æˆ˜()
```

ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†å­¦ä¹ åå‘ä¼ æ’­â€”â€”è®©AIçŸ¥é”™å°±æ”¹çš„ç¥å¥‡ç®—æ³•ï¼

---

### ç¬¬5ç« ï¼šåå‘ä¼ æ’­â€”â€”è®©AIçŸ¥é”™å°±æ”¹çš„é­”æ³•

#### ğŸ¯ æœ¬ç« å¯¼è¯»

è¿˜è®°å¾—å°æ—¶å€™åšæ•°å­¦é¢˜å—ï¼Ÿè€å¸ˆåœ¨ä½ çš„ä½œä¸šæœ¬ä¸Šæ‰“äº†ä¸ªâŒï¼Œç„¶åä½ å°±çŸ¥é“è¦æ”¹æ­£ã€‚ä½†è€å¸ˆä¸ä»…å‘Šè¯‰ä½ é”™äº†ï¼Œè¿˜ä¼šå‘Šè¯‰ä½ é”™åœ¨å“ªä¸€æ­¥ï¼Œè¿™æ ·ä½ æ‰èƒ½çœŸæ­£å­¦ä¼šã€‚

åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰å°±æ˜¯ç¥ç»ç½‘ç»œçš„"è€å¸ˆ"ã€‚å®ƒä¸ä»…å‘Šè¯‰ç½‘ç»œé¢„æµ‹é”™äº†ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå®ƒèƒ½ç²¾ç¡®åœ°å‘Šè¯‰ç½‘ç»œä¸­çš„æ¯ä¸€ä¸ªå‚æ•°ï¼š"å˜¿ï¼Œä½ è¦å¾€è¿™ä¸ªæ–¹å‘è°ƒæ•´è¿™ä¹ˆå¤šï¼"

è¿™å¬èµ·æ¥åƒé­”æ³•ï¼Œä½†å…¶å®èƒŒåæ˜¯ä¼˜é›…çš„æ•°å­¦ã€‚ä»Šå¤©ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ­å¼€åå‘ä¼ æ’­çš„ç¥ç§˜é¢çº±ï¼

#### ğŸ­ åå‘ä¼ æ’­çš„ç›´è§‚ç†è§£

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle, FancyBboxPatch
import matplotlib.patches as mpatches

def åå‘ä¼ æ’­çš„è¿é”ååº”():
    """ç”¨å¤šç±³è¯ºéª¨ç‰Œæ•ˆåº”æ¥ç†è§£åå‘ä¼ æ’­"""
    
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # ä¸Šå›¾ï¼šå‰å‘ä¼ æ’­ï¼ˆæ¨å€’å¤šç±³è¯ºï¼‰
    ax1.set_xlim(-1, 11)
    ax1.set_ylim(0, 3)
    ax1.set_title('å‰å‘ä¼ æ’­ï¼šåƒæ¨å€’å¤šç±³è¯ºéª¨ç‰Œ', fontsize=16)
    
    # ç”»å¤šç±³è¯ºéª¨ç‰Œ
    dominoes = ['è¾“å…¥x', 'wâ‚Â·x', '+bâ‚', 'ReLU', 'wâ‚‚Â·h', '+bâ‚‚', 'è¾“å‡ºy']
    colors = ['lightblue', 'lightgreen', 'lightgreen', 'yellow', 
              'lightcoral', 'lightcoral', 'orange']
    
    for i, (domino, color) in enumerate(zip(dominoes, colors)):
        rect = FancyBboxPatch((i*1.5, 0.5), 0.8, 1.5, 
                             boxstyle="round,pad=0.1",
                             facecolor=color, edgecolor='black', linewidth=2)
        ax1.add_patch(rect)
        ax1.text(i*1.5 + 0.4, 1.25, domino, ha='center', va='center', 
                fontsize=10, weight='bold')
    
    # ç”»ç®­å¤´è¡¨ç¤ºæ¨å€’æ–¹å‘
    for i in range(len(dominoes)-1):
        ax1.arrow(i*1.5 + 0.9, 1.25, 0.5, 0, 
                 head_width=0.1, head_length=0.1, fc='blue', ec='blue')
    
    ax1.axis('off')
    ax1.text(5, 2.5, 'ä¿¡å·å‘å‰ä¼ æ’­ â†’', ha='center', fontsize=14, 
            bbox=dict(boxstyle='round', facecolor='wheat'))
    
    # ä¸‹å›¾ï¼šåå‘ä¼ æ’­ï¼ˆé”™è¯¯ä¿¡å·å›ä¼ ï¼‰
    ax2.set_xlim(-1, 11)
    ax2.set_ylim(0, 3)
    ax2.set_title('åå‘ä¼ æ’­ï¼šé”™è¯¯ä¿¡å·åŸè·¯è¿”å›', fontsize=16)
    
    # ç”»åŒæ ·çš„éª¨ç‰Œ
    for i, (domino, color) in enumerate(zip(dominoes, colors)):
        rect = FancyBboxPatch((i*1.5, 0.5), 0.8, 1.5,
                             boxstyle="round,pad=0.1",
                             facecolor=color, edgecolor='black', linewidth=2)
        ax2.add_patch(rect)
        ax2.text(i*1.5 + 0.4, 1.25, domino, ha='center', va='center',
                fontsize=10, weight='bold')
    
    # ç”»åå‘ç®­å¤´
    for i in range(len(dominoes)-1, 0, -1):
        ax2.arrow(i*1.5 - 0.1, 0.8, -0.5, 0,
                 head_width=0.1, head_length=0.1, fc='red', ec='red')
    
    # æ ‡æ³¨æ¢¯åº¦
    gradients = ['âˆ‚L/âˆ‚y', 'âˆ‚L/âˆ‚wâ‚‚', 'âˆ‚L/âˆ‚bâ‚‚', 'âˆ‚L/âˆ‚h', 'âˆ‚L/âˆ‚wâ‚', 'âˆ‚L/âˆ‚bâ‚', 'âˆ‚L/âˆ‚x']
    for i, grad in enumerate(gradients):
        ax2.text((len(dominoes)-1-i)*1.5 + 0.4, 0.2, grad, 
                ha='center', va='center', fontsize=9, color='red')
    
    ax2.axis('off')
    ax2.text(5, 2.5, 'â† æ¢¯åº¦åå‘ä¼ æ’­', ha='center', fontsize=14,
            bbox=dict(boxstyle='round', facecolor='lightcoral'))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ’¡ å…³é”®æ´å¯Ÿï¼š")
    print("1. å‰å‘ä¼ æ’­ï¼šè®¡ç®—é¢„æµ‹å€¼ï¼Œæ¯ä¸€æ­¥çš„è¾“å‡ºæ˜¯ä¸‹ä¸€æ­¥çš„è¾“å…¥")
    print("2. åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦ï¼Œæ¯ä¸€æ­¥çš„æ¢¯åº¦ä¾èµ–äºåä¸€æ­¥çš„æ¢¯åº¦")
    print("3. è¿™å°±æ˜¯'åå‘'çš„å«ä¹‰ï¼šæ¢¯åº¦ä»è¾“å‡ºå±‚å‘è¾“å…¥å±‚ä¼ æ’­")

åå‘ä¼ æ’­çš„è¿é”ååº”()
```

#### ğŸ”— é“¾å¼æ³•åˆ™ï¼šåå‘ä¼ æ’­çš„æ•°å­¦åŸºç¡€

```python
def é“¾å¼æ³•åˆ™å¯è§†åŒ–():
    """å¯è§†åŒ–é“¾å¼æ³•åˆ™"""
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„è®¡ç®—å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # å·¦å›¾ï¼šè®¡ç®—å›¾
    ax1.set_xlim(-1, 5)
    ax1.set_ylim(-1, 3)
    ax1.set_title('è®¡ç®—å›¾ï¼šz = (x + y)Â²', fontsize=14)
    
    # èŠ‚ç‚¹
    nodes = {
        'x': (0, 2),
        'y': (0, 0),
        '+': (2, 1),
        'Â²': (4, 1),
        'z': (5, 1)
    }
    
    # ç”»èŠ‚ç‚¹
    for name, (x, y) in nodes.items():
        if name in ['x', 'y', 'z']:
            circle = plt.Circle((x, y), 0.3, color='lightblue', ec='black')
        else:
            circle = plt.Circle((x, y), 0.3, color='lightgreen', ec='black')
        ax1.add_patch(circle)
        ax1.text(x, y, name, ha='center', va='center', fontsize=12, weight='bold')
    
    # ç”»è¾¹å’Œæ ‡æ³¨
    edges = [
        (('x', '+'), 'x'),
        (('y', '+'), 'y'),
        (('+', 'Â²'), 'u=x+y'),
        (('Â²', 'z'), 'z=uÂ²')
    ]
    
    for (start, end), label in edges:
        x1, y1 = nodes[start]
        x2, y2 = nodes[end]
        ax1.arrow(x1+0.3, y1, x2-x1-0.6, y2-y1,
                 head_width=0.1, head_length=0.1, fc='black', ec='black')
        # æ ‡æ³¨
        mid_x, mid_y = (x1+x2)/2, (y1+y2)/2
        ax1.text(mid_x, mid_y+0.2, label, ha='center', fontsize=10)
    
    ax1.axis('off')
    
    # å³å›¾ï¼šé“¾å¼æ³•åˆ™è®¡ç®—
    ax2.text(0.5, 0.9, 'é“¾å¼æ³•åˆ™è®¡ç®—è¿‡ç¨‹ï¼š', ha='center', fontsize=14, 
            weight='bold', transform=ax2.transAxes)
    
    # è®¾ç½®å…·ä½“å€¼
    x_val, y_val = 3, 2
    u_val = x_val + y_val  # 5
    z_val = u_val ** 2     # 25
    
    # å‰å‘ä¼ æ’­å€¼
    forward_text = f"""å‰å‘ä¼ æ’­ï¼š
    x = {x_val}, y = {y_val}
    u = x + y = {u_val}
    z = uÂ² = {z_val}
    """
    
    # åå‘ä¼ æ’­è®¡ç®—
    dz_dz = 1  # è¾“å‡ºå¯¹è‡ªå·±çš„å¯¼æ•°
    dz_du = 2 * u_val  # d(uÂ²)/du = 2u = 10
    du_dx = 1  # d(x+y)/dx = 1
    du_dy = 1  # d(x+y)/dy = 1
    
    # é“¾å¼æ³•åˆ™
    dz_dx = dz_du * du_dx  # 10 * 1 = 10
    dz_dy = dz_du * du_dy  # 10 * 1 = 10
    
    backward_text = f"""
åå‘ä¼ æ’­ï¼ˆé“¾å¼æ³•åˆ™ï¼‰ï¼š
    âˆ‚z/âˆ‚z = {dz_dz}
    âˆ‚z/âˆ‚u = 2u = 2Ã—{u_val} = {dz_du}
    âˆ‚u/âˆ‚x = {du_dx}
    âˆ‚u/âˆ‚y = {du_dy}
    
    âˆ‚z/âˆ‚x = âˆ‚z/âˆ‚u Ã— âˆ‚u/âˆ‚x = {dz_du} Ã— {du_dx} = {dz_dx}
    âˆ‚z/âˆ‚y = âˆ‚z/âˆ‚u Ã— âˆ‚u/âˆ‚y = {dz_du} Ã— {du_dy} = {dz_dy}
    """
    
    ax2.text(0.1, 0.7, forward_text, transform=ax2.transAxes, 
            fontsize=11, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
    
    ax2.text(0.1, 0.35, backward_text, transform=ax2.transAxes,
            fontsize=11, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))
    
    ax2.axis('off')
    
    plt.tight_layout()
    plt.show()
    
    # æ›´å¤æ‚çš„ä¾‹å­
    print("\nğŸ” æ›´å¤æ‚çš„ä¾‹å­ï¼š")
    print("å¦‚æœ z = sin(xÂ²+yÂ³)ï¼Œé‚£ä¹ˆï¼š")
    print("âˆ‚z/âˆ‚x = cos(xÂ²+yÂ³) Ã— 2x")
    print("âˆ‚z/âˆ‚y = cos(xÂ²+yÂ³) Ã— 3yÂ²")
    print("\nè¿™å°±æ˜¯é“¾å¼æ³•åˆ™çš„å¨åŠ›ï¼šå¤æ‚å‡½æ•°çš„å¯¼æ•° = ç®€å•å‡½æ•°å¯¼æ•°çš„ä¹˜ç§¯ï¼")

é“¾å¼æ³•åˆ™å¯è§†åŒ–()
```

#### ğŸ§® æ‰‹åŠ¨å®ç°åå‘ä¼ æ’­

```python
class ComputationalGraph:
    """è®¡ç®—å›¾ï¼šå®ç°è‡ªåŠ¨å¾®åˆ†çš„åŸºç¡€"""
    
    def __init__(self):
        self.nodes = []
        self.gradients = {}
    
    class Node:
        """è®¡ç®—å›¾ä¸­çš„èŠ‚ç‚¹"""
        def __init__(self, name, value=None):
            self.name = name
            self.value = value
            self.grad = 0
            self.inputs = []
            self.operation = None
    
    def variable(self, name, value):
        """åˆ›å»ºå˜é‡èŠ‚ç‚¹"""
        node = self.Node(name, value)
        self.nodes.append(node)
        return node
    
    def add(self, a, b, name="add"):
        """åŠ æ³•æ“ä½œ"""
        node = self.Node(name)
        node.inputs = [a, b]
        node.operation = 'add'
        node.value = a.value + b.value
        self.nodes.append(node)
        return node
    
    def multiply(self, a, b, name="mul"):
        """ä¹˜æ³•æ“ä½œ"""
        node = self.Node(name)
        node.inputs = [a, b]
        node.operation = 'multiply'
        node.value = a.value * b.value
        self.nodes.append(node)
        return node
    
    def power(self, a, n, name="pow"):
        """å¹‚æ“ä½œ"""
        node = self.Node(name)
        node.inputs = [a]
        node.operation = 'power'
        node.n = n
        node.value = a.value ** n
        self.nodes.append(node)
        return node
    
    def backward(self, output_node):
        """åå‘ä¼ æ’­ç®—æ³•"""
        # åˆå§‹åŒ–ï¼šè¾“å‡ºèŠ‚ç‚¹çš„æ¢¯åº¦ä¸º1
        output_node.grad = 1
        
        # åå‘éå†èŠ‚ç‚¹
        for node in reversed(self.nodes):
            if node.operation == 'add':
                # åŠ æ³•çš„æ¢¯åº¦ï¼šç›´æ¥ä¼ é€’
                node.inputs[0].grad += node.grad
                node.inputs[1].grad += node.grad
                
            elif node.operation == 'multiply':
                # ä¹˜æ³•çš„æ¢¯åº¦ï¼šäº¤å‰ç›¸ä¹˜
                node.inputs[0].grad += node.grad * node.inputs[1].value
                node.inputs[1].grad += node.grad * node.inputs[0].value
                
            elif node.operation == 'power':
                # å¹‚çš„æ¢¯åº¦ï¼šn * x^(n-1)
                node.inputs[0].grad += node.grad * node.n * (node.inputs[0].value ** (node.n - 1))

def æ‰‹åŠ¨åå‘ä¼ æ’­æ¼”ç¤º():
    """æ¼”ç¤ºæ‰‹åŠ¨å®ç°çš„åå‘ä¼ æ’­"""
    
    print("ğŸ”§ æ‰‹åŠ¨å®ç°åå‘ä¼ æ’­\n")
    
    # åˆ›å»ºè®¡ç®—å›¾
    graph = ComputationalGraph()
    
    # å®šä¹‰å˜é‡
    x = graph.variable('x', 2)
    w = graph.variable('w', 3)
    b = graph.variable('b', 1)
    
    # æ„å»ºè®¡ç®—ï¼šy = (w*x + b)Â²
    wx = graph.multiply(w, x, "w*x")
    wx_plus_b = graph.add(wx, b, "w*x+b")
    y = graph.power(wx_plus_b, 2, "y")
    
    print(f"å‰å‘ä¼ æ’­ç»“æœï¼š")
    print(f"x = {x.value}")
    print(f"w = {w.value}")
    print(f"b = {b.value}")
    print(f"w*x = {wx.value}")
    print(f"w*x+b = {wx_plus_b.value}")
    print(f"y = (w*x+b)Â² = {y.value}")
    
    # æ‰§è¡Œåå‘ä¼ æ’­
    graph.backward(y)
    
    print(f"\nåå‘ä¼ æ’­ç»“æœï¼š")
    print(f"âˆ‚y/âˆ‚x = {x.grad}")
    print(f"âˆ‚y/âˆ‚w = {w.grad}")
    print(f"âˆ‚y/âˆ‚b = {b.grad}")
    
    # éªŒè¯ç»“æœ
    print(f"\næ‰‹åŠ¨éªŒè¯ï¼š")
    print(f"y = (wx+b)Â² = ({w.value}Ã—{x.value}+{b.value})Â² = {wx_plus_b.value}Â² = {y.value}")
    print(f"âˆ‚y/âˆ‚x = 2(wx+b)Ã—w = 2Ã—{wx_plus_b.value}Ã—{w.value} = {2*wx_plus_b.value*w.value}")
    print(f"âˆ‚y/âˆ‚w = 2(wx+b)Ã—x = 2Ã—{wx_plus_b.value}Ã—{x.value} = {2*wx_plus_b.value*x.value}")
    print(f"âˆ‚y/âˆ‚b = 2(wx+b)Ã—1 = 2Ã—{wx_plus_b.value} = {2*wx_plus_b.value}")
    
    # å¯è§†åŒ–è®¡ç®—å›¾
    visualize_computation_graph()

def visualize_computation_graph():
    """å¯è§†åŒ–è®¡ç®—å›¾å’Œæ¢¯åº¦æµ"""
    
    fig, ax = plt.subplots(figsize=(10, 8))
    
    # èŠ‚ç‚¹ä½ç½®
    positions = {
        'x': (1, 3),
        'w': (1, 1),
        'b': (3, 0),
        'w*x': (3, 2),
        'w*x+b': (5, 1.5),
        'y': (7, 1.5)
    }
    
    # ç”»èŠ‚ç‚¹
    for name, (x, y) in positions.items():
        if name in ['x', 'w', 'b']:
            color = 'lightblue'
        elif name == 'y':
            color = 'lightcoral'
        else:
            color = 'lightgreen'
        
        circle = plt.Circle((x, y), 0.4, color=color, ec='black', linewidth=2)
        ax.add_patch(circle)
        ax.text(x, y, name, ha='center', va='center', fontsize=11, weight='bold')
    
    # ç”»è¾¹ï¼ˆå‰å‘ä¼ æ’­ï¼‰
    edges = [
        ('x', 'w*x'),
        ('w', 'w*x'),
        ('w*x', 'w*x+b'),
        ('b', 'w*x+b'),
        ('w*x+b', 'y')
    ]
    
    for start, end in edges:
        x1, y1 = positions[start]
        x2, y2 = positions[end]
        ax.arrow(x1+0.3, y1, x2-x1-0.6, y2-y1,
                head_width=0.1, head_length=0.1, 
                fc='blue', ec='blue', alpha=0.7, linewidth=2)
    
    # ç”»æ¢¯åº¦ï¼ˆåå‘ä¼ æ’­ï¼‰
    gradient_edges = list(reversed(edges))
    for start, end in gradient_edges:
        x1, y1 = positions[start]
        x2, y2 = positions[end]
        ax.arrow(x2-0.3, y2, x1-x2+0.6, y1-y2,
                head_width=0.1, head_length=0.1,
                fc='red', ec='red', alpha=0.5, linewidth=1.5,
                linestyle='--')
    
    # æ·»åŠ å›¾ä¾‹
    blue_patch = mpatches.Patch(color='blue', label='å‰å‘ä¼ æ’­')
    red_patch = mpatches.Patch(color='red', label='åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦ï¼‰')
    ax.legend(handles=[blue_patch, red_patch], loc='upper right')
    
    ax.set_xlim(0, 8)
    ax.set_ylim(-1, 4)
    ax.set_title('è®¡ç®—å›¾ï¼šy = (wÃ—x + b)Â²', fontsize=14)
    ax.axis('off')
    
    plt.tight_layout()
    plt.show()

æ‰‹åŠ¨åå‘ä¼ æ’­æ¼”ç¤º()
```

#### ğŸ—ï¸ æ„å»ºä¸€ä¸ªè¿·ä½ è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿ

```python
class Tensor:
    """è¿·ä½ ç‰ˆçš„è‡ªåŠ¨å¾®åˆ†å¼ é‡"""
    
    def __init__(self, data, requires_grad=False, operation=None, operands=None):
        self.data = np.array(data, dtype=np.float32)
        self.requires_grad = requires_grad
        self.grad = None
        self.operation = operation  # åˆ›å»ºè¿™ä¸ªå¼ é‡çš„æ“ä½œ
        self.operands = operands or []  # æ“ä½œæ•°
        
        if self.requires_grad:
            self.grad = np.zeros_like(self.data)
    
    def __add__(self, other):
        """åŠ æ³•"""
        if not isinstance(other, Tensor):
            other = Tensor(other)
        
        result = Tensor(
            self.data + other.data,
            requires_grad=self.requires_grad or other.requires_grad,
            operation='add',
            operands=[self, other]
        )
        return result
    
    def __mul__(self, other):
        """ä¹˜æ³•"""
        if not isinstance(other, Tensor):
            other = Tensor(other)
        
        result = Tensor(
            self.data * other.data,
            requires_grad=self.requires_grad or other.requires_grad,
            operation='mul',
            operands=[self, other]
        )
        return result
    
    def sum(self):
        """æ±‚å’Œ"""
        result = Tensor(
            np.sum(self.data),
            requires_grad=self.requires_grad,
            operation='sum',
            operands=[self]
        )
        return result
    
    def backward(self, grad=None):
        """åå‘ä¼ æ’­"""
        if not self.requires_grad:
            return
        
        # åˆå§‹åŒ–æ¢¯åº¦
        if grad is None:
            grad = np.ones_like(self.data)
        
        # ç´¯ç§¯æ¢¯åº¦
        if self.grad is None:
            self.grad = grad
        else:
            self.grad += grad
        
        # æ ¹æ®æ“ä½œç±»å‹è®¡ç®—æ¢¯åº¦
        if self.operation == 'add':
            # åŠ æ³•ï¼šæ¢¯åº¦ç›´æ¥ä¼ é€’
            if self.operands[0].requires_grad:
                self.operands[0].backward(grad)
            if self.operands[1].requires_grad:
                self.operands[1].backward(grad)
                
        elif self.operation == 'mul':
            # ä¹˜æ³•ï¼šäº¤å‰ç›¸ä¹˜
            if self.operands[0].requires_grad:
                self.operands[0].backward(grad * self.operands[1].data)
            if self.operands[1].requires_grad:
                self.operands[1].backward(grad * self.operands[0].data)
                
        elif self.operation == 'sum':
            # æ±‚å’Œï¼šå¹¿æ’­æ¢¯åº¦
            if self.operands[0].requires_grad:
                grad_expanded = np.ones_like(self.operands[0].data) * grad
                self.operands[0].backward(grad_expanded)

def è¿·ä½ è‡ªåŠ¨å¾®åˆ†æ¼”ç¤º():
    """æ¼”ç¤ºæˆ‘ä»¬çš„è¿·ä½ è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿ"""
    
    print("ğŸ¤– è¿·ä½ è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿæ¼”ç¤º\n")
    
    # åˆ›å»ºå¼ é‡
    x = Tensor([[1, 2], [3, 4]], requires_grad=True)
    w = Tensor([[2, 0], [0, 2]], requires_grad=True)
    b = Tensor([1, 1], requires_grad=True)
    
    print("è¾“å…¥å¼ é‡ï¼š")
    print(f"x = \n{x.data}")
    print(f"w = \n{w.data}")
    print(f"b = {b.data}")
    
    # å‰å‘ä¼ æ’­: y = sum(w * x + b)
    y = w * x + b
    loss = y.sum()
    
    print(f"\nå‰å‘ä¼ æ’­ï¼š")
    print(f"w * x = \n{(w * x).data}")
    print(f"w * x + b = \n{y.data}")
    print(f"loss = sum(w * x + b) = {loss.data}")
    
    # åå‘ä¼ æ’­
    loss.backward()
    
    print(f"\nåå‘ä¼ æ’­ç»“æœï¼š")
    print(f"âˆ‚loss/âˆ‚x = \n{x.grad}")
    print(f"âˆ‚loss/âˆ‚w = \n{w.grad}")
    print(f"âˆ‚loss/âˆ‚b = {b.grad}")
    
    # éªŒè¯æ¢¯åº¦
    print("\næ¢¯åº¦æ£€æŸ¥ï¼š")
    print("å¯¹äº loss = sum(w * x + b):")
    print("- âˆ‚loss/âˆ‚x = w ï¼ˆå› ä¸ºsumçš„æ¢¯åº¦æ˜¯1ï¼Œä¹˜æ³•çš„æ¢¯åº¦æ˜¯wï¼‰")
    print("- âˆ‚loss/âˆ‚w = x ï¼ˆå› ä¸ºsumçš„æ¢¯åº¦æ˜¯1ï¼Œä¹˜æ³•çš„æ¢¯åº¦æ˜¯xï¼‰")
    print("- âˆ‚loss/âˆ‚b = [1, 1] ï¼ˆå› ä¸ºsumå¯¹æ¯ä¸ªå…ƒç´ çš„æ¢¯åº¦éƒ½æ˜¯1ï¼‰")
    
    # æ¢¯åº¦ä¸‹é™æ›´æ–°
    learning_rate = 0.1
    print(f"\nä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°å‚æ•°ï¼ˆå­¦ä¹ ç‡={learning_rate}ï¼‰ï¼š")
    
    x_new = x.data - learning_rate * x.grad
    w_new = w.data - learning_rate * w.grad
    b_new = b.data - learning_rate * b.grad
    
    print(f"x_new = \n{x_new}")
    print(f"w_new = \n{w_new}")
    print(f"b_new = {b_new}")

è¿·ä½ è‡ªåŠ¨å¾®åˆ†æ¼”ç¤º()
```

#### ğŸª ç¥ç»ç½‘ç»œä¸­çš„åå‘ä¼ æ’­

```python
class NeuralNetworkWithBackprop:
    """å¸¦æœ‰è¯¦ç»†åå‘ä¼ æ’­çš„ç¥ç»ç½‘ç»œ"""
    
    def __init__(self):
        # ä¸€ä¸ªç®€å•çš„2-3-1ç½‘ç»œ
        self.W1 = np.random.randn(2, 3) * 0.5
        self.b1 = np.zeros((1, 3))
        self.W2 = np.random.randn(3, 1) * 0.5
        self.b2 = np.zeros((1, 1))
        
        # ä¿å­˜ä¸­é—´å€¼
        self.cache = {}
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        s = self.sigmoid(x)
        return s * (1 - s)
    
    def forward(self, X):
        """å‰å‘ä¼ æ’­ï¼Œä¿å­˜ä¸­é—´å€¼"""
        # ç¬¬ä¸€å±‚
        self.cache['X'] = X
        self.cache['Z1'] = X @ self.W1 + self.b1
        self.cache['A1'] = self.sigmoid(self.cache['Z1'])
        
        # ç¬¬äºŒå±‚
        self.cache['Z2'] = self.cache['A1'] @ self.W2 + self.b2
        self.cache['A2'] = self.sigmoid(self.cache['Z2'])
        
        return self.cache['A2']
    
    def backward_step_by_step(self, X, y_true):
        """é€æ­¥å±•ç¤ºåå‘ä¼ æ’­è¿‡ç¨‹"""
        m = X.shape[0]
        
        # å‰å‘ä¼ æ’­
        y_pred = self.forward(X)
        
        print("ğŸ” åå‘ä¼ æ’­è¯¦ç»†æ­¥éª¤ï¼š\n")
        
        # æ­¥éª¤1ï¼šè®¡ç®—æŸå¤±
        loss = -np.mean(y_true * np.log(y_pred + 1e-8) + 
                        (1 - y_true) * np.log(1 - y_pred + 1e-8))
        print(f"æ­¥éª¤1 - æŸå¤±å‡½æ•°: L = {loss:.4f}")
        
        # æ­¥éª¤2ï¼šè¾“å‡ºå±‚æ¢¯åº¦
        dA2 = -(y_true / (y_pred + 1e-8) - (1 - y_true) / (1 - y_pred + 1e-8)) / m
        print(f"\næ­¥éª¤2 - è¾“å‡ºå±‚æ¢¯åº¦:")
        print(f"âˆ‚L/âˆ‚A2 = {dA2.flatten()[:3]}... (æ˜¾ç¤ºå‰3ä¸ª)")
        
        # æ­¥éª¤3ï¼šé€šè¿‡sigmoidåå‘ä¼ æ’­
        dZ2 = dA2 * self.sigmoid_derivative(self.cache['Z2'])
        print(f"\næ­¥éª¤3 - é€šè¿‡sigmoidæ¿€æ´»å‡½æ•°:")
        print(f"âˆ‚L/âˆ‚Z2 = âˆ‚L/âˆ‚A2 Ã— Ïƒ'(Z2)")
        print(f"       = {dZ2.flatten()[:3]}...")
        
        # æ­¥éª¤4ï¼šè®¡ç®—W2å’Œb2çš„æ¢¯åº¦
        dW2 = self.cache['A1'].T @ dZ2
        db2 = np.sum(dZ2, axis=0, keepdims=True)
        print(f"\næ­¥éª¤4 - ç¬¬äºŒå±‚æƒé‡æ¢¯åº¦:")
        print(f"âˆ‚L/âˆ‚W2 = A1áµ€ Ã— âˆ‚L/âˆ‚Z2")
        print(f"shape: {dW2.shape}")
        
        # æ­¥éª¤5ï¼šä¼ æ’­åˆ°éšè—å±‚
        dA1 = dZ2 @ self.W2.T
        print(f"\næ­¥éª¤5 - ä¼ æ’­åˆ°éšè—å±‚:")
        print(f"âˆ‚L/âˆ‚A1 = âˆ‚L/âˆ‚Z2 Ã— W2áµ€")
        print(f"shape: {dA1.shape}")
        
        # æ­¥éª¤6ï¼šé€šè¿‡éšè—å±‚sigmoid
        dZ1 = dA1 * self.sigmoid_derivative(self.cache['Z1'])
        print(f"\næ­¥éª¤6 - é€šè¿‡éšè—å±‚æ¿€æ´»å‡½æ•°:")
        print(f"âˆ‚L/âˆ‚Z1 = âˆ‚L/âˆ‚A1 Ã— Ïƒ'(Z1)")
        
        # æ­¥éª¤7ï¼šè®¡ç®—W1å’Œb1çš„æ¢¯åº¦
        dW1 = X.T @ dZ1
        db1 = np.sum(dZ1, axis=0, keepdims=True)
        print(f"\næ­¥éª¤7 - ç¬¬ä¸€å±‚æƒé‡æ¢¯åº¦:")
        print(f"âˆ‚L/âˆ‚W1 = Xáµ€ Ã— âˆ‚L/âˆ‚Z1")
        print(f"shape: {dW1.shape}")
        
        return {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2}
    
    def visualize_gradients(self, gradients):
        """å¯è§†åŒ–æ¢¯åº¦"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # å¯è§†åŒ–æ¯å±‚çš„æ¢¯åº¦
        im1 = axes[0, 0].imshow(gradients['dW1'], cmap='RdBu', aspect='auto')
        axes[0, 0].set_title('ç¬¬ä¸€å±‚æƒé‡æ¢¯åº¦ (âˆ‚L/âˆ‚W1)')
        axes[0, 0].set_xlabel('éšè—å±‚ç¥ç»å…ƒ')
        axes[0, 0].set_ylabel('è¾“å…¥ç‰¹å¾')
        plt.colorbar(im1, ax=axes[0, 0])
        
        im2 = axes[0, 1].imshow(gradients['dW2'], cmap='RdBu', aspect='auto')
        axes[0, 1].set_title('ç¬¬äºŒå±‚æƒé‡æ¢¯åº¦ (âˆ‚L/âˆ‚W2)')
        axes[0, 1].set_xlabel('è¾“å‡ºç¥ç»å…ƒ')
        axes[0, 1].set_ylabel('éšè—å±‚ç¥ç»å…ƒ')
        plt.colorbar(im2, ax=axes[0, 1])
        
        # æ¢¯åº¦åˆ†å¸ƒç›´æ–¹å›¾
        axes[1, 0].hist(gradients['dW1'].flatten(), bins=30, alpha=0.7, color='blue')
        axes[1, 0].set_title('W1æ¢¯åº¦åˆ†å¸ƒ')
        axes[1, 0].set_xlabel('æ¢¯åº¦å€¼')
        axes[1, 0].set_ylabel('é¢‘æ•°')
        
        axes[1, 1].hist(gradients['dW2'].flatten(), bins=30, alpha=0.7, color='green')
        axes[1, 1].set_title('W2æ¢¯åº¦åˆ†å¸ƒ')
        axes[1, 1].set_xlabel('æ¢¯åº¦å€¼')
        axes[1, 1].set_ylabel('é¢‘æ•°')
        
        plt.tight_layout()
        plt.show()

def ç¥ç»ç½‘ç»œåå‘ä¼ æ’­æ¼”ç¤º():
    """å®Œæ•´çš„ç¥ç»ç½‘ç»œåå‘ä¼ æ’­æ¼”ç¤º"""
    
    # åˆ›å»ºç®€å•çš„æ•°æ®é›†
    np.random.seed(42)
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([[0], [1], [1], [0]])  # XORé—®é¢˜
    
    # åˆ›å»ºç½‘ç»œ
    nn = NeuralNetworkWithBackprop()
    
    print("ğŸ§  ç¥ç»ç½‘ç»œç»“æ„ï¼š")
    print(f"è¾“å…¥å±‚: 2ä¸ªç¥ç»å…ƒ")
    print(f"éšè—å±‚: 3ä¸ªç¥ç»å…ƒ (sigmoidæ¿€æ´»)")
    print(f"è¾“å‡ºå±‚: 1ä¸ªç¥ç»å…ƒ (sigmoidæ¿€æ´»)")
    print(f"\næƒé‡å½¢çŠ¶:")
    print(f"W1: {nn.W1.shape}, W2: {nn.W2.shape}")
    
    # æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„å‰å‘å’Œåå‘ä¼ æ’­
    print("\n" + "="*50 + "\n")
    gradients = nn.backward_step_by_step(X, y)
    
    # å¯è§†åŒ–æ¢¯åº¦
    nn.visualize_gradients(gradients)
    
    # å±•ç¤ºæ¢¯åº¦æ¶ˆå¤±é—®é¢˜
    å±•ç¤ºæ¢¯åº¦æ¶ˆå¤±é—®é¢˜()

def å±•ç¤ºæ¢¯åº¦æ¶ˆå¤±é—®é¢˜():
    """å±•ç¤ºæ·±å±‚ç½‘ç»œä¸­çš„æ¢¯åº¦æ¶ˆå¤±"""
    
    print("\nâš ï¸ æ¢¯åº¦æ¶ˆå¤±é—®é¢˜æ¼”ç¤ºï¼š")
    
    # sigmoidå‡½æ•°çš„å¯¼æ•°æœ€å¤§å€¼æ˜¯0.25
    x = np.linspace(-10, 10, 1000)
    sigmoid = 1 / (1 + np.exp(-x))
    sigmoid_grad = sigmoid * (1 - sigmoid)
    
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(x, sigmoid, 'b-', linewidth=2, label='sigmoid(x)')
    plt.plot(x, sigmoid_grad, 'r--', linewidth=2, label="sigmoid'(x)")
    plt.axhline(y=0.25, color='green', linestyle=':', label='æœ€å¤§æ¢¯åº¦=0.25')
    plt.xlabel('x')
    plt.ylabel('y')
    plt.title('Sigmoidå‡½æ•°åŠå…¶å¯¼æ•°')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    # æ¨¡æ‹Ÿæ¢¯åº¦åœ¨å¤šå±‚ä¸­çš„ä¼ æ’­
    layers = range(1, 11)
    gradient_sigmoid = 0.25 ** np.array(layers)  # æœ€åæƒ…å†µ
    gradient_relu = 0.9 ** np.array(layers)      # ReLUçš„å…¸å‹æƒ…å†µ
    
    plt.semilogy(layers, gradient_sigmoid, 'r-o', label='Sigmoid (æœ€åæƒ…å†µ)')
    plt.semilogy(layers, gradient_relu, 'g-s', label='ReLU (å…¸å‹æƒ…å†µ)')
    plt.axhline(y=1e-5, color='red', linestyle='--', alpha=0.5)
    plt.text(8, 1e-5, 'æ¢¯åº¦æ¶ˆå¤±é˜ˆå€¼', color='red')
    
    plt.xlabel('ç½‘ç»œæ·±åº¦ï¼ˆå±‚æ•°ï¼‰')
    plt.ylabel('æ¢¯åº¦å¤§å°ï¼ˆå¯¹æ•°å°ºåº¦ï¼‰')
    plt.title('æ¢¯åº¦åœ¨æ·±å±‚ç½‘ç»œä¸­çš„è¡°å‡')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("\nğŸ’¡ å…³é”®æ´å¯Ÿï¼š")
    print("1. Sigmoidçš„å¯¼æ•°æœ€å¤§åªæœ‰0.25ï¼Œå¤šå±‚ç›¸ä¹˜åæ¢¯åº¦è¿…é€Ÿæ¶ˆå¤±")
    print("2. 10å±‚ç½‘ç»œä¸­ï¼Œæ¢¯åº¦å¯èƒ½è¡°å‡åˆ°åŸæ¥çš„0.25^10 â‰ˆ 9.5Ã—10^-7")
    print("3. è¿™å°±æ˜¯ä¸ºä»€ä¹ˆç°ä»£ç½‘ç»œæ›´å–œæ¬¢ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°")

ç¥ç»ç½‘ç»œåå‘ä¼ æ’­æ¼”ç¤º()
```

#### ğŸ¯ åå‘ä¼ æ’­çš„æŠ€å·§å’Œé™·é˜±

```python
def åå‘ä¼ æ’­æŠ€å·§æ€»ç»“():
    """æ€»ç»“åå‘ä¼ æ’­çš„æœ€ä½³å®è·µ"""
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.ravel()
    
    # æŠ€å·§1ï¼šæ¢¯åº¦è£å‰ª
    ax = axes[0]
    gradients = np.random.randn(1000) * 5
    clipped = np.clip(gradients, -2, 2)
    
    ax.hist(gradients, bins=50, alpha=0.5, label='åŸå§‹æ¢¯åº¦', color='blue')
    ax.hist(clipped, bins=50, alpha=0.5, label='è£å‰ªåæ¢¯åº¦', color='red')
    ax.set_title('æŠ€å·§1ï¼šæ¢¯åº¦è£å‰ª')
    ax.set_xlabel('æ¢¯åº¦å€¼')
    ax.set_ylabel('é¢‘æ•°')
    ax.legend()
    
    # æŠ€å·§2ï¼šæ‰¹å½’ä¸€åŒ–æ•ˆæœ
    ax = axes[1]
    x = np.linspace(-3, 3, 100)
    before_bn = np.random.randn(1000) * 2 + 1
    after_bn = (before_bn - before_bn.mean()) / before_bn.std()
    
    ax.hist(before_bn, bins=30, alpha=0.5, label='å½’ä¸€åŒ–å‰', color='blue')
    ax.hist(after_bn, bins=30, alpha=0.5, label='å½’ä¸€åŒ–å', color='green')
    ax.set_title('æŠ€å·§2ï¼šæ‰¹å½’ä¸€åŒ–')
    ax.legend()
    
    # æŠ€å·§3ï¼šå­¦ä¹ ç‡è°ƒåº¦
    ax = axes[2]
    epochs = np.arange(100)
    lr_constant = np.ones(100) * 0.01
    lr_decay = 0.01 * (0.95 ** epochs)
    lr_cosine = 0.005 + 0.005 * np.cos(np.pi * epochs / 100)
    
    ax.plot(epochs, lr_constant, label='å›ºå®šå­¦ä¹ ç‡')
    ax.plot(epochs, lr_decay, label='æŒ‡æ•°è¡°å‡')
    ax.plot(epochs, lr_cosine, label='ä½™å¼¦é€€ç«')
    ax.set_title('æŠ€å·§3ï¼šå­¦ä¹ ç‡è°ƒåº¦')
    ax.set_xlabel('è½®æ¬¡')
    ax.set_ylabel('å­¦ä¹ ç‡')
    ax.legend()
    
    # é™·é˜±1ï¼šæ¢¯åº¦çˆ†ç‚¸
    ax = axes[3]
    layers = range(1, 21)
    exploding = 1.5 ** np.array(layers)
    normal = np.ones(len(layers))
    
    ax.semilogy(layers, exploding, 'r-o', label='æ¢¯åº¦çˆ†ç‚¸')
    ax.semilogy(layers, normal, 'g--', label='æ­£å¸¸æ¢¯åº¦')
    ax.set_title('é™·é˜±1ï¼šæ¢¯åº¦çˆ†ç‚¸')
    ax.set_xlabel('å±‚æ•°')
    ax.set_ylabel('æ¢¯åº¦å¤§å°')
    ax.legend()
    
    # é™·é˜±2ï¼šéç‚¹
    ax = axes[4]
    x = np.linspace(-2, 2, 100)
    y = np.linspace(-2, 2, 100)
    X, Y = np.meshgrid(x, y)
    Z = X**2 - Y**2  # éç‚¹å‡½æ•°
    
    contour = ax.contour(X, Y, Z, levels=20)
    ax.clabel(contour, inline=True, fontsize=8)
    ax.plot(0, 0, 'ro', markersize=10)
    ax.set_title('é™·é˜±2ï¼šéç‚¹')
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    
    # é™·é˜±3ï¼šå±€éƒ¨æœ€å°å€¼
    ax = axes[5]
    x = np.linspace(-5, 5, 1000)
    y = np.sin(2*x) + 0.1*x**2
    
    ax.plot(x, y, 'b-', linewidth=2)
    # æ ‡è®°å±€éƒ¨æœ€å°å€¼
    local_mins = [-3.7, -0.5, 2.6]
    for xmin in local_mins:
        ax.plot(xmin, np.sin(2*xmin) + 0.1*xmin**2, 'ro', markersize=8)
    ax.set_title('é™·é˜±3ï¼šå±€éƒ¨æœ€å°å€¼')
    ax.set_xlabel('x')
    ax.set_ylabel('f(x)')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ“ åå‘ä¼ æ’­æœ€ä½³å®è·µæ€»ç»“ï¼š\n")
    
    best_practices = [
        ("æ¢¯åº¦è£å‰ª", "é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼Œé™åˆ¶æ¢¯åº¦çš„æœ€å¤§å€¼"),
        ("æ‰¹å½’ä¸€åŒ–", "ç¨³å®šè®­ç»ƒï¼ŒåŠ é€Ÿæ”¶æ•›"),
        ("å­¦ä¹ ç‡è°ƒåº¦", "å‰æœŸå¿«é€Ÿä¸‹é™ï¼ŒåæœŸç²¾ç»†è°ƒæ•´"),
        ("æ®‹å·®è¿æ¥", "ç¼“è§£æ¢¯åº¦æ¶ˆå¤±ï¼Œè®©ç½‘ç»œæ›´æ·±"),
        ("æ­£ç¡®åˆå§‹åŒ–", "Xavier/Heåˆå§‹åŒ–ï¼Œé¿å…æ¢¯åº¦é—®é¢˜"),
        ("ä½¿ç”¨Adam", "è‡ªé€‚åº”å­¦ä¹ ç‡ï¼Œå¯¹å¤§å¤šæ•°é—®é¢˜éƒ½æœ‰æ•ˆ")
    ]
    
    for practice, benefit in best_practices:
        print(f"âœ… {practice}ï¼š{benefit}")
    
    print("\nâš ï¸ å¸¸è§é™·é˜±ï¼š")
    pitfalls = [
        ("æ¢¯åº¦çˆ†ç‚¸", "ä½¿ç”¨æ¢¯åº¦è£å‰ªæˆ–æ›´å°çš„å­¦ä¹ ç‡"),
        ("æ¢¯åº¦æ¶ˆå¤±", "ä½¿ç”¨ReLUã€æ®‹å·®è¿æ¥æˆ–LSTM"),
        ("éç‚¹", "ä½¿ç”¨åŠ¨é‡æˆ–Adamä¼˜åŒ–å™¨"),
        ("æ•°å€¼ä¸ç¨³å®š", "ä½¿ç”¨float32æˆ–æ›´é«˜ç²¾åº¦ï¼Œé¿å…é™¤é›¶")
    ]
    
    for pitfall, solution in pitfalls:
        print(f"âŒ {pitfall} â†’ è§£å†³æ–¹æ¡ˆï¼š{solution}")

åå‘ä¼ æ’­æŠ€å·§æ€»ç»“()
```

#### ğŸ¨ å®æˆ˜é¡¹ç›®ï¼šä»é›¶å®ç°åå‘ä¼ æ’­

```python
class BackpropNet:
    """ä»é›¶å®ç°çš„æ”¯æŒåå‘ä¼ æ’­çš„ç¥ç»ç½‘ç»œ"""
    
    def __init__(self, layers):
        """
        layers: æ¯å±‚çš„ç¥ç»å…ƒæ•°é‡ï¼Œå¦‚[2, 4, 3, 1]
        """
        self.layers = layers
        self.weights = []
        self.biases = []
        
        # åˆå§‹åŒ–æƒé‡å’Œåç½®
        for i in range(len(layers) - 1):
            w = np.random.randn(layers[i], layers[i+1]) * np.sqrt(2.0 / layers[i])
            b = np.zeros((1, layers[i+1]))
            self.weights.append(w)
            self.biases.append(b)
    
    def relu(self, x):
        return np.maximum(0, x)
    
    def relu_grad(self, x):
        return (x > 0).astype(float)
    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        """å‰å‘ä¼ æ’­ï¼Œä¿å­˜æ‰€æœ‰ä¸­é—´ç»“æœ"""
        self.activations = [X]
        self.z_values = []
        
        for i in range(len(self.weights)):
            z = self.activations[-1] @ self.weights[i] + self.biases[i]
            self.z_values.append(z)
            
            # æœ€åä¸€å±‚ç”¨softmaxï¼Œå…¶ä»–å±‚ç”¨ReLU
            if i == len(self.weights) - 1:
                a = self.softmax(z)
            else:
                a = self.relu(z)
            
            self.activations.append(a)
        
        return self.activations[-1]
    
    def backward(self, y_true):
        """å®Œæ•´çš„åå‘ä¼ æ’­å®ç°"""
        m = y_true.shape[0]
        num_layers = len(self.weights)
        
        # åˆå§‹åŒ–æ¢¯åº¦
        weight_grads = []
        bias_grads = []
        
        # è®¡ç®—è¾“å‡ºå±‚çš„æ¢¯åº¦
        delta = self.activations[-1] - y_true  # å¯¹äºsoftmax+äº¤å‰ç†µ
        
        # åå‘éå†æ¯ä¸€å±‚
        for i in range(num_layers - 1, -1, -1):
            # è®¡ç®—æƒé‡å’Œåç½®çš„æ¢¯åº¦
            weight_grad = self.activations[i].T @ delta / m
            bias_grad = np.sum(delta, axis=0, keepdims=True) / m
            
            weight_grads.insert(0, weight_grad)
            bias_grads.insert(0, bias_grad)
            
            # å¦‚æœä¸æ˜¯ç¬¬ä¸€å±‚ï¼Œç»§ç»­ä¼ æ’­æ¢¯åº¦
            if i > 0:
                delta = delta @ self.weights[i].T
                delta *= self.relu_grad(self.z_values[i-1])
        
        return weight_grads, bias_grads
    
    def update_parameters(self, weight_grads, bias_grads, learning_rate):
        """ä½¿ç”¨æ¢¯åº¦æ›´æ–°å‚æ•°"""
        for i in range(len(self.weights)):
            self.weights[i] -= learning_rate * weight_grads[i]
            self.biases[i] -= learning_rate * bias_grads[i]

def å®Œæ•´åå‘ä¼ æ’­é¡¹ç›®():
    """ä¸€ä¸ªå®Œæ•´çš„åå‘ä¼ æ’­è®­ç»ƒé¡¹ç›®"""
    
    # ç”Ÿæˆèºæ—‹æ•°æ®é›†
    np.random.seed(42)
    n_samples = 300
    n_classes = 3
    
    X = []
    y = []
    
    for class_id in range(n_classes):
        r = np.linspace(0.0, 1, n_samples // n_classes)
        t = np.linspace(class_id * 4, (class_id + 1) * 4, 
                       n_samples // n_classes) + np.random.randn(n_samples // n_classes) * 0.2
        X.append(np.c_[r * np.sin(t), r * np.cos(t)])
        y.append([class_id] * (n_samples // n_classes))
    
    X = np.vstack(X)
    y = np.array(y)
    
    # One-hotç¼–ç 
    y_onehot = np.zeros((y.size, n_classes))
    y_onehot[np.arange(y.size), y] = 1
    
    # åˆ›å»ºç½‘ç»œ
    net = BackpropNet([2, 10, 10, 3])
    
    # è®­ç»ƒå‚æ•°
    epochs = 1000
    learning_rate = 0.5
    
    # è®°å½•è®­ç»ƒå†å²
    losses = []
    accuracies = []
    
    # åˆ›å»ºå®æ—¶å¯è§†åŒ–
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    for epoch in range(epochs):
        # å‰å‘ä¼ æ’­
        output = net.forward(X)
        
        # è®¡ç®—æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰
        loss = -np.mean(np.sum(y_onehot * np.log(output + 1e-8), axis=1))
        losses.append(loss)
        
        # è®¡ç®—å‡†ç¡®ç‡
        predictions = np.argmax(output, axis=1)
        accuracy = np.mean(predictions == y)
        accuracies.append(accuracy)
        
        # åå‘ä¼ æ’­
        weight_grads, bias_grads = net.backward(y_onehot)
        
        # æ›´æ–°å‚æ•°
        net.update_parameters(weight_grads, bias_grads, learning_rate)
        
        # æ¯100è½®æ›´æ–°å¯è§†åŒ–
        if epoch % 100 == 0 or epoch == epochs - 1:
            axes[0].clear()
            axes[1].clear()
            axes[2].clear()
            
            # å†³ç­–è¾¹ç•Œ
            xx, yy = np.meshgrid(np.linspace(-1.5, 1.5, 100),
                               np.linspace(-1.5, 1.5, 100))
            Z = net.forward(np.c_[xx.ravel(), yy.ravel()])
            Z = np.argmax(Z, axis=1).reshape(xx.shape)
            
            axes[0].contourf(xx, yy, Z, alpha=0.4, cmap='viridis')
            scatter = axes[0].scatter(X[:, 0], X[:, 1], c=y, 
                                    cmap='viridis', edgecolors='black', s=30)
            axes[0].set_title(f'å†³ç­–è¾¹ç•Œ (Epoch {epoch})')
            
            # æŸå¤±æ›²çº¿
            axes[1].plot(losses, 'b-', linewidth=2)
            axes[1].set_xlabel('Epoch')
            axes[1].set_ylabel('äº¤å‰ç†µæŸå¤±')
            axes[1].set_title('è®­ç»ƒæŸå¤±')
            axes[1].grid(True, alpha=0.3)
            
            # å‡†ç¡®ç‡æ›²çº¿
            axes[2].plot(accuracies, 'g-', linewidth=2)
            axes[2].set_xlabel('Epoch')
            axes[2].set_ylabel('å‡†ç¡®ç‡')
            axes[2].set_title('è®­ç»ƒå‡†ç¡®ç‡')
            axes[2].set_ylim(0, 1.1)
            axes[2].grid(True, alpha=0.3)
            
            plt.suptitle(f'åå‘ä¼ æ’­è®­ç»ƒè¿›åº¦', fontsize=16)
            plt.tight_layout()
            
            if epoch < epochs - 1:
                plt.pause(0.1)
    
    plt.show()
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}")
    print(f"æœ€ç»ˆå‡†ç¡®ç‡: {accuracies[-1]:.2%}")
    
    # åˆ†ææ¢¯åº¦æµ
    print("\nğŸ“Š æ¢¯åº¦åˆ†æï¼š")
    _, final_grads = net.backward(y_onehot)
    
    for i, grad in enumerate(final_grads):
        print(f"ç¬¬{i+1}å±‚æ¢¯åº¦èŒƒæ•°: {np.linalg.norm(grad):.6f}")

å®Œæ•´åå‘ä¼ æ’­é¡¹ç›®()
```

#### ğŸ’¡ æœ¬ç« å°ç»“

1. **åå‘ä¼ æ’­çš„æœ¬è´¨**ï¼š
   - åˆ©ç”¨é“¾å¼æ³•åˆ™è®¡ç®—æ¢¯åº¦
   - è¯¯å·®ä¿¡å·ä»è¾“å‡ºå±‚å‘è¾“å…¥å±‚ä¼ æ’­
   - æ¯ä¸€å±‚çš„æ¢¯åº¦ä¾èµ–äºåä¸€å±‚çš„æ¢¯åº¦

2. **é“¾å¼æ³•åˆ™æ˜¯æ ¸å¿ƒ**ï¼š
   - å¤åˆå‡½æ•°çš„å¯¼æ•° = å„éƒ¨åˆ†å¯¼æ•°çš„ä¹˜ç§¯
   - âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚y Ã— âˆ‚y/âˆ‚w

3. **è®¡ç®—å›¾çš„ä½œç”¨**ï¼š
   - å‰å‘ä¼ æ’­ï¼šè®¡ç®—è¾“å‡º
   - åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦
   - è‡ªåŠ¨å¾®åˆ†çš„åŸºç¡€

4. **å®ç°è¦ç‚¹**ï¼š
   - ä¿å­˜å‰å‘ä¼ æ’­çš„ä¸­é—´ç»“æœ
   - æŒ‰ç›¸åé¡ºåºè®¡ç®—æ¢¯åº¦
   - æ­£ç¡®å¤„ç†çŸ©é˜µç»´åº¦

5. **å¸¸è§é—®é¢˜**ï¼š
   - **æ¢¯åº¦æ¶ˆå¤±**ï¼šæ·±å±‚ç½‘ç»œçš„æŒ‘æˆ˜
   - **æ¢¯åº¦çˆ†ç‚¸**ï¼šéœ€è¦æ¢¯åº¦è£å‰ª
   - **æ•°å€¼ç¨³å®šæ€§**ï¼šé¿å…é™¤é›¶å’Œæº¢å‡º

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆåå‘ä¼ æ’­æ¯”æ•°å€¼æ¢¯åº¦è®¡ç®—ï¼ˆæœ‰é™å·®åˆ†ï¼‰æ›´é«˜æ•ˆï¼Ÿ
2. å¦‚æœæ¿€æ´»å‡½æ•°ä¸å¯å¯¼ï¼ˆå¦‚ReLUåœ¨0ç‚¹ï¼‰ï¼Œåå‘ä¼ æ’­å¦‚ä½•å¤„ç†ï¼Ÿ
3. ä¸ºä»€ä¹ˆè¯´åå‘ä¼ æ’­æ˜¯"è‡ªåŠ¨å¾®åˆ†"çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼Ÿ

#### ğŸ”¬ æ‰©å±•å®éªŒ

```python
def åå‘ä¼ æ’­æ€§èƒ½å¯¹æ¯”():
    """æ¯”è¾ƒä¸åŒæ–¹æ³•è®¡ç®—æ¢¯åº¦çš„æ€§èƒ½"""
    
    print("âš¡ æ€§èƒ½å¯¹æ¯”å®éªŒï¼š\n")
    
    # åˆ›å»ºä¸€ä¸ªä¸­ç­‰è§„æ¨¡çš„ç½‘ç»œ
    input_size = 100
    hidden_size = 50
    output_size = 10
    batch_size = 32
    
    # éšæœºæ•°æ®
    X = np.random.randn(batch_size, input_size)
    W = np.random.randn(input_size, hidden_size)
    
    # æ–¹æ³•1ï¼šæ•°å€¼æ¢¯åº¦ï¼ˆæœ‰é™å·®åˆ†ï¼‰
    import time
    
    def numerical_gradient(f, x, h=1e-5):
        grad = np.zeros_like(x)
        it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
        
        while not it.finished:
            idx = it.multi_index
            old_value = x[idx]
            
            x[idx] = old_value + h
            fxh = f(x)
            
            x[idx] = old_value - h
            fxh2 = f(x)
            
            grad[idx] = (fxh - fxh2) / (2*h)
            x[idx] = old_value
            
            it.iternext()
        
        return grad
    
    # å®šä¹‰æŸå¤±å‡½æ•°
    def loss_fn(W):
        return np.sum((X @ W) ** 2)
    
    # æµ‹è¯•æ•°å€¼æ¢¯åº¦ï¼ˆåªæµ‹è¯•ä¸€å°éƒ¨åˆ†ï¼Œå› ä¸ºå¤ªæ…¢ï¼‰
    print("æµ‹è¯•æ•°å€¼æ¢¯åº¦è®¡ç®—ï¼ˆä»…è®¡ç®—å‰10ä¸ªå…ƒç´ ï¼‰...")
    start_time = time.time()
    W_small = W[:10, :10].copy()
    X_small = X[:, :10]
    
    def loss_fn_small(W_small):
        return np.sum((X_small @ W_small) ** 2)
    
    num_grad = numerical_gradient(loss_fn_small, W_small)
    num_time = time.time() - start_time
    print(f"æ•°å€¼æ¢¯åº¦ç”¨æ—¶: {num_time:.4f}ç§’")
    
    # æ–¹æ³•2ï¼šåå‘ä¼ æ’­
    print("\næµ‹è¯•åå‘ä¼ æ’­è®¡ç®—...")
    start_time = time.time()
    
    # å‰å‘ä¼ æ’­
    Y = X @ W
    loss = np.sum(Y ** 2)
    
    # åå‘ä¼ æ’­
    dY = 2 * Y
    dW = X.T @ dY
    
    bp_time = time.time() - start_time
    print(f"åå‘ä¼ æ’­ç”¨æ—¶: {bp_time:.4f}ç§’")
    
    print(f"\né€Ÿåº¦æå‡: {num_time / bp_time:.0f}å€ï¼")
    print("\nè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ·±åº¦å­¦ä¹ ç¦»ä¸å¼€åå‘ä¼ æ’­ï¼")

åå‘ä¼ æ’­æ€§èƒ½å¯¹æ¯”()
```

// ... existing code ...

ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†å­¦ä¹ æŸå¤±å‡½æ•°â€”â€”å¦‚ä½•è¡¡é‡AIçš„è¡¨ç°ï¼

---

### ç¬¬6ç« ï¼šæŸå¤±å‡½æ•°â€”â€”å¦‚ä½•è¡¡é‡AIçš„è¡¨ç°ï¼Ÿ

#### ğŸ¯ æœ¬ç« å¯¼è¯»

æƒ³è±¡ä½ åœ¨æ•™ä¸€ä¸ªå°æœ‹å‹è®¤å­—ã€‚ä»–æŠŠ"è‹¹æœ"è®¤æˆäº†"é¦™è•‰"ï¼Œä½ ä¼šè¯´ï¼š"é”™äº†ï¼Œå·®å¾—æœ‰ç‚¹è¿œã€‚"ä½†å¦‚æœä»–æŠŠ"è‹¹æœ"è®¤æˆäº†"è‹¹é‡Œ"ï¼Œä½ å¯èƒ½ä¼šè¯´ï¼š"å¾ˆæ¥è¿‘äº†ï¼Œå°±å·®ä¸€ç‚¹ï¼"

è¿™å°±æ˜¯æŸå¤±å‡½æ•°çš„ä½œç”¨â€”â€”å®ƒä¸ä»…å‘Šè¯‰AI"é”™äº†"ï¼Œæ›´é‡è¦çš„æ˜¯å‘Šè¯‰AI"é”™å¾—æœ‰å¤šç¦»è°±"ã€‚æœ‰äº†è¿™ä¸ª"ç¦»è°±ç¨‹åº¦"çš„åº¦é‡ï¼ŒAIæ‰çŸ¥é“è¯¥å¦‚ä½•æ”¹è¿›ã€‚

ä»Šå¤©ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢AIä¸–ç•Œä¸­çš„"è¯„åˆ†æ ‡å‡†"â€”â€”æŸå¤±å‡½æ•°ï¼

#### ğŸ¯ æŸå¤±å‡½æ•°ï¼šAIçš„æˆç»©å•

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from mpl_toolkits.mplot3d import Axes3D

def æŸå¤±å‡½æ•°çš„ç›´è§‚ç†è§£():
    """ç”¨æ‰“é¶æ¥ç†è§£æŸå¤±å‡½æ•°"""
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # åœºæ™¯1ï¼šå®Œç¾å‘½ä¸­
    ax1 = axes[0]
    circle1 = plt.Circle((0, 0), 1, fill=False, edgecolor='red', linewidth=2)
    circle2 = plt.Circle((0, 0), 0.5, fill=False, edgecolor='red', linewidth=2)
    circle3 = plt.Circle((0, 0), 0.1, fill=False, edgecolor='red', linewidth=2)
    ax1.add_patch(circle1)
    ax1.add_patch(circle2)
    ax1.add_patch(circle3)
    ax1.plot(0, 0, 'go', markersize=10, label='é¢„æµ‹')
    ax1.plot(0, 0, 'r*', markersize=15, label='ç›®æ ‡')
    ax1.set_xlim(-1.5, 1.5)
    ax1.set_ylim(-1.5, 1.5)
    ax1.set_aspect('equal')
    ax1.set_title('æŸå¤± = 0ï¼ˆå®Œç¾ï¼ï¼‰')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # åœºæ™¯2ï¼šç•¥æœ‰åå·®
    ax2 = axes[1]
    circle1 = plt.Circle((0, 0), 1, fill=False, edgecolor='red', linewidth=2)
    circle2 = plt.Circle((0, 0), 0.5, fill=False, edgecolor='red', linewidth=2)
    circle3 = plt.Circle((0, 0), 0.1, fill=False, edgecolor='red', linewidth=2)
    ax2.add_patch(circle1)
    ax2.add_patch(circle2)
    ax2.add_patch(circle3)
    ax2.plot(0.3, 0.2, 'go', markersize=10, label='é¢„æµ‹')
    ax2.plot(0, 0, 'r*', markersize=15, label='ç›®æ ‡')
    ax2.arrow(0, 0, 0.3, 0.2, head_width=0.05, head_length=0.05, 
              fc='blue', ec='blue', linestyle='--', alpha=0.7)
    ax2.set_xlim(-1.5, 1.5)
    ax2.set_ylim(-1.5, 1.5)
    ax2.set_aspect('equal')
    ax2.set_title('æŸå¤± = 0.36ï¼ˆè¿˜ä¸é”™ï¼‰')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # åœºæ™¯3ï¼šä¸¥é‡åç¦»
    ax3 = axes[2]
    circle1 = plt.Circle((0, 0), 1, fill=False, edgecolor='red', linewidth=2)
    circle2 = plt.Circle((0, 0), 0.5, fill=False, edgecolor='red', linewidth=2)
    circle3 = plt.Circle((0, 0), 0.1, fill=False, edgecolor='red', linewidth=2)
    ax3.add_patch(circle1)
    ax3.add_patch(circle2)
    ax3.add_patch(circle3)
    ax3.plot(1.2, 0.8, 'go', markersize=10, label='é¢„æµ‹')
    ax3.plot(0, 0, 'r*', markersize=15, label='ç›®æ ‡')
    ax3.arrow(0, 0, 1.2, 0.8, head_width=0.05, head_length=0.05,
              fc='blue', ec='blue', linestyle='--', alpha=0.7)
    ax3.set_xlim(-1.5, 1.5)
    ax3.set_ylim(-1.5, 1.5)
    ax3.set_aspect('equal')
    ax3.set_title('æŸå¤± = 2.08ï¼ˆéœ€è¦åŠªåŠ›ï¼ï¼‰')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    plt.suptitle('æŸå¤±å‡½æ•°ï¼šè¡¡é‡é¢„æµ‹ä¸ç›®æ ‡çš„è·ç¦»', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    print("ğŸ’¡ å…³é”®æ¦‚å¿µï¼š")
    print("1. æŸå¤±å‡½æ•°è¡¡é‡é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å·®è·")
    print("2. æŸå¤±è¶Šå°ï¼Œè¯´æ˜é¢„æµ‹è¶Šå‡†ç¡®")
    print("3. AIé€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°æ¥å­¦ä¹ ")
    print("4. ä¸åŒçš„ä»»åŠ¡éœ€è¦ä¸åŒçš„æŸå¤±å‡½æ•°")

æŸå¤±å‡½æ•°çš„ç›´è§‚ç†è§£()
```

#### ğŸ“Š å›å½’ä»»åŠ¡çš„æŸå¤±å‡½æ•°

```python
def å›å½’æŸå¤±å‡½æ•°å…¨å®¶ç¦():
    """å±•ç¤ºå¸¸è§çš„å›å½’æŸå¤±å‡½æ•°"""
    
    # ç”Ÿæˆæ•°æ®
    y_true = np.array([1.0])
    y_pred = np.linspace(-2, 4, 1000)
    
    # å®šä¹‰å„ç§æŸå¤±å‡½æ•°
    def mse_loss(y_true, y_pred):
        """å‡æ–¹è¯¯å·® MSE"""
        return (y_true - y_pred) ** 2
    
    def mae_loss(y_true, y_pred):
        """å¹³å‡ç»å¯¹è¯¯å·® MAE"""
        return np.abs(y_true - y_pred)
    
    def huber_loss(y_true, y_pred, delta=1.0):
        """HuberæŸå¤±ï¼šç»“åˆMSEå’ŒMAEçš„ä¼˜ç‚¹"""
        error = y_true - y_pred
        is_small_error = np.abs(error) <= delta
        small_error_loss = 0.5 * error ** 2
        large_error_loss = delta * (np.abs(error) - 0.5 * delta)
        return np.where(is_small_error, small_error_loss, large_error_loss)
    
    def log_cosh_loss(y_true, y_pred):
        """Log-CoshæŸå¤±ï¼šå¹³æ»‘ç‰ˆçš„MAE"""
        return np.log(np.cosh(y_pred - y_true))
    
    # è®¡ç®—æŸå¤±
    mse = mse_loss(y_true, y_pred)
    mae = mae_loss(y_true, y_pred)
    huber = huber_loss(y_true, y_pred)
    log_cosh = log_cosh_loss(y_true, y_pred)
    
    # å¯è§†åŒ–
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # MSE
    ax = axes[0, 0]
    ax.plot(y_pred, mse, 'b-', linewidth=2)
    ax.axvline(x=y_true[0], color='red', linestyle='--', alpha=0.7, label='çœŸå®å€¼')
    ax.set_xlabel('é¢„æµ‹å€¼')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('å‡æ–¹è¯¯å·® (MSE)')
    ax.grid(True, alpha=0.3)
    ax.legend()
    ax.text(0.02, 0.98, 'ç‰¹ç‚¹ï¼š\nâ€¢ å¯¹å¤§è¯¯å·®æ•æ„Ÿ\nâ€¢ å¤„å¤„å¯å¯¼\nâ€¢ æ˜“å—å¼‚å¸¸å€¼å½±å“', 
            transform=ax.transAxes, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    # MAE
    ax = axes[0, 1]
    ax.plot(y_pred, mae, 'g-', linewidth=2)
    ax.axvline(x=y_true[0], color='red', linestyle='--', alpha=0.7, label='çœŸå®å€¼')
    ax.set_xlabel('é¢„æµ‹å€¼')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('å¹³å‡ç»å¯¹è¯¯å·® (MAE)')
    ax.grid(True, alpha=0.3)
    ax.legend()
    ax.text(0.02, 0.98, 'ç‰¹ç‚¹ï¼š\nâ€¢ å¯¹å¼‚å¸¸å€¼é²æ£’\nâ€¢ åœ¨0ç‚¹ä¸å¯å¯¼\nâ€¢ æ¢¯åº¦æ’å®š', 
            transform=ax.transAxes, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))
    
    # Huber
    ax = axes[1, 0]
    ax.plot(y_pred, huber, 'r-', linewidth=2)
    ax.axvline(x=y_true[0], color='red', linestyle='--', alpha=0.7, label='çœŸå®å€¼')
    ax.set_xlabel('é¢„æµ‹å€¼')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('HuberæŸå¤±')
    ax.grid(True, alpha=0.3)
    ax.legend()
    ax.text(0.02, 0.98, 'ç‰¹ç‚¹ï¼š\nâ€¢ ç»“åˆMSEå’ŒMAE\nâ€¢ å°è¯¯å·®ç”¨MSE\nâ€¢ å¤§è¯¯å·®ç”¨MAE', 
            transform=ax.transAxes, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))
    
    # Log-Cosh
    ax = axes[1, 1]
    ax.plot(y_pred, log_cosh, 'm-', linewidth=2)
    ax.axvline(x=y_true[0], color='red', linestyle='--', alpha=0.7, label='çœŸå®å€¼')
    ax.set_xlabel('é¢„æµ‹å€¼')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('Log-CoshæŸå¤±')
    ax.grid(True, alpha=0.3)
    ax.legend()
    ax.text(0.02, 0.98, 'ç‰¹ç‚¹ï¼š\nâ€¢ ç±»ä¼¼Huber\nâ€¢ å¤„å¤„äºŒé˜¶å¯å¯¼\nâ€¢ è®¡ç®—ç¨³å®š', 
            transform=ax.transAxes, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='plum', alpha=0.8))
    
    plt.suptitle('å›å½’æŸå¤±å‡½æ•°å¯¹æ¯”', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    # å¯¹æ¯”å¼‚å¸¸å€¼çš„å½±å“
    å¼‚å¸¸å€¼å½±å“å¯¹æ¯”()

def å¼‚å¸¸å€¼å½±å“å¯¹æ¯”():
    """å±•ç¤ºä¸åŒæŸå¤±å‡½æ•°å¯¹å¼‚å¸¸å€¼çš„æ•æ„Ÿåº¦"""
    
    # ç”Ÿæˆå¸¦å¼‚å¸¸å€¼çš„æ•°æ®
    np.random.seed(42)
    n_samples = 50
    X = np.linspace(0, 10, n_samples)
    y_true = 2 * X + 1 + np.random.randn(n_samples) * 0.5
    
    # æ·»åŠ å¼‚å¸¸å€¼
    outlier_indices = [10, 25, 40]
    y_true[outlier_indices] = y_true[outlier_indices] + [8, -7, 9]
    
    # ä½¿ç”¨ä¸åŒæŸå¤±å‡½æ•°æ‹Ÿåˆ
    from sklearn.linear_model import LinearRegression, HuberRegressor
    from sklearn.metrics import mean_squared_error, mean_absolute_error
    
    # MSEå›å½’
    lr_mse = LinearRegression()
    lr_mse.fit(X.reshape(-1, 1), y_true)
    y_pred_mse = lr_mse.predict(X.reshape(-1, 1))
    
    # Huberå›å½’
    lr_huber = HuberRegressor(epsilon=1.35)
    lr_huber.fit(X.reshape(-1, 1), y_true)
    y_pred_huber = lr_huber.predict(X.reshape(-1, 1))
    
    # å¯è§†åŒ–
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.scatter(X, y_true, alpha=0.7, label='æ•°æ®ç‚¹')
    plt.scatter(X[outlier_indices], y_true[outlier_indices], 
                color='red', s=100, label='å¼‚å¸¸å€¼', edgecolors='black')
    plt.plot(X, y_pred_mse, 'b-', linewidth=2, label='MSEæ‹Ÿåˆ')
    plt.plot(X, y_pred_huber, 'r--', linewidth=2, label='Huberæ‹Ÿåˆ')
    plt.xlabel('X')
    plt.ylabel('y')
    plt.title('å¼‚å¸¸å€¼å¯¹ä¸åŒæŸå¤±å‡½æ•°çš„å½±å“')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    residuals_mse = y_true - y_pred_mse
    residuals_huber = y_true - y_pred_huber
    
    plt.scatter(range(n_samples), residuals_mse, alpha=0.7, label='MSEæ®‹å·®')
    plt.scatter(range(n_samples), residuals_huber, alpha=0.7, label='Huberæ®‹å·®')
    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    plt.xlabel('æ ·æœ¬ç´¢å¼•')
    plt.ylabel('æ®‹å·®')
    plt.title('æ®‹å·®åˆ†æ')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ’¡ è§‚å¯Ÿï¼š")
    print("1. MSEå¯¹å¼‚å¸¸å€¼éå¸¸æ•æ„Ÿï¼Œæ‹Ÿåˆçº¿è¢«æ‹‰å")
    print("2. HuberæŸå¤±æ›´é²æ£’ï¼Œå—å¼‚å¸¸å€¼å½±å“è¾ƒå°")
    print("3. é€‰æ‹©æŸå¤±å‡½æ•°è¦è€ƒè™‘æ•°æ®çš„ç‰¹ç‚¹")

å›å½’æŸå¤±å‡½æ•°å…¨å®¶ç¦()
```

#### ğŸ­ åˆ†ç±»ä»»åŠ¡çš„æŸå¤±å‡½æ•°

```python
def åˆ†ç±»æŸå¤±å‡½æ•°è¯¦è§£():
    """åˆ†ç±»ä»»åŠ¡ä¸­çš„æŸå¤±å‡½æ•°"""
    
    # äºŒåˆ†ç±»ç¤ºä¾‹
    def binary_cross_entropy(y_true, y_pred):
        """äºŒå…ƒäº¤å‰ç†µ"""
        epsilon = 1e-7  # é¿å…log(0)
        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
        return -y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred)
    
    def hinge_loss(y_true, y_pred):
        """åˆé¡µæŸå¤±ï¼ˆSVMï¼‰"""
        # y_true åº”è¯¥æ˜¯ {-1, 1}
        return np.maximum(0, 1 - y_true * y_pred)
    
    def focal_loss(y_true, y_pred, gamma=2.0):
        """Focal Lossï¼šå¤„ç†ç±»åˆ«ä¸å¹³è¡¡"""
        epsilon = 1e-7
        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
        pt = np.where(y_true == 1, y_pred, 1 - y_pred)
        return -(1 - pt) ** gamma * np.log(pt)
    
    # å¯è§†åŒ–äºŒåˆ†ç±»æŸå¤±å‡½æ•°
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # å¯¹æ­£æ ·æœ¬ï¼ˆy_true=1ï¼‰çš„æŸå¤±
    y_pred = np.linspace(0.001, 0.999, 1000)
    
    ax = axes[0, 0]
    bce_pos = binary_cross_entropy(1, y_pred)
    ax.plot(y_pred, bce_pos, 'b-', linewidth=2)
    ax.set_xlabel('é¢„æµ‹æ¦‚ç‡')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('äºŒå…ƒäº¤å‰ç†µ (æ­£æ ·æœ¬)')
    ax.grid(True, alpha=0.3)
    ax.axvline(x=1, color='green', linestyle='--', alpha=0.7, label='ç†æƒ³é¢„æµ‹')
    ax.text(0.1, 3, 'é¢„æµ‹è¶Šæ¥è¿‘1ï¼Œ\næŸå¤±è¶Šå°', fontsize=10,
            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
    
    # å¯¹è´Ÿæ ·æœ¬ï¼ˆy_true=0ï¼‰çš„æŸå¤±
    ax = axes[0, 1]
    bce_neg = binary_cross_entropy(0, y_pred)
    ax.plot(y_pred, bce_neg, 'r-', linewidth=2)
    ax.set_xlabel('é¢„æµ‹æ¦‚ç‡')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('äºŒå…ƒäº¤å‰ç†µ (è´Ÿæ ·æœ¬)')
    ax.grid(True, alpha=0.3)
    ax.axvline(x=0, color='green', linestyle='--', alpha=0.7, label='ç†æƒ³é¢„æµ‹')
    ax.text(0.6, 3, 'é¢„æµ‹è¶Šæ¥è¿‘0ï¼Œ\næŸå¤±è¶Šå°', fontsize=10,
            bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))
    
    # Focal Losså¯¹æ¯”
    ax = axes[0, 2]
    for gamma in [0, 0.5, 1, 2, 5]:
        fl = focal_loss(1, y_pred, gamma)
        ax.plot(y_pred, fl, linewidth=2, label=f'Î³={gamma}')
    ax.set_xlabel('é¢„æµ‹æ¦‚ç‡')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('Focal Loss (æ­£æ ·æœ¬)')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.text(0.1, 4, 'Î³è¶Šå¤§ï¼Œå¯¹æ˜“åˆ†ç±»\næ ·æœ¬çš„æƒ©ç½šè¶Šå°', fontsize=10,
            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.7))
    
    # å¤šåˆ†ç±»äº¤å‰ç†µ
    å¤šåˆ†ç±»æŸå¤±å‡½æ•°æ¼”ç¤º(axes[1, :])
    
    plt.suptitle('åˆ†ç±»æŸå¤±å‡½æ•°è¯¦è§£', fontsize=16)
    plt.tight_layout()
    plt.show()

def å¤šåˆ†ç±»æŸå¤±å‡½æ•°æ¼”ç¤º(axes):
    """å¤šåˆ†ç±»æŸå¤±å‡½æ•°çš„å¯è§†åŒ–"""
    
    # æ¨¡æ‹Ÿ3åˆ†ç±»é—®é¢˜
    n_classes = 3
    
    # çœŸå®æ ‡ç­¾æ˜¯ç±»åˆ«1
    y_true = np.array([0, 1, 0])  # one-hotç¼–ç 
    
    # åˆ›å»ºé¢„æµ‹æ¦‚ç‡çš„ç½‘æ ¼
    p1_range = np.linspace(0, 1, 50)
    p2_range = np.linspace(0, 1, 50)
    P1, P2 = np.meshgrid(p1_range, p2_range)
    
    # è®¡ç®—äº¤å‰ç†µæŸå¤±
    losses = np.zeros_like(P1)
    for i in range(P1.shape[0]):
        for j in range(P1.shape[1]):
            p1, p2 = P1[i, j], P2[i, j]
            p3 = 1 - p1 - p2
            
            if p3 >= 0 and p1 >= 0 and p2 >= 0:  # åˆæ³•çš„æ¦‚ç‡åˆ†å¸ƒ
                y_pred = np.array([p1, p2, p3])
                # äº¤å‰ç†µæŸå¤±
                epsilon = 1e-7
                y_pred_clipped = np.clip(y_pred, epsilon, 1 - epsilon)
                loss = -np.sum(y_true * np.log(y_pred_clipped))
                losses[i, j] = loss
            else:
                losses[i, j] = np.nan
    
    # 3Då¯è§†åŒ–
    ax = axes[0]
    ax = plt.subplot(2, 3, 4, projection='3d')
    valid_mask = ~np.isnan(losses)
    surf = ax.plot_surface(P1[valid_mask].reshape(-1, 50)[:40, :40], 
                          P2[valid_mask].reshape(-1, 50)[:40, :40], 
                          losses[valid_mask].reshape(-1, 50)[:40, :40], 
                          cmap='viridis', alpha=0.8)
    ax.set_xlabel('P(ç±»åˆ«0)')
    ax.set_ylabel('P(ç±»åˆ«1)')
    ax.set_zlabel('äº¤å‰ç†µæŸå¤±')
    ax.set_title('å¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±æ›²é¢')
    
    # ç­‰é«˜çº¿å›¾
    ax = axes[1]
    contour = ax.contourf(P1, P2, losses, levels=20, cmap='viridis')
    ax.plot(0, 1, 'r*', markersize=20, label='æœ€ä¼˜ç‚¹')
    ax.set_xlabel('P(ç±»åˆ«0)')
    ax.set_ylabel('P(ç±»åˆ«1)')
    ax.set_title('æŸå¤±ç­‰é«˜çº¿å›¾')
    plt.colorbar(contour, ax=ax)
    ax.text(0.1, 0.9, 'P(ç±»åˆ«2) = 1 - P(ç±»åˆ«0) - P(ç±»åˆ«1)', 
            fontsize=10, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    # æ¢¯åº¦æ–¹å‘
    ax = axes[2]
    # è®¡ç®—æ¢¯åº¦
    grad_p1 = np.gradient(losses, axis=1)
    grad_p2 = np.gradient(losses, axis=0)
    
    # åªæ˜¾ç¤ºéƒ¨åˆ†ç®­å¤´
    skip = 5
    valid = ~np.isnan(losses)
    ax.quiver(P1[::skip, ::skip][valid[::skip, ::skip]], 
              P2[::skip, ::skip][valid[::skip, ::skip]], 
              -grad_p1[::skip, ::skip][valid[::skip, ::skip]], 
              -grad_p2[::skip, ::skip][valid[::skip, ::skip]], 
              alpha=0.5)
    ax.plot(0, 1, 'r*', markersize=20, label='æœ€ä¼˜ç‚¹')
    ax.set_xlabel('P(ç±»åˆ«0)')
    ax.set_ylabel('P(ç±»åˆ«1)')
    ax.set_title('æ¢¯åº¦åœºï¼ˆæŒ‡å‘æœ€ä¼˜ç‚¹ï¼‰')
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    
    print("\nğŸ’¡ å¤šåˆ†ç±»äº¤å‰ç†µçš„ç‰¹ç‚¹ï¼š")
    print("1. å½“é¢„æµ‹å®Œå…¨æ­£ç¡®æ—¶ï¼ˆå¦‚[0,1,0]ï¼‰ï¼ŒæŸå¤±ä¸º0")
    print("2. æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°ï¼Œæœ‰å”¯ä¸€æœ€å°å€¼")
    print("3. æ¢¯åº¦æŒ‡å‘æœ€ä¼˜è§£çš„æ–¹å‘")

åˆ†ç±»æŸå¤±å‡½æ•°è¯¦è§£()
```

#### ğŸ¯ ä¸ºä»€ä¹ˆé€‰æ‹©ç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Ÿ

```python
def æŸå¤±å‡½æ•°é€‰æ‹©æŒ‡å—():
    """å±•ç¤ºå¦‚ä½•é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°"""
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # åœºæ™¯1ï¼šæœ‰å¼‚å¸¸å€¼çš„å›å½’
    ax = axes[0, 0]
    np.random.seed(42)
    X = np.linspace(0, 10, 100)
    y = 2 * X + 1 + np.random.randn(100) * 0.5
    # æ·»åŠ å¼‚å¸¸å€¼
    outliers = np.random.choice(100, 5, replace=False)
    y[outliers] += np.random.randn(5) * 10
    
    ax.scatter(X, y, alpha=0.6)
    ax.scatter(X[outliers], y[outliers], color='red', s=100, 
               edgecolors='black', label='å¼‚å¸¸å€¼')
    ax.set_title('åœºæ™¯ï¼šæ•°æ®å«å¼‚å¸¸å€¼')
    ax.set_xlabel('X')
    ax.set_ylabel('y')
    ax.legend()
    ax.text(0.5, 0.95, 'æ¨èï¼šHuberæˆ–MAEæŸå¤±', 
            transform=ax.transAxes, ha='center', fontsize=12,
            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))
    
    # åœºæ™¯2ï¼šç±»åˆ«ä¸å¹³è¡¡
    ax = axes[0, 1]
    classes = ['æ­£å¸¸', 'å¼‚å¸¸']
    counts = [950, 50]
    colors = ['green', 'red']
    ax.bar(classes, counts, color=colors, alpha=0.7)
    ax.set_title('åœºæ™¯ï¼šç±»åˆ«ä¸¥é‡ä¸å¹³è¡¡')
    ax.set_ylabel('æ ·æœ¬æ•°')
    ax.text(0.5, 0.95, 'æ¨èï¼šFocal Lossæˆ–åŠ æƒäº¤å‰ç†µ', 
            transform=ax.transAxes, ha='center', fontsize=12,
            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))
    
    # åœºæ™¯3ï¼šæ¦‚ç‡æ ¡å‡†å¾ˆé‡è¦
    ax = axes[1, 0]
    # æ¨¡æ‹Ÿç½®ä¿¡åº¦åˆ†å¸ƒ
    confidence = np.linspace(0, 1, 100)
    well_calibrated = confidence
    overconfident = confidence ** 0.5
    underconfident = confidence ** 2
    
    ax.plot(confidence, well_calibrated, 'g-', linewidth=2, label='ç†æƒ³æ ¡å‡†')
    ax.plot(confidence, overconfident, 'r--', linewidth=2, label='è¿‡åº¦è‡ªä¿¡')
    ax.plot(confidence, underconfident, 'b--', linewidth=2, label='ä¿¡å¿ƒä¸è¶³')
    ax.set_xlabel('é¢„æµ‹ç½®ä¿¡åº¦')
    ax.set_ylabel('å®é™…å‡†ç¡®ç‡')
    ax.set_title('åœºæ™¯ï¼šéœ€è¦æ¦‚ç‡æ ¡å‡†')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.text(0.5, 0.05, 'æ¨èï¼šäº¤å‰ç†µæŸå¤±', 
            transform=ax.transAxes, ha='center', fontsize=12,
            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))
    
    # åœºæ™¯4ï¼šæ’åºä»»åŠ¡
    ax = axes[1, 1]
    # æ¨¡æ‹Ÿæ’åºå¾—åˆ†
    items = ['A', 'B', 'C', 'D', 'E']
    true_scores = [5, 4, 3, 2, 1]
    pred_scores = [4.8, 3.9, 3.2, 2.5, 0.8]
    
    x = np.arange(len(items))
    width = 0.35
    ax.bar(x - width/2, true_scores, width, label='çœŸå®æ’åº', alpha=0.7)
    ax.bar(x + width/2, pred_scores, width, label='é¢„æµ‹æ’åº', alpha=0.7)
    ax.set_xticks(x)
    ax.set_xticklabels(items)
    ax.set_ylabel('å¾—åˆ†')
    ax.set_title('åœºæ™¯ï¼šæ’åº/æ¨èä»»åŠ¡')
    ax.legend()
    ax.text(0.5, 0.95, 'æ¨èï¼šPairwise/Listwiseæ’åºæŸå¤±', 
            transform=ax.transAxes, ha='center', fontsize=12,
            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))
    
    plt.suptitle('æŸå¤±å‡½æ•°é€‰æ‹©æŒ‡å—', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    # æ‰“å°é€‰æ‹©å»ºè®®
    print("\nğŸ“‹ æŸå¤±å‡½æ•°é€‰æ‹©å†³ç­–æ ‘ï¼š")
    print("\n1. å›å½’ä»»åŠ¡")
    print("   â”œâ”€ æ•°æ®å¹²å‡€ â†’ MSE")
    print("   â”œâ”€ æœ‰å¼‚å¸¸å€¼ â†’ Huberæˆ–MAE")
    print("   â””â”€ éœ€è¦ä¸ç¡®å®šæ€§ä¼°è®¡ â†’ è´Ÿå¯¹æ•°ä¼¼ç„¶")
    print("\n2. åˆ†ç±»ä»»åŠ¡")
    print("   â”œâ”€ äºŒåˆ†ç±»")
    print("   â”‚   â”œâ”€ ç±»åˆ«å¹³è¡¡ â†’ äºŒå…ƒäº¤å‰ç†µ")
    print("   â”‚   â””â”€ ç±»åˆ«ä¸å¹³è¡¡ â†’ Focal Lossæˆ–åŠ æƒäº¤å‰ç†µ")
    print("   â””â”€ å¤šåˆ†ç±»")
    print("       â”œâ”€ æ ‡å‡†å¤šåˆ†ç±» â†’ äº¤å‰ç†µ")
    print("       â”œâ”€ æ ‡ç­¾å¹³æ»‘ â†’ Label Smoothingäº¤å‰ç†µ")
    print("       â””â”€ å¤šæ ‡ç­¾ â†’ Binaryäº¤å‰ç†µï¼ˆæ¯ä¸ªæ ‡ç­¾ç‹¬ç«‹ï¼‰")

æŸå¤±å‡½æ•°é€‰æ‹©æŒ‡å—()
```

#### ğŸ”§ è‡ªå®šä¹‰æŸå¤±å‡½æ•°

```python
class CustomLossFunctions:
    """è‡ªå®šä¹‰æŸå¤±å‡½æ•°çš„å®ç°"""
    
    @staticmethod
    def quantile_loss(y_true, y_pred, quantile=0.5):
        """åˆ†ä½æ•°æŸå¤±ï¼šç”¨äºé¢„æµ‹ç‰¹å®šåˆ†ä½æ•°"""
        error = y_true - y_pred
        return np.mean(np.maximum(quantile * error, (quantile - 1) * error))
    
    @staticmethod
    def dice_loss(y_true, y_pred, smooth=1e-6):
        """DiceæŸå¤±ï¼šç”¨äºå›¾åƒåˆ†å‰²"""
        intersection = np.sum(y_true * y_pred)
        return 1 - (2 * intersection + smooth) / (np.sum(y_true) + np.sum(y_pred) + smooth)
    
    @staticmethod
    def contrastive_loss(anchor, positive, negative, margin=1.0):
        """å¯¹æ¯”æŸå¤±ï¼šç”¨äºåº¦é‡å­¦ä¹ """
        pos_dist = np.linalg.norm(anchor - positive)
        neg_dist = np.linalg.norm(anchor - negative)
        return np.maximum(0, pos_dist - neg_dist + margin)
    
    @staticmethod
    def custom_weighted_loss(y_true, y_pred, weight_fn):
        """è‡ªå®šä¹‰åŠ æƒæŸå¤±"""
        base_loss = (y_true - y_pred) ** 2
        weights = weight_fn(y_true)
        return np.mean(weights * base_loss)

def è‡ªå®šä¹‰æŸå¤±å‡½æ•°æ¼”ç¤º():
    """æ¼”ç¤ºå„ç§è‡ªå®šä¹‰æŸå¤±å‡½æ•°"""
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # åˆ†ä½æ•°æŸå¤±
    ax = axes[0, 0]
    y_true = 0
    x = np.linspace(-3, 3, 1000)
    
    for q in [0.1, 0.25, 0.5, 0.75, 0.9]:
        loss = [CustomLossFunctions.quantile_loss(y_true, pred, q) for pred in x]
        ax.plot(x, loss, linewidth=2, label=f'Ï„={q}')
    
    ax.axvline(x=0, color='red', linestyle='--', alpha=0.5)
    ax.set_xlabel('é¢„æµ‹å€¼ - çœŸå®å€¼')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('åˆ†ä½æ•°æŸå¤±')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.text(0.02, 0.98, 'ç”¨é€”ï¼šé¢„æµ‹ç½®ä¿¡åŒºé—´', 
            transform=ax.transAxes, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    # å¯¹æ¯”æŸå¤±
    ax = axes[0, 1]
    # å¯è§†åŒ–ä¸‰å…ƒç»„
    anchor = np.array([0, 0])
    
    # åˆ›å»ºä¸€ä¸ªåœ†å½¢åŒºåŸŸè¡¨ç¤ºmargin
    circle = plt.Circle(anchor, 1.0, fill=False, edgecolor='gray', 
                       linestyle='--', linewidth=2)
    ax.add_patch(circle)
    
    # æ­£æ ·æœ¬ï¼ˆåº”è¯¥é è¿‘anchorï¼‰
    positive = np.array([0.5, 0.3])
    ax.plot(*positive, 'go', markersize=12, label='æ­£æ ·æœ¬')
    ax.plot([anchor[0], positive[0]], [anchor[1], positive[1]], 'g-', alpha=0.5)
    
    # è´Ÿæ ·æœ¬ï¼ˆåº”è¯¥è¿œç¦»anchorï¼‰
    negative = np.array([1.5, 1.2])
    ax.plot(*negative, 'ro', markersize=12, label='è´Ÿæ ·æœ¬')
    ax.plot([anchor[0], negative[0]], [anchor[1], negative[1]], 'r-', alpha=0.5)
    
    ax.plot(*anchor, 'bs', markersize=15, label='é”šç‚¹')
    ax.set_xlim(-2, 2)
    ax.set_ylim(-2, 2)
    ax.set_aspect('equal')
    ax.set_title('å¯¹æ¯”æŸå¤±ï¼ˆä¸‰å…ƒç»„ï¼‰')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.text(0.02, 0.98, 'ç›®æ ‡ï¼šæ­£æ ·æœ¬é è¿‘ï¼Œè´Ÿæ ·æœ¬è¿œç¦»', 
            transform=ax.transAxes, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))
    
    # è‡ªå®šä¹‰åŠ æƒæŸå¤±
    ax = axes[1, 0]
    x = np.linspace(0, 10, 100)
    y_true = np.sin(x) + np.random.randn(100) * 0.1
    
    # å®šä¹‰æƒé‡å‡½æ•°ï¼šç»™æŸäº›åŒºåŸŸæ›´é«˜æƒé‡
    def importance_weight(x):
        return 1 + 2 * np.exp(-(x - 5)**2)
    
    weights = importance_weight(x)
    
    ax.scatter(x, y_true, alpha=0.5, s=weights*20, c=weights, cmap='Reds')
    ax.plot(x, np.sin(x), 'b-', linewidth=2, label='çœŸå®å‡½æ•°')
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    ax.set_title('è‡ªå®šä¹‰åŠ æƒæŸå¤±')
    cbar = plt.colorbar(ax.scatter([], [], c=[], cmap='Reds'), ax=ax)
    cbar.set_label('æƒé‡')
    ax.text(0.02, 0.98, 'é‡ç‚¹åŒºåŸŸï¼ˆxâ‰ˆ5ï¼‰æƒé‡æ›´é«˜', 
            transform=ax.transAxes, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))
    
    # ç»„åˆæŸå¤±
    ax = axes[1, 1]
    
    # æ¨¡æ‹Ÿå¤šä»»åŠ¡å­¦ä¹ 
    tasks = ['ä»»åŠ¡A\n(å›å½’)', 'ä»»åŠ¡B\n(åˆ†ç±»)', 'ä»»åŠ¡C\n(æ’åº)']
    losses = [0.8, 1.2, 0.5]
    weights = [0.5, 0.3, 0.2]
    
    x = np.arange(len(tasks))
    bars = ax.bar(x, losses, alpha=0.7, label='åŸå§‹æŸå¤±')
    
    # æ ‡æ³¨æƒé‡
    for i, (bar, weight) in enumerate(zip(bars, weights)):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.05,
                f'Ã—{weight}', ha='center', va='bottom', fontsize=12)
    
    # åŠ æƒåçš„æŸå¤±
    weighted_losses = [l * w for l, w in zip(losses, weights)]
    ax.bar(x, weighted_losses, alpha=0.7, label='åŠ æƒæŸå¤±', 
           bottom=[l - wl for l, wl in zip(losses, weighted_losses)])
    
    ax.set_xticks(x)
    ax.set_xticklabels(tasks)
    ax.set_ylabel('æŸå¤±å€¼')
    ax.set_title('å¤šä»»åŠ¡å­¦ä¹ çš„ç»„åˆæŸå¤±')
    ax.legend()
    
    # æ€»æŸå¤±
    total_loss = sum(weighted_losses)
    ax.axhline(y=total_loss, color='red', linestyle='--', alpha=0.7)
    ax.text(0.5, total_loss + 0.05, f'æ€»æŸå¤± = {total_loss:.2f}', 
            ha='center', fontsize=12, color='red')
    
    plt.suptitle('è‡ªå®šä¹‰æŸå¤±å‡½æ•°ç¤ºä¾‹', fontsize=16)
    plt.tight_layout()
    plt.show()

è‡ªå®šä¹‰æŸå¤±å‡½æ•°æ¼”ç¤º()
```

#### ğŸ“ˆ æŸå¤±å‡½æ•°çš„æ€§è´¨

```python
def æŸå¤±å‡½æ•°æ€§è´¨åˆ†æ():
    """åˆ†ææŸå¤±å‡½æ•°çš„é‡è¦æ€§è´¨"""
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # æ€§è´¨1ï¼šå‡¸æ€§
    ax = axes[0, 0]
    x = np.linspace(-3, 3, 1000)
    
    # å‡¸å‡½æ•°
    convex = x**2
    # éå‡¸å‡½æ•°
    non_convex = np.sin(2*x) + 0.1*x**2
    
    ax.plot(x, convex, 'b-', linewidth=2, label='å‡¸å‡½æ•° (MSE)')
    ax.plot(x, non_convex, 'r-', linewidth=2, label='éå‡¸å‡½æ•°')
    
    # æ ‡æ³¨å±€éƒ¨æœ€å°å€¼
    local_mins_x = [-2.4, -0.5, 1.5]
    local_mins_y = [np.sin(2*xi) + 0.1*xi**2 for xi in local_mins_x]
    ax.scatter(local_mins_x, local_mins_y, color='red', s=100, zorder=5)
    
    ax.set_xlabel('å‚æ•°')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('æ€§è´¨1ï¼šå‡¸æ€§')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.text(0.02, 0.98, 'å‡¸å‡½æ•°ä¿è¯å…¨å±€æœ€ä¼˜', 
            transform=ax.transAxes, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    # æ€§è´¨2ï¼šå¹³æ»‘æ€§
    ax = axes[0, 1]
    
    # å¹³æ»‘å‡½æ•°
    smooth = x**2
    smooth_grad = 2*x
    
    # éå¹³æ»‘å‡½æ•°
    non_smooth = np.abs(x)
    non_smooth_grad = np.sign(x)
    
    ax.plot(x, smooth, 'b-', linewidth=2, label='å¹³æ»‘ (MSE)')
    ax.plot(x, non_smooth, 'r-', linewidth=2, label='éå¹³æ»‘ (MAE)')
    
    ax.set_xlabel('å‚æ•°')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('æ€§è´¨2ï¼šå¹³æ»‘æ€§')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.text(0.02, 0.98, 'å¹³æ»‘å‡½æ•°æ˜“äºä¼˜åŒ–', 
            transform=ax.transAxes, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))
    
    # æ€§è´¨3ï¼šæ¢¯åº¦ç‰¹æ€§
    ax = axes[0, 2]
    
    ax.plot(x, smooth_grad, 'b-', linewidth=2, label='MSEæ¢¯åº¦')
    ax.plot(x, non_smooth_grad, 'r-', linewidth=2, label='MAEæ¢¯åº¦')
    
    ax.set_xlabel('å‚æ•°')
    ax.set_ylabel('æ¢¯åº¦')
    ax.set_title('æ€§è´¨3ï¼šæ¢¯åº¦ç‰¹æ€§')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    ax.text(0.02, 0.98, 'MAEæ¢¯åº¦æ’å®šï¼Œ\nMSEæ¢¯åº¦çº¿æ€§å¢é•¿', 
            transform=ax.transAxes, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))
    
    # æ€§è´¨4ï¼šé²æ£’æ€§
    ax = axes[1, 0]
    
    # æ­£å¸¸æ•°æ®
    normal_data = np.random.randn(1000)
    # æ·»åŠ å¼‚å¸¸å€¼
    outlier_data = np.concatenate([normal_data, [10, -10, 15]])
    
    bins = np.linspace(-5, 20, 50)
    ax.hist(outlier_data, bins=bins, alpha=0.7, density=True)
    ax.axvline(x=np.mean(outlier_data), color='red', linestyle='--', 
               linewidth=2, label=f'å‡å€¼={np.mean(outlier_data):.2f}')
    ax.axvline(x=np.median(outlier_data), color='green', linestyle='--', 
               linewidth=2, label=f'ä¸­ä½æ•°={np.median(outlier_data):.2f}')
    
    ax.set_xlabel('æ•°å€¼')
    ax.set_ylabel('å¯†åº¦')
    ax.set_title('æ€§è´¨4ï¼šé²æ£’æ€§')
    ax.legend()
    ax.text(0.98, 0.98, 'MAEå¯¹åº”ä¸­ä½æ•°\n(æ›´é²æ£’)', 
            transform=ax.transAxes, verticalalignment='top', ha='right',
            bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))
    
    # æ€§è´¨5ï¼šæ¦‚ç‡è§£é‡Š
    ax = axes[1, 1]
    
    # ä¸åŒå™ªå£°åˆ†å¸ƒ
    x_range = np.linspace(-3, 3, 1000)
    gaussian = (1/np.sqrt(2*np.pi)) * np.exp(-0.5 * x_range**2)
    laplace = 0.5 * np.exp(-np.abs(x_range))
    
    ax.plot(x_range, gaussian, 'b-', linewidth=2, label='é«˜æ–¯å™ªå£° â†’ MSE')
    ax.plot(x_range, laplace, 'r-', linewidth=2, label='æ‹‰æ™®æ‹‰æ–¯å™ªå£° â†’ MAE')
    
    ax.set_xlabel('è¯¯å·®')
    ax.set_ylabel('æ¦‚ç‡å¯†åº¦')
    ax.set_title('æ€§è´¨5ï¼šæ¦‚ç‡è§£é‡Š')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # æ€§è´¨6ï¼šè®¡ç®—æ•ˆç‡
    ax = axes[1, 2]
    
    operations = ['MSE', 'MAE', 'Huber', 'Cross\nEntropy', 'Focal\nLoss']
    compute_times = [1.0, 1.2, 2.5, 3.0, 4.5]  # ç›¸å¯¹æ—¶é—´
    
    bars = ax.bar(operations, compute_times, 
                   color=['blue', 'green', 'orange', 'red', 'purple'], alpha=0.7)
    
    ax.set_ylabel('ç›¸å¯¹è®¡ç®—æ—¶é—´')
    ax.set_title('æ€§è´¨6ï¼šè®¡ç®—æ•ˆç‡')
    
    for bar, time in zip(bars, compute_times):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                f'{time:.1f}x', ha='center', va='bottom')
    
    plt.suptitle('æŸå¤±å‡½æ•°çš„é‡è¦æ€§è´¨', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    print("\nğŸ“Š æŸå¤±å‡½æ•°æ€§è´¨æ€»ç»“ï¼š")
    print("\n1. å‡¸æ€§ï¼šä¿è¯ä¼˜åŒ–èƒ½æ‰¾åˆ°å…¨å±€æœ€ä¼˜")
    print("2. å¹³æ»‘æ€§ï¼šæ¢¯åº¦è¿ç»­ï¼Œä¼˜åŒ–æ›´ç¨³å®š")
    print("3. æ¢¯åº¦ç‰¹æ€§ï¼šå½±å“æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§")
    print("4. é²æ£’æ€§ï¼šå¯¹å¼‚å¸¸å€¼çš„æ•æ„Ÿç¨‹åº¦")
    print("5. æ¦‚ç‡è§£é‡Šï¼šå¯¹åº”ä¸åŒçš„å™ªå£°å‡è®¾")
    print("6. è®¡ç®—æ•ˆç‡ï¼šå½±å“è®­ç»ƒé€Ÿåº¦")

æŸå¤±å‡½æ•°æ€§è´¨åˆ†æ()
```

#### ğŸ® å®æˆ˜ï¼šæŸå¤±å‡½æ•°å®éªŒå®¤

```python
class LossLaboratory:
    """æŸå¤±å‡½æ•°å®éªŒå®¤ï¼šæ¯”è¾ƒä¸åŒæŸå¤±å‡½æ•°çš„æ•ˆæœ"""
    
    def __init__(self):
        self.losses_history = {}
        
    def generate_regression_data(self, n_samples=100, noise_type='gaussian'):
        """ç”Ÿæˆå›å½’æ•°æ®"""
        np.random.seed(42)
        X = np.linspace(0, 10, n_samples).reshape(-1, 1)
        y_true = 2 * X.squeeze() + 1
        
        if noise_type == 'gaussian':
            noise = np.random.randn(n_samples) * 2
        elif noise_type == 'laplace':
            noise = np.random.laplace(0, 2, n_samples)
        elif noise_type == 'outliers':
            noise = np.random.randn(n_samples) * 0.5
            # æ·»åŠ å¼‚å¸¸å€¼
            outlier_idx = np.random.choice(n_samples, 10, replace=False)
            noise[outlier_idx] = np.random.randn(10) * 10
        
        y = y_true + noise
        return X, y, y_true
    
    def train_with_loss(self, X, y, loss_type='mse', epochs=100, lr=0.01):
        """ä½¿ç”¨æŒ‡å®šæŸå¤±å‡½æ•°è®­ç»ƒæ¨¡å‹"""
        # åˆå§‹åŒ–å‚æ•°
        w = np.random.randn()
        b = np.random.randn()
        
        losses = []
        
        for epoch in range(epochs):
            # å‰å‘ä¼ æ’­
            y_pred = w * X.squeeze() + b
            
            # è®¡ç®—æŸå¤±å’Œæ¢¯åº¦
            if loss_type == 'mse':
                loss = np.mean((y - y_pred) ** 2)
                dw = -2 * np.mean((y - y_pred) * X.squeeze())
                db = -2 * np.mean(y - y_pred)
            elif loss_type == 'mae':
                loss = np.mean(np.abs(y - y_pred))
                dw = -np.mean(np.sign(y - y_pred) * X.squeeze())
                db = -np.mean(np.sign(y - y_pred))
            elif loss_type == 'huber':
                delta = 1.0
                error = y - y_pred
                is_small = np.abs(error) <= delta
                
                huber_loss = np.where(is_small, 
                                     0.5 * error ** 2,
                                     delta * (np.abs(error) - 0.5 * delta))
                loss = np.mean(huber_loss)
                
                huber_grad = np.where(is_small, error, delta * np.sign(error))
                dw = -np.mean(huber_grad * X.squeeze())
                db = -np.mean(huber_grad)
            
            # æ¢¯åº¦ä¸‹é™
            w -= lr * dw
            b -= lr * db
            
            losses.append(loss)
        
        return w, b, losses
    
    def compare_losses(self):
        """æ¯”è¾ƒä¸åŒæŸå¤±å‡½æ•°åœ¨ä¸åŒæ•°æ®ä¸Šçš„è¡¨ç°"""
        
        fig, axes = plt.subplots(3, 3, figsize=(15, 12))
        
        noise_types = ['gaussian', 'laplace', 'outliers']
        loss_types = ['mse', 'mae', 'huber']
        
        for i, noise_type in enumerate(noise_types):
            # ç”Ÿæˆæ•°æ®
            X, y, y_true = self.generate_regression_data(noise_type=noise_type)
            
            for j, loss_type in enumerate(loss_types):
                ax = axes[i, j]
                
                # è®­ç»ƒæ¨¡å‹
                w, b, losses = self.train_with_loss(X, y, loss_type)
                
                # å¯è§†åŒ–ç»“æœ
                ax.scatter(X, y, alpha=0.5, label='æ•°æ®')
                ax.plot(X, y_true, 'g-', linewidth=2, label='çœŸå®')
                ax.plot(X, w * X.squeeze() + b, 'r--', linewidth=2, 
                       label=f'æ‹Ÿåˆ (w={w:.2f}, b={b:.2f})')
                
                ax.set_title(f'{noise_type.capitalize()} + {loss_type.upper()}')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                # ä¿å­˜æŸå¤±å†å²
                self.losses_history[f'{noise_type}_{loss_type}'] = losses
        
        plt.suptitle('ä¸åŒå™ªå£°ç±»å‹å’ŒæŸå¤±å‡½æ•°çš„ç»„åˆæ•ˆæœ', fontsize=16)
        plt.tight_layout()
        plt.show()
        
        # ç»˜åˆ¶æŸå¤±æ›²çº¿
        self.plot_loss_curves()
    
    def plot_loss_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 4))
        
        noise_types = ['gaussian', 'laplace', 'outliers']
        colors = {'mse': 'blue', 'mae': 'green', 'huber': 'red'}
        
        for i, noise_type in enumerate(noise_types):
            ax = axes[i]
            
            for loss_type in ['mse', 'mae', 'huber']:
                key = f'{noise_type}_{loss_type}'
                if key in self.losses_history:
                    ax.plot(self.losses_history[key], 
                           color=colors[loss_type], 
                           linewidth=2,
                           label=loss_type.upper())
            
            ax.set_xlabel('Epoch')
            ax.set_ylabel('æŸå¤±')
            ax.set_title(f'{noise_type.capitalize()}å™ªå£°')
            ax.legend()
            ax.grid(True, alpha=0.3)
            ax.set_yscale('log')
        
        plt.suptitle('è®­ç»ƒæŸå¤±æ›²çº¿å¯¹æ¯”', fontsize=14)
        plt.tight_layout()
        plt.show()

# è¿è¡Œå®éªŒ
lab = LossLaboratory()
lab.compare_losses()

# é¢å¤–å®éªŒï¼šæŸå¤±å‡½æ•°å¯¹æ¢¯åº¦çš„å½±å“
def æ¢¯åº¦è¡Œä¸ºåˆ†æ():
    """åˆ†æä¸åŒæŸå¤±å‡½æ•°çš„æ¢¯åº¦è¡Œä¸º"""
    
    errors = np.linspace(-5, 5, 1000)
    
    # MSEæ¢¯åº¦
    mse_grad = 2 * errors
    
    # MAEæ¢¯åº¦
    mae_grad = np.sign(errors)
    
    # Huberæ¢¯åº¦
    delta = 1.0
    huber_grad = np.where(np.abs(errors) <= delta, 
                         errors, 
                         delta * np.sign(errors))
    
    plt.figure(figsize=(10, 6))
    plt.plot(errors, mse_grad, 'b-', linewidth=2, label='MSEæ¢¯åº¦')
    plt.plot(errors, mae_grad, 'g-', linewidth=2, label='MAEæ¢¯åº¦')
    plt.plot(errors, huber_grad, 'r-', linewidth=2, label='Huberæ¢¯åº¦')
    
    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)
    
    # æ ‡æ³¨åŒºåŸŸ
    plt.fill_between([-delta, delta], -5, 5, alpha=0.2, color='gray',
                    label='HuberäºŒæ¬¡åŒºåŸŸ')
    
    plt.xlabel('é¢„æµ‹è¯¯å·®')
    plt.ylabel('æ¢¯åº¦')
    plt.title('ä¸åŒæŸå¤±å‡½æ•°çš„æ¢¯åº¦ç‰¹æ€§')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(-5, 5)
    
    plt.show()
    
    print("\nğŸ¯ æ¢¯åº¦ç‰¹æ€§åˆ†æï¼š")
    print("1. MSEï¼šæ¢¯åº¦éšè¯¯å·®çº¿æ€§å¢é•¿ï¼Œå¯¹å¤§è¯¯å·®ååº”å¼ºçƒˆ")
    print("2. MAEï¼šæ¢¯åº¦æ’å®šï¼Œä¸å—è¯¯å·®å¤§å°å½±å“")
    print("3. Huberï¼šå°è¯¯å·®æ—¶åƒMSEï¼Œå¤§è¯¯å·®æ—¶åƒMAE")

æ¢¯åº¦è¡Œä¸ºåˆ†æ()
```

#### ğŸ’¡ æœ¬ç« å°ç»“

1. **æŸå¤±å‡½æ•°çš„æœ¬è´¨**ï¼š
   - è¡¡é‡é¢„æµ‹ä¸çœŸå®å€¼çš„å·®è·
   - ä¸ºä¼˜åŒ–æä¾›æ–¹å‘å’Œå¤§å°
   - ä¸åŒæŸå¤±å‡½æ•°æœ‰ä¸åŒçš„å‡è®¾å’Œç‰¹æ€§

2. **å›å½’æŸå¤±å‡½æ•°**ï¼š
   - **MSE**ï¼šå¯¹å¤§è¯¯å·®æ•æ„Ÿï¼Œå‡è®¾é«˜æ–¯å™ªå£°
   - **MAE**ï¼šå¯¹å¼‚å¸¸å€¼é²æ£’ï¼Œå‡è®¾æ‹‰æ™®æ‹‰æ–¯å™ªå£°
   - **Huber**ï¼šç»“åˆMSEå’ŒMAEçš„ä¼˜ç‚¹
   - **åˆ†ä½æ•°æŸå¤±**ï¼šé¢„æµ‹ç‰¹å®šåˆ†ä½æ•°

3. **åˆ†ç±»æŸå¤±å‡½æ•°**ï¼š
   - **äº¤å‰ç†µ**ï¼šæœ€å¸¸ç”¨ï¼Œæœ‰æ¦‚ç‡è§£é‡Š
   - **Focal Loss**ï¼šå¤„ç†ç±»åˆ«ä¸å¹³è¡¡
   - **Hinge Loss**ï¼šSVMä½¿ç”¨ï¼Œæœ€å¤§é—´éš”
   - **å¯¹æ¯”æŸå¤±**ï¼šåº¦é‡å­¦ä¹ 

4. **é€‰æ‹©åŸåˆ™**ï¼š
   - è€ƒè™‘æ•°æ®ç‰¹ç‚¹ï¼ˆå™ªå£°ç±»å‹ã€å¼‚å¸¸å€¼ï¼‰
   - è€ƒè™‘ä»»åŠ¡éœ€æ±‚ï¼ˆæ¦‚ç‡æ ¡å‡†ã€æ’åºï¼‰
   - è€ƒè™‘è®¡ç®—æ•ˆç‡
   - å¯ä»¥ç»„åˆå¤šä¸ªæŸå¤±å‡½æ•°

5. **æŸå¤±å‡½æ•°çš„æ€§è´¨**ï¼š
   - **å‡¸æ€§**ï¼šå½±å“ä¼˜åŒ–éš¾åº¦
   - **å¹³æ»‘æ€§**ï¼šå½±å“æ¢¯åº¦è®¡ç®—
   - **é²æ£’æ€§**ï¼šå¯¹å¼‚å¸¸å€¼çš„æ•æ„Ÿåº¦
   - **å¯è§£é‡Šæ€§**ï¼šæ˜¯å¦æœ‰æ¦‚ç‡æ„ä¹‰

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆåˆ†ç±»ä»»åŠ¡ä¸èƒ½ç›´æ¥ç”¨å‡†ç¡®ç‡ä½œä¸ºæŸå¤±å‡½æ•°ï¼Ÿ
2. å¦‚æœæ•°æ®ä¸­æ—¢æœ‰é«˜æ–¯å™ªå£°åˆæœ‰å¼‚å¸¸å€¼ï¼Œåº”è¯¥é€‰æ‹©ä»€ä¹ˆæŸå¤±å‡½æ•°ï¼Ÿ
3. ä¸ºä»€ä¹ˆæ·±åº¦å­¦ä¹ ä¸­å¾ˆå°‘ç”¨é«˜é˜¶ï¼ˆå¦‚4æ¬¡æ–¹ï¼‰çš„æŸå¤±å‡½æ•°ï¼Ÿ

#### ğŸ”¬ æ‰©å±•å®éªŒ

```python
def æŸå¤±å‡½æ•°åˆ›æ–°å®éªŒ():
    """æ¢ç´¢åˆ›æ–°çš„æŸå¤±å‡½æ•°è®¾è®¡"""
    
    print("ğŸ”¬ æŸå¤±å‡½æ•°åˆ›æ–°å®éªŒ\n")
    
    # å®éªŒ1ï¼šè‡ªé€‚åº”æŸå¤±å‡½æ•°
    class AdaptiveLoss:
        def __init__(self):
            self.alpha = 2.0  # åˆå§‹ä¸ºMSE
            
        def compute(self, y_true, y_pred, epoch):
            """éšè®­ç»ƒè¿›ç¨‹è°ƒæ•´çš„æŸå¤±å‡½æ•°"""
            # æ—©æœŸç”¨MSEå¿«é€Ÿæ”¶æ•›ï¼ŒåæœŸç”¨MAEç²¾ç»†è°ƒæ•´
            self.alpha = 2.0 - (epoch / 100) * 0.8  # ä»2é™åˆ°1.2
            error = np.abs(y_true - y_pred)
            return np.mean(error ** self.alpha)
    
    # å®éªŒ2ï¼šä¸ç¡®å®šæ€§æ„ŸçŸ¥æŸå¤±
    def uncertainty_aware_loss(y_true, y_pred_mean, y_pred_std):
        """åŒæ—¶é¢„æµ‹å‡å€¼å’Œä¸ç¡®å®šæ€§"""
        # è´Ÿå¯¹æ•°ä¼¼ç„¶
        nll = 0.5 * np.log(2 * np.pi * y_pred_std**2) + \
              0.5 * ((y_true - y_pred_mean)**2) / (y_pred_std**2)
        
        # æ­£åˆ™åŒ–é¡¹ï¼Œé˜²æ­¢é¢„æµ‹è¿‡å¤§çš„ä¸ç¡®å®šæ€§
        reg = 0.01 * np.log(y_pred_std)
        
        return np.mean(nll + reg)
    
    # å¯è§†åŒ–
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # è‡ªé€‚åº”æŸå¤±
    epochs = np.arange(100)
    alphas = 2.0 - (epochs / 100) * 0.8
    ax1.plot(epochs, alphas, 'b-', linewidth=2)
    ax1.set_xlabel('è®­ç»ƒè½®æ¬¡')
    ax1.set_ylabel('Î±å€¼')
    ax1.set_title('è‡ªé€‚åº”æŸå¤±å‡½æ•°çš„Î±å˜åŒ–')
    ax1.grid(True, alpha=0.3)
    ax1.fill_between(epochs[:30], 0, 2.5, alpha=0.2, color='blue',
                    label='å¿«é€Ÿæ”¶æ•›é˜¶æ®µ')
    ax1.fill_between(epochs[70:], 0, 2.5, alpha=0.2, color='green',
                    label='ç²¾ç»†è°ƒæ•´é˜¶æ®µ')
    ax1.legend()
    
    # ä¸ç¡®å®šæ€§æ„ŸçŸ¥
    y_true = 0
    y_pred_mean = np.linspace(-3, 3, 100)
    uncertainties = [0.5, 1.0, 2.0]
    
    for std in uncertainties:
        y_pred_std = np.ones_like(y_pred_mean) * std
        loss = [uncertainty_aware_loss(y_true, pred, std) 
                for pred in y_pred_mean]
        ax2.plot(y_pred_mean, loss, linewidth=2, 
                label=f'Ïƒ={std}')
    
    ax2.set_xlabel('é¢„æµ‹å‡å€¼')
    ax2.set_ylabel('æŸå¤±')
    ax2.set_title('ä¸ç¡®å®šæ€§æ„ŸçŸ¥æŸå¤±')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ’¡ åˆ›æ–°æ€è·¯ï¼š")
    print("1. è‡ªé€‚åº”æŸå¤±ï¼šæ ¹æ®è®­ç»ƒé˜¶æ®µåŠ¨æ€è°ƒæ•´")
    print("2. ä¸ç¡®å®šæ€§æ„ŸçŸ¥ï¼šåŒæ—¶å­¦ä¹ é¢„æµ‹å’Œç½®ä¿¡åº¦")
    print("3. å¤šå°ºåº¦æŸå¤±ï¼šåœ¨ä¸åŒåˆ†è¾¨ç‡ä¸Šè®¡ç®—æŸå¤±")
    print("4. å¯¹æŠ—æ€§æŸå¤±ï¼šå¢å¼ºæ¨¡å‹é²æ£’æ€§")

æŸå¤±å‡½æ•°åˆ›æ–°å®éªŒ()
```

ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†å­¦ä¹ ä¼˜åŒ–å™¨â€”â€”Adamä¸ºä»€ä¹ˆè¿™ä¹ˆæµè¡Œï¼Ÿ

---

### ç¬¬7ç« ï¼šä¼˜åŒ–å™¨â€”â€”Adamä¸ºä»€ä¹ˆè¿™ä¹ˆæµè¡Œï¼Ÿ
#### ğŸ¯ æœ¬ç« å¯¼è¯»

å¦‚æœè¯´æŸå¤±å‡½æ•°å‘Šè¯‰æˆ‘ä»¬"é”™äº†å¤šå°‘"ï¼Œæ¢¯åº¦å‘Šè¯‰æˆ‘ä»¬"å¾€å“ªä¸ªæ–¹å‘æ”¹"ï¼Œé‚£ä¹ˆä¼˜åŒ–å™¨å°±æ˜¯å‘Šè¯‰æˆ‘ä»¬"è¯¥æ€ä¹ˆèµ°"ã€‚

æƒ³è±¡ä½ åœ¨ä¸€ä¸ªé™Œç”Ÿçš„å±±åŒºå¯»å®ï¼Œä½ çŸ¥é“å®è—åœ¨æœ€ä½çš„å±±è°·é‡Œï¼ˆæŸå¤±æœ€å°ï¼‰ï¼Œä¹ŸçŸ¥é“å½“å‰ä½ç½®çš„å¡åº¦ï¼ˆæ¢¯åº¦ï¼‰ï¼Œä½†æ˜¯ï¼š
- åº”è¯¥èµ°å¤šå¿«ï¼Ÿï¼ˆå­¦ä¹ ç‡ï¼‰
- é‡åˆ°é™¡å¡æ€ä¹ˆåŠï¼Ÿï¼ˆæ¢¯åº¦çˆ†ç‚¸ï¼‰
- åœ¨å¹³åŸä¸Šæ€ä¹ˆèµ°ï¼Ÿï¼ˆæ¢¯åº¦æ¶ˆå¤±ï¼‰
- è¦ä¸è¦è€ƒè™‘ä¹‹å‰çš„è·¯å¾„ï¼Ÿï¼ˆåŠ¨é‡ï¼‰

è¿™å°±æ˜¯ä¼˜åŒ–å™¨è¦è§£å†³çš„é—®é¢˜ã€‚è€ŒAdamï¼Œå°±åƒä¸€ä¸ªç»éªŒä¸°å¯Œçš„å‘å¯¼ï¼Œå‡ ä¹èƒ½åº”å¯¹æ‰€æœ‰åœ°å½¢ã€‚

#### ğŸš¶ ä»æœ€ç®€å•çš„SGDè¯´èµ·

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from IPython.display import HTML

def visualize_optimizers():
    """å¯è§†åŒ–ä¸åŒä¼˜åŒ–å™¨çš„è¡Œä¸º"""
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æŸå¤±å‡½æ•°æ™¯è§‚
    def loss_landscape(x, y):
        # Bealeå‡½æ•°ï¼šæœ‰å¼¯æ›²çš„å³¡è°·ï¼Œå¾ˆé€‚åˆæµ‹è¯•ä¼˜åŒ–å™¨
        return (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2
    
    # è®¡ç®—æ¢¯åº¦
    def compute_gradient(x, y):
        dx = 2*(1.5 - x + x*y)*(-1 + y) + \
             2*(2.25 - x + x*y**2)*(-1 + y**2) + \
             2*(2.625 - x + x*y**3)*(-1 + y**3)
        
        dy = 2*(1.5 - x + x*y)*(x) + \
             2*(2.25 - x + x*y**2)*(2*x*y) + \
             2*(2.625 - x + x*y**3)*(3*x*y**2)
        
        return dx, dy
    
    # è®¾ç½®ç½‘æ ¼
    x_range = np.linspace(-1, 4, 100)
    y_range = np.linspace(-1, 2, 100)
    X, Y = np.meshgrid(x_range, y_range)
    Z = loss_landscape(X, Y)
    
    # åˆå§‹åŒ–å›¾å½¢
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle('ä¸åŒä¼˜åŒ–å™¨çš„è·¯å¾„å¯¹æ¯”', fontsize=16)
    
    # ä¼˜åŒ–å™¨é…ç½®
    optimizers = {
        'SGD': {'ax': axes[0, 0], 'color': 'blue'},
        'SGD + Momentum': {'ax': axes[0, 1], 'color': 'green'},
        'RMSprop': {'ax': axes[1, 0], 'color': 'red'},
        'Adam': {'ax': axes[1, 1], 'color': 'purple'}
    }
    
    # å¯¹æ¯ä¸ªä¼˜åŒ–å™¨è¿è¡Œä¼˜åŒ–
    for opt_name, config in optimizers.items():
        ax = config['ax']
        
        # ç»˜åˆ¶ç­‰é«˜çº¿
        contour = ax.contour(X, Y, Z, levels=30, alpha=0.6)
        ax.clabel(contour, inline=True, fontsize=8)
        
        # èµ·å§‹ç‚¹
        x, y = 0.0, 0.0
        trajectory_x = [x]
        trajectory_y = [y]
        
        # ä¼˜åŒ–å™¨ç‰¹å®šå‚æ•°
        learning_rate = 0.01
        
        if opt_name == 'SGD':
            # çº¯SGD
            for _ in range(100):
                dx, dy = compute_gradient(x, y)
                x -= learning_rate * dx
                y -= learning_rate * dy
                trajectory_x.append(x)
                trajectory_y.append(y)
                
        elif opt_name == 'SGD + Momentum':
            # å¸¦åŠ¨é‡çš„SGD
            momentum = 0.9
            vx, vy = 0, 0
            
            for _ in range(100):
                dx, dy = compute_gradient(x, y)
                vx = momentum * vx - learning_rate * dx
                vy = momentum * vy - learning_rate * dy
                x += vx
                y += vy
                trajectory_x.append(x)
                trajectory_y.append(y)
                
        elif opt_name == 'RMSprop':
            # RMSprop
            epsilon = 1e-8
            decay_rate = 0.9
            sx, sy = 0, 0
            
            for _ in range(100):
                dx, dy = compute_gradient(x, y)
                sx = decay_rate * sx + (1 - decay_rate) * dx**2
                sy = decay_rate * sy + (1 - decay_rate) * dy**2
                x -= learning_rate * dx / (np.sqrt(sx) + epsilon)
                y -= learning_rate * dy / (np.sqrt(sy) + epsilon)
                trajectory_x.append(x)
                trajectory_y.append(y)
                
        elif opt_name == 'Adam':
            # Adam
            beta1, beta2 = 0.9, 0.999
            epsilon = 1e-8
            mx, my = 0, 0  # ä¸€é˜¶çŸ©ä¼°è®¡
            vx, vy = 0, 0  # äºŒé˜¶çŸ©ä¼°è®¡
            t = 0
            
            for _ in range(100):
                t += 1
                dx, dy = compute_gradient(x, y)
                
                # æ›´æ–°åå·®ä¿®æ­£çš„ä¸€é˜¶çŸ©ä¼°è®¡
                mx = beta1 * mx + (1 - beta1) * dx
                my = beta1 * my + (1 - beta1) * dy
                
                # æ›´æ–°åå·®ä¿®æ­£çš„äºŒé˜¶çŸ©ä¼°è®¡
                vx = beta2 * vx + (1 - beta2) * dx**2
                vy = beta2 * vy + (1 - beta2) * dy**2
                
                # åå·®ä¿®æ­£
                mx_hat = mx / (1 - beta1**t)
                my_hat = my / (1 - beta1**t)
                vx_hat = vx / (1 - beta2**t)
                vy_hat = vy / (1 - beta2**t)
                
                # æ›´æ–°å‚æ•°
                x -= learning_rate * mx_hat / (np.sqrt(vx_hat) + epsilon)
                y -= learning_rate * my_hat / (np.sqrt(vy_hat) + epsilon)
                
                trajectory_x.append(x)
                trajectory_y.append(y)
        
        # ç»˜åˆ¶è½¨è¿¹
        ax.plot(trajectory_x, trajectory_y, config['color'], 
                linewidth=2, marker='o', markersize=3, alpha=0.8)
        ax.plot(trajectory_x[0], trajectory_y[0], 'ko', markersize=10, 
                label='èµ·ç‚¹')
        ax.plot(trajectory_x[-1], trajectory_y[-1], 'r*', markersize=15, 
                label='ç»ˆç‚¹')
        
        ax.set_title(f'{opt_name}')
        ax.set_xlabel('å‚æ•° x')
        ax.set_ylabel('å‚æ•° y')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

visualize_optimizers()
```

#### ğŸƒ åŠ¨é‡ï¼ˆMomentumï¼‰ï¼šè®°ä½æ¥æ—¶çš„è·¯

```python
def momentum_intuition():
    """åŠ¨é‡çš„ç›´è§‚ç†è§£"""
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # 1. æ²¡æœ‰åŠ¨é‡ vs æœ‰åŠ¨é‡
    ax = axes[0, 0]
    
    # åˆ›å»ºä¸€ä¸ªæœ‰éœ‡è¡çš„æŸå¤±å‡½æ•°
    x = np.linspace(-2, 2, 1000)
    loss = 0.1 * x**2 + 0.5 * np.sin(10*x)
    gradient = 0.2 * x + 5 * np.cos(10*x)
    
    ax.plot(x, loss, 'b-', linewidth=2, label='æŸå¤±å‡½æ•°')
    ax.set_xlabel('å‚æ•°')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('éœ‡è¡çš„æŸå¤±å‡½æ•°')
    ax.grid(True, alpha=0.3)
    ax.legend()
    
    # 2. SGDçš„è·¯å¾„
    ax = axes[0, 1]
    
    # æ¨¡æ‹ŸSGD
    x_sgd = -1.5
    path_sgd = [x_sgd]
    lr = 0.01
    
    for _ in range(50):
        grad = 0.2 * x_sgd + 5 * np.cos(10 * x_sgd)
        x_sgd -= lr * grad
        path_sgd.append(x_sgd)
    
    ax.plot(x, loss, 'b-', linewidth=1, alpha=0.5)
    ax.plot(path_sgd, [0.1 * p**2 + 0.5 * np.sin(10*p) for p in path_sgd], 
            'ro-', markersize=4, linewidth=1, label='SGDè·¯å¾„')
    ax.set_title('SGDï¼šåœ¨éœ‡è¡ä¸­ç¼“æ…¢å‰è¿›')
    ax.set_xlabel('å‚æ•°')
    ax.set_ylabel('æŸå¤±')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 3. å¸¦åŠ¨é‡çš„SGD
    ax = axes[1, 0]
    
    # æ¨¡æ‹ŸåŠ¨é‡SGD
    x_mom = -1.5
    velocity = 0
    path_mom = [x_mom]
    momentum = 0.9
    
    for _ in range(50):
        grad = 0.2 * x_mom + 5 * np.cos(10 * x_mom)
        velocity = momentum * velocity - lr * grad
        x_mom += velocity
        path_mom.append(x_mom)
    
    ax.plot(x, loss, 'b-', linewidth=1, alpha=0.5)
    ax.plot(path_mom, [0.1 * p**2 + 0.5 * np.sin(10*p) for p in path_mom], 
            'go-', markersize=4, linewidth=1, label='Momentumè·¯å¾„')
    ax.set_title('Momentumï¼šåƒçƒä¸€æ ·æ»šåŠ¨')
    ax.set_xlabel('å‚æ•°')
    ax.set_ylabel('æŸå¤±')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 4. åŠ¨é‡çš„ç‰©ç†ç±»æ¯”
    ax = axes[1, 1]
    
    # ç”»ä¸€ä¸ªæ–œå¡
    slope_x = np.linspace(0, 10, 100)
    slope_y = -0.5 * slope_x + 5 + 0.5 * np.sin(2*slope_x)
    
    ax.plot(slope_x, slope_y, 'k-', linewidth=3)
    ax.fill_between(slope_x, slope_y, -2, alpha=0.3, color='brown')
    
    # ç”»å°çƒçš„è½¨è¿¹
    ball_positions = []
    x_ball = 1
    v_ball = 0
    
    for i in range(30):
        # é‡åŠ›åŠ é€Ÿåº¦ï¼ˆç›¸å½“äºæ¢¯åº¦ï¼‰
        slope_grad = -0.5 + np.cos(2*x_ball)
        v_ball = 0.9 * v_ball + 0.1 * slope_grad
        x_ball += v_ball
        
        if i % 3 == 0:  # æ¯3æ­¥ç”»ä¸€ä¸ªçƒ
            circle = plt.Circle((x_ball, -0.5*x_ball + 5 + 0.5*np.sin(2*x_ball) + 0.3), 
                               0.2, color='red', alpha=0.7)
            ax.add_patch(circle)
    
    ax.set_xlim(0, 10)
    ax.set_ylim(-2, 6)
    ax.set_title('ç‰©ç†ç±»æ¯”ï¼šå°çƒæ»šä¸‹å±±å¡')
    ax.set_xlabel('ä½ç½®')
    ax.set_ylabel('é«˜åº¦')
    ax.text(1, 5.5, 'èµ·ç‚¹', fontsize=12)
    ax.text(8, 1, 'ç›®æ ‡', fontsize=12)
    ax.arrow(5, 4, 1, -0.5, head_width=0.2, head_length=0.1, fc='blue', ec='blue')
    ax.text(5.5, 4.2, 'åŠ¨é‡æ–¹å‘', fontsize=10, color='blue')
    
    plt.suptitle('åŠ¨é‡ï¼ˆMomentumï¼‰çš„ç›´è§‚ç†è§£', fontsize=16)
    plt.tight_layout()
    plt.show()

momentum_intuition()
```

#### ğŸ“Š è‡ªé€‚åº”å­¦ä¹ ç‡ï¼šRMSpropçš„æ™ºæ…§

```python
def adaptive_learning_rate():
    """è‡ªé€‚åº”å­¦ä¹ ç‡çš„å¿…è¦æ€§"""
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # 1. é—®é¢˜å±•ç¤ºï¼šä¸åŒæ–¹å‘çš„æ¢¯åº¦å·®å¼‚å¾ˆå¤§
    ax = axes[0, 0]
    
    # åˆ›å»ºä¸€ä¸ªæ¤­åœ†å½¢çš„æŸå¤±å‡½æ•°
    x = np.linspace(-3, 3, 100)
    y = np.linspace(-3, 3, 100)
    X, Y = np.meshgrid(x, y)
    Z = X**2 + 10*Y**2  # yæ–¹å‘çš„æ›²ç‡æ˜¯xæ–¹å‘çš„10å€
    
    contour = ax.contour(X, Y, Z, levels=20)
    ax.clabel(contour, inline=True, fontsize=8)
    ax.set_title('é—®é¢˜ï¼šæ¤­åœ†å½¢æŸå¤±å‡½æ•°')
    ax.set_xlabel('å‚æ•°1')
    ax.set_ylabel('å‚æ•°2')
    ax.set_aspect('equal')
    
    # 2. å›ºå®šå­¦ä¹ ç‡çš„é—®é¢˜
    ax = axes[0, 1]
    
    # SGD with fixed learning rate
    x_sgd, y_sgd = 2.5, 2.5
    path_x, path_y = [x_sgd], [y_sgd]
    lr = 0.01
    
    for _ in range(50):
        grad_x = 2 * x_sgd
        grad_y = 20 * y_sgd  # yæ–¹å‘æ¢¯åº¦å¤§å¾—å¤š
        x_sgd -= lr * grad_x
        y_sgd -= lr * grad_y
        path_x.append(x_sgd)
        path_y.append(y_sgd)
    
    contour = ax.contour(X, Y, Z, levels=20, alpha=0.3)
    ax.plot(path_x, path_y, 'r.-', linewidth=2, markersize=4)
    ax.set_title('å›ºå®šå­¦ä¹ ç‡ï¼šéœ‡è¡ä¸¥é‡')
    ax.set_xlabel('å‚æ•°1')
    ax.set_ylabel('å‚æ•°2') 
    ax.set_aspect('equal')
    
    # 3. RMSpropçš„è§£å†³æ–¹æ¡ˆ
    ax = axes[0, 2]
    
    # RMSprop
    x_rms, y_rms = 2.5, 2.5
    path_x_rms, path_y_rms = [x_rms], [y_rms]
    s_x, s_y = 0, 0
    decay_rate = 0.9
    epsilon = 1e-8
    
    for _ in range(50):
        grad_x = 2 * x_rms
        grad_y = 20 * y_rms
        
        # ç´¯ç§¯æ¢¯åº¦å¹³æ–¹
        s_x = decay_rate * s_x + (1 - decay_rate) * grad_x**2
        s_y = decay_rate * s_y + (1 - decay_rate) * grad_y**2
        
        # è‡ªé€‚åº”å­¦ä¹ ç‡
        x_rms -= lr * grad_x / (np.sqrt(s_x) + epsilon)
        y_rms -= lr * grad_y / (np.sqrt(s_y) + epsilon)
        
        path_x_rms.append(x_rms)
        path_y_rms.append(y_rms)
    
    contour = ax.contour(X, Y, Z, levels=20, alpha=0.3)
    ax.plot(path_x_rms, path_y_rms, 'g.-', linewidth=2, markersize=4)
    ax.set_title('RMSpropï¼šå¹³æ»‘æ”¶æ•›')
    ax.set_xlabel('å‚æ•°1')
    ax.set_ylabel('å‚æ•°2')
    ax.set_aspect('equal')
    
    # 4. æ¢¯åº¦ç´¯ç§¯çš„å¯è§†åŒ–
    ax = axes[1, 0]
    
    steps = np.arange(50)
    grad_history = 1 + 0.5 * np.sin(steps/2)  # æ¨¡æ‹Ÿå˜åŒ–çš„æ¢¯åº¦
    
    # è®¡ç®—ç´¯ç§¯å¹³æ–¹æ¢¯åº¦
    accumulated = []
    s = 0
    for g in grad_history:
        s = 0.9 * s + 0.1 * g**2
        accumulated.append(np.sqrt(s))
    
    ax.plot(steps, grad_history, 'b-', label='å³æ—¶æ¢¯åº¦', alpha=0.5)
    ax.plot(steps, accumulated, 'r-', linewidth=2, label='ç´¯ç§¯æ¢¯åº¦(RMS)')
    ax.fill_between(steps, 0, accumulated, alpha=0.3, color='red')
    ax.set_xlabel('è®­ç»ƒæ­¥æ•°')
    ax.set_ylabel('æ¢¯åº¦å¤§å°')
    ax.set_title('RMSpropçš„æ¢¯åº¦ç´¯ç§¯')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 5. å­¦ä¹ ç‡çš„è‡ªé€‚åº”è°ƒæ•´
    ax = axes[1, 1]
    
    # ä¸åŒå‚æ•°çš„å­¦ä¹ ç‡å˜åŒ–
    param_names = ['å‚æ•°1\n(æ¢¯åº¦å°)', 'å‚æ•°2\n(æ¢¯åº¦å¤§)', 'å‚æ•°3\n(æ¢¯åº¦æ³¢åŠ¨)']
    base_lr = 0.01
    
    # æ¨¡æ‹Ÿä¸åŒçš„æ¢¯åº¦æ¨¡å¼
    grad_patterns = [
        np.ones(50) * 0.1,  # å°è€Œç¨³å®š
        np.ones(50) * 2.0,  # å¤§è€Œç¨³å®š
        0.5 + 1.5 * np.sin(np.arange(50)/3)  # æ³¢åŠ¨
    ]
    
    x_pos = np.arange(len(param_names))
    effective_lrs = []
    
    for pattern in grad_patterns:
        s = 0
        avg_lr = 0
        for g in pattern:
            s = 0.9 * s + 0.1 * g**2
            avg_lr += base_lr / (np.sqrt(s) + 1e-8)
        effective_lrs.append(avg_lr / len(pattern))
    
    bars = ax.bar(x_pos, effective_lrs, color=['green', 'red', 'blue'], alpha=0.7)
    ax.set_xticks(x_pos)
    ax.set_xticklabels(param_names)
    ax.set_ylabel('å¹³å‡æœ‰æ•ˆå­¦ä¹ ç‡')
    ax.set_title('ä¸åŒå‚æ•°çš„è‡ªé€‚åº”å­¦ä¹ ç‡')
    ax.axhline(y=base_lr, color='black', linestyle='--', label=f'åŸºç¡€å­¦ä¹ ç‡={base_lr}')
    ax.legend()
    
    # 6. RMSprop vs SGD æ€§èƒ½å¯¹æ¯”
    ax = axes[1, 2]
    
    # åœ¨ä¸åŒæ¡ä»¶ä¸‹æ¯”è¾ƒæ”¶æ•›é€Ÿåº¦
    conditions = ['å‡åŒ€æ¢¯åº¦', 'ä¸å‡åŒ€æ¢¯åº¦', 'å™ªå£°æ¢¯åº¦']
    sgd_steps = [50, 150, 200]
    rmsprop_steps = [30, 50, 80]
    
    x_pos = np.arange(len(conditions))
    width = 0.35
    
    bars1 = ax.bar(x_pos - width/2, sgd_steps, width, label='SGD', color='red', alpha=0.7)
    bars2 = ax.bar(x_pos + width/2, rmsprop_steps, width, label='RMSprop', color='green', alpha=0.7)
    
    ax.set_xlabel('æ¡ä»¶')
    ax.set_ylabel('æ”¶æ•›æ‰€éœ€æ­¥æ•°')
    ax.set_title('æ”¶æ•›é€Ÿåº¦å¯¹æ¯”')
    ax.set_xticks(x_pos)
    ax.set_xticklabels(conditions)
    ax.legend()
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{int(height)}', ha='center', va='bottom')
    
    plt.suptitle('è‡ªé€‚åº”å­¦ä¹ ç‡ï¼šRMSpropçš„åŸç†', fontsize=16)
    plt.tight_layout()
    plt.show()

adaptive_learning_rate()
```

#### ğŸ‘‘ Adamï¼šé›†å¤§æˆè€…

Adam (Adaptive Moment Estimation) ç»“åˆäº†åŠ¨é‡å’Œè‡ªé€‚åº”å­¦ä¹ ç‡çš„ä¼˜ç‚¹ï¼š

```python
def adam_deep_dive():
    """æ·±å…¥ç†è§£Adamä¼˜åŒ–å™¨"""
    
    # Adamçš„æ ¸å¿ƒæ€æƒ³å¯è§†åŒ–
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # 1. Adamçš„ä¸‰ä¸ªç»„æˆéƒ¨åˆ†
    ax = axes[0, 0]
    
    # ç”¨éŸ¦æ©å›¾å±•ç¤º
    from matplotlib.patches import Circle
    
    # åˆ›å»ºä¸‰ä¸ªåœ†
    circle1 = Circle((0.35, 0.7), 0.3, alpha=0.5, color='blue', label='æ¢¯åº¦')
    circle2 = Circle((0.65, 0.7), 0.3, alpha=0.5, color='green', label='åŠ¨é‡')
    circle3 = Circle((0.5, 0.4), 0.3, alpha=0.5, color='red', label='è‡ªé€‚åº”LR')
    
    ax.add_patch(circle1)
    ax.add_patch(circle2)
    ax.add_patch(circle3)
    
    ax.text(0.5, 0.55, 'Adam', fontsize=16, ha='center', weight='bold')
    ax.text(0.2, 0.85, 'æ¢¯åº¦', fontsize=12, ha='center')
    ax.text(0.8, 0.85, 'åŠ¨é‡', fontsize=12, ha='center')
    ax.text(0.5, 0.15, 'è‡ªé€‚åº”', fontsize=12, ha='center')
    
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.set_aspect('equal')
    ax.axis('off')
    ax.set_title('Adam = æ¢¯åº¦ + åŠ¨é‡ + è‡ªé€‚åº”')
    
    # 2. ä¸€é˜¶çŸ©å’ŒäºŒé˜¶çŸ©
    ax = axes[0, 1]
    
    # æ¨¡æ‹Ÿæ¢¯åº¦åºåˆ—
    t = np.arange(100)
    gradient = 2 * np.sin(t/10) + 0.5 * np.random.randn(100)
    
    # è®¡ç®—ä¸€é˜¶çŸ©ï¼ˆåŠ¨é‡ï¼‰
    beta1 = 0.9
    m = np.zeros_like(gradient)
    for i in range(1, len(gradient)):
        m[i] = beta1 * m[i-1] + (1-beta1) * gradient[i]
    
    # è®¡ç®—äºŒé˜¶çŸ©ï¼ˆæ¢¯åº¦å¹³æ–¹çš„ç§»åŠ¨å¹³å‡ï¼‰
    beta2 = 0.999
    v = np.zeros_like(gradient)
    for i in range(1, len(gradient)):
        v[i] = beta2 * v[i-1] + (1-beta2) * gradient[i]**2
    
    ax.plot(t, gradient, 'b-', alpha=0.5, linewidth=1, label='åŸå§‹æ¢¯åº¦')
    ax.plot(t, m, 'g-', linewidth=2, label='ä¸€é˜¶çŸ© (åŠ¨é‡)')
    ax.plot(t, np.sqrt(v), 'r-', linewidth=2, label='äºŒé˜¶çŸ© (RMS)')
    ax.set_xlabel('æ­¥æ•°')
    ax.set_ylabel('å€¼')
    ax.set_title('Adamçš„çŸ©ä¼°è®¡')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 3. åå·®ä¿®æ­£çš„é‡è¦æ€§
    ax = axes[0, 2]
    
    # å±•ç¤ºåå·®ä¿®æ­£çš„æ•ˆæœ
    steps = np.arange(1, 21)
    beta = 0.9
    
    # æœªä¿®æ­£çš„ä¼°è®¡
    biased = 1 - beta**steps
    
    # ä¿®æ­£å› å­
    correction = 1 / (1 - beta**steps)
    
    ax.plot(steps, biased, 'r-', linewidth=2, marker='o', 
            label='æœªä¿®æ­£ä¼°è®¡', markersize=5)
    ax.plot(steps, np.ones_like(steps), 'g--', linewidth=2, 
            label='çœŸå®å€¼')
    ax.fill_between(steps, biased, 1, alpha=0.3, color='red')
    
    ax.set_xlabel('æ­¥æ•°')
    ax.set_ylabel('ä¼°è®¡åå·®')
    ax.set_title(f'åå·®ä¿®æ­£ (Î²={beta})')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.text(10, 0.5, 'æ—©æœŸæ­¥éª¤\nåå·®å¾ˆå¤§!', fontsize=10, 
            ha='center', bbox=dict(boxstyle="round,pad=0.3", 
                                 facecolor="yellow", alpha=0.7))
    
    # 4. Adam vs å…¶ä»–ä¼˜åŒ–å™¨çš„è½¨è¿¹
    ax = axes[1, 0]
    
    # åˆ›å»ºRosenbrockå‡½æ•°ï¼ˆè‘—åçš„ä¼˜åŒ–æµ‹è¯•å‡½æ•°ï¼‰
    def rosenbrock(x, y):
        return (1-x)**2 + 100*(y-x**2)**2
    
    x_range = np.linspace(-2, 2, 100)
    y_range = np.linspace(-1, 3, 100)
    X, Y = np.meshgrid(x_range, y_range)
    Z = rosenbrock(X, Y)
    
    # ç»˜åˆ¶ç­‰é«˜çº¿
    levels = np.logspace(-1, 3, 20)
    contour = ax.contour(X, Y, Z, levels=levels, alpha=0.6)
    
    # è¿è¡Œä¸åŒä¼˜åŒ–å™¨
    optimizers_paths = {}
    start_point = (-1.5, 2.5)
    
    # Adamè·¯å¾„
    x, y = start_point
    path = [(x, y)]
    m_x, m_y = 0, 0
    v_x, v_y = 0, 0
    lr = 0.01
    
    for t in range(1, 300):
        # è®¡ç®—æ¢¯åº¦
        dx = -2*(1-x) - 400*x*(y-x**2)
        dy = 200*(y-x**2)
        
        # Adamæ›´æ–°
        m_x = 0.9*m_x + 0.1*dx
        m_y = 0.9*m_y + 0.1*dy
        v_x = 0.999*v_x + 0.001*dx**2
        v_y = 0.999*v_y + 0.001*dy**2
        
        # åå·®ä¿®æ­£
        m_x_hat = m_x / (1 - 0.9**t)
        m_y_hat = m_y / (1 - 0.9**t)
        v_x_hat = v_x / (1 - 0.999**t)
        v_y_hat = v_y / (1 - 0.999**t)
        
        # æ›´æ–°
        x -= lr * m_x_hat / (np.sqrt(v_x_hat) + 1e-8)
        y -= lr * m_y_hat / (np.sqrt(v_y_hat) + 1e-8)
        
        if t % 5 == 0:
            path.append((x, y))
    
    path = np.array(path)
    ax.plot(path[:, 0], path[:, 1], 'purple', linewidth=3, 
            marker='o', markersize=4, label='Adam', alpha=0.8)
    
    ax.plot(1, 1, 'r*', markersize=20, label='æœ€ä¼˜ç‚¹')
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    ax.set_title('Rosenbrockå‡½æ•°ä¼˜åŒ–')
    ax.legend()
    ax.set_xlim(-2, 2)
    ax.set_ylim(-1, 3)
    
    # 5. å­¦ä¹ ç‡è°ƒåº¦ä¸Adam
    ax = axes[1, 1]
    
    epochs = np.arange(100)
    
    # ä¸åŒçš„å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥
    constant_lr = np.ones_like(epochs) * 0.001
    exponential_lr = 0.001 * 0.95**epochs
    cosine_lr = 0.001 * 0.5 * (1 + np.cos(np.pi * epochs / 100))
    warmup_lr = np.where(epochs < 10, 
                        0.001 * epochs / 10,
                        0.001)
    
    ax.plot(epochs, constant_lr, 'b-', linewidth=2, label='å¸¸æ•°')
    ax.plot(epochs, exponential_lr, 'g-', linewidth=2, label='æŒ‡æ•°è¡°å‡')
    ax.plot(epochs, cosine_lr, 'r-', linewidth=2, label='ä½™å¼¦é€€ç«')
    ax.plot(epochs, warmup_lr, 'purple', linewidth=2, label='é¢„çƒ­')
    
    ax.set_xlabel('è®­ç»ƒè½®æ¬¡')
    ax.set_ylabel('å­¦ä¹ ç‡')
    ax.set_title('Adam + å­¦ä¹ ç‡è°ƒåº¦')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_yscale('log')
    
    # 6. Adamçš„è¶…å‚æ•°æ•æ„Ÿæ€§
    ax = axes[1, 2]
    
    # æµ‹è¯•ä¸åŒçš„betaå€¼
    beta1_values = [0.5, 0.9, 0.95, 0.99]
    colors = plt.cm.viridis(np.linspace(0, 1, len(beta1_values)))
    
    for beta1, color in zip(beta1_values, colors):
        # æ¨¡æ‹Ÿæ”¶æ•›æ›²çº¿
        loss = []
        L = 10  # åˆå§‹æŸå¤±
        
        for t in range(50):
            # ç®€åŒ–çš„æ”¶æ•›æ¨¡æ‹Ÿ
            L *= (0.95 - 0.05 * (1-beta1))
            loss.append(L)
        
        ax.plot(loss, color=color, linewidth=2, 
                label=f'Î²â‚={beta1}')
    
    ax.set_xlabel('è¿­ä»£æ¬¡æ•°')
    ax.set_ylabel('æŸå¤± (å¯¹æ•°)')
    ax.set_title('Î²â‚å‚æ•°çš„å½±å“')
    ax.set_yscale('log')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.suptitle('Adamä¼˜åŒ–å™¨æ·±åº¦è§£æ', fontsize=16)
    plt.tight_layout()
    plt.show()

adam_deep_dive()
```

#### ğŸ”¬ Adamä¸ºä»€ä¹ˆè¿™ä¹ˆæµè¡Œï¼Ÿ

```python
def why_adam_popular():
    """è§£é‡ŠAdamæµè¡Œçš„åŸå› """
    
    print("ğŸŒŸ Adamä¼˜åŒ–å™¨çš„ä¼˜åŠ¿åˆ†æ\n")
    
    # åˆ›å»ºä¸€ä¸ªå¯¹æ¯”å®éªŒ
    fig, axes = plt.subplots(3, 2, figsize=(12, 14))
    
    # 1. å¯¹ä¸åŒé—®é¢˜çš„é€‚åº”æ€§
    ax = axes[0, 0]
    
    problems = ['ç¨€ç–æ¢¯åº¦', 'å™ªå£°æ¢¯åº¦', 'ä¸åŒå°ºåº¦', 'éç‚¹']
    optimizers = ['SGD', 'Momentum', 'RMSprop', 'Adam']
    
    # æ€§èƒ½è¯„åˆ†ï¼ˆ1-5ï¼‰
    performance = np.array([
        [2, 2, 3, 3],  # SGD
        [3, 3, 3, 4],  # Momentum
        [4, 4, 4, 3],  # RMSprop
        [5, 5, 5, 5],  # Adam
    ])
    
    im = ax.imshow(performance, cmap='RdYlGn', vmin=1, vmax=5)
    
    # è®¾ç½®æ ‡ç­¾
    ax.set_xticks(np.arange(len(problems)))
    ax.set_yticks(np.arange(len(optimizers)))
    ax.set_xticklabels(problems)
    ax.set_yticklabels(optimizers)
    
    # æ·»åŠ æ•°å€¼
    for i in range(len(optimizers)):
        for j in range(len(problems)):
            text = ax.text(j, i, performance[i, j],
                         ha="center", va="center", color="black")
    
    ax.set_title('é—®é¢˜é€‚åº”æ€§è¯„åˆ†')
    plt.colorbar(im, ax=ax)
    
    # 2. è¶…å‚æ•°é²æ£’æ€§
    ax = axes[0, 1]
    
    # ä¸åŒå­¦ä¹ ç‡ä¸‹çš„è¡¨ç°
    learning_rates = np.logspace(-4, -1, 20)
    
    # æ¨¡æ‹Ÿä¸åŒä¼˜åŒ–å™¨çš„æ€§èƒ½
    sgd_perf = np.exp(-((np.log10(learning_rates) + 2.5)**2))
    adam_perf = 0.9 - 0.1 * np.abs(np.log10(learning_rates) + 2.5)
    
    ax.plot(learning_rates, sgd_perf, 'b-', linewidth=2, label='SGD')
    ax.plot(learning_rates, adam_perf, 'purple', linewidth=2, label='Adam')
    ax.fill_between(learning_rates, sgd_perf, alpha=0.3, color='blue')
    ax.fill_between(learning_rates, adam_perf, alpha=0.3, color='purple')
    
    ax.set_xscale('log')
    ax.set_xlabel('å­¦ä¹ ç‡')
    ax.set_ylabel('æ€§èƒ½')
    ax.set_title('è¶…å‚æ•°é²æ£’æ€§')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.axvline(x=0.001, color='red', linestyle='--', alpha=0.5)
    ax.text(0.001, 0.5, 'Adamé»˜è®¤å€¼', rotation=90, va='bottom')
    
    # 3. æ”¶æ•›é€Ÿåº¦å¯¹æ¯”
    ax = axes[1, 0]
    
    epochs = np.arange(100)
    
    # æ¨¡æ‹ŸæŸå¤±æ›²çº¿
    sgd_loss = 10 * np.exp(-epochs/50) + 0.5 * np.sin(epochs/5)
    momentum_loss = 10 * np.exp(-epochs/30) + 0.3 * np.sin(epochs/5)
    adam_loss = 10 * np.exp(-epochs/20) + 0.1 * np.sin(epochs/5)
    
    ax.plot(epochs, sgd_loss, 'b-', linewidth=2, label='SGD')
    ax.plot(epochs, momentum_loss, 'g-', linewidth=2, label='Momentum')
    ax.plot(epochs, adam_loss, 'purple', linewidth=2, label='Adam')
    
    ax.set_xlabel('è®­ç»ƒè½®æ¬¡')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('æ”¶æ•›é€Ÿåº¦å¯¹æ¯”')
    ax.set_yscale('log')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 4. å†…å­˜ä½¿ç”¨
    ax = axes[1, 1]
    
    optimizers = ['SGD', 'Momentum', 'RMSprop', 'Adam', 'AdamW']
    memory_usage = [1, 2, 2, 3, 3]  # ç›¸å¯¹å†…å­˜ä½¿ç”¨
    colors = ['blue', 'green', 'orange', 'purple', 'red']
    
    bars = ax.bar(optimizers, memory_usage, color=colors, alpha=0.7)
    ax.set_ylabel('ç›¸å¯¹å†…å­˜ä½¿ç”¨')
    ax.set_title('å†…å­˜å¼€é”€å¯¹æ¯”')
    ax.axhline(y=1, color='black', linestyle='--', alpha=0.3)
    
    for bar, mem in zip(bars, memory_usage):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.05,
               f'{mem}x', ha='center', va='bottom')
    
    # 5. å®é™…åº”ç”¨ç»Ÿè®¡
    ax = axes[2, 0]
    
    # æ¨¡æ‹Ÿçš„ä½¿ç”¨ç»Ÿè®¡
    applications = ['CVè®ºæ–‡', 'NLPè®ºæ–‡', 'å·¥ä¸šç•Œ', 'Kaggle']
    adam_usage = [75, 85, 80, 70]
    sgd_usage = [20, 10, 15, 20]
    other_usage = [5, 5, 5, 10]
    
    width = 0.5
    x = np.arange(len(applications))
    
    p1 = ax.bar(x, adam_usage, width, label='Adam', color='purple', alpha=0.8)
    p2 = ax.bar(x, sgd_usage, width, bottom=adam_usage, label='SGD', color='blue', alpha=0.8)
    p3 = ax.bar(x, other_usage, width, bottom=np.array(adam_usage)+np.array(sgd_usage), 
                label='å…¶ä»–', color='gray', alpha=0.8)
    
    ax.set_ylabel('ä½¿ç”¨æ¯”ä¾‹ (%)')
    ax.set_title('ä¼˜åŒ–å™¨ä½¿ç”¨ç»Ÿè®¡')
    ax.set_xticks(x)
    ax.set_xticklabels(applications)
    ax.legend()
    
    # 6. Adamçš„å˜ä½“
    ax = axes[2, 1]
    
    variants = ['Adam', 'AdamW', 'RAdam', 'NAdam', 'AdaBound']
    years = [2014, 2017, 2019, 2021, 2018]
    improvements = [0, 5, 8, 10, 6]  # ç›¸å¯¹æ”¹è¿›
    
    scatter = ax.scatter(years, improvements, s=200, c=range(len(variants)), 
                        cmap='viridis', alpha=0.7)
    
    for i, (year, imp, var) in enumerate(zip(years, improvements, variants)):
        ax.annotate(var, (year, imp), xytext=(5, 5), 
                   textcoords='offset points', fontsize=10)
    
    ax.set_xlabel('å‘å¸ƒå¹´ä»½')
    ax.set_ylabel('ç›¸å¯¹æ”¹è¿› (%)')
    ax.set_title('Adamå˜ä½“å‘å±•')
    ax.grid(True, alpha=0.3)
    
    plt.suptitle('Adamä¸ºä»€ä¹ˆè¿™ä¹ˆæµè¡Œï¼Ÿ', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    # æ‰“å°æ€»ç»“
    print("\nğŸ“Š Adamæµè¡Œçš„å…³é”®åŸå› ï¼š\n")
    print("1. âœ… è¶…å‚æ•°é²æ£’æ€§ï¼šé»˜è®¤å‚æ•°é€‚ç”¨äºå¤§å¤šæ•°æƒ…å†µ")
    print("2. âœ… è‡ªé€‚åº”æ€§ï¼šè‡ªåŠ¨è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ ç‡")
    print("3. âœ… å¿«é€Ÿæ”¶æ•›ï¼šç»“åˆäº†åŠ¨é‡å’Œè‡ªé€‚åº”å­¦ä¹ ç‡")
    print("4. âœ… ç¨€ç–æ¢¯åº¦å‹å¥½ï¼šé€‚åˆNLPç­‰ç¨€ç–ç‰¹å¾åœºæ™¯")
    print("5. âœ… å®ç°ç®€å•ï¼šä»£ç æ¸…æ™°ï¼Œæ˜“äºç†è§£å’Œè°ƒè¯•")
    print("6. âœ… å¹¿æ³›éªŒè¯ï¼šåœ¨å„ç§ä»»åŠ¡ä¸Šéƒ½è¡¨ç°è‰¯å¥½")

why_adam_popular()
```

#### ğŸ’» å®æˆ˜ï¼šå®ç°ä¸€ä¸ªè¿·ä½ Adam

```python
class MiniAdam:
    """ä¸€ä¸ªç®€åŒ–ç‰ˆçš„Adamä¼˜åŒ–å™¨å®ç°"""
    
    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-8):
        self.params = params
        self.lr = lr
        self.beta1, self.beta2 = betas
        self.eps = eps
        self.t = 0
        
        # åˆå§‹åŒ–ä¸€é˜¶å’ŒäºŒé˜¶çŸ©
        self.m = {id(p): np.zeros_like(p) for p in params}
        self.v = {id(p): np.zeros_like(p) for p in params}
    
    def step(self, grads):
        """æ‰§è¡Œä¸€æ­¥å‚æ•°æ›´æ–°"""
        self.t += 1
        
        for param, grad in zip(self.params, grads):
            param_id = id(param)
            
            # æ›´æ–°åå·®ä¿®æ­£çš„ä¸€é˜¶çŸ©ä¼°è®¡
            self.m[param_id] = self.beta1 * self.m[param_id] + (1 - self.beta1) * grad
            
            # æ›´æ–°åå·®ä¿®æ­£çš„äºŒé˜¶çŸ©ä¼°è®¡
            self.v[param_id] = self.beta2 * self.v[param_id] + (1 - self.beta2) * grad**2
            
            # åå·®ä¿®æ­£
            m_hat = self.m[param_id] / (1 - self.beta1**self.t)
            v_hat = self.v[param_id] / (1 - self.beta2**self.t)
            
            # æ›´æ–°å‚æ•°
            param -= self.lr * m_hat / (np.sqrt(v_hat) + self.eps)
        
        return self.params

# æµ‹è¯•æˆ‘ä»¬çš„Adamå®ç°
def test_mini_adam():
    """æµ‹è¯•è¿·ä½ Adamä¼˜åŒ–å™¨"""
    
    print("ğŸ§ª æµ‹è¯•è‡ªåˆ¶Adamä¼˜åŒ–å™¨\n")
    
    # å®šä¹‰ä¸€ä¸ªç®€å•çš„äºŒæ¬¡å‡½æ•°
    def quadratic(x, y):
        return x**2 + 4*y**2
    
    def gradient(x, y):
        return 2*x, 8*y
    
    # åˆå§‹åŒ–å‚æ•°
    x, y = 2.0, 2.0
    params = [np.array([x]), np.array([y])]
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = MiniAdam(params, lr=0.1)
    
    # è®°å½•è½¨è¿¹
    trajectory = [(x, y)]
    losses = [quadratic(x, y)]
    
    # ä¼˜åŒ–è¿‡ç¨‹
    for i in range(50):
        # è®¡ç®—æ¢¯åº¦
        grad_x, grad_y = gradient(params[0][0], params[1][0])
        grads = [np.array([grad_x]), np.array([grad_y])]
        
        # æ›´æ–°å‚æ•°
        params = optimizer.step(grads)
        
        # è®°å½•
        x, y = params[0][0], params[1][0]
        trajectory.append((x, y))
        losses.append(quadratic(x, y))
        
        if i % 10 == 0:
            print(f"Step {i}: x={x:.4f}, y={y:.4f}, loss={losses[-1]:.4f}")
    
    # å¯è§†åŒ–
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # ä¼˜åŒ–è½¨è¿¹
    trajectory = np.array(trajectory)
    
    # ç»˜åˆ¶ç­‰é«˜çº¿
    x_range = np.linspace(-2.5, 2.5, 100)
    y_range = np.linspace(-2.5, 2.5, 100)
    X, Y = np.meshgrid(x_range, y_range)
    Z = X**2 + 4*Y**2
    
    contour = ax1.contour(X, Y, Z, levels=20, alpha=0.6)
    ax1.plot(trajectory[:, 0], trajectory[:, 1], 'ro-', 
             linewidth=2, markersize=4, label='ä¼˜åŒ–è·¯å¾„')
    ax1.plot(0, 0, 'g*', markersize=15, label='æœ€ä¼˜ç‚¹')
    ax1.set_xlabel('x')
    ax1.set_ylabel('y')
    ax1.set_title('Adamä¼˜åŒ–è½¨è¿¹')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # æŸå¤±æ›²çº¿
    ax2.plot(losses, 'b-', linewidth=2)
    ax2.set_xlabel('è¿­ä»£æ¬¡æ•°')
    ax2.set_ylabel('æŸå¤±å€¼')
    ax2.set_title('æŸå¤±ä¸‹é™æ›²çº¿')
    ax2.set_yscale('log')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

test_mini_adam()
```

#### ğŸ¯ Adamçš„æœ€ä½³å®è·µ

```python
def adam_best_practices():
    """Adamä½¿ç”¨çš„æœ€ä½³å®è·µ"""
    
    print("ğŸ“ Adamä¼˜åŒ–å™¨æœ€ä½³å®è·µæŒ‡å—\n")
    
    practices = {
        "1. å­¦ä¹ ç‡é€‰æ‹©": {
            "é»˜è®¤å€¼": "0.001 (1e-3)",
            "Transformer": "~5e-4",
            "CNN": "~1e-3",
            "Fine-tuning": "~1e-5",
            "æç¤º": "å½“lossä¸ä¸‹é™æ—¶ï¼Œé¦–å…ˆå°è¯•é™ä½å­¦ä¹ ç‡"
        },
        
        "2. Betaå‚æ•°": {
            "é»˜è®¤å€¼": "Î²1=0.9, Î²2=0.999",
            "å¿«é€Ÿé€‚åº”": "Î²1=0.8",
            "ç¨³å®šè®­ç»ƒ": "Î²2=0.9999",
            "æç¤º": "ä¸€èˆ¬ä¸éœ€è¦è°ƒæ•´ï¼Œé™¤éæœ‰ç‰¹æ®Šéœ€æ±‚"
        },
        
        "3. Epsilon": {
            "é»˜è®¤å€¼": "1e-8",
            "åŠç²¾åº¦è®­ç»ƒ": "1e-4",
            "æ•°å€¼ç¨³å®š": "1e-7",
            "æç¤º": "å¤ªå°å¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®š"
        },
        
        "4. æƒé‡è¡°å‡": {
            "æ ‡å‡†Adam": "åœ¨æŸå¤±å‡½æ•°ä¸­åŠ L2æ­£åˆ™",
            "AdamW": "è§£è€¦æƒé‡è¡°å‡",
            "æ¨èå€¼": "0.01 ~ 0.1",
            "æç¤º": "AdamWé€šå¸¸æ¯”æ ‡å‡†Adam+L2æ›´å¥½"
        },
        
        "5. å­¦ä¹ ç‡è°ƒåº¦": {
            "é¢„çƒ­": "å‰5-10%æ­¥æ•°çº¿æ€§å¢é•¿",
            "è¡°å‡": "ä½™å¼¦é€€ç«æˆ–æŒ‡æ•°è¡°å‡",
            "é‡å¯": "SGDR (å‘¨æœŸæ€§é‡å¯)",
            "æç¤º": "å¤§æ¨¡å‹è®­ç»ƒå¿…é¡»ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦"
        },
        
        "6. æ¢¯åº¦è£å‰ª": {
            "ç›®çš„": "é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸",
            "èŒƒå›´": "é€šå¸¸1.0~5.0",
            "æ–¹å¼": "æŒ‰èŒƒæ•°è£å‰ª",
            "æç¤º": "RNN/Transformerç»å¸¸éœ€è¦"
        }
    }
    
    # å¯è§†åŒ–æœ€ä½³å®è·µ
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.ravel()
    
    for idx, (practice, details) in enumerate(practices.items()):
        ax = axes[idx]
        ax.text(0.5, 0.9, practice, fontsize=14, weight='bold',
               ha='center', transform=ax.transAxes)
        
        y_pos = 0.7
        for key, value in details.items():
            if key != "æç¤º":
                ax.text(0.1, y_pos, f"{key}:", fontsize=10, weight='bold',
                       transform=ax.transAxes)
                ax.text(0.1, y_pos-0.08, f"  {value}", fontsize=9,
                       transform=ax.transAxes, wrap=True)
                y_pos -= 0.15
        
        # æ·»åŠ æç¤ºæ¡†
        if "æç¤º" in details:
            ax.text(0.5, 0.05, f"ğŸ’¡ {details['æç¤º']}", fontsize=9,
                   ha='center', transform=ax.transAxes,
                   bbox=dict(boxstyle="round,pad=0.3", 
                           facecolor="yellow", alpha=0.7))
        
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)
        ax.axis('off')
    
    plt.suptitle('Adamä¼˜åŒ–å™¨æœ€ä½³å®è·µ', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    # ä»£ç ç¤ºä¾‹
    print("\nğŸ“‹ å®é™…ä½¿ç”¨ç¤ºä¾‹ï¼š")
    print("\n```python")
    print("# PyTorchä¸­çš„Adamä½¿ç”¨")
    print("import torch.optim as optim")
    print()
    print("# åŸºç¡€ç”¨æ³•")
    print("optimizer = optim.Adam(model.parameters(), lr=1e-3)")
    print()
    print("# è¿›é˜¶ç”¨æ³•")
    print("optimizer = optim.AdamW(")
    print("    model.parameters(),")
    print("    lr=5e-4,")
    print("    betas=(0.9, 0.999),")
    print("    eps=1e-8,")
    print("    weight_decay=0.01")
    print(")")
    print()
    print("# å¸¦å­¦ä¹ ç‡è°ƒåº¦")
    print("scheduler = optim.lr_scheduler.CosineAnnealingLR(")
    print("    optimizer, T_max=num_epochs")
    print(")")
    print()
    print("# è®­ç»ƒå¾ªç¯")
    print("for epoch in range(num_epochs):")
    print("    for batch in dataloader:")
    print("        optimizer.zero_grad()")
    print("        loss = model(batch)")
    print("        loss.backward()")
    print("        ")
    print("        # æ¢¯åº¦è£å‰ª")
    print("        torch.nn.utils.clip_grad_norm_(")
    print("            model.parameters(), max_norm=1.0")
    print("        )")
    print("        ")
    print("        optimizer.step()")
    print("    ")
    print("    scheduler.step()")
    print("```")

adam_best_practices()
```

#### ğŸ” Adamçš„é—®é¢˜ä¸æ”¹è¿›

```python
def adam_limitations():
    """Adamçš„å±€é™æ€§å’Œæ”¹è¿›æ–¹æ¡ˆ"""
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # 1. æ³›åŒ–èƒ½åŠ›é—®é¢˜
    ax = axes[0, 0]
    
    epochs = np.arange(100)
    
    # æ¨¡æ‹Ÿè®­ç»ƒå’ŒéªŒè¯æŸå¤±
    sgd_train = 2 * np.exp(-epochs/30) + 0.1
    sgd_val = 2 * np.exp(-epochs/30) + 0.15 + 0.05 * np.sqrt(epochs/100)
    
    adam_train = 2 * np.exp(-epochs/20) + 0.05
    adam_val = 2 * np.exp(-epochs/20) + 0.1 + 0.1 * np.sqrt(epochs/100)
    
    ax.plot(epochs, sgd_train, 'b-', linewidth=2, label='SGDè®­ç»ƒ')
    ax.plot(epochs, sgd_val, 'b--', linewidth=2, label='SGDéªŒè¯')
    ax.plot(epochs, adam_train, 'r-', linewidth=2, label='Adamè®­ç»ƒ')
    ax.plot(epochs, adam_val, 'r--', linewidth=2, label='AdaméªŒè¯')
    
    ax.set_xlabel('è®­ç»ƒè½®æ¬¡')
    ax.set_ylabel('æŸå¤±')
    ax.set_title('é—®é¢˜1ï¼šæ³›åŒ–å·®è·')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.text(50, 0.5, 'Adamè¿‡æ‹Ÿåˆ\næ›´ä¸¥é‡', fontsize=10,
           bbox=dict(boxstyle="round,pad=0.3", 
                   facecolor="red", alpha=0.3))
    
    # 2. äºŒé˜¶çŸ©åå·®
    ax = axes[0, 1]
    
    # æ¨¡æ‹Ÿç¨€ç–æ¢¯åº¦æƒ…å†µ
    steps = np.arange(100)
    sparse_grad = np.zeros(100)
    sparse_grad[::10] = np.random.randn(10) * 5  # ç¨€ç–å¤§æ¢¯åº¦
    
    # è®¡ç®—äºŒé˜¶çŸ©ä¼°è®¡
    v = np.zeros_like(sparse_grad)
    beta2 = 0.999
    for i in range(1, len(sparse_grad)):
        v[i] = beta2 * v[i-1] + (1-beta2) * sparse_grad[i]**2
    
    ax.stem(steps, sparse_grad, 'b-', label='ç¨€ç–æ¢¯åº¦', basefmt=' ')
    ax.plot(steps, np.sqrt(v), 'r-', linewidth=2, label='äºŒé˜¶çŸ©ä¼°è®¡')
    ax.set_xlabel('æ­¥æ•°')
    ax.set_ylabel('å€¼')
    ax.set_title('é—®é¢˜2ï¼šç¨€ç–æ›´æ–°æ—¶çš„åå·®')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 3. æ”¹è¿›æ–¹æ¡ˆå¯¹æ¯”ï¼ˆä½¿ç”¨æ¡å½¢å›¾ä»£æ›¿é›·è¾¾å›¾ï¼‰
    ax = axes[1, 0]
    
    methods = ['Adam', 'AdamW', 'RAdam', 'NAdam', 'AdaBound']
    improvements = {
        'æ”¶æ•›é€Ÿåº¦': [4, 4, 4.5, 5, 4],
        'æ³›åŒ–èƒ½åŠ›': [3, 4.5, 4, 4, 4.5],
        'ç¨³å®šæ€§': [3.5, 4, 5, 4.5, 4.5],
        'æ˜“ç”¨æ€§': [5, 5, 4, 4, 3.5]
    }
    
    # ä½¿ç”¨åˆ†ç»„æ¡å½¢å›¾
    categories = list(improvements.keys())
    x = np.arange(len(methods))
    width = 0.2
    
    for i, (cat, values) in enumerate(improvements.items()):
        offset = (i - len(categories)/2 + 0.5) * width
        ax.bar(x + offset, values, width, label=cat)
    
    ax.set_xlabel('ä¼˜åŒ–å™¨')
    ax.set_ylabel('è¯„åˆ†')
    ax.set_title('Adamå˜ä½“æ€§èƒ½å¯¹æ¯”')
    ax.set_xticks(x)
    ax.set_xticklabels(methods)
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')
    
    # 4. å®é™…é€‰æ‹©å»ºè®®
    ax = axes[1, 1]
    
    scenarios = ['CVåˆ†ç±»', 'NLPé¢„è®­ç»ƒ', 'å¾®è°ƒ', 'å¼ºåŒ–å­¦ä¹ ', 'GAN']
    recommendations = ['SGD+åŠ¨é‡', 'AdamW', 'AdamWå°lr', 'Adam', 'RMSprop/Adam']
    colors = ['blue', 'green', 'green', 'purple', 'orange']
    
    y_pos = np.arange(len(scenarios))
    bars = ax.barh(y_pos, [1]*len(scenarios), color=colors, alpha=0.6)
    
    for i, (scenario, rec) in enumerate(zip(scenarios, recommendations)):
        ax.text(0.5, i, rec, ha='center', va='center', fontsize=10, weight='bold')
    
    ax.set_yticks(y_pos)
    ax.set_yticklabels(scenarios)
    ax.set_xlim(0, 1)
    ax.set_title('ä¸åŒåœºæ™¯çš„ä¼˜åŒ–å™¨é€‰æ‹©')
    ax.set_xticks([])
    
    plt.tight_layout()
    plt.show()
    
    print("\nâš ï¸ Adamçš„ä¸»è¦é—®é¢˜ï¼š")
    print("\n1. æ³›åŒ–èƒ½åŠ›ï¼šAdamå¯èƒ½å¯¼è‡´æ›´ä¸¥é‡çš„è¿‡æ‹Ÿåˆ")
    print("2. äºŒé˜¶çŸ©åå·®ï¼šåœ¨ç¨€ç–æ¢¯åº¦ä¸‹å¯èƒ½ä¸å‡†ç¡®")
    print("3. å­¦ä¹ ç‡è°ƒåº¦ï¼šå¯¹å­¦ä¹ ç‡è¡°å‡ä¸å¦‚SGDæ•æ„Ÿ")
    print("4. å†…å­˜æ¶ˆè€—ï¼šéœ€è¦å­˜å‚¨ä¸€é˜¶å’ŒäºŒé˜¶çŸ©")
    
    print("\nâœ¨ æ”¹è¿›æ–¹æ¡ˆï¼š")
    print("\n1. AdamWï¼šè§£è€¦æƒé‡è¡°å‡ï¼Œæ”¹å–„æ³›åŒ–")
    print("2. RAdamï¼šä¿®æ­£æ—©æœŸçš„æ–¹å·®ï¼Œæ›´ç¨³å®š")
    print("3. NAdamï¼šç»“åˆNesterovåŠ¨é‡")
    print("4. AdaBoundï¼šåŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡è¾¹ç•Œ")
    print("5. LAMBï¼šå¤§æ‰¹é‡è®­ç»ƒçš„ä¼˜åŒ–")

adam_limitations()
```

#### ğŸ’¡ æœ¬ç« å°ç»“

1. **ä¼˜åŒ–å™¨çš„æ¼”è¿›**ï¼š
   - SGD â†’ åŠ¨é‡ â†’ è‡ªé€‚åº”å­¦ä¹ ç‡ â†’ Adam
   - æ¯ä¸€æ­¥éƒ½è§£å†³äº†ç‰¹å®šçš„é—®é¢˜
   - Adamé›†å¤§æˆï¼Œä½†ä¸æ˜¯ä¸‡èƒ½çš„

2. **Adamçš„æ ¸å¿ƒåˆ›æ–°**ï¼š
   - **ä¸€é˜¶çŸ©**ï¼šåŠ¨é‡ï¼Œå¹³æ»‘æ¢¯åº¦æ–¹å‘
   - **äºŒé˜¶çŸ©**ï¼šè‡ªé€‚åº”å­¦ä¹ ç‡ï¼Œé€‚åº”ä¸åŒå°ºåº¦
   - **åå·®ä¿®æ­£**ï¼šè§£å†³æ—©æœŸä¼°è®¡ä¸å‡†çš„é—®é¢˜

3. **ä¸ºä»€ä¹ˆAdamæµè¡Œ**ï¼š
   - âœ… è¶…å‚æ•°é²æ£’ï¼šé»˜è®¤å€¼å°±å¾ˆå¥½ç”¨
   - âœ… æ”¶æ•›å¿«ï¼šç»“åˆäº†å¤šç§ä¼˜åŒ–æŠ€å·§
   - âœ… é€‚åº”æ€§å¼ºï¼šè‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡
   - âœ… å®ç°ç®€å•ï¼šä»£ç æ¸…æ™°æ˜“æ‡‚

4. **ä½¿ç”¨å»ºè®®**ï¼š
   - ç¬¬ä¸€é€‰æ‹©ï¼Œç‰¹åˆ«æ˜¯åˆæœŸå®éªŒ
   - æ³¨æ„è¿‡æ‹Ÿåˆï¼Œè€ƒè™‘AdamW
   - å¤§è§„æ¨¡è®­ç»ƒæ—¶æ³¨æ„å†…å­˜
   - æŸäº›åœºæ™¯SGDå¯èƒ½æ›´å¥½

5. **è®°ä½**ï¼š
   - æ²¡æœ‰æœ€å¥½çš„ä¼˜åŒ–å™¨ï¼Œåªæœ‰æœ€åˆé€‚çš„
   - ä¼˜åŒ–å™¨ + å­¦ä¹ ç‡è°ƒåº¦ + æ­£åˆ™åŒ– = æˆåŠŸè®­ç»ƒ
   - è°ƒå‚ç»éªŒå¾ˆé‡è¦ï¼Œå¤šå®éªŒ

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆè®¡ç®—æœºè§†è§‰ä»»åŠ¡æœ€åç»å¸¸åˆ‡æ¢åˆ°SGDï¼Ÿ
2. Adamçš„è‡ªé€‚åº”å­¦ä¹ ç‡å¯èƒ½å¸¦æ¥ä»€ä¹ˆé—®é¢˜ï¼Ÿ
3. å¦‚æœä½ è¦è®¾è®¡ä¸€ä¸ªæ–°çš„ä¼˜åŒ–å™¨ï¼Œä¼šåŠ å…¥ä»€ä¹ˆç‰¹æ€§ï¼Ÿ

#### ğŸ”¬ æ‰©å±•å®éªŒ

```python
def advanced_optimizer_lab():
    """é«˜çº§ä¼˜åŒ–å™¨å®éªŒå®¤"""
    
    print("ğŸ”¬ æ‰©å±•å®éªŒï¼šä¼˜åŒ–å™¨ç»„åˆä¸åˆ›æ–°\n")
    
    # å®éªŒ1ï¼šæ··åˆä¼˜åŒ–ç­–ç•¥
    class HybridOptimizer:
        """å‰æœŸç”¨Adamå¿«é€Ÿä¸‹é™ï¼ŒåæœŸç”¨SGDç²¾ç»†è°ƒæ•´"""
        
        def __init__(self, params, switch_epoch=50):
            self.adam = MiniAdam(params, lr=0.001)
            self.sgd_lr = 0.01
            self.switch_epoch = switch_epoch
            self.epoch = 0
            self.params = params
        
        def step(self, grads):
            self.epoch += 1
            
            if self.epoch < self.switch_epoch:
                # ä½¿ç”¨Adam
                return self.adam.step(grads)
            else:
                # åˆ‡æ¢åˆ°SGD
                for param, grad in zip(self.params, grads):
                    param -= self.sgd_lr * grad
                return self.params
    
    # å®éªŒ2ï¼šè‡ªé€‚åº”Î²å‚æ•°
    def adaptive_beta_experiment():
        """æ ¹æ®è®­ç»ƒè¿›åº¦è‡ªåŠ¨è°ƒæ•´Î²å‚æ•°"""
        
        epochs = np.arange(100)
        
        # Î²1: ä»0.9é€æ¸é™åˆ°0.8ï¼ˆå‡å°‘åŠ¨é‡ä¾èµ–ï¼‰
        beta1_schedule = 0.9 - 0.1 * (epochs / 100)
        
        # Î²2: ä»0.999é€æ¸é™åˆ°0.99ï¼ˆå¢åŠ å­¦ä¹ ç‡å˜åŒ–ï¼‰
        beta2_schedule = 0.999 - 0.009 * (epochs / 100)
        
        plt.figure(figsize=(10, 5))
        plt.plot(epochs, beta1_schedule, 'b-', linewidth=2, label='Î²â‚')
        plt.plot(epochs, beta2_schedule, 'r-', linewidth=2, label='Î²â‚‚')
        plt.xlabel('è®­ç»ƒè½®æ¬¡')
        plt.ylabel('Î²å€¼')
        plt.title('è‡ªé€‚åº”Î²å‚æ•°è°ƒåº¦')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()
    
    adaptive_beta_experiment()
    
    print("\nğŸ’¡ åˆ›æ–°æ€è·¯ï¼š")
    print("1. æ··åˆä¼˜åŒ–ï¼šç»“åˆä¸åŒä¼˜åŒ–å™¨çš„ä¼˜ç‚¹")
    print("2. è‡ªé€‚åº”è¶…å‚æ•°ï¼šè®©ä¼˜åŒ–å™¨è‡ªå·±å­¦ä¹ æœ€ä½³å‚æ•°")
    print("3. ä»»åŠ¡ç‰¹å®šä¼˜åŒ–ï¼šé’ˆå¯¹ç‰¹å®šé—®é¢˜è®¾è®¡ä¼˜åŒ–å™¨")
    print("4. å…ƒå­¦ä¹ ä¼˜åŒ–å™¨ï¼šç”¨ç¥ç»ç½‘ç»œæ¥å­¦ä¹ å¦‚ä½•ä¼˜åŒ–")

advanced_optimizer_lab()
```

ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†å­¦ä¹ è¿‡æ‹Ÿåˆä¸æ­£åˆ™åŒ–â€”â€”è®©AIå­¦ä¼šä¸¾ä¸€åä¸‰ã€‚

### ç¬¬8ç« ï¼šè¿‡æ‹Ÿåˆä¸æ­£åˆ™åŒ–â€”â€”è®©AIå­¦ä¼šä¸¾ä¸€åä¸‰

#### ğŸ¯ æœ¬ç« å¯¼è¯»

æƒ³è±¡ä½ åœ¨å‡†å¤‡è€ƒè¯•ã€‚æœ‰ä¸¤ç§å­¦ä¹ æ–¹æ³•ï¼š

1. **æ­»è®°ç¡¬èƒŒå‹**ï¼šæŠŠæ‰€æœ‰é¢˜ç›®å’Œç­”æ¡ˆéƒ½èƒŒä¸‹æ¥
2. **ç†è§£åŸç†å‹**ï¼šæŒæ¡è§£é¢˜æ€è·¯ï¼Œé‡åˆ°æ–°é¢˜ä¹Ÿèƒ½è§£å†³

ç¬¬ä¸€ç§æ–¹æ³•åœ¨è€ƒåŸé¢˜æ—¶æ»¡åˆ†ï¼Œä½†ç¨å¾®å˜ä¸ªæ•°å­—å°±ä¸ä¼šäº†ã€‚ç¬¬äºŒç§æ–¹æ³•å¯èƒ½åœ¨ç»ƒä¹ é¢˜ä¸Šä¸æ˜¯æ»¡åˆ†ï¼Œä½†é¢å¯¹æ–°é¢˜æ›´æœ‰æŠŠæ¡ã€‚

è¿™å°±æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„**è¿‡æ‹Ÿåˆ**ï¼ˆoverfittingï¼‰é—®é¢˜â€”â€”æ¨¡å‹"æ­»è®°ç¡¬èƒŒ"äº†è®­ç»ƒæ•°æ®ï¼Œå´å¤±å»äº†ä¸¾ä¸€åä¸‰çš„èƒ½åŠ›ã€‚ä»Šå¤©ï¼Œè®©æˆ‘ä»¬æ·±å…¥ç†è§£è¿™ä¸ªé—®é¢˜ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡**æ­£åˆ™åŒ–**ï¼ˆregularizationï¼‰è®©AIçœŸæ­£å­¦ä¼š"ç†è§£"è€Œä¸æ˜¯"èƒŒè¯µ"ã€‚

#### ğŸ­ è¿‡æ‹Ÿåˆçš„ç›´è§‚ç†è§£

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
import warnings
warnings.filterwarnings('ignore')

def è¿‡æ‹Ÿåˆæ¼”ç¤º():
    """é€šè¿‡å¤šé¡¹å¼æ‹Ÿåˆå±•ç¤ºæ¬ æ‹Ÿåˆã€æ­£å¸¸æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆ"""
    
    # ç”Ÿæˆå¸¦å™ªå£°çš„æ•°æ®
    np.random.seed(42)
    n_samples = 30
    X = np.sort(np.random.rand(n_samples) * 10)
    y_true = np.sin(X) + X * 0.5  # çœŸå®å‡½æ•°
    y = y_true + np.random.randn(n_samples) * 0.5  # åŠ å…¥å™ªå£°
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    X_test = np.linspace(0, 10, 300)
    y_test_true = np.sin(X_test) + X_test * 0.5
    
    # ä¸åŒå¤æ‚åº¦çš„æ¨¡å‹
    degrees = [1, 3, 15]  # å¤šé¡¹å¼é˜¶æ•°
    titles = ['æ¬ æ‹Ÿåˆï¼ˆå¤ªç®€å•ï¼‰', 'æ­£å¸¸æ‹Ÿåˆï¼ˆåˆšåˆšå¥½ï¼‰', 'è¿‡æ‹Ÿåˆï¼ˆå¤ªå¤æ‚ï¼‰']
    
    plt.figure(figsize=(15, 5))
    
    for i, (degree, title) in enumerate(zip(degrees, titles)):
        plt.subplot(1, 3, i + 1)
        
        # å¤šé¡¹å¼ç‰¹å¾è½¬æ¢
        poly = PolynomialFeatures(degree=degree)
        X_poly = poly.fit_transform(X.reshape(-1, 1))
        X_test_poly = poly.transform(X_test.reshape(-1, 1))
        
        # è®­ç»ƒæ¨¡å‹
        model = LinearRegression()
        model.fit(X_poly, y)
        
        # é¢„æµ‹
        y_pred = model.predict(X_poly)
        y_test_pred = model.predict(X_test_poly)
        
        # è®¡ç®—è®­ç»ƒè¯¯å·®å’Œæµ‹è¯•è¯¯å·®
        train_error = np.mean((y - y_pred) ** 2)
        
        # ç»˜å›¾
        plt.scatter(X, y, color='blue', s=50, alpha=0.6, label='è®­ç»ƒæ•°æ®')
        plt.plot(X_test, y_test_true, 'g--', linewidth=2, label='çœŸå®å‡½æ•°')
        plt.plot(X_test, y_test_pred, 'r-', linewidth=2, label=f'æ‹Ÿåˆå‡½æ•°(é˜¶æ•°={degree})')
        
        plt.xlabel('X')
        plt.ylabel('y')
        plt.title(f'{title}\nè®­ç»ƒè¯¯å·®: {train_error:.3f}')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # é™åˆ¶yè½´èŒƒå›´ï¼Œé¿å…è¿‡æ‹Ÿåˆå›¾å¤ªå¤¸å¼ 
        plt.ylim(-3, 8)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ” å…³é”®è§‚å¯Ÿï¼š")
    print("1. æ¬ æ‹Ÿåˆï¼šæ¨¡å‹å¤ªç®€å•ï¼Œè¿è®­ç»ƒæ•°æ®éƒ½æ‹Ÿåˆä¸å¥½")
    print("2. æ­£å¸¸æ‹Ÿåˆï¼šåœ¨è®­ç»ƒæ•°æ®å’Œæ³›åŒ–èƒ½åŠ›é—´æ‰¾åˆ°å¹³è¡¡")
    print("3. è¿‡æ‹Ÿåˆï¼šå®Œç¾æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œä½†åç¦»äº†çœŸå®è§„å¾‹")

è¿‡æ‹Ÿåˆæ¼”ç¤º()
```

#### ğŸ“Š è®­ç»ƒè¯¯å·® vs éªŒè¯è¯¯å·®

```python
def å­¦ä¹ æ›²çº¿åˆ†æ():
    """å±•ç¤ºæ¨¡å‹å¤æ‚åº¦ä¸è¯¯å·®çš„å…³ç³»"""
    
    # ç”Ÿæˆæ•°æ®
    np.random.seed(42)
    n_samples = 100
    X = np.random.rand(n_samples, 1) * 10
    y = np.sin(X).ravel() + X.ravel() * 0.5 + np.random.randn(n_samples) * 0.5
    
    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    split_idx = 70
    X_train, X_val = X[:split_idx], X[split_idx:]
    y_train, y_val = y[:split_idx], y[split_idx:]
    
    # æµ‹è¯•ä¸åŒå¤æ‚åº¦
    max_degree = 20
    degrees = range(1, max_degree + 1)
    train_errors = []
    val_errors = []
    
    for degree in degrees:
        # å¤šé¡¹å¼ç‰¹å¾
        poly = PolynomialFeatures(degree=degree)
        X_train_poly = poly.fit_transform(X_train)
        X_val_poly = poly.transform(X_val)
        
        # è®­ç»ƒæ¨¡å‹
        model = LinearRegression()
        model.fit(X_train_poly, y_train)
        
        # è®¡ç®—è¯¯å·®
        train_pred = model.predict(X_train_poly)
        val_pred = model.predict(X_val_poly)
        
        train_error = np.mean((y_train - train_pred) ** 2)
        val_error = np.mean((y_val - val_pred) ** 2)
        
        train_errors.append(train_error)
        val_errors.append(val_error)
    
    # ç»˜åˆ¶å­¦ä¹ æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(degrees, train_errors, 'b-o', linewidth=2, markersize=6, label='è®­ç»ƒè¯¯å·®')
    plt.plot(degrees, val_errors, 'r-s', linewidth=2, markersize=6, label='éªŒè¯è¯¯å·®')
    
    # æ ‡æ³¨å…³é”®åŒºåŸŸ
    plt.axvspan(1, 3, alpha=0.2, color='yellow', label='æ¬ æ‹ŸåˆåŒºåŸŸ')
    plt.axvspan(8, max_degree, alpha=0.2, color='red', label='è¿‡æ‹ŸåˆåŒºåŸŸ')
    plt.axvspan(3, 8, alpha=0.2, color='green', label='æœ€ä½³åŒºåŸŸ')
    
    plt.xlabel('æ¨¡å‹å¤æ‚åº¦ï¼ˆå¤šé¡¹å¼é˜¶æ•°ï¼‰')
    plt.ylabel('å‡æ–¹è¯¯å·®')
    plt.title('å­¦ä¹ æ›²çº¿ï¼šè®­ç»ƒè¯¯å·® vs éªŒè¯è¯¯å·®')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.yscale('log')  # ä½¿ç”¨å¯¹æ•°åˆ»åº¦
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ“ˆ å­¦ä¹ æ›²çº¿å‘Šè¯‰æˆ‘ä»¬ï¼š")
    print("1. è®­ç»ƒè¯¯å·®éšå¤æ‚åº¦å¢åŠ è€Œé™ä½")
    print("2. éªŒè¯è¯¯å·®å…ˆé™åå‡ï¼Œå­˜åœ¨æœ€ä¼˜ç‚¹")
    print("3. ä¸¤è€…å·®è·è¶Šå¤§ï¼Œè¿‡æ‹Ÿåˆè¶Šä¸¥é‡")

å­¦ä¹ æ›²çº¿åˆ†æ()
```

#### ğŸ›¡ï¸ æ­£åˆ™åŒ–ï¼šå¯¹æŠ—è¿‡æ‹Ÿåˆçš„åˆ©å™¨

```python
from sklearn.linear_model import Ridge, Lasso, ElasticNet

def æ­£åˆ™åŒ–æ–¹æ³•æ¯”è¾ƒ():
    """æ¯”è¾ƒä¸åŒæ­£åˆ™åŒ–æ–¹æ³•çš„æ•ˆæœ"""
    
    # ç”Ÿæˆé«˜ç»´ç¨€ç–æ•°æ®
    np.random.seed(42)
    n_samples = 50
    n_features = 100  # ç‰¹å¾æ¯”æ ·æœ¬è¿˜å¤šï¼
    
    # åªæœ‰10ä¸ªç‰¹å¾æ˜¯çœŸæ­£æœ‰ç”¨çš„
    n_informative = 10
    true_weights = np.zeros(n_features)
    informative_idx = np.random.choice(n_features, n_informative, replace=False)
    true_weights[informative_idx] = np.random.randn(n_informative) * 2
    
    # ç”Ÿæˆæ•°æ®
    X = np.random.randn(n_samples, n_features)
    y = X @ true_weights + np.random.randn(n_samples) * 0.5
    
    # ä¸åŒçš„æ­£åˆ™åŒ–æ–¹æ³•
    models = {
        'æ— æ­£åˆ™åŒ–': LinearRegression(),
        'L2æ­£åˆ™åŒ–(Ridge)': Ridge(alpha=1.0),
        'L1æ­£åˆ™åŒ–(Lasso)': Lasso(alpha=0.1),
        'L1+L2(ElasticNet)': ElasticNet(alpha=0.1, l1_ratio=0.5)
    }
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    axes = axes.ravel()
    
    for idx, (name, model) in enumerate(models.items()):
        ax = axes[idx]
        
        # è®­ç»ƒæ¨¡å‹
        model.fit(X, y)
        weights = model.coef_ if hasattr(model, 'coef_') else model.coef_
        
        # å¯è§†åŒ–æƒé‡
        ax.bar(range(n_features), weights, width=0.8)
        ax.axhline(y=0, color='k', linestyle='-', linewidth=0.5)
        
        # æ ‡å‡ºçœŸå®æœ‰ç”¨çš„ç‰¹å¾
        for i in informative_idx:
            ax.axvline(x=i, color='red', linestyle='--', alpha=0.5)
        
        ax.set_xlabel('ç‰¹å¾ç´¢å¼•')
        ax.set_ylabel('æƒé‡å€¼')
        ax.set_title(f'{name}')
        ax.set_ylim(-5, 5)
        
        # è®¡ç®—ç¨€ç–åº¦
        sparsity = np.sum(np.abs(weights) < 0.01) / n_features * 100
        ax.text(0.02, 0.98, f'ç¨€ç–åº¦: {sparsity:.1f}%', 
                transform=ax.transAxes, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ¯ æ­£åˆ™åŒ–æ–¹æ³•å¯¹æ¯”ï¼š")
    print("1. æ— æ­£åˆ™åŒ–ï¼šæ‰€æœ‰ç‰¹å¾éƒ½æœ‰æƒé‡ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆ")
    print("2. L2æ­£åˆ™åŒ–ï¼šæƒé‡å˜å°ä½†ä¸ä¸ºé›¶ï¼Œå¹³æ»‘æ•ˆæœ")
    print("3. L1æ­£åˆ™åŒ–ï¼šå¾ˆå¤šæƒé‡å˜ä¸ºé›¶ï¼Œç‰¹å¾é€‰æ‹©æ•ˆæœ")
    print("4. ElasticNetï¼šç»“åˆL1å’ŒL2çš„ä¼˜ç‚¹")

æ­£åˆ™åŒ–æ–¹æ³•æ¯”è¾ƒ()
```

#### ğŸ² Dropoutï¼šæ·±åº¦å­¦ä¹ çš„æ­£åˆ™åŒ–

```python
def dropout_æ¼”ç¤º():
    """å±•ç¤ºDropoutå¦‚ä½•é˜²æ­¢è¿‡æ‹Ÿåˆ"""
    
    class SimpleNN:
        def __init__(self, dropout_rate=0.0):
            self.dropout_rate = dropout_rate
            np.random.seed(42)
            
            # ç®€å•çš„ä¸‰å±‚ç½‘ç»œ
            self.W1 = np.random.randn(10, 20) * 0.1
            self.W2 = np.random.randn(20, 20) * 0.1
            self.W3 = np.random.randn(20, 1) * 0.1
            
        def forward(self, X, training=True):
            # ç¬¬ä¸€å±‚
            h1 = np.maximum(0, X @ self.W1)  # ReLU
            if training and self.dropout_rate > 0:
                mask1 = np.random.rand(*h1.shape) > self.dropout_rate
                h1 = h1 * mask1 / (1 - self.dropout_rate)  # ç¼©æ”¾
            
            # ç¬¬äºŒå±‚
            h2 = np.maximum(0, h1 @ self.W2)  # ReLU
            if training and self.dropout_rate > 0:
                mask2 = np.random.rand(*h2.shape) > self.dropout_rate
                h2 = h2 * mask2 / (1 - self.dropout_rate)
            
            # è¾“å‡ºå±‚
            output = h2 @ self.W3
            return output
    
    # å¯è§†åŒ–Dropoutæ•ˆæœ
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # å·¦å›¾ï¼šç½‘ç»œç»“æ„ç¤ºæ„å›¾
    def draw_network(ax, dropout_rate, title):
        ax.set_xlim(-1, 4)
        ax.set_ylim(-1, 6)
        ax.axis('off')
        ax.set_title(title)
        
        # ç”»èŠ‚ç‚¹
        layers = [10, 20, 20, 1]
        x_positions = [0, 1, 2, 3]
        
        for layer_idx, (x, n_nodes) in enumerate(zip(x_positions, layers)):
            y_positions = np.linspace(0, 5, n_nodes)
            for y in y_positions:
                # æ ¹æ®dropoutéšæœºå†³å®šèŠ‚ç‚¹æ˜¯å¦æ¿€æ´»
                if layer_idx > 0 and layer_idx < 3 and np.random.rand() < dropout_rate:
                    color = 'lightgray'
                    alpha = 0.3
                else:
                    color = 'blue'
                    alpha = 1.0
                
                circle = plt.Circle((x, y), 0.05, color=color, alpha=alpha)
                ax.add_patch(circle)
        
        # ç”»è¿æ¥ï¼ˆç®€åŒ–ç‰ˆï¼Œåªç”»éƒ¨åˆ†ï¼‰
        for i in range(3):
            for j in range(5):  # åªç”»éƒ¨åˆ†è¿æ¥
                y1 = np.random.choice(np.linspace(0, 5, layers[i]))
                y2 = np.random.choice(np.linspace(0, 5, layers[i+1]))
                alpha = 0.1 if dropout_rate > 0 else 0.3
                ax.plot([x_positions[i], x_positions[i+1]], [y1, y2], 
                       'gray', alpha=alpha, linewidth=0.5)
    
    draw_network(ax1, 0.0, 'Without Dropout\nï¼ˆæ‰€æœ‰ç¥ç»å…ƒå‚ä¸ï¼‰')
    draw_network(ax2, 0.5, 'With Dropout (50%)\nï¼ˆéšæœºå…³é—­éƒ¨åˆ†ç¥ç»å…ƒï¼‰')
    
    # ä¸‹æ–¹ï¼šå±•ç¤ºDropoutå¯¹è®­ç»ƒçš„å½±å“
    fig2, ax3 = plt.subplots(figsize=(10, 6))
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    epochs = 50
    X_train = np.random.randn(100, 10)
    y_train = np.sum(X_train[:, :3], axis=1, keepdims=True)  # åªä¾èµ–å‰3ä¸ªç‰¹å¾
    
    for dropout_rate, color, label in [(0.0, 'red', 'No Dropout'), 
                                        (0.3, 'blue', 'Dropout=0.3'),
                                        (0.5, 'green', 'Dropout=0.5')]:
        losses = []
        model = SimpleNN(dropout_rate)
        
        for epoch in range(epochs):
            pred = model.forward(X_train, training=True)
            loss = np.mean((pred - y_train) ** 2)
            losses.append(loss)
            
            # ç®€å•çš„æ¢¯åº¦ä¸‹é™æ›´æ–°ï¼ˆçœç•¥åå‘ä¼ æ’­ç»†èŠ‚ï¼‰
            # ...
        
        ax3.plot(losses, color=color, label=label, linewidth=2)
    
    ax3.set_xlabel('è®­ç»ƒè½®æ¬¡')
    ax3.set_ylabel('æŸå¤±å€¼')
    ax3.set_title('Dropoutå¯¹è®­ç»ƒè¿‡ç¨‹çš„å½±å“')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ’¡ Dropoutçš„å·¥ä½œåŸç†ï¼š")
    print("1. è®­ç»ƒæ—¶éšæœº'å…³é—­'ä¸€äº›ç¥ç»å…ƒ")
    print("2. å¼ºè¿«ç½‘ç»œä¸ä¾èµ–ç‰¹å®šç¥ç»å…ƒ")
    print("3. ç›¸å½“äºè®­ç»ƒäº†å¤šä¸ªå­ç½‘ç»œçš„é›†æˆ")
    print("4. æµ‹è¯•æ—¶ä½¿ç”¨å…¨éƒ¨ç¥ç»å…ƒï¼Œä½†è¦ç¼©æ”¾è¾“å‡º")

dropout_æ¼”ç¤º()
```

#### ğŸ“ æ•°æ®å¢å¼ºï¼šè®©æ•°æ®å‘Šè¯‰æ›´å¤šæ•…äº‹

```python
def æ•°æ®å¢å¼ºæ¼”ç¤º():
    """å±•ç¤ºæ•°æ®å¢å¼ºå¦‚ä½•å¸®åŠ©æ¨¡å‹æ³›åŒ–"""
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„"å›¾åƒ"ï¼ˆç”¨2Dæ•°æ®æ¨¡æ‹Ÿï¼‰
    def create_pattern():
        """åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¨¡å¼"""
        x = np.linspace(-1, 1, 20)
        y = np.linspace(-1, 1, 20)
        X, Y = np.meshgrid(x, y)
        Z = np.exp(-(X**2 + Y**2)) + 0.5 * np.exp(-((X-0.5)**2 + (Y-0.5)**2))
        return Z
    
    # æ•°æ®å¢å¼ºå‡½æ•°
    def augment_data(data, augmentation_type):
        """ä¸åŒç±»å‹çš„æ•°æ®å¢å¼º"""
        if augmentation_type == 'åŸå§‹':
            return data
        elif augmentation_type == 'æ—‹è½¬':
            return np.rot90(data, k=np.random.randint(1, 4))
        elif augmentation_type == 'ç¿»è½¬':
            if np.random.rand() > 0.5:
                return np.fliplr(data)
            else:
                return np.flipud(data)
        elif augmentation_type == 'å™ªå£°':
            noise = np.random.randn(*data.shape) * 0.1
            return data + noise
        elif augmentation_type == 'ç¼©æ”¾':
            scale = np.random.uniform(0.8, 1.2)
            return data * scale
    
    # åˆ›å»ºåŸå§‹æ•°æ®
    original = create_pattern()
    
    # å±•ç¤ºä¸åŒçš„æ•°æ®å¢å¼ºæ•ˆæœ
    augmentations = ['åŸå§‹', 'æ—‹è½¬', 'ç¿»è½¬', 'å™ªå£°', 'ç¼©æ”¾']
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.ravel()
    
    for idx, aug_type in enumerate(augmentations):
        ax = axes[idx]
        augmented = augment_data(original, aug_type)
        
        im = ax.imshow(augmented, cmap='viridis')
        ax.set_title(f'{aug_type}æ•°æ®')
        ax.axis('off')
        plt.colorbar(im, ax=ax, fraction=0.046)
    
    # æœ€åä¸€ä¸ªå­å›¾ï¼šå±•ç¤ºå¢å¼ºå¯¹è®­ç»ƒçš„å½±å“
    ax = axes[5]
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ•ˆæœ
    sample_sizes = [10, 50, 100, 500]
    no_aug_performance = [0.6, 0.7, 0.75, 0.78]
    with_aug_performance = [0.7, 0.82, 0.87, 0.90]
    
    x = np.arange(len(sample_sizes))
    width = 0.35
    
    bars1 = ax.bar(x - width/2, no_aug_performance, width, 
                    label='æ— æ•°æ®å¢å¼º', color='red', alpha=0.7)
    bars2 = ax.bar(x + width/2, with_aug_performance, width, 
                    label='æœ‰æ•°æ®å¢å¼º', color='green', alpha=0.7)
    
    ax.set_xlabel('è®­ç»ƒæ ·æœ¬æ•°')
    ax.set_ylabel('æ¨¡å‹æ€§èƒ½')
    ax.set_title('æ•°æ®å¢å¼ºå¯¹æ¨¡å‹æ€§èƒ½çš„æå‡')
    ax.set_xticks(x)
    ax.set_xticklabels(sample_sizes)
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')
    
    # æ ‡æ³¨æå‡ç™¾åˆ†æ¯”
    for i, (v1, v2) in enumerate(zip(no_aug_performance, with_aug_performance)):
        improvement = (v2 - v1) / v1 * 100
        ax.text(i, v2 + 0.02, f'+{improvement:.0f}%', 
                ha='center', va='bottom', fontsize=10, color='green')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ¨ æ•°æ®å¢å¼ºçš„ä»·å€¼ï¼š")
    print("1. ä»æœ‰é™æ•°æ®ä¸­åˆ›é€ æ›´å¤šæ ·åŒ–çš„è®­ç»ƒæ ·æœ¬")
    print("2. è®©æ¨¡å‹å­¦ä¹ åˆ°ä¸å˜æ€§ï¼ˆæ—‹è½¬ä¸å˜ã€å¹³ç§»ä¸å˜ç­‰ï¼‰")
    print("3. ç‰¹åˆ«é€‚åˆæ•°æ®é‡å°‘çš„åœºæ™¯")
    print("4. ä¸åŒä»»åŠ¡éœ€è¦ä¸åŒçš„å¢å¼ºç­–ç•¥")

æ•°æ®å¢å¼ºæ¼”ç¤º()
```

#### ğŸ¯ æ—©åœæ³•ï¼šçŸ¥é“ä½•æ—¶åœæ­¢

```python
def æ—©åœæ³•æ¼”ç¤º():
    """å±•ç¤ºæ—©åœæ³•å¦‚ä½•é˜²æ­¢è¿‡æ‹Ÿåˆ"""
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    np.random.seed(42)
    epochs = 100
    
    # ç”Ÿæˆè®­ç»ƒå’ŒéªŒè¯æŸå¤±æ›²çº¿
    train_loss = []
    val_loss = []
    
    for epoch in range(epochs):
        # è®­ç»ƒæŸå¤±æŒç»­ä¸‹é™
        train = 5 * np.exp(-epoch/20) + 0.1 + np.random.randn() * 0.05
        train_loss.append(max(0.1, train))
        
        # éªŒè¯æŸå¤±å…ˆé™åå‡
        if epoch < 30:
            val = 5 * np.exp(-epoch/15) + 0.3 + np.random.randn() * 0.1
        else:
            val = 0.8 + 0.02 * (epoch - 30) + np.random.randn() * 0.1
        val_loss.append(val)
    
    # æ‰¾åˆ°æœ€ä½³åœæ­¢ç‚¹
    best_epoch = np.argmin(val_loss)
    best_val_loss = val_loss[best_epoch]
    
    # å®ç°æ—©åœé€»è¾‘
    patience = 10  # å®¹å¿åº¦
    min_delta = 0.001  # æœ€å°æ”¹å–„
    
    def find_early_stop_epoch(val_loss, patience, min_delta):
        best_loss = float('inf')
        best_epoch = 0
        patience_counter = 0
        
        for epoch, loss in enumerate(val_loss):
            if loss < best_loss - min_delta:
                best_loss = loss
                best_epoch = epoch
                patience_counter = 0
            else:
                patience_counter += 1
                
            if patience_counter >= patience:
                return epoch - patience + 1
        
        return len(val_loss)
    
    early_stop_epoch = find_early_stop_epoch(val_loss, patience, min_delta)
    
    # å¯è§†åŒ–
    plt.figure(figsize=(12, 6))
    
    # æŸå¤±æ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(train_loss, 'b-', linewidth=2, label='è®­ç»ƒæŸå¤±')
    plt.plot(val_loss, 'r-', linewidth=2, label='éªŒè¯æŸå¤±')
    
    # æ ‡è®°å…³é”®ç‚¹
    plt.axvline(x=best_epoch, color='green', linestyle='--', 
                label=f'æœ€ä½³æ¨¡å‹ (epoch {best_epoch})')
    plt.axvline(x=early_stop_epoch, color='orange', linestyle='--', 
                label=f'æ—©åœç‚¹ (epoch {early_stop_epoch})')
    
    # é«˜äº®è¿‡æ‹ŸåˆåŒºåŸŸ
    plt.axvspan(early_stop_epoch, epochs, alpha=0.2, color='red', 
                label='è¿‡æ‹ŸåˆåŒºåŸŸ')
    
    plt.xlabel('è®­ç»ƒè½®æ¬¡')
    plt.ylabel('æŸå¤±å€¼')
    plt.title('æ—©åœæ³•åŸç†')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # æ—©åœç®—æ³•æµç¨‹
    plt.subplot(1, 2, 2)
    plt.text(0.5, 0.9, 'æ—©åœæ³•ç®—æ³•æµç¨‹', fontsize=16, weight='bold',
             ha='center', transform=plt.gca().transAxes)
    
    steps = [
        '1. è®¾ç½®patienceï¼ˆå®¹å¿åº¦ï¼‰',
        '2. ç›‘æ§éªŒè¯é›†æŸå¤±',
        '3. å¦‚æœéªŒè¯æŸå¤±æ”¹å–„ï¼š',
        '   - ä¿å­˜æ¨¡å‹',
        '   - é‡ç½®è®¡æ•°å™¨',
        '4. å¦‚æœéªŒè¯æŸå¤±ä¸æ”¹å–„ï¼š',
        '   - è®¡æ•°å™¨+1',
        '5. å¦‚æœè®¡æ•°å™¨â‰¥patienceï¼š',
        '   - åœæ­¢è®­ç»ƒ',
        '   - æ¢å¤æœ€ä½³æ¨¡å‹'
    ]
    
    for i, step in enumerate(steps):
        y_pos = 0.8 - i * 0.08
        if step.startswith('   '):
            plt.text(0.15, y_pos, step, fontsize=11,
                    transform=plt.gca().transAxes, color='blue')
        else:
            plt.text(0.05, y_pos, step, fontsize=12,
                    transform=plt.gca().transAxes)
    
    plt.axis('off')
    
    plt.tight_layout()
    plt.show()
    
    print(f"ğŸ“Š æ—©åœæ³•ç»“æœï¼š")
    print(f"æœ€ä½³æ¨¡å‹å‡ºç°åœ¨ç¬¬ {best_epoch} è½®")
    print(f"æ—©åœå‘ç”Ÿåœ¨ç¬¬ {early_stop_epoch} è½®")
    print(f"é¿å…äº†é¢å¤–çš„ {epochs - early_stop_epoch} è½®æ— æ•ˆè®­ç»ƒ")

æ—©åœæ³•æ¼”ç¤º()
```

#### ğŸ§ª æ­£åˆ™åŒ–æŠ€æœ¯å¤§æ¯”æ‹¼

```python
def æ­£åˆ™åŒ–æŠ€æœ¯æ¯”è¾ƒ():
    """æ¯”è¾ƒå„ç§æ­£åˆ™åŒ–æŠ€æœ¯çš„æ•ˆæœ"""
    
    # å‡†å¤‡æ•°æ®
    np.random.seed(42)
    n_train = 50
    n_test = 200
    noise_level = 0.3
    
    # ç”Ÿæˆéçº¿æ€§æ•°æ®
    X_train = np.sort(np.random.rand(n_train) * 4 - 2)
    y_train = np.sin(2 * X_train) + X_train + np.random.randn(n_train) * noise_level
    
    X_test = np.linspace(-2.5, 2.5, n_test)
    y_test = np.sin(2 * X_test) + X_test
    
    # ä¸åŒçš„æ­£åˆ™åŒ–ç­–ç•¥
    strategies = {
        'æ— æ­£åˆ™åŒ–': {
            'color': 'red',
            'alpha': 0.0,
            'dropout': 0.0,
            'early_stop': False,
            'data_aug': False
        },
        'L2æ­£åˆ™åŒ–': {
            'color': 'blue',
            'alpha': 0.1,
            'dropout': 0.0,
            'early_stop': False,
            'data_aug': False
        },
        'Dropout': {
            'color': 'green',
            'alpha': 0.0,
            'dropout': 0.3,
            'early_stop': False,
            'data_aug': False
        },
        'æ—©åœæ³•': {
            'color': 'orange',
            'alpha': 0.0,
            'dropout': 0.0,
            'early_stop': True,
            'data_aug': False
        },
        'ç»„åˆæ–¹æ³•': {
            'color': 'purple',
            'alpha': 0.05,
            'dropout': 0.2,
            'early_stop': True,
            'data_aug': True
        }
    }
    
    plt.figure(figsize=(15, 10))
    
    # ä¸»å›¾ï¼šæ‹Ÿåˆæ•ˆæœå¯¹æ¯”
    plt.subplot(2, 2, (1, 3))
    plt.scatter(X_train, y_train, color='black', s=50, alpha=0.7, label='è®­ç»ƒæ•°æ®')
    plt.plot(X_test, y_test, 'k--', linewidth=2, label='çœŸå®å‡½æ•°')
    
    results = {}
    
    for name, config in strategies.items():
        # æ¨¡æ‹Ÿä¸åŒæ­£åˆ™åŒ–ä¸‹çš„æ‹Ÿåˆç»“æœ
        # è¿™é‡Œç”¨å¤šé¡¹å¼æ‹Ÿåˆæ¥æ¼”ç¤º
        degree = 15
        poly = PolynomialFeatures(degree=degree)
        X_train_poly = poly.fit_transform(X_train.reshape(-1, 1))
        
        # åº”ç”¨æ­£åˆ™åŒ–
        if config['alpha'] > 0:
            model = Ridge(alpha=config['alpha'])
        else:
            model = LinearRegression()
        
        # æ•°æ®å¢å¼ºï¼ˆç®€åŒ–ç‰ˆï¼šæ·»åŠ æ‰°åŠ¨ï¼‰
        if config['data_aug']:
            X_aug = np.concatenate([X_train, X_train + np.random.randn(n_train) * 0.05])
            y_aug = np.concatenate([y_train, y_train + np.random.randn(n_train) * 0.05])
            X_aug_poly = poly.fit_transform(X_aug.reshape(-1, 1))
            model.fit(X_aug_poly, y_aug)
        else:
            model.fit(X_train_poly, y_train)
        
        # é¢„æµ‹
        X_test_poly = poly.transform(X_test.reshape(-1, 1))
        y_pred = model.predict(X_test_poly)
        
        # æ¨¡æ‹Ÿdropoutæ•ˆæœï¼ˆç®€åŒ–ç‰ˆï¼‰
        if config['dropout'] > 0:
            y_pred = y_pred * (1 - config['dropout'] * 0.3)
        
        plt.plot(X_test, y_pred, color=config['color'], linewidth=2, 
                label=name, alpha=0.8)
        
        # è®¡ç®—æµ‹è¯•è¯¯å·®
        test_error = np.mean((y_pred - y_test) ** 2)
        results[name] = test_error
    
    plt.xlabel('X')
    plt.ylabel('y')
    plt.title('ä¸åŒæ­£åˆ™åŒ–æ–¹æ³•çš„æ‹Ÿåˆæ•ˆæœå¯¹æ¯”')
    plt.legend(loc='upper left')
    plt.grid(True, alpha=0.3)
    plt.ylim(-5, 5)
    
    # æ€§èƒ½å¯¹æ¯”æŸ±çŠ¶å›¾
    plt.subplot(2, 2, 2)
    names = list(results.keys())
    errors = list(results.values())
    colors = [strategies[name]['color'] for name in names]
    
    bars = plt.bar(range(len(names)), errors, color=colors, alpha=0.7)
    plt.xticks(range(len(names)), names, rotation=45, ha='right')
    plt.ylabel('æµ‹è¯•è¯¯å·®')
    plt.title('æ­£åˆ™åŒ–æ–¹æ³•æ€§èƒ½å¯¹æ¯”')
    plt.grid(True, alpha=0.3, axis='y')
    
    # æ ‡æ³¨æ”¹å–„ç™¾åˆ†æ¯”
    baseline = errors[0]  # æ— æ­£åˆ™åŒ–ä½œä¸ºåŸºå‡†
    for i, (bar, error) in enumerate(zip(bars[1:], errors[1:]), 1):
        improvement = (baseline - error) / baseline * 100
        if improvement > 0:
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,
                    f'-{improvement:.0f}%', ha='center', va='bottom', 
                    fontsize=10, color='green')
    
    # æ­£åˆ™åŒ–é€‰æ‹©æŒ‡å—
    plt.subplot(2, 2, 4)
    plt.text(0.5, 0.95, 'æ­£åˆ™åŒ–æ–¹æ³•é€‰æ‹©æŒ‡å—', fontsize=14, weight='bold',
             ha='center', transform=plt.gca().transAxes)
    
    guidelines = [
        ('æ•°æ®é‡å°‘', 'L2æ­£åˆ™åŒ– + æ•°æ®å¢å¼º'),
        ('æ¨¡å‹å¾ˆæ·±', 'Dropout + æ‰¹å½’ä¸€åŒ–'),
        ('è®­ç»ƒæ—¶é—´é•¿', 'æ—©åœæ³• + å­¦ä¹ ç‡è¡°å‡'),
        ('ç‰¹å¾å¾ˆå¤š', 'L1æ­£åˆ™åŒ–ï¼ˆç‰¹å¾é€‰æ‹©ï¼‰'),
        ('ä¸€èˆ¬æƒ…å†µ', 'ç»„åˆå¤šç§æ–¹æ³•'),
    ]
    
    for i, (scenario, method) in enumerate(guidelines):
        y_pos = 0.8 - i * 0.15
        plt.text(0.1, y_pos, f'åœºæ™¯ï¼š{scenario}', fontsize=12,
                transform=plt.gca().transAxes, weight='bold')
        plt.text(0.1, y_pos - 0.06, f'æ¨èï¼š{method}', fontsize=11,
                transform=plt.gca().transAxes, color='blue')
    
    plt.axis('off')
    
    plt.tight_layout()
    plt.show()

æ­£åˆ™åŒ–æŠ€æœ¯æ¯”è¾ƒ()
```

#### ğŸ“ æœ¬ç« å°ç»“

è¿‡æ‹Ÿåˆæ˜¯æœºå™¨å­¦ä¹ ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œè€Œæ­£åˆ™åŒ–æ˜¯æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆå·¥å…·ç®±ï¼š

1. **è¿‡æ‹Ÿåˆçš„æœ¬è´¨**ï¼šæ¨¡å‹è®°ä½äº†è®­ç»ƒæ•°æ®çš„å™ªå£°ï¼Œè€Œä¸æ˜¯å­¦åˆ°äº†çœŸæ­£çš„è§„å¾‹
2. **æ­£åˆ™åŒ–çš„æ€æƒ³**ï¼šé€šè¿‡çº¦æŸæ¨¡å‹å¤æ‚åº¦ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›
3. **ä¸»è¦æ–¹æ³•**ï¼š
   - **å‚æ•°æ­£åˆ™åŒ–**ï¼šL1ã€L2æ­£åˆ™åŒ–
   - **ç»“æ„æ­£åˆ™åŒ–**ï¼šDropoutã€æ‰¹å½’ä¸€åŒ–
   - **æ•°æ®æ­£åˆ™åŒ–**ï¼šæ•°æ®å¢å¼ºã€å™ªå£°æ³¨å…¥
   - **è®­ç»ƒæ­£åˆ™åŒ–**ï¼šæ—©åœã€å­¦ä¹ ç‡è¡°å‡

#### ğŸ’¡ å®ç”¨å»ºè®®

1. **å…ˆä»ç®€å•æ¨¡å‹å¼€å§‹**ï¼šå®å¯æ¬ æ‹Ÿåˆï¼Œå†é€æ­¥å¢åŠ å¤æ‚åº¦
2. **ç›‘æ§éªŒè¯é›†æ€§èƒ½**ï¼šè¿™æ˜¯åˆ¤æ–­è¿‡æ‹Ÿåˆçš„é‡‘æ ‡å‡†
3. **ç»„åˆä½¿ç”¨å¤šç§æ–¹æ³•**ï¼šä¸åŒæ­£åˆ™åŒ–æŠ€æœ¯å¯ä»¥äº’è¡¥
4. **æ ¹æ®ä»»åŠ¡é€‰æ‹©**ï¼š
   - å›¾åƒä»»åŠ¡ï¼šæ•°æ®å¢å¼ºå¾ˆæœ‰æ•ˆ
   - NLPä»»åŠ¡ï¼šDropout + æƒé‡è¡°å‡
   - å°æ•°æ®é›†ï¼šå¼ºæ­£åˆ™åŒ– + æ•°æ®å¢å¼º

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆè¯´"æ‰€æœ‰çš„æ­£åˆ™åŒ–æœ¬è´¨ä¸Šéƒ½æ˜¯åœ¨æ³¨å…¥å…ˆéªŒçŸ¥è¯†"ï¼Ÿ
2. å¦‚æœè®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®éƒ½å¾ˆé«˜ï¼Œåº”è¯¥æ€ä¹ˆåŠï¼Ÿ
3. è¿‡åº¦æ­£åˆ™åŒ–ä¼šå¸¦æ¥ä»€ä¹ˆé—®é¢˜ï¼Ÿå¦‚ä½•å¹³è¡¡ï¼Ÿ

ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†å­¦ä¹ Batchå¤„ç†ä¸Paddingâ€”â€”ä¸ºä»€ä¹ˆè¦æŠŠæ•°æ®æ‰“åŒ…ï¼Ÿè¿™æ˜¯æé«˜è®­ç»ƒæ•ˆç‡çš„å…³é”®æŠ€æœ¯ã€‚

### ç¬¬9ç« ï¼šBatchå¤„ç†ä¸Paddingâ€”â€”ä¸ºä»€ä¹ˆè¦æŠŠæ•°æ®æ‰“åŒ…ï¼Ÿ

#### ğŸ¯ æœ¬ç« å¯¼è¯»

æƒ³è±¡ä½ åœ¨æ¬å®¶ã€‚ä½ å¯ä»¥é€‰æ‹©ï¼š
1. ä¸€æ¬¡æ¬ä¸€ä»¶ä¸œè¥¿ï¼Œæ¥å›è·‘100è¶Ÿ
2. ç”¨ç®±å­æ‰“åŒ…ï¼Œä¸€æ¬¡æ¬10ä»¶ï¼Œåªè·‘10è¶Ÿ

æ˜¾ç„¶ç¬¬äºŒç§æ›´é«˜æ•ˆã€‚è¿™å°±æ˜¯æ·±åº¦å­¦ä¹ ä¸­**æ‰¹å¤„ç†ï¼ˆBatch Processingï¼‰**çš„æ ¸å¿ƒæ€æƒ³â€”â€”æŠŠå¤šä¸ªæ ·æœ¬æ‰“åŒ…åœ¨ä¸€èµ·å¤„ç†ï¼Œå¤§å¹…æå‡è®­ç»ƒæ•ˆç‡ã€‚

ä½†é—®é¢˜æ¥äº†ï¼šå¦‚æœæœ‰çš„ç®±å­è£…ä¸æ»¡æ€ä¹ˆåŠï¼Ÿè¿™å°±éœ€è¦**å¡«å……ï¼ˆPaddingï¼‰**æŠ€æœ¯ã€‚ä»Šå¤©ï¼Œè®©æˆ‘ä»¬æ·±å…¥ç†è§£è¿™ä¸¤ä¸ªçœ‹ä¼¼ç®€å•å´æå…¶é‡è¦çš„æ¦‚å¿µã€‚

#### ğŸ“¦ ä¸ºä»€ä¹ˆéœ€è¦æ‰¹å¤„ç†ï¼Ÿ

```python
import numpy as np
import time
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import seaborn as sns

def æ‰¹å¤„ç†æ•ˆç‡å¯¹æ¯”():
    """å¯¹æ¯”é€ä¸ªå¤„ç†å’Œæ‰¹å¤„ç†çš„æ•ˆç‡å·®å¼‚"""
    
    # æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„çŸ©é˜µè¿ç®—
    def process_single(x, W):
        """é€ä¸ªå¤„ç†"""
        return np.dot(W, x)
    
    def process_batch(X, W):
        """æ‰¹é‡å¤„ç†"""
        return np.dot(W, X.T).T
    
    # å‚æ•°è®¾ç½®
    input_dim = 512
    output_dim = 256
    W = np.random.randn(output_dim, input_dim)
    
    # ä¸åŒæ‰¹æ¬¡å¤§å°çš„æµ‹è¯•
    batch_sizes = [1, 8, 16, 32, 64, 128, 256]
    n_samples = 1024
    
    single_times = []
    batch_times = []
    speedups = []
    
    for batch_size in batch_sizes:
        # ç”Ÿæˆæ•°æ®
        X = np.random.randn(n_samples, input_dim)
        
        # é€ä¸ªå¤„ç†
        start = time.time()
        results_single = []
        for i in range(n_samples):
            results_single.append(process_single(X[i], W))
        single_time = time.time() - start
        single_times.append(single_time)
        
        # æ‰¹å¤„ç†
        start = time.time()
        results_batch = []
        for i in range(0, n_samples, batch_size):
            batch = X[i:i+batch_size]
            results_batch.append(process_batch(batch, W))
        batch_time = time.time() - start
        batch_times.append(batch_time)
        
        speedups.append(single_time / batch_time)
    
    # å¯è§†åŒ–ç»“æœ
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # è¿è¡Œæ—¶é—´å¯¹æ¯”
    x = np.arange(len(batch_sizes))
    width = 0.35
    
    bars1 = ax1.bar(x - width/2, single_times, width, label='é€ä¸ªå¤„ç†', color='red', alpha=0.7)
    bars2 = ax1.bar(x + width/2, batch_times, width, label='æ‰¹å¤„ç†', color='green', alpha=0.7)
    
    ax1.set_xlabel('æ‰¹æ¬¡å¤§å°')
    ax1.set_ylabel('è¿è¡Œæ—¶é—´ (ç§’)')
    ax1.set_title('å¤„ç†æ—¶é—´å¯¹æ¯”')
    ax1.set_xticks(x)
    ax1.set_xticklabels(batch_sizes)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # åŠ é€Ÿæ¯”
    ax2.plot(batch_sizes, speedups, 'bo-', markersize=10, linewidth=2)
    ax2.set_xlabel('æ‰¹æ¬¡å¤§å°')
    ax2.set_ylabel('åŠ é€Ÿæ¯”')
    ax2.set_title('æ‰¹å¤„ç†å¸¦æ¥çš„åŠ é€Ÿæ•ˆæœ')
    ax2.grid(True, alpha=0.3)
    ax2.set_xscale('log', base=2)
    
    # æ ‡æ³¨æœ€ä¼˜ç‚¹
    max_speedup_idx = np.argmax(speedups)
    ax2.annotate(f'æœ€ä¼˜æ‰¹æ¬¡å¤§å°: {batch_sizes[max_speedup_idx]}',
                xy=(batch_sizes[max_speedup_idx], speedups[max_speedup_idx]),
                xytext=(batch_sizes[max_speedup_idx]*2, speedups[max_speedup_idx]*0.9),
                arrowprops=dict(arrowstyle='->', color='red'),
                fontsize=12, color='red')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸš€ æ‰¹å¤„ç†çš„ä¼˜åŠ¿ï¼š")
    print(f"1. æœ€é«˜åŠ é€Ÿæ¯”: {max(speedups):.2f}x")
    print(f"2. æœ€ä¼˜æ‰¹æ¬¡å¤§å°: {batch_sizes[max_speedup_idx]}")
    print("3. åŸå› ï¼šçŸ©é˜µè¿ç®—çš„å¹¶è¡ŒåŒ–ã€ç¼“å­˜åˆ©ç”¨ç‡æå‡")

æ‰¹å¤„ç†æ•ˆç‡å¯¹æ¯”()
```

#### ğŸ§® æ‰¹å¤„ç†çš„æ•°å­¦åŸç†

```python
def æ‰¹å¤„ç†æ•°å­¦åŸç†():
    """å±•ç¤ºæ‰¹å¤„ç†åœ¨ç¥ç»ç½‘ç»œä¸­çš„æ•°å­¦è¿ç®—"""
    
    print("ğŸ“ æ‰¹å¤„ç†çš„æ•°å­¦æœ¬è´¨ï¼šä»å‘é‡è¿ç®—åˆ°çŸ©é˜µè¿ç®—\n")
    
    # å•æ ·æœ¬å‰å‘ä¼ æ’­
    print("1ï¸âƒ£ å•æ ·æœ¬å¤„ç†:")
    print("   è¾“å…¥: x âˆˆ R^d")
    print("   æƒé‡: W âˆˆ R^(hÃ—d)")
    print("   è¾“å‡º: y = Wx + b âˆˆ R^h")
    print("   è®¡ç®—å¤æ‚åº¦: O(hÃ—d)")
    
    print("\n2ï¸âƒ£ æ‰¹å¤„ç† (batch_size = B):")
    print("   è¾“å…¥: X âˆˆ R^(BÃ—d)")
    print("   æƒé‡: W âˆˆ R^(hÃ—d)")
    print("   è¾“å‡º: Y = XW^T + b âˆˆ R^(BÃ—h)")
    print("   è®¡ç®—å¤æ‚åº¦: O(BÃ—hÃ—d)")
    print("   ä½†åˆ©ç”¨äº†BLASä¼˜åŒ–ï¼Œå®é™…è¿è¡Œæ›´å¿«ï¼")
    
    # å¯è§†åŒ–çŸ©é˜µè¿ç®—
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # å•æ ·æœ¬è¿ç®—
    ax1.set_title('å•æ ·æœ¬è¿ç®—', fontsize=14)
    ax1.set_xlim(0, 10)
    ax1.set_ylim(0, 10)
    ax1.axis('off')
    
    # ç”»çŸ©é˜µ
    # è¾“å…¥å‘é‡ x
    x_rect = Rectangle((1, 4), 0.5, 3, facecolor='lightblue', edgecolor='black')
    ax1.add_patch(x_rect)
    ax1.text(1.25, 5.5, 'x\n(d)', ha='center', va='center', fontsize=12)
    
    # æƒé‡çŸ©é˜µ W
    W_rect = Rectangle((3, 3), 2, 4, facecolor='lightgreen', edgecolor='black')
    ax1.add_patch(W_rect)
    ax1.text(4, 5, 'W\n(hÃ—d)', ha='center', va='center', fontsize=12)
    
    # è¾“å‡ºå‘é‡ y
    y_rect = Rectangle((7, 3.5), 0.5, 3, facecolor='lightcoral', edgecolor='black')
    ax1.add_patch(y_rect)
    ax1.text(7.25, 5, 'y\n(h)', ha='center', va='center', fontsize=12)
    
    # ç®­å¤´
    ax1.arrow(1.5, 5.5, 1.3, 0, head_width=0.2, head_length=0.1, fc='black', ec='black')
    ax1.arrow(5.2, 5, 1.5, 0, head_width=0.2, head_length=0.1, fc='black', ec='black')
    ax1.text(2.25, 6, 'Ã—', fontsize=16)
    ax1.text(6, 5.5, '=', fontsize=16)
    
    # æ‰¹å¤„ç†è¿ç®—
    ax2.set_title('æ‰¹å¤„ç†è¿ç®—', fontsize=14)
    ax2.set_xlim(0, 10)
    ax2.set_ylim(0, 10)
    ax2.axis('off')
    
    # è¾“å…¥çŸ©é˜µ X
    X_rect = Rectangle((1, 3), 1.5, 4, facecolor='lightblue', edgecolor='black')
    ax2.add_patch(X_rect)
    ax2.text(1.75, 5, 'X\n(BÃ—d)', ha='center', va='center', fontsize=12)
    
    # æƒé‡çŸ©é˜µ W^T
    W_rect = Rectangle((3.5, 2), 2, 5, facecolor='lightgreen', edgecolor='black')
    ax2.add_patch(W_rect)
    ax2.text(4.5, 4.5, 'W^T\n(dÃ—h)', ha='center', va='center', fontsize=12)
    
    # è¾“å‡ºçŸ©é˜µ Y
    Y_rect = Rectangle((7, 3), 1.5, 4, facecolor='lightcoral', edgecolor='black')
    ax2.add_patch(Y_rect)
    ax2.text(7.75, 5, 'Y\n(BÃ—h)', ha='center', va='center', fontsize=12)
    
    # ç®­å¤´
    ax2.arrow(2.6, 5, 0.8, 0, head_width=0.2, head_length=0.1, fc='black', ec='black')
    ax2.arrow(5.6, 5, 1.2, 0, head_width=0.2, head_length=0.1, fc='black', ec='black')
    ax2.text(3, 5.5, 'Ã—', fontsize=16)
    ax2.text(6.3, 5.5, '=', fontsize=16)
    
    plt.tight_layout()
    plt.show()
    
    # å®é™…è®¡ç®—ç¤ºä¾‹
    print("\nğŸ”¢ å…·ä½“è®¡ç®—ç¤ºä¾‹ï¼š")
    
    batch_size = 3
    input_dim = 4
    hidden_dim = 2
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    X = np.random.randn(batch_size, input_dim).round(2)
    W = np.random.randn(hidden_dim, input_dim).round(2)
    b = np.random.randn(hidden_dim).round(2)
    
    print(f"\nè¾“å…¥ X ({batch_size}Ã—{input_dim}):")
    print(X)
    print(f"\næƒé‡ W ({hidden_dim}Ã—{input_dim}):")
    print(W)
    print(f"\nåç½® b ({hidden_dim}):")
    print(b)
    
    # æ‰¹å¤„ç†è®¡ç®—
    Y = X @ W.T + b
    print(f"\nè¾“å‡º Y = XW^T + b ({batch_size}Ã—{hidden_dim}):")
    print(Y.round(2))

æ‰¹å¤„ç†æ•°å­¦åŸç†()
```

#### ğŸ¯ Paddingï¼šè®©ä¸è§„åˆ™æ•°æ®å˜æ•´é½

```python
def paddingæ¼”ç¤º():
    """å±•ç¤ºä¸åŒçš„paddingç­–ç•¥"""
    
    # æ¨¡æ‹Ÿä¸åŒé•¿åº¦çš„åºåˆ—
    sequences = [
        [1, 2, 3],
        [4, 5, 6, 7, 8],
        [9, 10],
        [11, 12, 13, 14]
    ]
    
    print("ğŸ¯ åŸå§‹åºåˆ—ï¼ˆé•¿åº¦ä¸ä¸€ï¼‰ï¼š")
    for i, seq in enumerate(sequences):
        print(f"  åºåˆ—{i+1}: {seq} (é•¿åº¦={len(seq)})")
    
    # ä¸åŒçš„paddingç­–ç•¥
    def pad_sequences(sequences, padding='post', truncating='post', maxlen=None, value=0):
        """å®ç°ç®€å•çš„paddingåŠŸèƒ½"""
        if maxlen is None:
            maxlen = max(len(seq) for seq in sequences)
        
        padded = []
        for seq in sequences:
            if len(seq) > maxlen:
                # æˆªæ–­
                if truncating == 'post':
                    new_seq = seq[:maxlen]
                else:  # pre
                    new_seq = seq[-maxlen:]
            else:
                # å¡«å……
                pad_length = maxlen - len(seq)
                if padding == 'post':
                    new_seq = seq + [value] * pad_length
                else:  # pre
                    new_seq = [value] * pad_length + seq
            padded.append(new_seq)
        
        return np.array(padded)
    
    # å±•ç¤ºä¸åŒpaddingç­–ç•¥
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    strategies = [
        ('åå¡«å……', 'post', 0),
        ('å‰å¡«å……', 'pre', 0),
        ('ç‰¹æ®Šæ ‡è®°å¡«å……', 'post', -1),
        ('å¾ªç¯å¡«å……', 'post', None)
    ]
    
    for idx, (ax, (name, padding_type, pad_value)) in enumerate(zip(axes.flat, strategies)):
        if name == 'å¾ªç¯å¡«å……':
            # ç‰¹æ®Šå¤„ç†å¾ªç¯å¡«å……
            maxlen = max(len(seq) for seq in sequences)
            padded = []
            for seq in sequences:
                if len(seq) < maxlen:
                    n_repeat = maxlen // len(seq) + 1
                    extended = (seq * n_repeat)[:maxlen]
                else:
                    extended = seq[:maxlen]
                padded.append(extended)
            padded = np.array(padded)
        else:
            padded = pad_sequences(sequences, padding=padding_type, value=pad_value)
        
        # å¯è§†åŒ–
        im = ax.imshow(padded, cmap='RdYlBu', aspect='auto')
        ax.set_title(f'{name}', fontsize=14)
        ax.set_xlabel('ä½ç½®')
        ax.set_ylabel('åºåˆ—')
        ax.set_yticks(range(len(sequences)))
        ax.set_yticklabels([f'åºåˆ—{i+1}' for i in range(len(sequences))])
        
        # æ ‡æ³¨æ•°å€¼
        for i in range(padded.shape[0]):
            for j in range(padded.shape[1]):
                text = ax.text(j, i, str(padded[i, j]),
                             ha="center", va="center", color="black", fontsize=10)
        
        plt.colorbar(im, ax=ax)
    
    plt.tight_layout()
    plt.show()
    
    print("\nğŸ“‹ Paddingç­–ç•¥å¯¹æ¯”ï¼š")
    print("1. åå¡«å……(Post-padding): åœ¨åºåˆ—æœ«å°¾æ·»åŠ å¡«å……å€¼")
    print("2. å‰å¡«å……(Pre-padding): åœ¨åºåˆ—å¼€å¤´æ·»åŠ å¡«å……å€¼")
    print("3. ç‰¹æ®Šæ ‡è®°å¡«å……: ä½¿ç”¨ç‰¹æ®Šå€¼(å¦‚-1)æ ‡è®°å¡«å……ä½ç½®")
    print("4. å¾ªç¯å¡«å……: é‡å¤åºåˆ—å†…å®¹è¿›è¡Œå¡«å……")

paddingæ¼”ç¤º()
```

#### ğŸ­ Maskæœºåˆ¶ï¼šå‘Šè¯‰æ¨¡å‹å“ªäº›æ˜¯"çœŸå®"çš„

```python
def maskæœºåˆ¶æ¼”ç¤º():
    """å±•ç¤ºå¦‚ä½•ä½¿ç”¨maskå¿½ç•¥paddingéƒ¨åˆ†"""
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ³¨æ„åŠ›æœºåˆ¶ç¤ºä¾‹
    class SimplifiedAttention:
        def __init__(self):
            pass
        
        def compute_attention(self, query, key, value, mask=None):
            """ç®€åŒ–çš„æ³¨æ„åŠ›è®¡ç®—"""
            # QÂ·K^T
            scores = np.matmul(query, key.T)
            
            # åº”ç”¨mask
            if mask is not None:
                # å°†paddingä½ç½®çš„åˆ†æ•°è®¾ä¸ºæå°å€¼
                scores = np.where(mask, scores, -1e9)
            
            # Softmax
            attention_weights = self.softmax(scores)
            
            # åŠ æƒæ±‚å’Œ
            output = np.matmul(attention_weights, value)
            
            return output, attention_weights
        
        def softmax(self, x):
            exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
            return exp_x / np.sum(exp_x, axis=-1, keepdims=True)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    batch_size = 2
    seq_len = 5
    hidden_dim = 4
    
    # æ¨¡æ‹Ÿä¸¤ä¸ªåºåˆ—ï¼Œç¬¬ä¸€ä¸ªé•¿åº¦ä¸º3ï¼Œç¬¬äºŒä¸ªé•¿åº¦ä¸º4
    sequences = np.random.randn(batch_size, seq_len, hidden_dim)
    
    # åˆ›å»ºmask (Trueè¡¨ç¤ºæœ‰æ•ˆä½ç½®ï¼ŒFalseè¡¨ç¤ºpadding)
    mask = np.array([
        [True, True, True, False, False],    # åºåˆ—1ï¼šå‰3ä¸ªä½ç½®æœ‰æ•ˆ
        [True, True, True, True, False]       # åºåˆ—2ï¼šå‰4ä¸ªä½ç½®æœ‰æ•ˆ
    ])
    
    # å¯è§†åŒ–
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    
    attention = SimplifiedAttention()
    
    for batch_idx in range(batch_size):
        # æå–å•ä¸ªåºåˆ—
        seq = sequences[batch_idx]
        seq_mask = mask[batch_idx]
        
        # æ— maskçš„æ³¨æ„åŠ›
        _, weights_no_mask = attention.compute_attention(seq, seq, seq, mask=None)
        
        # æœ‰maskçš„æ³¨æ„åŠ›
        mask_expanded = seq_mask[:, np.newaxis] & seq_mask[np.newaxis, :]
        _, weights_with_mask = attention.compute_attention(seq, seq, seq, mask=mask_expanded)
        
        # å¯è§†åŒ–åºåˆ—
        ax = axes[batch_idx, 0]
        im = ax.imshow(seq.T, cmap='coolwarm', aspect='auto')
        ax.set_title(f'åºåˆ—{batch_idx+1} (æœ‰æ•ˆé•¿åº¦={np.sum(seq_mask)})')
        ax.set_xlabel('ä½ç½®')
        ax.set_ylabel('ç‰¹å¾ç»´åº¦')
        
        # æ ‡è®°paddingä½ç½®
        for i in range(seq_len):
            if not seq_mask[i]:
                ax.axvline(x=i-0.5, color='red', linestyle='--', linewidth=2)
                ax.axvline(x=i+0.5, color='red', linestyle='--', linewidth=2)
                ax.text(i, -0.5, 'PAD', ha='center', va='top', color='red', fontsize=10)
        
        # æ— maskçš„æ³¨æ„åŠ›æƒé‡
        ax = axes[batch_idx, 1]
        im = ax.imshow(weights_no_mask, cmap='Blues', vmin=0, vmax=1)
        ax.set_title('æ— Maskçš„æ³¨æ„åŠ›æƒé‡')
        ax.set_xlabel('Keyä½ç½®')
        ax.set_ylabel('Queryä½ç½®')
        plt.colorbar(im, ax=ax)
        
        # æœ‰maskçš„æ³¨æ„åŠ›æƒé‡
        ax = axes[batch_idx, 2]
        im = ax.imshow(weights_with_mask, cmap='Blues', vmin=0, vmax=1)
        ax.set_title('æœ‰Maskçš„æ³¨æ„åŠ›æƒé‡')
        ax.set_xlabel('Keyä½ç½®')
        ax.set_ylabel('Queryä½ç½®')
        plt.colorbar(im, ax=ax)
        
        # æ ‡æ³¨maskåŒºåŸŸ
        for i in range(seq_len):
            for j in range(seq_len):
                if not mask_expanded[i, j]:
                    rect = Rectangle((j-0.5, i-0.5), 1, 1, 
                                   facecolor='red', alpha=0.3)
                    ax.add_patch(rect)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ­ Maskæœºåˆ¶çš„ä½œç”¨ï¼š")
    print("1. é˜²æ­¢æ¨¡å‹å…³æ³¨paddingä½ç½®")
    print("2. ç¡®ä¿paddingä¸å½±å“æ¨¡å‹è¾“å‡º")
    print("3. åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­ç‰¹åˆ«é‡è¦")
    print("4. ä¸åŒä»»åŠ¡å¯èƒ½éœ€è¦ä¸åŒçš„maskç­–ç•¥")

maskæœºåˆ¶æ¼”ç¤º()
```

#### ğŸš€ æ‰¹å¤„ç†åœ¨GPUä¸Šçš„å¨åŠ›

```python
def GPUæ‰¹å¤„ç†ä¼˜åŠ¿():
    """å±•ç¤ºæ‰¹å¤„ç†åœ¨GPUä¸Šçš„ä¼˜åŠ¿"""
    
    # GPU vs CPUçš„ç†è®ºå¯¹æ¯”
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
    
    # 1. å•æ ·æœ¬å¤„ç†
    ax1.set_title('å•æ ·æœ¬å¤„ç†', fontsize=14)
    ax1.set_xlim(0, 10)
    ax1.set_ylim(0, 10)
    ax1.axis('off')
    
    # CPUæ ¸å¿ƒ
    cpu_core = Rectangle((1, 4), 2, 2, facecolor='lightblue', edgecolor='black')
    ax1.add_patch(cpu_core)
    ax1.text(2, 5, 'CPU\næ ¸å¿ƒ', ha='center', va='center', fontsize=10)
    
    # ä»»åŠ¡é˜Ÿåˆ—
    tasks = ['æ ·æœ¬1', 'æ ·æœ¬2', 'æ ·æœ¬3', 'æ ·æœ¬4']
    for i, task in enumerate(tasks):
        rect = Rectangle((5, 6.5-i*1.5), 1.5, 1, 
                        facecolor='lightyellow', edgecolor='black')
        ax1.add_patch(rect)
        ax1.text(5.75, 7-i*1.5, task, ha='center', va='center', fontsize=9)
    
    ax1.arrow(3.2, 5, 1.5, 0, head_width=0.2, head_length=0.1, fc='red', ec='red')
    ax1.text(3.5, 5.5, 'ä¸²è¡Œ', color='red', fontsize=10)
    ax1.text(5, 1, 'æ—¶é—´ = 4T', fontsize=12, weight='bold')
    
    # 2. CPUæ‰¹å¤„ç†
    ax2.set_title('CPUæ‰¹å¤„ç†', fontsize=14)
    ax2.set_xlim(0, 10)
    ax2.set_ylim(0, 10)
    ax2.axis('off')
    
    # å¤šä¸ªCPUæ ¸å¿ƒ
    for i in range(4):
        cpu_core = Rectangle((1, 6.5-i*1.5), 2, 1.2, 
                           facecolor='lightblue', edgecolor='black')
        ax2.add_patch(cpu_core)
        ax2.text(2, 7.1-i*1.5, f'æ ¸å¿ƒ{i+1}', ha='center', va='center', fontsize=9)
    
    # æ‰¹å¤„ç†ä»»åŠ¡
    batch_rect = Rectangle((5, 3), 3, 4, facecolor='lightgreen', edgecolor='black')
    ax2.add_patch(batch_rect)
    ax2.text(6.5, 5, 'æ‰¹å¤„ç†\n(4ä¸ªæ ·æœ¬)', ha='center', va='center', fontsize=10)
    
    ax2.arrow(3.2, 5, 1.5, 0, head_width=0.2, head_length=0.1, fc='green', ec='green')
    ax2.text(3.5, 5.5, 'å¹¶è¡Œ', color='green', fontsize=10)
    ax2.text(5, 1, 'æ—¶é—´ â‰ˆ 1.5T', fontsize=12, weight='bold')
    
    # 3. GPUæ‰¹å¤„ç†
    ax3.set_title('GPUæ‰¹å¤„ç†', fontsize=14)
    ax3.set_xlim(0, 10)
    ax3.set_ylim(0, 10)
    ax3.axis('off')
    
    # GPUæ ¸å¿ƒé˜µåˆ—
    for i in range(8):
        for j in range(8):
            gpu_core = Rectangle((1+j*0.35, 7-i*0.35), 0.3, 0.3, 
                               facecolor='lightcoral', edgecolor='black', linewidth=0.5)
            ax3.add_patch(gpu_core)
    
    ax3.text(2.4, 8.5, 'GPUæ ¸å¿ƒé˜µåˆ—\n(æ•°åƒä¸ª)', ha='center', va='center', fontsize=10)
    
    # å¤§æ‰¹é‡å¤„ç†
    big_batch = Rectangle((5, 2), 3, 6, facecolor='darkgreen', edgecolor='black')
    ax3.add_patch(big_batch)
    ax3.text(6.5, 5, 'å¤§æ‰¹é‡\nå¤„ç†\n(ä¸Šç™¾ä¸ª\næ ·æœ¬)', ha='center', va='center', 
             fontsize=10, color='white')
    
    ax3.arrow(4.2, 5, 0.6, 0, head_width=0.2, head_length=0.1, fc='darkgreen', ec='darkgreen')
    ax3.text(4, 5.5, 'è¶…å¹¶è¡Œ', color='darkgreen', fontsize=10, weight='bold')
    ax3.text(5, 1, 'æ—¶é—´ â‰ˆ T', fontsize=12, weight='bold')
    
    plt.tight_layout()
    plt.show()
    
    # æ‰¹å¤„ç†å¤§å°å¯¹GPUåˆ©ç”¨ç‡çš„å½±å“
    batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]
    gpu_utilization = [5, 10, 20, 40, 65, 85, 95, 98, 99, 99]
    memory_usage = [10, 15, 25, 40, 60, 80, 90, 95, 98, 100]
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # GPUåˆ©ç”¨ç‡
    ax1.plot(batch_sizes, gpu_utilization, 'bo-', markersize=8, linewidth=2)
    ax1.fill_between(batch_sizes, gpu_utilization, alpha=0.3)
    ax1.set_xlabel('æ‰¹æ¬¡å¤§å°')
    ax1.set_ylabel('GPUåˆ©ç”¨ç‡ (%)')
    ax1.set_title('æ‰¹æ¬¡å¤§å°å¯¹GPUåˆ©ç”¨ç‡çš„å½±å“')
    ax1.set_xscale('log', base=2)
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=90, color='red', linestyle='--', label='é«˜æ•ˆåˆ©ç”¨é˜ˆå€¼')
    ax1.legend()
    
    # å†…å­˜ä½¿ç”¨
    ax2.plot(batch_sizes, memory_usage, 'ro-', markersize=8, linewidth=2, label='æ˜¾å­˜ä½¿ç”¨')
    ax2.fill_between(batch_sizes, memory_usage, alpha=0.3, color='red')
    ax2.set_xlabel('æ‰¹æ¬¡å¤§å°')
    ax2.set_ylabel('æ˜¾å­˜ä½¿ç”¨ç‡ (%)')
    ax2.set_title('æ‰¹æ¬¡å¤§å°å¯¹æ˜¾å­˜ä½¿ç”¨çš„å½±å“')
    ax2.set_xscale('log', base=2)
    ax2.grid(True, alpha=0.3)
    ax2.axhline(y=100, color='darkred', linestyle='--', label='æ˜¾å­˜ä¸Šé™')
    ax2.legend()
    
    # æ ‡æ³¨æœ€ä¼˜åŒºé—´
    optimal_start = 32
    optimal_end = 128
    for ax in [ax1, ax2]:
        ax.axvspan(optimal_start, optimal_end, alpha=0.2, color='green', label='æœ€ä¼˜åŒºé—´')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ’¡ GPUæ‰¹å¤„ç†çš„å…³é”®ç‚¹ï¼š")
    print("1. æ‰¹æ¬¡å¤ªå°ï¼šGPUåˆ©ç”¨ç‡ä½ï¼Œæµªè´¹è®¡ç®—èµ„æº")
    print("2. æ‰¹æ¬¡å¤ªå¤§ï¼šå¯èƒ½è¶…å‡ºæ˜¾å­˜é™åˆ¶")
    print("3. æœ€ä¼˜æ‰¹æ¬¡ï¼šåœ¨GPUåˆ©ç”¨ç‡å’Œæ˜¾å­˜é™åˆ¶é—´å¹³è¡¡")
    print("4. é€šå¸¸32-128æ˜¯ä¸é”™çš„èµ·ç‚¹")

GPUæ‰¹å¤„ç†ä¼˜åŠ¿()
```

#### ğŸ”§ åŠ¨æ€æ‰¹å¤„ç†ä¸å˜é•¿åºåˆ—å¤„ç†

```python
def åŠ¨æ€æ‰¹å¤„ç†ç­–ç•¥():
    """å±•ç¤ºå¤„ç†å˜é•¿åºåˆ—çš„é«˜çº§ç­–ç•¥"""
    
    # ç”Ÿæˆä¸åŒé•¿åº¦çš„åºåˆ—
    np.random.seed(42)
    n_sequences = 100
    sequences = []
    
    for _ in range(n_sequences):
        length = np.random.randint(10, 200)
        seq = np.random.randn(length, 128)  # 128ç»´ç‰¹å¾
        sequences.append(seq)
    
    lengths = [len(seq) for seq in sequences]
    
    # 1. åˆ†æ¡¶ç­–ç•¥
    def bucket_sequences(sequences, bucket_boundaries):
        """å°†åºåˆ—æŒ‰é•¿åº¦åˆ†ç»„"""
        buckets = {i: [] for i in range(len(bucket_boundaries) + 1)}
        
        for seq in sequences:
            length = len(seq)
            bucket_id = 0
            for i, boundary in enumerate(bucket_boundaries):
                if length > boundary:
                    bucket_id = i + 1
                else:
                    break
            buckets[bucket_id].append(seq)
        
        return buckets
    
    # è®¾ç½®æ¡¶è¾¹ç•Œ
    bucket_boundaries = [30, 60, 100, 150]
    buckets = bucket_sequences(sequences, bucket_boundaries)
    
    # å¯è§†åŒ–åˆ†æ¡¶ç»“æœ
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
    
    # åºåˆ—é•¿åº¦åˆ†å¸ƒ
    ax1.hist(lengths, bins=30, alpha=0.7, color='blue', edgecolor='black')
    ax1.set_xlabel('åºåˆ—é•¿åº¦')
    ax1.set_ylabel('æ•°é‡')
    ax1.set_title('åŸå§‹åºåˆ—é•¿åº¦åˆ†å¸ƒ')
    
    # æ·»åŠ æ¡¶è¾¹ç•Œçº¿
    for boundary in bucket_boundaries:
        ax1.axvline(x=boundary, color='red', linestyle='--', linewidth=2)
    
    # åˆ†æ¡¶ç»“æœ
    bucket_sizes = [len(bucket) for bucket in buckets.values()]
    bucket_labels = ['0-30', '31-60', '61-100', '101-150', '151+']
    
    ax2.bar(bucket_labels, bucket_sizes, color='green', alpha=0.7, edgecolor='black')
    ax2.set_xlabel('é•¿åº¦åŒºé—´')
    ax2.set_ylabel('åºåˆ—æ•°é‡')
    ax2.set_title('åˆ†æ¡¶ç»“æœ')
    ax2.grid(True, alpha=0.3, axis='y')
    
    # Paddingæµªè´¹å¯¹æ¯”
    # è®¡ç®—ä¸åŒç­–ç•¥çš„paddingæµªè´¹
    strategies = {
        'å…¨å±€padding': sum(max(lengths) - l for l in lengths),
        'åˆ†æ¡¶padding': 0
    }
    
    # è®¡ç®—åˆ†æ¡¶paddingæµªè´¹
    for bucket_id, bucket_seqs in buckets.items():
        if bucket_seqs:
            bucket_lengths = [len(seq) for seq in bucket_seqs]
            max_len = max(bucket_lengths)
            strategies['åˆ†æ¡¶padding'] += sum(max_len - l for l in bucket_lengths)
    
    # æ·»åŠ åŠ¨æ€batchingï¼ˆç›¸ä¼¼é•¿åº¦ç»„åˆï¼‰
    sorted_lengths = sorted(lengths)
    dynamic_waste = 0
    batch_size = 8
    
    for i in range(0, len(sorted_lengths), batch_size):
        batch = sorted_lengths[i:i+batch_size]
        if batch:
            max_len = max(batch)
            dynamic_waste += sum(max_len - l for l in batch)
    
    strategies['åŠ¨æ€batching'] = dynamic_waste
    
    # å¯è§†åŒ–paddingæµªè´¹
    strategy_names = list(strategies.keys())
    waste_values = list(strategies.values())
    
    bars = ax3.bar(strategy_names, waste_values, 
                    color=['red', 'yellow', 'green'], alpha=0.7, edgecolor='black')
    ax3.set_ylabel('Paddingæµªè´¹ï¼ˆæ€»å…ƒç´ æ•°ï¼‰')
    ax3.set_title('ä¸åŒç­–ç•¥çš„Paddingæµªè´¹å¯¹æ¯”')
    ax3.grid(True, alpha=0.3, axis='y')
    
    # æ ‡æ³¨èŠ‚çœç™¾åˆ†æ¯”
    baseline = waste_values[0]
    for i, (bar, waste) in enumerate(zip(bars[1:], waste_values[1:]), 1):
        saving = (baseline - waste) / baseline * 100
        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1000,
                f'-{saving:.0f}%', ha='center', va='bottom', 
                fontsize=10, color='green', weight='bold')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ¯ é«˜æ•ˆæ‰¹å¤„ç†ç­–ç•¥ï¼š")
    print("1. åˆ†æ¡¶(Bucketing)ï¼šç›¸ä¼¼é•¿åº¦çš„åºåˆ—æ”¾åœ¨ä¸€èµ·")
    print("2. åŠ¨æ€batchingï¼šæ ¹æ®å½“å‰åºåˆ—é•¿åº¦åŠ¨æ€ç»„æ‰¹")
    print("3. æ’åºbatchingï¼šå…ˆæ’åºå†åˆ†æ‰¹ï¼Œæœ€å°åŒ–padding")
    print(f"4. æœ¬ä¾‹ä¸­åˆ†æ¡¶å¯èŠ‚çœ{(baseline-strategies['åˆ†æ¡¶padding'])/baseline*100:.0f}%çš„padding")

åŠ¨æ€æ‰¹å¤„ç†ç­–ç•¥()
```

#### ğŸ’¾ å†…å­˜æ•ˆç‡ï¼šæ‰¹å¤„ç†çš„å¦ä¸€é¢

```python
def å†…å­˜æ•ˆç‡åˆ†æ():
    """åˆ†ææ‰¹å¤„ç†å¯¹å†…å­˜ä½¿ç”¨çš„å½±å“"""
    
    # æ¨¡æ‹Ÿä¸åŒæ¨¡å‹å¤§å°å’Œæ‰¹æ¬¡å¤§å°çš„å†…å­˜ä½¿ç”¨
    model_params = {
        'BERT-Base': 110e6,      # 110Må‚æ•°
        'BERT-Large': 340e6,     # 340Må‚æ•°
        'GPT-2': 1.5e9,          # 1.5Bå‚æ•°
        'GPT-3': 175e9           # 175Bå‚æ•°
    }
    
    # è®¡ç®—å†…å­˜ä½¿ç”¨ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
    def calculate_memory(n_params, batch_size, seq_len=512, 
                        bytes_per_param=4, activation_multiplier=4):
        """
        è®¡ç®—æ¨¡å‹å†…å­˜ä½¿ç”¨
        - å‚æ•°å†…å­˜ï¼šn_params * bytes_per_param
        - æ¢¯åº¦å†…å­˜ï¼šåŒå‚æ•°å†…å­˜
        - æ¿€æ´»å†…å­˜ï¼šbatch_size * seq_len * hidden_dim * activation_multiplier
        """
        param_memory = n_params * bytes_per_param / 1e9  # GB
        grad_memory = param_memory  # æ¢¯åº¦å ç”¨åŒæ ·å†…å­˜
        
        # ç®€åŒ–æ¿€æ´»å†…å­˜è®¡ç®—
        hidden_dim = int(np.sqrt(n_params / 12))  # ç²—ç•¥ä¼°è®¡
        activation_memory = (batch_size * seq_len * hidden_dim * 
                           activation_multiplier * bytes_per_param / 1e9)
        
        total_memory = param_memory + grad_memory + activation_memory
        
        return {
            'param': param_memory,
            'grad': grad_memory,
            'activation': activation_memory,
            'total': total_memory
        }
    
    # åˆ†æä¸åŒæ‰¹æ¬¡å¤§å°
    batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128]
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    axes = axes.ravel()
    
    for idx, (model_name, n_params) in enumerate(model_params.items()):
        ax = axes[idx]
        
        memory_breakdown = []
        for bs in batch_sizes:
            mem = calculate_memory(n_params, bs)
            memory_breakdown.append(mem)
        
        # å †å æ¡å½¢å›¾
        param_mem = [m['param'] for m in memory_breakdown]
        grad_mem = [m['grad'] for m in memory_breakdown]
        activation_mem = [m['activation'] for m in memory_breakdown]
        
        x = np.arange(len(batch_sizes))
        width = 0.6
        
        p1 = ax.bar(x, param_mem, width, label='å‚æ•°å†…å­˜', color='lightblue')
        p2 = ax.bar(x, grad_mem, width, bottom=param_mem, 
                    label='æ¢¯åº¦å†…å­˜', color='lightgreen')
        p3 = ax.bar(x, activation_mem, width,
                    bottom=np.array(param_mem) + np.array(grad_mem), 
                    label='æ¿€æ´»å†…å­˜', color='lightcoral')
        
        ax.set_xlabel('æ‰¹æ¬¡å¤§å°')
        ax.set_ylabel('å†…å­˜ä½¿ç”¨ (GB)')
        ax.set_title(f'{model_name} ({n_params/1e9:.1f}Bå‚æ•°)')
        ax.set_xticks(x)
        ax.set_xticklabels(batch_sizes)
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')
        
        # æ ‡æ³¨æ€»å†…å­˜
        for i, mem in enumerate(memory_breakdown):
            total = mem['total']
            ax.text(i, total + 0.5, f'{total:.1f}GB', 
                   ha='center', va='bottom', fontsize=9)
        
        # æ·»åŠ GPUå†…å­˜é™åˆ¶çº¿
        gpu_limits = {'V100': 32, 'A100': 80}
        for gpu_name, limit in gpu_limits.items():
            ax.axhline(y=limit, color='red', linestyle='--', alpha=0.5)
            ax.text(len(batch_sizes)-1, limit+1, f'{gpu_name} limit', 
                   ha='right', fontsize=9, color='red')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ’¾ å†…å­˜ç®¡ç†è¦ç‚¹ï¼š")
    print("1. å‚æ•°å’Œæ¢¯åº¦å†…å­˜å›ºå®šï¼Œä¸éšæ‰¹æ¬¡å¤§å°å˜åŒ–")
    print("2. æ¿€æ´»å†…å­˜éšæ‰¹æ¬¡å¤§å°çº¿æ€§å¢é•¿")
    print("3. å¤§æ¨¡å‹çš„æ‰¹æ¬¡å¤§å°å—GPUå†…å­˜ä¸¥æ ¼é™åˆ¶")
    print("4. æ¢¯åº¦ç´¯ç§¯å¯ä»¥æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡è®­ç»ƒ")

å†…å­˜æ•ˆç‡åˆ†æ()
```

#### ğŸ“ æœ¬ç« å°ç»“

æ‰¹å¤„ç†å’ŒPaddingçœ‹ä¼¼ç®€å•ï¼Œå´æ˜¯æ·±åº¦å­¦ä¹ å·¥ç¨‹å®è·µä¸­çš„æ ¸å¿ƒæŠ€æœ¯ï¼š

1. **æ‰¹å¤„ç†çš„ä»·å€¼**ï¼š
   - å……åˆ†åˆ©ç”¨ç¡¬ä»¶å¹¶è¡Œè®¡ç®—èƒ½åŠ›
   - å¤§å¹…æå‡è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦
   - æ›´ç¨³å®šçš„æ¢¯åº¦ä¼°è®¡

2. **Paddingçš„å¿…è¦æ€§**ï¼š
   - å¤„ç†å˜é•¿åºåˆ—çš„ç»Ÿä¸€æ–¹æ¡ˆ
   - é…åˆMaskæœºåˆ¶ä¿è¯æ­£ç¡®æ€§
   - æƒè¡¡è®¡ç®—æ•ˆç‡å’Œå†…å­˜ä½¿ç”¨

3. **å®è·µè¦ç‚¹**ï¼š
   - æ‰¹æ¬¡å¤§å°éœ€è¦å¹³è¡¡é€Ÿåº¦å’Œå†…å­˜
   - åŠ¨æ€æ‰¹å¤„ç†å¯ä»¥å‡å°‘paddingæµªè´¹
   - GPUå’ŒCPUçš„æ‰¹å¤„ç†ç­–ç•¥ä¸åŒ

#### ğŸ’¡ å®ç”¨å»ºè®®

1. **é€‰æ‹©æ‰¹æ¬¡å¤§å°**ï¼š
   - ä»32æˆ–64å¼€å§‹å°è¯•
   - ç›‘æ§GPUåˆ©ç”¨ç‡å’Œå†…å­˜ä½¿ç”¨
   - è€ƒè™‘ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯çªç ´å†…å­˜é™åˆ¶

2. **å¤„ç†å˜é•¿åºåˆ—**ï¼š
   - ä¼˜å…ˆè€ƒè™‘åˆ†æ¡¶ç­–ç•¥
   - å®ç°é«˜æ•ˆçš„æ•°æ®åŠ è½½å™¨
   - æ³¨æ„paddingå¯¹æ¨¡å‹çš„å½±å“

3. **ä¼˜åŒ–æŠ€å·§**ï¼š
   - æ··åˆç²¾åº¦è®­ç»ƒèŠ‚çœå†…å­˜
   - åŠ¨æ€paddingå‡å°‘æµªè´¹
   - é¢„å…ˆæ’åºå¯ä»¥æé«˜æ•ˆç‡

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆè¯´æ‰¹å¤„ç†å¤§å°ä¼šå½±å“æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Ÿ
2. å¦‚ä½•åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­åè°ƒæ‰¹å¤„ç†ï¼Ÿ
3. Transformeræ¨¡å‹ä¸­çš„paddingéœ€è¦ç‰¹åˆ«æ³¨æ„ä»€ä¹ˆï¼Ÿ

ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†æ·±å…¥GPUçš„ä¸–ç•Œï¼Œç†è§£å¹¶è¡Œè®¡ç®—åŸºç¡€â€”â€”ä¸ºä»€ä¹ˆGPUç‰¹åˆ«é€‚åˆè®­ç»ƒAIï¼Ÿ

### ç¬¬10ç« ï¼šå¹¶è¡Œè®¡ç®—åŸºç¡€â€”â€”GPUä¸ºä»€ä¹ˆé€‚åˆè®­ç»ƒAIï¼Ÿ

#### ğŸ¯ æœ¬ç« å¯¼è¯»

æƒ³è±¡ä¸€ä¸ªåœºæ™¯ï¼šä½ éœ€è¦ç»™1000ä¸ªä¿¡å°è´´é‚®ç¥¨ã€‚

**æ–¹æ¡ˆA**ï¼šä½ ä¸€ä¸ªäººï¼Œæ¯ä¸ªä¿¡å°èŠ±6ç§’ï¼ˆæ’•é‚®ç¥¨3ç§’+è´´3ç§’ï¼‰ï¼Œæ€»å…±éœ€è¦100åˆ†é’Ÿã€‚

**æ–¹æ¡ˆB**ï¼šä½ æ‰¾æ¥100ä¸ªæœ‹å‹ï¼Œæ¯äººè´Ÿè´£10ä¸ªä¿¡å°ï¼Œå¤§å®¶åŒæ—¶å¼€å·¥ï¼Œ1åˆ†é’Ÿæå®šï¼

è¿™å°±æ˜¯**å¹¶è¡Œè®¡ç®—**çš„é­…åŠ›â€”â€”é€šè¿‡åŒæ—¶å¤„ç†å¤šä¸ªä»»åŠ¡æ¥åŠ é€Ÿè®¡ç®—ã€‚è€ŒGPUï¼Œå°±æ˜¯ä¸“é—¨ä¸ºè¿™ç§å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—è€Œç”Ÿçš„ç¡¬ä»¶ã€‚ä»Šå¤©ï¼Œè®©æˆ‘ä»¬æ·±å…¥äº†è§£ä¸ºä»€ä¹ˆGPUæˆä¸ºäº†AIè®­ç»ƒçš„ä¸»åŠ›å†›ã€‚

#### ğŸ—ï¸ CPU vs GPUï¼šæ¶æ„å¤§ä¸åŒ

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle, FancyBboxPatch, Circle
import matplotlib.patches as mpatches
from matplotlib.collections import PatchCollection

def CPU_GPUæ¶æ„å¯¹æ¯”():
    """å¯è§†åŒ–CPUå’ŒGPUçš„æ¶æ„å·®å¼‚"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    
    # CPUæ¶æ„
    ax1.set_title('CPUæ¶æ„ï¼ˆå°‘è€Œç²¾ï¼‰', fontsize=16, weight='bold')
    ax1.set_xlim(0, 10)
    ax1.set_ylim(0, 10)
    ax1.axis('off')
    
    # CPUæ ¸å¿ƒï¼ˆ4ä¸ªå¤§æ ¸å¿ƒï¼‰
    cpu_cores = []
    positions = [(2, 7), (5, 7), (2, 4), (5, 4)]
    for i, (x, y) in enumerate(positions):
        # æ ¸å¿ƒ
        core = FancyBboxPatch((x-1, y-1), 2, 2, 
                             boxstyle="round,pad=0.1",
                             facecolor='lightblue', 
                             edgecolor='black', linewidth=2)
        ax1.add_patch(core)
        ax1.text(x, y, f'æ ¸å¿ƒ{i+1}\n(å¤æ‚)', ha='center', va='center', fontsize=10)
        
        # ALUï¼ˆç®—æœ¯é€»è¾‘å•å…ƒï¼‰
        alu = Rectangle((x-0.8, y+1.2), 0.6, 0.3, 
                       facecolor='red', edgecolor='black')
        ax1.add_patch(alu)
        ax1.text(x-0.5, y+1.35, 'ALU', ha='center', va='center', fontsize=8)
        
        # æ§åˆ¶å•å…ƒ
        control = Rectangle((x+0.2, y+1.2), 0.6, 0.3,
                          facecolor='green', edgecolor='black')
        ax1.add_patch(control)
        ax1.text(x+0.5, y+1.35, 'Control', ha='center', va='center', fontsize=8)
    
    # ç¼“å­˜
    cache_l3 = Rectangle((1, 1), 6, 1, facecolor='lightyellow', 
                        edgecolor='black', linewidth=2)
    ax1.add_patch(cache_l3)
    ax1.text(4, 1.5, 'L3 Cache (å¤§ç¼“å­˜)', ha='center', va='center', fontsize=10)
    
    # å†…å­˜æ§åˆ¶å™¨
    mem_ctrl = Rectangle((7.5, 4), 1.5, 2, facecolor='lightgray',
                        edgecolor='black', linewidth=2)
    ax1.add_patch(mem_ctrl)
    ax1.text(8.25, 5, 'å†…å­˜\næ§åˆ¶å™¨', ha='center', va='center', fontsize=9)
    
    # GPUæ¶æ„
    ax2.set_title('GPUæ¶æ„ï¼ˆå¤šè€Œç®€ï¼‰', fontsize=16, weight='bold')
    ax2.set_xlim(0, 10)
    ax2.set_ylim(0, 10)
    ax2.axis('off')
    
    # SMï¼ˆæµå¤šå¤„ç†å™¨ï¼‰
    sm_positions = [(1.5, 7), (3.5, 7), (5.5, 7), (7.5, 7),
                    (1.5, 4), (3.5, 4), (5.5, 4), (7.5, 4)]
    
    for i, (x, y) in enumerate(sm_positions):
        # SMå—
        sm = FancyBboxPatch((x-0.8, y-1.2), 1.6, 2.4,
                           boxstyle="round,pad=0.05",
                           facecolor='lightcoral',
                           edgecolor='black', linewidth=1)
        ax2.add_patch(sm)
        ax2.text(x, y+0.8, f'SM{i+1}', ha='center', va='center', 
                fontsize=9, weight='bold')
        
        # CUDAæ ¸å¿ƒï¼ˆæ¯ä¸ªSMå†…æœ‰å¤šä¸ªï¼‰
        for row in range(4):
            for col in range(4):
                cuda_x = x - 0.6 + col * 0.3
                cuda_y = y - 0.8 + row * 0.3
                cuda_core = Circle((cuda_x, cuda_y), 0.08,
                                 facecolor='darkred', edgecolor='black')
                ax2.add_patch(cuda_core)
    
    # æ˜¾å­˜
    vram = Rectangle((1, 1), 7, 1, facecolor='lightgreen',
                    edgecolor='black', linewidth=2)
    ax2.add_patch(vram)
    ax2.text(4.5, 1.5, 'VRAM (é«˜å¸¦å®½æ˜¾å­˜)', ha='center', va='center', fontsize=10)
    
    # æ·»åŠ è¯´æ˜æ–‡å­—
    ax1.text(4, 0.2, 'CPU: 4-16ä¸ªå¤æ‚æ ¸å¿ƒ\nä¼˜åŒ–ä¸²è¡Œä»»åŠ¡å’Œå¤æ‚é€»è¾‘', 
            ha='center', va='center', fontsize=11, style='italic')
    ax2.text(4.5, 0.2, 'GPU: æ•°åƒä¸ªç®€å•æ ¸å¿ƒ\nä¼˜åŒ–å¹¶è¡Œè®¡ç®—å’Œååé‡',
            ha='center', va='center', fontsize=11, style='italic')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ” æ¶æ„å¯¹æ¯”è¦ç‚¹ï¼š")
    print("1. CPUï¼šå°‘é‡å¼ºå¤§æ ¸å¿ƒï¼Œæ“…é•¿å¤æ‚é€»è¾‘å’Œåˆ†æ”¯é¢„æµ‹")
    print("2. GPUï¼šå¤§é‡ç®€å•æ ¸å¿ƒï¼Œæ“…é•¿å¹¶è¡Œå¤„ç†ç›¸åŒæ“ä½œ")
    print("3. CPUä¼˜åŒ–å»¶è¿Ÿ(Latency)ï¼ŒGPUä¼˜åŒ–ååé‡(Throughput)")
    print("4. æ·±åº¦å­¦ä¹ å¤§å¤šæ˜¯çŸ©é˜µè¿ç®—ï¼Œå¤©ç„¶é€‚åˆGPUå¹¶è¡Œ")

CPU_GPUæ¶æ„å¯¹æ¯”()
```

#### ğŸš€ å¹¶è¡Œè®¡ç®—çš„å¨åŠ›

```python
def å¹¶è¡Œè®¡ç®—æ¼”ç¤º():
    """å±•ç¤ºä¸²è¡Œä¸å¹¶è¡Œè®¡ç®—çš„å·®å¼‚"""
    
    # æ¨¡æ‹ŸçŸ©é˜µä¹˜æ³•
    def simulate_matrix_multiply(size, parallel=False, n_cores=1):
        """æ¨¡æ‹ŸçŸ©é˜µä¹˜æ³•çš„è®¡ç®—æ—¶é—´"""
        # å‡è®¾æ¯ä¸ªä¹˜åŠ æ“ä½œéœ€è¦1ä¸ªæ—¶é—´å•ä½
        total_operations = size * size * size  # çŸ©é˜µä¹˜æ³•çš„è®¡ç®—å¤æ‚åº¦
        
        if parallel:
            # å¹¶è¡Œè®¡ç®—ï¼Œæ—¶é—´ä¸æ ¸å¿ƒæ•°æˆåæ¯”
            time = total_operations / n_cores
        else:
            # ä¸²è¡Œè®¡ç®—
            time = total_operations
            
        return time
    
    # ä¸åŒé—®é¢˜è§„æ¨¡
    matrix_sizes = [16, 32, 64, 128, 256, 512]
    
    # è®¡ç®—æ—¶é—´
    serial_times = []
    gpu_times = []
    speedups = []
    
    cpu_cores = 8
    gpu_cores = 2048  # æ¨¡æ‹ŸGPUæ ¸å¿ƒæ•°
    
    for size in matrix_sizes:
        serial_time = simulate_matrix_multiply(size, parallel=False)
        gpu_time = simulate_matrix_multiply(size, parallel=True, n_cores=gpu_cores)
        
        serial_times.append(serial_time)
        gpu_times.append(gpu_time)
        speedups.append(serial_time / gpu_time)
    
    # å¯è§†åŒ–
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # è®¡ç®—æ—¶é—´å¯¹æ¯”
    x = np.arange(len(matrix_sizes))
    width = 0.35
    
    bars1 = ax1.bar(x - width/2, serial_times, width, 
                     label='CPUä¸²è¡Œ', color='blue', alpha=0.7)
    bars2 = ax1.bar(x + width/2, gpu_times, width,
                     label='GPUå¹¶è¡Œ', color='green', alpha=0.7)
    
    ax1.set_xlabel('çŸ©é˜µå¤§å°')
    ax1.set_ylabel('è®¡ç®—æ—¶é—´ï¼ˆç›¸å¯¹å•ä½ï¼‰')
    ax1.set_title('çŸ©é˜µä¹˜æ³•è®¡ç®—æ—¶é—´å¯¹æ¯”')
    ax1.set_xticks(x)
    ax1.set_xticklabels([f'{s}Ã—{s}' for s in matrix_sizes])
    ax1.legend()
    ax1.set_yscale('log')
    ax1.grid(True, alpha=0.3)
    
    # åŠ é€Ÿæ¯”æ›²çº¿
    ax2.plot(matrix_sizes, speedups, 'ro-', markersize=10, linewidth=2)
    ax2.set_xlabel('çŸ©é˜µå¤§å°')
    ax2.set_ylabel('åŠ é€Ÿæ¯”')
    ax2.set_title(f'GPUåŠ é€Ÿæ•ˆæœï¼ˆ{gpu_cores}æ ¸å¿ƒ vs {cpu_cores}æ ¸å¿ƒï¼‰')
    ax2.grid(True, alpha=0.3)
    ax2.set_xscale('log', base=2)
    
    # æ ‡æ³¨ç†è®ºä¸Šé™
    ax2.axhline(y=gpu_cores/cpu_cores, color='red', linestyle='--', 
                label=f'ç†è®ºä¸Šé™: {gpu_cores/cpu_cores}x')
    ax2.legend()
    
    plt.tight_layout()
    plt.show()
    
    # å¹¶è¡Œæ•ˆç‡åˆ†æ
    print("\nğŸ“Š å¹¶è¡Œè®¡ç®—æ•ˆç‡åˆ†æï¼š")
    print(f"é—®é¢˜è§„æ¨¡  |  åŠ é€Ÿæ¯”  |  å¹¶è¡Œæ•ˆç‡")
    print("-" * 35)
    for size, speedup in zip(matrix_sizes, speedups):
        efficiency = speedup / (gpu_cores/cpu_cores) * 100
        print(f"{size:^9} | {speedup:^8.1f}x | {efficiency:^10.1f}%")

å¹¶è¡Œè®¡ç®—æ¼”ç¤º()
```

#### ğŸ§  æ·±åº¦å­¦ä¹ ä¸ºä»€ä¹ˆéœ€è¦GPUï¼Ÿ

```python
def æ·±åº¦å­¦ä¹ è®¡ç®—ç‰¹å¾():
    """å±•ç¤ºæ·±åº¦å­¦ä¹ çš„è®¡ç®—ç‰¹å¾"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. çŸ©é˜µè¿ç®—å¯†é›†
    ax1.set_title('æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒï¼šçŸ©é˜µè¿ç®—', fontsize=14)
    ax1.set_xlim(0, 10)
    ax1.set_ylim(0, 10)
    ax1.axis('off')
    
    # å‰å‘ä¼ æ’­ç¤ºæ„
    # è¾“å…¥
    input_matrix = Rectangle((1, 4), 1.5, 3, facecolor='lightblue', 
                           edgecolor='black', linewidth=2)
    ax1.add_patch(input_matrix)
    ax1.text(1.75, 5.5, 'Input\n(batchÃ—dim)', ha='center', va='center')
    
    # æƒé‡
    weight_matrix = Rectangle((3.5, 3), 2, 4, facecolor='lightgreen',
                            edgecolor='black', linewidth=2)
    ax1.add_patch(weight_matrix)
    ax1.text(4.5, 5, 'Weights\n(dimÃ—units)', ha='center', va='center')
    
    # è¾“å‡º
    output_matrix = Rectangle((7, 4), 1.5, 3, facecolor='lightcoral',
                            edgecolor='black', linewidth=2)
    ax1.add_patch(output_matrix)
    ax1.text(7.75, 5.5, 'Output\n(batchÃ—units)', ha='center', va='center')
    
    # çŸ©é˜µä¹˜æ³•ç¬¦å·
    ax1.text(2.75, 5.5, 'Ã—', fontsize=20)
    ax1.text(6, 5.5, '=', fontsize=20)
    
    ax1.text(5, 1.5, 'æ¯å±‚éƒ½æ˜¯å¤§è§„æ¨¡çŸ©é˜µè¿ç®—\néå¸¸é€‚åˆå¹¶è¡ŒåŒ–', 
            ha='center', va='center', fontsize=12, style='italic')
    
    # 2. ç›¸åŒæ“ä½œçš„å¤§é‡é‡å¤
    ax2.set_title('ç›¸åŒæ“ä½œçš„å¤§é‡é‡å¤', fontsize=14)
    
    # æ¨¡æ‹Ÿå·ç§¯æ“ä½œ
    image_size = 10
    kernel_size = 3
    
    # ç”»å›¾åƒç½‘æ ¼
    for i in range(image_size):
        for j in range(image_size):
            rect = Rectangle((j*0.8, i*0.8), 0.7, 0.7,
                           facecolor='lightgray', edgecolor='black', alpha=0.5)
            ax2.add_patch(rect)
    
    # é«˜äº®ä¸€äº›å·ç§¯çª—å£
    colors = ['red', 'green', 'blue', 'orange']
    positions = [(2, 2), (5, 2), (2, 5), (5, 5)]
    
    for (x, y), color in zip(positions, colors):
        for i in range(kernel_size):
            for j in range(kernel_size):
                rect = Rectangle(((x+j)*0.8, (y+i)*0.8), 0.7, 0.7,
                               facecolor=color, edgecolor='black', 
                               alpha=0.6, linewidth=2)
                ax2.add_patch(rect)
    
    ax2.set_xlim(-0.5, image_size*0.8)
    ax2.set_ylim(-0.5, image_size*0.8)
    ax2.set_aspect('equal')
    ax2.axis('off')
    ax2.text(4, -1, 'å·ç§¯ï¼šåŒä¸€æ“ä½œåº”ç”¨äºä¸åŒä½ç½®\nå®Œç¾çš„å¹¶è¡Œè®¡ç®—åœºæ™¯',
            ha='center', va='center', fontsize=12, style='italic')
    
    # 3. æ‰¹å¤„ç†å¸¦æ¥çš„å¹¶è¡Œæœºä¼š
    ax3.set_title('æ‰¹å¤„ç†çš„å¹¶è¡Œæ€§', fontsize=14)
    
    batch_size = 32
    sequence_len = 10
    
    # åˆ›å»ºæ‰¹å¤„ç†æ•°æ®å¯è§†åŒ–
    batch_data = np.random.rand(batch_size, sequence_len)
    im = ax3.imshow(batch_data, cmap='viridis', aspect='auto')
    ax3.set_xlabel('åºåˆ—é•¿åº¦')
    ax3.set_ylabel('æ‰¹æ¬¡æ ·æœ¬')
    ax3.set_yticks([0, 7, 15, 23, 31])
    ax3.set_yticklabels(['æ ·æœ¬1', 'æ ·æœ¬8', 'æ ·æœ¬16', 'æ ·æœ¬24', 'æ ·æœ¬32'])
    
    # æ·»åŠ ç®­å¤´è¡¨ç¤ºå¹¶è¡Œå¤„ç†
    for i in range(0, batch_size, 8):
        ax3.annotate('', xy=(sequence_len+0.5, i), xytext=(sequence_len+1.5, i),
                    arrowprops=dict(arrowstyle='->', color='red', lw=2))
    
    ax3.text(sequence_len+3, batch_size/2, 'å¹¶è¡Œ\nå¤„ç†', 
            ha='center', va='center', fontsize=12, color='red')
    
    # 4. è®¡ç®—å¯†åº¦åˆ†æ
    ax4.set_title('æ·±åº¦å­¦ä¹ æ“ä½œçš„è®¡ç®—å¯†åº¦', fontsize=14)
    
    operations = ['çŸ©é˜µä¹˜æ³•', 'å·ç§¯', 'æ³¨æ„åŠ›æœºåˆ¶', 'BatchNorm', 'æ¿€æ´»å‡½æ•°']
    compute_intensity = [95, 90, 85, 60, 40]  # è®¡ç®—å¯†é›†åº¦ç™¾åˆ†æ¯”
    memory_intensity = [5, 10, 15, 40, 60]   # å†…å­˜å¯†é›†åº¦ç™¾åˆ†æ¯”
    
    x = np.arange(len(operations))
    width = 0.35
    
    bars1 = ax4.bar(x, compute_intensity, width, label='è®¡ç®—å¯†é›†',
                     color='green', alpha=0.7)
    bars2 = ax4.bar(x, memory_intensity, width, bottom=compute_intensity,
                     label='å†…å­˜å¯†é›†', color='orange', alpha=0.7)
    
    ax4.set_ylabel('ç™¾åˆ†æ¯”')
    ax4.set_xlabel('æ“ä½œç±»å‹')
    ax4.set_xticks(x)
    ax4.set_xticklabels(operations, rotation=15, ha='right')
    ax4.legend()
    ax4.grid(True, alpha=0.3, axis='y')
    
    # æ·»åŠ é€‚åˆGPUçš„æ ‡è®°
    for i, intensity in enumerate(compute_intensity):
        if intensity > 80:
            ax4.text(i, 105, 'âœ“GPU', ha='center', va='bottom', 
                    color='green', fontsize=10, weight='bold')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ’¡ æ·±åº¦å­¦ä¹ é€‚åˆGPUçš„åŸå› ï¼š")
    print("1. å¤§é‡çŸ©é˜µè¿ç®—ï¼šå®Œç¾åŒ¹é…GPUçš„å¹¶è¡Œæ¶æ„")
    print("2. ç›¸åŒæ“ä½œé‡å¤ï¼šSIMDï¼ˆå•æŒ‡ä»¤å¤šæ•°æ®ï¼‰ç‰¹æ€§")
    print("3. æ‰¹å¤„ç†å¹¶è¡Œï¼šå¤šä¸ªæ ·æœ¬å¯ä»¥åŒæ—¶å¤„ç†")
    print("4. é«˜è®¡ç®—å¯†åº¦ï¼šè®¡ç®—æ—¶é—´>>å†…å­˜è®¿é—®æ—¶é—´")

æ·±åº¦å­¦ä¹ è®¡ç®—ç‰¹å¾()
```

#### ğŸƒâ€â™‚ï¸ GPUå†…å­˜å±‚æ¬¡ï¼šé€Ÿåº¦çš„ç§˜å¯†

```python
def GPUå†…å­˜å±‚æ¬¡ç»“æ„():
    """å±•ç¤ºGPUçš„å†…å­˜å±‚æ¬¡ç»“æ„"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    
    # GPUå†…å­˜å±‚æ¬¡é‡‘å­—å¡”
    ax1.set_title('GPUå†…å­˜å±‚æ¬¡ç»“æ„', fontsize=16, weight='bold')
    ax1.set_xlim(0, 10)
    ax1.set_ylim(0, 10)
    ax1.axis('off')
    
    # é‡‘å­—å¡”å±‚æ¬¡
    levels = [
        {'name': 'å¯„å­˜å™¨', 'y': 8, 'width': 2, 'color': 'darkred', 
         'speed': '~1 cycle', 'size': '~256KB/SM'},
        {'name': 'å…±äº«å†…å­˜', 'y': 6.5, 'width': 3, 'color': 'red',
         'speed': '~2 cycles', 'size': '~64KB/SM'},
        {'name': 'L1ç¼“å­˜', 'y': 5, 'width': 4, 'color': 'orange',
         'speed': '~28 cycles', 'size': '~128KB/SM'},
        {'name': 'L2ç¼“å­˜', 'y': 3.5, 'width': 5.5, 'color': 'yellow',
         'speed': '~200 cycles', 'size': '~6MB'},
        {'name': 'å…¨å±€å†…å­˜(VRAM)', 'y': 2, 'width': 7, 'color': 'lightgreen',
         'speed': '~500 cycles', 'size': '16-80GB'}
    ]
    
    for level in levels:
        # ç”»æ¢¯å½¢è¡¨ç¤ºå±‚æ¬¡
        x_center = 5
        x_left = x_center - level['width']/2
        x_right = x_center + level['width']/2
        
        trapezoid = plt.Polygon([(x_left, level['y']-0.6), 
                                (x_right, level['y']-0.6),
                                (x_right+0.3, level['y']+0.6), 
                                (x_left-0.3, level['y']+0.6)],
                               facecolor=level['color'], 
                               edgecolor='black', linewidth=2)
        ax1.add_patch(trapezoid)
        
        # æ·»åŠ æ–‡å­—
        ax1.text(x_center, level['y'], level['name'], 
                ha='center', va='center', fontsize=11, weight='bold')
        ax1.text(x_center-3.5, level['y'], level['speed'], 
                ha='center', va='center', fontsize=9)
        ax1.text(x_center+3.5, level['y'], level['size'], 
                ha='center', va='center', fontsize=9)
    
    # æ·»åŠ ç®­å¤´å’Œæ ‡ç­¾
    ax1.annotate('', xy=(1.5, 9), xytext=(1.5, 1),
                arrowprops=dict(arrowstyle='<->', color='blue', lw=2))
    ax1.text(1, 5, 'æ›´å¿«', rotation=90, ha='center', va='center', 
            color='blue', fontsize=12)
    
    ax1.annotate('', xy=(8.5, 1), xytext=(8.5, 9),
                arrowprops=dict(arrowstyle='<->', color='green', lw=2))
    ax1.text(9, 5, 'æ›´å¤§', rotation=90, ha='center', va='center',
            color='green', fontsize=12)
    
    # å†…å­˜è®¿é—®æ¨¡å¼å¯¹æ¯”
    ax2.set_title('åˆå¹¶å†…å­˜è®¿é—® vs éšæœºè®¿é—®', fontsize=16, weight='bold')
    
    # æ¨¡æ‹Ÿå†…å­˜è®¿é—®æ¨¡å¼
    memory_blocks = 16
    thread_count = 8
    
    # ä¸ŠåŠéƒ¨åˆ†ï¼šåˆå¹¶è®¿é—®
    ax2.text(0.5, 0.9, 'åˆå¹¶è®¿é—®ï¼ˆCoalescedï¼‰âœ“', transform=ax2.transAxes,
            fontsize=14, weight='bold', color='green')
    
    for i in range(thread_count):
        # çº¿ç¨‹
        thread = Circle((1.5, 0.7 - i*0.08), 0.03, 
                       facecolor='blue', edgecolor='black')
        ax2.add_patch(thread)
        ax2.text(1.3, 0.7 - i*0.08, f'T{i}', ha='center', va='center', fontsize=8)
        
        # å†…å­˜å—
        mem = Rectangle((3 + i*0.4, 0.7 - i*0.08 - 0.03), 0.3, 0.06,
                       facecolor='lightgreen', edgecolor='black')
        ax2.add_patch(mem)
        
        # ç®­å¤´
        ax2.arrow(1.55, 0.7 - i*0.08, 1.4, 0, 
                 head_width=0.02, head_length=0.05, fc='green', ec='green')
    
    # ä¸‹åŠéƒ¨åˆ†ï¼šéšæœºè®¿é—®
    ax2.text(0.5, 0.4, 'éšæœºè®¿é—®ï¼ˆRandomï¼‰âœ—', transform=ax2.transAxes,
            fontsize=14, weight='bold', color='red')
    
    # éšæœºçš„å†…å­˜ä½ç½®
    random_positions = np.random.randint(0, memory_blocks, thread_count)
    
    for i in range(thread_count):
        # çº¿ç¨‹
        thread = Circle((1.5, 0.2 - i*0.08), 0.03,
                       facecolor='blue', edgecolor='black')
        ax2.add_patch(thread)
        ax2.text(1.3, 0.2 - i*0.08, f'T{i}', ha='center', va='center', fontsize=8)
        
        # éšæœºå†…å­˜è®¿é—®
        mem_x = 3 + random_positions[i]*0.4
        mem = Rectangle((mem_x, 0.2 - i*0.08 - 0.03), 0.3, 0.06,
                       facecolor='lightcoral', edgecolor='black')
        ax2.add_patch(mem)
        
        # ç®­å¤´ï¼ˆä¸åŒé•¿åº¦è¡¨ç¤ºéšæœºè®¿é—®ï¼‰
        ax2.arrow(1.55, 0.2 - i*0.08, mem_x - 1.6, 0,
                 head_width=0.02, head_length=0.05, fc='red', ec='red')
    
    ax2.set_xlim(0.5, 7)
    ax2.set_ylim(-0.5, 0.8)
    ax2.axis('off')
    
    # æ€§èƒ½å¯¹æ¯”
    ax2.text(0.5, 0.05, 'æ€§èƒ½å·®å¼‚ï¼š10-100å€ï¼', transform=ax2.transAxes,
            fontsize=12, style='italic', ha='center')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ¯ GPUå†…å­˜ä¼˜åŒ–è¦ç‚¹ï¼š")
    print("1. å¯„å­˜å™¨æœ€å¿«ä½†æœ€å°ï¼Œç”¨äºå­˜å‚¨ä¸´æ—¶å˜é‡")
    print("2. å…±äº«å†…å­˜å¯ä»¥åœ¨çº¿ç¨‹å—å†…å…±äº«ï¼Œé€‚åˆåä½œè®¡ç®—")
    print("3. åˆå¹¶å†…å­˜è®¿é—®æ˜¯æ€§èƒ½å…³é”®")
    print("4. ç¼“å­˜åˆ©ç”¨ç‡å¯¹æ€§èƒ½å½±å“å·¨å¤§")

GPUå†…å­˜å±‚æ¬¡ç»“æ„()
```

#### âš¡ CUDAç¼–ç¨‹æ¨¡å‹

```python
def CUDAç¼–ç¨‹æ¨¡å‹():
    """å±•ç¤ºCUDAçš„ç¼–ç¨‹æ¨¡å‹"""
    
    fig = plt.figure(figsize=(16, 10))
    
    # åˆ›å»ºå­å›¾
    gs = fig.add_gridspec(2, 2, height_ratios=[1, 1.2])
    ax1 = fig.add_subplot(gs[0, :])
    ax2 = fig.add_subplot(gs[1, 0])
    ax3 = fig.add_subplot(gs[1, 1])
    
    # 1. Grid-Block-Threadå±‚æ¬¡ç»“æ„
    ax1.set_title('CUDAæ‰§è¡Œæ¨¡å‹ï¼šGrid â†’ Block â†’ Thread', fontsize=16, weight='bold')
    ax1.set_xlim(0, 12)
    ax1.set_ylim(0, 8)
    ax1.axis('off')
    
    # Grid
    grid_rect = Rectangle((1, 1), 10, 6, facecolor='lightgray',
                         edgecolor='black', linewidth=3)
    ax1.add_patch(grid_rect)
    ax1.text(6, 7.5, 'Gridï¼ˆç½‘æ ¼ï¼‰', ha='center', va='center', 
            fontsize=14, weight='bold')
    
    # Blocks
    block_colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']
    block_positions = [(2, 4.5), (5, 4.5), (8, 4.5),
                      (2, 2), (5, 2), (8, 2)]
    
    for i, (x, y) in enumerate(block_positions):
        color = block_colors[i % len(block_colors)]
        block = Rectangle((x, y), 2, 1.5, facecolor=color,
                         edgecolor='black', linewidth=2)
        ax1.add_patch(block)
        ax1.text(x+1, y+1.3, f'Block({i//3},{i%3})', 
                ha='center', va='center', fontsize=10)
        
        # Threads within block
        for row in range(2):
            for col in range(4):
                thread_x = x + 0.2 + col * 0.4
                thread_y = y + 0.2 + row * 0.5
                thread = Circle((thread_x, thread_y), 0.1,
                              facecolor='darkblue', edgecolor='black')
                ax1.add_patch(thread)
    
    # 2. çº¿ç¨‹æ‰§è¡Œæ¨¡å‹
    ax2.set_title('Warpæ‰§è¡Œæ¨¡å‹', fontsize=14, weight='bold')
    ax2.set_xlim(0, 10)
    ax2.set_ylim(0, 10)
    ax2.axis('off')
    
    # Warpï¼ˆ32ä¸ªçº¿ç¨‹ï¼‰
    warp_y_start = 7
    for warp_id in range(2):
        warp_y = warp_y_start - warp_id * 3
        
        # Warpæ¡†
        warp_rect = Rectangle((1, warp_y-1), 8, 2,
                            facecolor='lightyellow' if warp_id == 0 else 'lightgreen',
                            edgecolor='black', linewidth=2)
        ax2.add_patch(warp_rect)
        ax2.text(0.5, warp_y, f'Warp {warp_id}', ha='center', va='center',
                fontsize=11, weight='bold', rotation=90)
        
        # 32ä¸ªçº¿ç¨‹
        for i in range(32):
            x = 1.2 + (i % 8) * 0.9
            y = warp_y + 0.5 if i < 16 else warp_y - 0.5
            thread = Circle((x, y), 0.15,
                          facecolor='blue' if i < 16 else 'darkblue',
                          edgecolor='black')
            ax2.add_patch(thread)
            
        # SIMTè¯´æ˜
        ax2.text(5, warp_y + 1.5, 'SIMT: 32çº¿ç¨‹æ‰§è¡Œç›¸åŒæŒ‡ä»¤',
                ha='center', va='center', fontsize=10, style='italic')
    
    # 3. å†…å­˜è®¿é—®æ¨¡å¼
    ax3.set_title('çº¿ç¨‹å†…å­˜è®¿é—®', fontsize=14, weight='bold')
    ax3.set_xlim(0, 10)
    ax3.set_ylim(0, 10)
    ax3.axis('off')
    
    # ä¸åŒç±»å‹çš„å†…å­˜
    memory_types = [
        {'name': 'æ¯çº¿ç¨‹å±€éƒ¨å†…å­˜', 'y': 8, 'color': 'lightcoral', 'scope': 'ç§æœ‰'},
        {'name': 'å—å†…å…±äº«å†…å­˜', 'y': 6, 'color': 'lightblue', 'scope': 'å—å†…å…±äº«'},
        {'name': 'å…¨å±€å†…å­˜', 'y': 4, 'color': 'lightgreen', 'scope': 'æ‰€æœ‰çº¿ç¨‹'},
        {'name': 'å¸¸é‡å†…å­˜', 'y': 2, 'color': 'lightyellow', 'scope': 'åªè¯»'}
    ]
    
    for mem in memory_types:
        # å†…å­˜å—
        mem_rect = Rectangle((2, mem['y']-0.4), 4, 0.8,
                           facecolor=mem['color'], edgecolor='black', linewidth=2)
        ax3.add_patch(mem_rect)
        ax3.text(4, mem['y'], mem['name'], ha='center', va='center', fontsize=11)
        ax3.text(7, mem['y'], mem['scope'], ha='center', va='center', 
                fontsize=10, style='italic')
        
        # è®¿é—®ç®­å¤´
        if mem['scope'] == 'ç§æœ‰':
            ax3.arrow(1.5, mem['y'], 0.4, 0, head_width=0.1, head_length=0.1)
        elif mem['scope'] == 'å—å†…å…±äº«':
            for i in [-0.2, 0.2]:
                ax3.arrow(1.5, mem['y']+i, 0.4, 0, head_width=0.1, head_length=0.1)
        else:
            for i in [-0.3, 0, 0.3]:
                ax3.arrow(1.5, mem['y']+i, 0.4, 0, head_width=0.1, head_length=0.1)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ”§ CUDAç¼–ç¨‹è¦ç‚¹ï¼š")
    print("1. GridåŒ…å«å¤šä¸ªBlockï¼ŒBlockåŒ…å«å¤šä¸ªThread")
    print("2. æ¯ä¸ªWarpï¼ˆ32çº¿ç¨‹ï¼‰åŒæ­¥æ‰§è¡Œç›¸åŒæŒ‡ä»¤")
    print("3. åˆç†åˆ©ç”¨ä¸åŒå±‚æ¬¡çš„å†…å­˜")
    print("4. é¿å…Warpåˆ†æ­§ï¼ˆdivergenceï¼‰")

CUDAç¼–ç¨‹æ¨¡å‹()
```

#### ğŸ“Š å®æˆ˜ï¼šçŸ©é˜µä¹˜æ³•çš„GPUåŠ é€Ÿ

```python
def çŸ©é˜µä¹˜æ³•GPUä¼˜åŒ–():
    """å±•ç¤ºçŸ©é˜µä¹˜æ³•çš„GPUä¼˜åŒ–è¿‡ç¨‹"""
    
    # æ¨¡æ‹Ÿä¸åŒä¼˜åŒ–çº§åˆ«çš„æ€§èƒ½
    optimization_levels = [
        'CPUä¸²è¡Œ',
        'GPUæœ´ç´ å®ç°',
        'GPUå…±äº«å†…å­˜',
        'GPUåˆ†å—ä¼˜åŒ–',
        'cuBLASåº“'
    ]
    
    # ç›¸å¯¹æ€§èƒ½ï¼ˆGFLOPSï¼‰
    performance = [1, 50, 200, 500, 1000]
    
    # ä¼˜åŒ–æŠ€æœ¯è¯´æ˜
    techniques = [
        'åŸºç¡€forå¾ªç¯',
        'æ¯ä¸ªçº¿ç¨‹è®¡ç®—ä¸€ä¸ªå…ƒç´ ',
        'åˆ©ç”¨å…±äº«å†…å­˜å‡å°‘å…¨å±€è®¿é—®',
        'åˆ†å—+å‘é‡åŒ–è®¿é—®',
        'é«˜åº¦ä¼˜åŒ–çš„åº“å‡½æ•°'
    ]
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))
    
    # æ€§èƒ½å¯¹æ¯”
    colors = plt.cm.RdYlGn(np.linspace(0.2, 0.9, len(optimization_levels)))
    bars = ax1.bar(optimization_levels, performance, color=colors, 
                    edgecolor='black', linewidth=2)
    
    ax1.set_ylabel('æ€§èƒ½ (GFLOPS)', fontsize=12)
    ax1.set_title('çŸ©é˜µä¹˜æ³•æ€§èƒ½ä¼˜åŒ–', fontsize=14, weight='bold')
    ax1.set_yscale('log')
    ax1.grid(True, alpha=0.3, axis='y')
    
    # æ ‡æ³¨æ€§èƒ½æå‡å€æ•°
    for i, (bar, perf) in enumerate(zip(bars[1:], performance[1:]), 1):
        speedup = perf / performance[0]
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() * 1.1,
                f'{speedup:.0f}x', ha='center', va='bottom', fontsize=10)
    
    # ä¼˜åŒ–æŠ€æœ¯ç»†èŠ‚
    ax2.axis('off')
    ax2.set_title('ä¼˜åŒ–æŠ€æœ¯è¯¦è§£', fontsize=14, weight='bold')
    
    y_pos = 0.9
    for level, tech, perf in zip(optimization_levels, techniques, performance):
        # çº§åˆ«æ ‡é¢˜
        ax2.text(0.05, y_pos, level, fontsize=12, weight='bold')
        # æŠ€æœ¯è¯´æ˜
        ax2.text(0.35, y_pos, tech, fontsize=11)
        # æ€§èƒ½
        ax2.text(0.85, y_pos, f'{perf} GFLOPS', fontsize=11, 
                ha='right', color='green' if perf > 100 else 'black')
        
        y_pos -= 0.15
    
    # æ·»åŠ ä¼˜åŒ–å»ºè®®
    ax2.text(0.5, 0.15, 'ä¼˜åŒ–å»ºè®®ï¼š\n'
                        '1. ä»cuBLASç­‰ä¼˜åŒ–åº“å¼€å§‹\n'
                        '2. åªåœ¨å¿…è¦æ—¶è‡ªå·±å®ç°\n'
                        '3. æ³¨æ„å†…å­˜è®¿é—®æ¨¡å¼\n'
                        '4. ä½¿ç”¨æ€§èƒ½åˆ†æå·¥å…·',
            ha='center', va='center', fontsize=11,
            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.7))
    
    plt.tight_layout()
    plt.show()
    
    # æ˜¾ç¤ºå…·ä½“çš„ä¼˜åŒ–ç¤ºä¾‹
    print("\nğŸš€ çŸ©é˜µä¹˜æ³•GPUä¼˜åŒ–ç¤ºä¾‹ï¼š")
    print("```cuda")
    print("// æœ´ç´ ç‰ˆæœ¬")
    print("__global__ void matmul_naive(float* A, float* B, float* C, int N) {")
    print("    int row = blockIdx.y * blockDim.y + threadIdx.y;")
    print("    int col = blockIdx.x * blockDim.x + threadIdx.x;")
    print("    ")
    print("    float sum = 0.0f;")
    print("    for (int k = 0; k < N; k++) {")
    print("        sum += A[row * N + k] * B[k * N + col];")
    print("    }")
    print("    C[row * N + col] = sum;")
    print("}")
    print("```")

çŸ©é˜µä¹˜æ³•GPUä¼˜åŒ–()
```

#### ğŸ® GPUè®­ç»ƒçš„å®é™…è€ƒè™‘

```python
def GPUè®­ç»ƒå®è·µ():
    """GPUè®­ç»ƒçš„å®é™…è€ƒè™‘å› ç´ """
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. æ˜¾å­˜ä½¿ç”¨åˆ†æ
    ax1.set_title('æ¨¡å‹æ˜¾å­˜å ç”¨åˆ†æ', fontsize=14, weight='bold')
    
    components = ['æ¨¡å‹å‚æ•°', 'æ¢¯åº¦', 'ä¼˜åŒ–å™¨çŠ¶æ€', 'æ¿€æ´»å€¼', 'ä¸´æ—¶ç¼“å†²']
    sizes_bert = [0.44, 0.44, 0.88, 2.5, 0.5]  # GB for BERT-Large
    sizes_gpt = [6, 6, 12, 8, 2]  # GB for GPT-3 6.7B
    
    x = np.arange(len(components))
    width = 0.35
    
    bars1 = ax1.bar(x - width/2, sizes_bert, width, label='BERT-Large',
                     color='lightblue', edgecolor='black')
    bars2 = ax1.bar(x + width/2, sizes_gpt, width, label='GPT-3 6.7B',
                     color='lightcoral', edgecolor='black')
    
    ax1.set_ylabel('æ˜¾å­˜å ç”¨ (GB)')
    ax1.set_xticks(x)
    ax1.set_xticklabels(components, rotation=15, ha='right')
    ax1.legend()
    ax1.grid(True, alpha=0.3, axis='y')
    
    # 2. æ‰¹å¤„ç†å¤§å°vsè®­ç»ƒé€Ÿåº¦
    ax2.set_title('æ‰¹å¤„ç†å¤§å° vs è®­ç»ƒé€Ÿåº¦', fontsize=14, weight='bold')
    
    batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128]
    samples_per_sec = [10, 19, 37, 72, 135, 240, 380, 450]
    memory_usage = [2, 3, 5, 9, 17, 33, 65, 130]
    
    ax2_twin = ax2.twinx()
    
    line1 = ax2.plot(batch_sizes, samples_per_sec, 'bo-', 
                     markersize=8, linewidth=2, label='ååé‡')
    line2 = ax2_twin.plot(batch_sizes, memory_usage, 'ro-', 
                          markersize=8, linewidth=2, label='æ˜¾å­˜ä½¿ç”¨')
    
    ax2.set_xlabel('æ‰¹å¤„ç†å¤§å°')
    ax2.set_ylabel('æ ·æœ¬/ç§’', color='blue')
    ax2_twin.set_ylabel('æ˜¾å­˜ä½¿ç”¨ (GB)', color='red')
    ax2.set_xscale('log', base=2)
    ax2.grid(True, alpha=0.3)
    
    # æ ‡è®°æ˜¾å­˜ä¸Šé™
    ax2_twin.axhline(y=80, color='red', linestyle='--', alpha=0.5)
    ax2_twin.text(64, 82, 'A100 80GBé™åˆ¶', ha='center', fontsize=10)
    
    # åˆå¹¶å›¾ä¾‹
    lines = line1 + line2
    labels = [l.get_label() for l in lines]
    ax2.legend(lines, labels, loc='upper left')
    
    # 3. å¤šGPUæ‰©å±•
    ax3.set_title('å¤šGPUè®­ç»ƒæ‰©å±•æ€§', fontsize=14, weight='bold')
    
    n_gpus = [1, 2, 4, 8]
    ideal_speedup = n_gpus
    actual_speedup = [1, 1.9, 3.6, 6.5]
    
    ax3.plot(n_gpus, ideal_speedup, 'g--', linewidth=2, label='ç†æƒ³åŠ é€Ÿ')
    ax3.plot(n_gpus, actual_speedup, 'bo-', markersize=10, 
             linewidth=2, label='å®é™…åŠ é€Ÿ')
    
    ax3.set_xlabel('GPUæ•°é‡')
    ax3.set_ylabel('åŠ é€Ÿæ¯”')
    ax3.set_xticks(n_gpus)
    ax3.grid(True, alpha=0.3)
    ax3.legend()
    
    # æ ‡æ³¨æ•ˆç‡
    for n, actual in zip(n_gpus, actual_speedup):
        efficiency = actual / n * 100
        ax3.text(n, actual + 0.1, f'{efficiency:.0f}%', 
                ha='center', va='bottom', fontsize=9)
    
    # 4. GPUé€‰æ‹©å»ºè®®
    ax4.axis('off')
    ax4.set_title('GPUé€‰æ‹©æŒ‡å—', fontsize=14, weight='bold')
    
    gpu_recommendations = [
        ('ä»»åŠ¡ç±»å‹', 'GPUæ¨è', 'æ˜¾å­˜éœ€æ±‚'),
        ('---', '---', '---'),
        ('BERTå¾®è°ƒ', 'RTX 3090/4090', '24GB'),
        ('å°æ¨¡å‹è®­ç»ƒ', 'A100 40GB', '40GB'),
        ('å¤§æ¨¡å‹è®­ç»ƒ', 'A100 80GB', '80GB'),
        ('è¶…å¤§æ¨¡å‹', 'å¤šæœºå¤šå¡', 'åˆ†å¸ƒå¼'),
        ('æ¨ç†æœåŠ¡', 'T4/A10', '16GB'),
    ]
    
    y_pos = 0.85
    for task, gpu, memory in gpu_recommendations:
        ax4.text(0.1, y_pos, task, fontsize=11, weight='bold' if task=='ä»»åŠ¡ç±»å‹' else 'normal')
        ax4.text(0.5, y_pos, gpu, fontsize=11, weight='bold' if gpu=='GPUæ¨è' else 'normal')
        ax4.text(0.8, y_pos, memory, fontsize=11, weight='bold' if memory=='æ˜¾å­˜éœ€æ±‚' else 'normal')
        y_pos -= 0.12
    
    # æ·»åŠ æ³¨æ„äº‹é¡¹
    ax4.text(0.5, 0.15, 
            'âš ï¸ æ³¨æ„äº‹é¡¹ï¼š\n'
            'â€¢ æ˜¾å­˜éœ€æ±‚ = æ¨¡å‹å¤§å° Ã— 3-4\n'
            'â€¢ æ··åˆç²¾åº¦å¯èŠ‚çœ~50%æ˜¾å­˜\n'
            'â€¢ è€ƒè™‘æ•£çƒ­å’ŒåŠŸè€—\n'
            'â€¢ äº‘æœåŠ¡vsè‡ªå»ºéœ€æƒè¡¡',
            ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.7))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ’¼ GPUè®­ç»ƒå®æˆ˜è¦ç‚¹ï¼š")
    print("1. æ˜¾å­˜æ˜¯æœ€å¤§ç“¶é¢ˆï¼Œåˆç†ä¼°ç®—éœ€æ±‚")
    print("2. æ‰¹å¤„ç†å¤§å°å½±å“è®­ç»ƒé€Ÿåº¦å’Œæ”¶æ•›")
    print("3. å¤šGPUéœ€è¦è€ƒè™‘é€šä¿¡å¼€é”€")
    print("4. é€‰æ‹©åˆé€‚çš„GPUæ¯”ç›²ç›®è¿½æ±‚æœ€è´µæ›´é‡è¦")

GPUè®­ç»ƒå®è·µ()
```

#### ğŸ“ æœ¬ç« å°ç»“

GPUä¹‹æ‰€ä»¥æˆä¸ºæ·±åº¦å­¦ä¹ çš„åŠ é€Ÿå™¨ï¼Œæºäºå…¶ç‹¬ç‰¹çš„å¹¶è¡Œæ¶æ„ï¼š

1. **æ¶æ„ä¼˜åŠ¿**ï¼š
   - æ•°åƒä¸ªç®€å•æ ¸å¿ƒï¼Œé€‚åˆå¤§è§„æ¨¡å¹¶è¡Œ
   - é«˜å¸¦å®½æ˜¾å­˜ï¼Œæ»¡è¶³æ•°æ®å¯†é›†éœ€æ±‚
   - SIMTæ‰§è¡Œæ¨¡å‹ï¼Œé«˜æ•ˆå¤„ç†ç›¸åŒæ“ä½œ

2. **æ·±åº¦å­¦ä¹ é€‚é…æ€§**ï¼š
   - çŸ©é˜µè¿ç®—å¯†é›†ï¼Œå¤©ç„¶å¹¶è¡Œ
   - æ‰¹å¤„ç†æä¾›å¹¶è¡Œæœºä¼š
   - è®¡ç®—å¯†åº¦é«˜ï¼Œå……åˆ†åˆ©ç”¨GPU

3. **ç¼–ç¨‹è¦ç‚¹**ï¼š
   - ç†è§£Grid-Block-Threadå±‚æ¬¡
   - ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼
   - åˆ©ç”¨å…±äº«å†…å­˜å’Œç¼“å­˜

4. **å®è·µè€ƒè™‘**ï¼š
   - æ˜¾å­˜ç®¡ç†æ˜¯å…³é”®
   - æ‰¹å¤„ç†å¤§å°éœ€è¦æƒè¡¡
   - åˆç†é€‰æ‹©GPUå‹å·

#### ğŸ’¡ å®ç”¨å»ºè®®

1. **å…¥é—¨é˜¶æ®µ**ï¼š
   - ä½¿ç”¨æˆç†Ÿæ¡†æ¶ï¼ˆPyTorch/TensorFlowï¼‰
   - ä»å°æ¨¡å‹å¼€å§‹å®éªŒ
   - ç›‘æ§GPUåˆ©ç”¨ç‡å’Œæ˜¾å­˜

2. **ä¼˜åŒ–é˜¶æ®µ**ï¼š
   - ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
   - å®ç°é«˜æ•ˆçš„æ•°æ®åŠ è½½
   - è€ƒè™‘æ¨¡å‹å¹¶è¡Œå’Œæ•°æ®å¹¶è¡Œ

3. **ç”Ÿäº§é˜¶æ®µ**ï¼š
   - è¯„ä¼°äº‘æœåŠ¡vsè‡ªå»º
   - å®æ–½å®¹é”™å’Œæ£€æŸ¥ç‚¹
   - ä¼˜åŒ–æ¨ç†æ€§èƒ½

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆCNNæ¯”RNNæ›´é€‚åˆGPUåŠ é€Ÿï¼Ÿ
2. å¦‚ä½•ä¼°ç®—ä¸€ä¸ªæ¨¡å‹éœ€è¦å¤šå°‘GPUæ˜¾å­˜ï¼Ÿ
3. åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œé€šä¿¡ä¼šæˆä¸ºç“¶é¢ˆå—ï¼Ÿ

ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†å­¦ä¹ è‡ªåŠ¨å¾®åˆ†â€”â€”è®©æ¢¯åº¦è®¡ç®—å˜å¾—ç®€å•çš„é­”æ³•ã€‚

### ç¬¬11ç« ï¼šè‡ªåŠ¨å¾®åˆ†â€”â€”è®©æ¢¯åº¦è®¡ç®—å˜å¾—ç®€å•

#### ğŸ¯ æœ¬ç« å¯¼è¯»

è¿˜è®°å¾—é«˜ä¸­æ—¶ä»£ï¼Œè€å¸ˆè®©ä½ æ±‚å¯¼æ•°å—ï¼Ÿ

$f(x) = x^2 + 3x + 2$ï¼Œæ±‚ $f'(x)$ã€‚

ä½ ä¼šæœºæ¢°åœ°åº”ç”¨è§„åˆ™ï¼š$f'(x) = 2x + 3$ã€‚

ä½†å¦‚æœæ˜¯è¿™æ ·çš„å‡½æ•°å‘¢ï¼Ÿ
$f(x) = \sin(x^2) \cdot e^{-x} + \log(1 + x^3)$

æ‰‹ç®—ï¼Ÿå¤ªå¤æ‚äº†ï¼å¦‚æœæ˜¯ä¸€ä¸ªæœ‰ç™¾ä¸‡å‚æ•°çš„ç¥ç»ç½‘ç»œå‘¢ï¼Ÿæ ¹æœ¬ä¸å¯èƒ½ï¼

è¿™å°±æ˜¯**è‡ªåŠ¨å¾®åˆ†ï¼ˆAutomatic Differentiationï¼‰**çš„é­”åŠ›â€”â€”è®©è®¡ç®—æœºè‡ªåŠ¨å¸®ä½ ç®—æ¢¯åº¦ï¼Œè€Œä¸”å¿«é€Ÿã€å‡†ç¡®ã€é«˜æ•ˆã€‚å®ƒæ˜¯æ·±åº¦å­¦ä¹ æ¡†æ¶çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿè®­ç»ƒå„ç§å¤æ‚çš„ç¥ç»ç½‘ç»œã€‚

#### ğŸ¨ æ¢¯åº¦è®¡ç®—çš„ä¸‰ç§æ–¹æ³•

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle, FancyBboxPatch, Circle, FancyArrowPatch
import networkx as nx

def æ¢¯åº¦è®¡ç®—æ–¹æ³•å¯¹æ¯”():
    """å±•ç¤ºä¸‰ç§è®¡ç®—æ¢¯åº¦çš„æ–¹æ³•"""
    
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
    
    # 1. æ•°å€¼å¾®åˆ†ï¼ˆæœ‰é™å·®åˆ†ï¼‰
    ax1.set_title('æ•°å€¼å¾®åˆ†ï¼ˆNumericalï¼‰', fontsize=14, weight='bold')
    ax1.set_xlim(-1, 5)
    ax1.set_ylim(-1, 5)
    
    # ç”»å‡½æ•°æ›²çº¿
    x = np.linspace(0, 4, 100)
    y = x**2
    ax1.plot(x, y, 'b-', linewidth=2, label='f(x) = xÂ²')
    
    # ç”»åˆ‡çº¿è¿‘ä¼¼
    x0 = 2
    h = 0.5
    y0 = x0**2
    y1 = (x0 + h)**2
    
    ax1.plot(x0, y0, 'ro', markersize=10)
    ax1.plot(x0 + h, y1, 'go', markersize=10)
    ax1.plot([x0, x0 + h], [y0, y1], 'r--', linewidth=2)
    
    # æ ‡æ³¨
    ax1.annotate(f'f(x)', xy=(x0, y0), xytext=(x0-0.5, y0+0.5),
                arrowprops=dict(arrowstyle='->', color='red'))
    ax1.annotate(f'f(x+h)', xy=(x0+h, y1), xytext=(x0+h+0.3, y1+0.5),
                arrowprops=dict(arrowstyle='->', color='green'))
    
    ax1.text(2, 0.5, r"$f'(x) \approx \frac{f(x+h) - f(x)}{h}$", 
            fontsize=12, bbox=dict(boxstyle="round", facecolor='lightyellow'))
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    
    # ä¼˜ç¼ºç‚¹
    ax1.text(0.5, 4.5, 'ä¼˜ç‚¹ï¼šç®€å•ç›´è§‚\nç¼ºç‚¹ï¼šç²¾åº¦ä½ï¼Œè®¡ç®—æ…¢', 
            fontsize=10, bbox=dict(boxstyle="round", facecolor='lightcoral', alpha=0.5))
    
    # 2. ç¬¦å·å¾®åˆ†
    ax2.set_title('ç¬¦å·å¾®åˆ†ï¼ˆSymbolicï¼‰', fontsize=14, weight='bold')
    ax2.set_xlim(0, 10)
    ax2.set_ylim(0, 10)
    ax2.axis('off')
    
    # ç”»ç¬¦å·æ¨å¯¼è¿‡ç¨‹
    expressions = [
        (5, 8, r'$f(x) = x^2 \sin(x)$'),
        (5, 6.5, r'$\downarrow$ åº”ç”¨ä¹˜æ³•æ³•åˆ™'),
        (5, 5, r"$f'(x) = 2x\sin(x) + x^2\cos(x)$"),
        (5, 3.5, r'$\downarrow$ åŒ–ç®€'),
        (5, 2, r"$f'(x) = x(2\sin(x) + x\cos(x))$")
    ]
    
    for x, y, text in expressions:
        ax2.text(x, y, text, ha='center', va='center', fontsize=12,
                bbox=dict(boxstyle="round,pad=0.3", facecolor='lightblue', alpha=0.7))
    
    # ä¼˜ç¼ºç‚¹
    ax2.text(5, 0.5, 'ä¼˜ç‚¹ï¼šç²¾ç¡®\nç¼ºç‚¹ï¼šè¡¨è¾¾å¼è†¨èƒ€ï¼Œå®ç°å¤æ‚', 
            fontsize=10, bbox=dict(boxstyle="round", facecolor='lightyellow', alpha=0.5))
    
    # 3. è‡ªåŠ¨å¾®åˆ†
    ax3.set_title('è‡ªåŠ¨å¾®åˆ†ï¼ˆAutomaticï¼‰', fontsize=14, weight='bold')
    ax3.set_xlim(0, 10)
    ax3.set_ylim(0, 10)
    ax3.axis('off')
    
    # ç”»è®¡ç®—å›¾
    nodes = {
        'x': (2, 5),
        'sin': (4, 7),
        'xÂ²': (4, 3),
        '*': (6, 5),
        'f': (8, 5)
    }
    
    # ç”»èŠ‚ç‚¹
    for node, (x, y) in nodes.items():
        if node in ['x', 'f']:
            color = 'lightgreen' if node == 'x' else 'lightcoral'
        else:
            color = 'lightblue'
        
        circle = Circle((x, y), 0.4, facecolor=color, edgecolor='black', linewidth=2)
        ax3.add_patch(circle)
        ax3.text(x, y, node, ha='center', va='center', fontsize=10, weight='bold')
    
    # ç”»è¾¹
    edges = [('x', 'sin'), ('x', 'xÂ²'), ('sin', '*'), ('xÂ²', '*'), ('*', 'f')]
    for start, end in edges:
        x1, y1 = nodes[start]
        x2, y2 = nodes[end]
        arrow = FancyArrowPatch((x1, y1), (x2, y2),
                               connectionstyle="arc3,rad=0.2",
                               arrowstyle='->', mutation_scale=20,
                               color='black', linewidth=2)
        ax3.add_patch(arrow)
    
    # æ¢¯åº¦æ ‡æ³¨
    ax3.text(6, 2, 'å‰å‘ä¼ æ’­ â†’\nâ† åå‘ä¼ æ’­', ha='center', fontsize=11,
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # ä¼˜ç¼ºç‚¹
    ax3.text(5, 0.5, 'ä¼˜ç‚¹ï¼šç²¾ç¡®ã€é«˜æ•ˆã€æ˜“å®ç°\nç¼ºç‚¹ï¼šéœ€è¦å­˜å‚¨ä¸­é—´ç»“æœ', 
            fontsize=10, bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.5))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ” ä¸‰ç§æ–¹æ³•å¯¹æ¯”ï¼š")
    print("1. æ•°å€¼å¾®åˆ†ï¼šé€‚åˆéªŒè¯ï¼Œä¸é€‚åˆå®é™…è®­ç»ƒ")
    print("2. ç¬¦å·å¾®åˆ†ï¼šé€‚åˆç®€å•å‡½æ•°ï¼Œä¸é€‚åˆå¤æ‚ç½‘ç»œ")
    print("3. è‡ªåŠ¨å¾®åˆ†ï¼šæ·±åº¦å­¦ä¹ çš„æ ‡å‡†æ–¹æ³•")

æ¢¯åº¦è®¡ç®—æ–¹æ³•å¯¹æ¯”()
```

#### ğŸŒ² è®¡ç®—å›¾ï¼šè‡ªåŠ¨å¾®åˆ†çš„åŸºç¡€

```python
def è®¡ç®—å›¾è¯¦è§£():
    """å±•ç¤ºè®¡ç®—å›¾çš„æ„å»ºå’Œæ¢¯åº¦ä¼ æ’­"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    
    # å·¦å›¾ï¼šå‰å‘ä¼ æ’­
    ax1.set_title('å‰å‘ä¼ æ’­ï¼šæ„å»ºè®¡ç®—å›¾', fontsize=14, weight='bold')
    ax1.set_xlim(0, 10)
    ax1.set_ylim(0, 10)
    ax1.axis('off')
    
    # å®šä¹‰ä¸€ä¸ªç®€å•çš„è®¡ç®—ï¼šz = (x + y) * w
    nodes_forward = {
        'x=2': (1, 7, 'lightgreen'),
        'y=3': (1, 3, 'lightgreen'),
        'w=4': (1, 5, 'lightgreen'),
        '+': (4, 5, 'lightblue'),
        'a=5': (4, 5, 'lightyellow'),
        '*': (7, 5, 'lightblue'),
        'z=20': (9, 5, 'lightcoral')
    }
    
    # ç”»èŠ‚ç‚¹
    for node, (x, y, color) in nodes_forward.items():
        if '=' in node:
            # å˜é‡èŠ‚ç‚¹
            rect = FancyBboxPatch((x-0.5, y-0.3), 1, 0.6,
                                 boxstyle="round,pad=0.1",
                                 facecolor=color, edgecolor='black', linewidth=2)
            ax1.add_patch(rect)
            ax1.text(x, y, node, ha='center', va='center', fontsize=10)
        else:
            # æ“ä½œèŠ‚ç‚¹
            circle = Circle((x, y), 0.4, facecolor=color, 
                          edgecolor='black', linewidth=2)
            ax1.add_patch(circle)
            ax1.text(x, y, node, ha='center', va='center', 
                    fontsize=12, weight='bold')
    
    # ç”»è¾¹å’Œå€¼
    edges_forward = [
        ('x=2', '+', '2'),
        ('y=3', '+', '3'),
        ('+', 'a=5', '5'),
        ('a=5', '*', '5'),
        ('w=4', '*', '4'),
        ('*', 'z=20', '20')
    ]
    
    # ç®€åŒ–è¾¹çš„ç»˜åˆ¶
    node_positions = {
        'x=2': (1, 7), 'y=3': (1, 3), 'w=4': (1, 5),
        '+': (4, 5), 'a=5': (4, 5), '*': (7, 5), 'z=20': (9, 5)
    }
    
    for start, end, value in edges_forward:
        if start in node_positions and end in node_positions:
            x1, y1 = node_positions[start]
            x2, y2 = node_positions[end]
            
            # ç‰¹æ®Šå¤„ç†a=5çš„ä½ç½®
            if start == 'a=5':
                x1 = 4.5
            if end == 'a=5':
                x2 = 3.5
                
            arrow = FancyArrowPatch((x1, y1), (x2, y2),
                                   connectionstyle="arc3,rad=0.1",
                                   arrowstyle='->', mutation_scale=15,
                                   color='blue', linewidth=2)
            ax1.add_patch(arrow)
            
            # æ ‡æ³¨ä¼ é€’çš„å€¼
            mid_x, mid_y = (x1 + x2) / 2, (y1 + y2) / 2
            ax1.text(mid_x, mid_y + 0.3, value, ha='center', 
                    fontsize=9, color='blue')
    
    # å³å›¾ï¼šåå‘ä¼ æ’­
    ax2.set_title('åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦', fontsize=14, weight='bold')
    ax2.set_xlim(0, 10)
    ax2.set_ylim(0, 10)
    ax2.axis('off')
    
    # ç”»ç›¸åŒçš„èŠ‚ç‚¹ç»“æ„
    for node, (x, y, color) in nodes_forward.items():
        if '=' in node:
            rect = FancyBboxPatch((x-0.5, y-0.3), 1, 0.6,
                                 boxstyle="round,pad=0.1",
                                 facecolor=color, edgecolor='black', linewidth=2)
            ax2.add_patch(rect)
            ax2.text(x, y, node.split('=')[0], ha='center', va='center', fontsize=10)
        else:
            circle = Circle((x, y), 0.4, facecolor=color, 
                          edgecolor='black', linewidth=2)
            ax2.add_patch(circle)
            ax2.text(x, y, node, ha='center', va='center', 
                    fontsize=12, weight='bold')
    
    # ç”»åå‘ä¼ æ’­çš„æ¢¯åº¦
    gradients = [
        ('z=20', '*', 'âˆ‚L/âˆ‚z=1'),
        ('*', 'a=5', 'âˆ‚L/âˆ‚a=4'),
        ('*', 'w=4', 'âˆ‚L/âˆ‚w=5'),
        ('a=5', '+', 'âˆ‚L/âˆ‚a=4'),
        ('+', 'x=2', 'âˆ‚L/âˆ‚x=4'),
        ('+', 'y=3', 'âˆ‚L/âˆ‚y=4')
    ]
    
    for start, end, grad in gradients:
        if start in node_positions and end in node_positions:
            x1, y1 = node_positions[start]
            x2, y2 = node_positions[end]
            
            # ç‰¹æ®Šå¤„ç†a=5çš„ä½ç½®
            if start == 'a=5':
                x1 = 3.5
            if end == 'a=5':
                x2 = 4.5
                
            arrow = FancyArrowPatch((x1, y1), (x2, y2),
                                   connectionstyle="arc3,rad=-0.1",
                                   arrowstyle='->', mutation_scale=15,
                                   color='red', linewidth=2)
            ax2.add_patch(arrow)
            
            # æ ‡æ³¨æ¢¯åº¦
            mid_x, mid_y = (x1 + x2) / 2, (y1 + y2) / 2
            ax2.text(mid_x, mid_y - 0.5, grad, ha='center', 
                    fontsize=8, color='red')
    
    # æ·»åŠ é“¾å¼æ³•åˆ™è¯´æ˜
    ax2.text(5, 1, 'é“¾å¼æ³•åˆ™ï¼š\nâˆ‚L/âˆ‚x = âˆ‚L/âˆ‚z Ã— âˆ‚z/âˆ‚a Ã— âˆ‚a/âˆ‚x\n= 1 Ã— 4 Ã— 1 = 4',
            ha='center', fontsize=10,
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ“Š è®¡ç®—å›¾çš„æ ¸å¿ƒæ¦‚å¿µï¼š")
    print("1. å‰å‘ä¼ æ’­ï¼šæŒ‰ç…§è®¡ç®—é¡ºåºæ„å»ºå›¾ï¼Œä¿å­˜ä¸­é—´ç»“æœ")
    print("2. åå‘ä¼ æ’­ï¼šä»è¾“å‡ºå¼€å§‹ï¼Œé€å±‚è®¡ç®—æ¢¯åº¦")
    print("3. é“¾å¼æ³•åˆ™ï¼šæ¢¯åº¦ = å±€éƒ¨æ¢¯åº¦ Ã— ä¸Šæ¸¸æ¢¯åº¦")

è®¡ç®—å›¾è¯¦è§£()
```

#### ğŸ”§ è‡ªåŠ¨å¾®åˆ†çš„å®ç°

```python
class ç®€å•è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿ:
    """å®ç°ä¸€ä¸ªç®€å•çš„è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿ"""
    
    def __init__(self):
        print("ğŸ› ï¸ å®ç°ä¸€ä¸ªç©å…·ç‰ˆè‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿ")
        
    class Tensor:
        """æ”¯æŒè‡ªåŠ¨å¾®åˆ†çš„å¼ é‡ç±»"""
        def __init__(self, data, requires_grad=False, grad_fn=None):
            self.data = np.array(data, dtype=np.float32)
            self.requires_grad = requires_grad
            self.grad = None
            self.grad_fn = grad_fn  # è®°å½•åˆ›å»ºè¿™ä¸ªå¼ é‡çš„æ“ä½œ
            
            if requires_grad:
                self.grad = np.zeros_like(self.data)
        
        def __repr__(self):
            return f"Tensor({self.data}, grad={self.grad})"
        
        def backward(self, grad=None):
            """åå‘ä¼ æ’­"""
            if not self.requires_grad:
                return
                
            # å¦‚æœæ˜¯æ ‡é‡ä¸”æ²¡æœ‰æä¾›æ¢¯åº¦ï¼Œé»˜è®¤ä¸º1
            if grad is None:
                if self.data.size == 1:
                    grad = np.ones_like(self.data)
                else:
                    raise RuntimeError("éœ€è¦æŒ‡å®šæ¢¯åº¦")
            
            # ç´¯ç§¯æ¢¯åº¦
            self.grad += grad
            
            # å¦‚æœæœ‰grad_fnï¼Œç»§ç»­åå‘ä¼ æ’­
            if self.grad_fn is not None:
                self.grad_fn.backward(grad)
        
        # é‡è½½è¿ç®—ç¬¦
        def __add__(self, other):
            return AddBackward.apply(self, other)
        
        def __mul__(self, other):
            return MulBackward.apply(self, other)
        
        def __pow__(self, power):
            return PowBackward.apply(self, power)
    
    class Function:
        """è‡ªåŠ¨å¾®åˆ†å‡½æ•°çš„åŸºç±»"""
        @staticmethod
        def forward(*args):
            raise NotImplementedError
        
        @staticmethod
        def backward(*args):
            raise NotImplementedError
    
    class AddBackward:
        """åŠ æ³•çš„åå‘ä¼ æ’­"""
        def __init__(self, x, y):
            self.x = x
            self.y = y
        
        @classmethod
        def apply(cls, x, y):
            # å‰å‘ä¼ æ’­
            z_data = x.data + y.data
            
            # åˆ›å»ºç»“æœå¼ é‡
            requires_grad = x.requires_grad or y.requires_grad
            if requires_grad:
                grad_fn = cls(x, y)
            else:
                grad_fn = None
                
            z = ç®€å•è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿ.Tensor(z_data, requires_grad, grad_fn)
            return z
        
        def backward(self, grad):
            # åŠ æ³•çš„å¯¼æ•°éƒ½æ˜¯1
            if self.x.requires_grad:
                self.x.backward(grad * 1)
            if self.y.requires_grad:
                self.y.backward(grad * 1)
    
    class MulBackward:
        """ä¹˜æ³•çš„åå‘ä¼ æ’­"""
        def __init__(self, x, y):
            self.x = x
            self.y = y
        
        @classmethod
        def apply(cls, x, y):
            z_data = x.data * y.data
            
            requires_grad = x.requires_grad or y.requires_grad
            if requires_grad:
                grad_fn = cls(x, y)
            else:
                grad_fn = None
                
            z = ç®€å•è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿ.Tensor(z_data, requires_grad, grad_fn)
            return z
        
        def backward(self, grad):
            # ä¹˜æ³•çš„å¯¼æ•°ï¼šd(xy)/dx = y, d(xy)/dy = x
            if self.x.requires_grad:
                self.x.backward(grad * self.y.data)
            if self.y.requires_grad:
                self.y.backward(grad * self.x.data)
    
    class PowBackward:
        """å¹‚è¿ç®—çš„åå‘ä¼ æ’­"""
        def __init__(self, x, power):
            self.x = x
            self.power = power
        
        @classmethod
        def apply(cls, x, power):
            z_data = x.data ** power
            
            if x.requires_grad:
                grad_fn = cls(x, power)
            else:
                grad_fn = None
                
            z = ç®€å•è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿ.Tensor(z_data, x.requires_grad, grad_fn)
            return z
        
        def backward(self, grad):
            # å¹‚è¿ç®—çš„å¯¼æ•°ï¼šd(x^n)/dx = n * x^(n-1)
            if self.x.requires_grad:
                grad_x = grad * self.power * (self.x.data ** (self.power - 1))
                self.x.backward(grad_x)
    
    def æ¼”ç¤ºè‡ªåŠ¨å¾®åˆ†(self):
        """æ¼”ç¤ºè‡ªåŠ¨å¾®åˆ†çš„ä½¿ç”¨"""
        print("\nğŸ“ ç¤ºä¾‹1ï¼šç®€å•å‡½æ•° z = xÂ² + 2xy + yÂ²")
        
        # åˆ›å»ºå˜é‡
        x = self.Tensor(2.0, requires_grad=True)
        y = self.Tensor(3.0, requires_grad=True)
        
        # å‰å‘ä¼ æ’­
        z = x**2 + x*y*2 + y**2
        print(f"å‰å‘ç»“æœ: z = {z.data}")
        
        # åå‘ä¼ æ’­
        z.backward()
        print(f"æ¢¯åº¦: âˆ‚z/âˆ‚x = {x.grad}, âˆ‚z/âˆ‚y = {y.grad}")
        
        # éªŒè¯æ¢¯åº¦
        # z = xÂ² + 2xy + yÂ²
        # âˆ‚z/âˆ‚x = 2x + 2y = 2*2 + 2*3 = 10
        # âˆ‚z/âˆ‚y = 2x + 2y = 2*2 + 2*3 = 10
        print(f"ç†è®ºæ¢¯åº¦: âˆ‚z/âˆ‚x = {2*x.data + 2*y.data}, âˆ‚z/âˆ‚y = {2*x.data + 2*y.data}")
        
        # å¯è§†åŒ–è®¡ç®—å›¾
        self.å¯è§†åŒ–è®¡ç®—å›¾()
    
    def å¯è§†åŒ–è®¡ç®—å›¾(self):
        """å¯è§†åŒ–è®¡ç®—å›¾ç»“æ„"""
        fig, ax = plt.subplots(figsize=(10, 8))
        ax.set_title('è‡ªåŠ¨æ„å»ºçš„è®¡ç®—å›¾', fontsize=14, weight='bold')
        
        # ä½¿ç”¨networkxåˆ›å»ºæœ‰å‘å›¾
        G = nx.DiGraph()
        
        # æ·»åŠ èŠ‚ç‚¹
        nodes = [
            ('x', {'pos': (1, 4), 'color': 'lightgreen'}),
            ('y', {'pos': (1, 2), 'color': 'lightgreen'}),
            ('xÂ²', {'pos': (3, 4), 'color': 'lightblue'}),
            ('xy', {'pos': (3, 3), 'color': 'lightblue'}),
            ('2xy', {'pos': (5, 3), 'color': 'lightblue'}),
            ('yÂ²', {'pos': (3, 2), 'color': 'lightblue'}),
            ('+1', {'pos': (7, 3.5), 'color': 'lightblue'}),
            ('+2', {'pos': (7, 2.5), 'color': 'lightblue'}),
            ('z', {'pos': (9, 3), 'color': 'lightcoral'})
        ]
        
        for node, attrs in nodes:
            G.add_node(node, **attrs)
        
        # æ·»åŠ è¾¹
        edges = [
            ('x', 'xÂ²'), ('x', 'xy'), ('y', 'xy'), ('y', 'yÂ²'),
            ('xy', '2xy'), ('xÂ²', '+1'), ('2xy', '+1'),
            ('+1', '+2'), ('yÂ²', '+2'), ('+2', 'z')
        ]
        G.add_edges_from(edges)
        
        # è·å–ä½ç½®
        pos = nx.get_node_attributes(G, 'pos')
        colors = [G.nodes[node]['color'] for node in G.nodes()]
        
        # ç»˜åˆ¶å›¾
        nx.draw(G, pos, ax=ax, with_labels=True, node_color=colors,
                node_size=1000, font_size=10, font_weight='bold',
                arrows=True, arrowsize=20, edge_color='gray',
                arrowstyle='->', linewidths=2)
        
        # æ·»åŠ æ¢¯åº¦æµæ ‡æ³¨
        ax.text(5, 1, 'å‰å‘ä¼ æ’­ â†’', fontsize=12, color='blue', weight='bold')
        ax.text(5, 0.5, 'â† åå‘ä¼ æ’­', fontsize=12, color='red', weight='bold')
        
        plt.tight_layout()
        plt.show()

# è¿è¡Œæ¼”ç¤º
autograd = ç®€å•è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿ()
autograd.æ¼”ç¤ºè‡ªåŠ¨å¾®åˆ†()
```

#### ğŸš€ æ¡†æ¶ä¸­çš„è‡ªåŠ¨å¾®åˆ†

```python
def æ¡†æ¶è‡ªåŠ¨å¾®åˆ†å¯¹æ¯”():
    """å¯¹æ¯”ä¸åŒæ¡†æ¶çš„è‡ªåŠ¨å¾®åˆ†å®ç°"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # PyTorché£æ ¼
    ax1.set_title('PyTorché£æ ¼ï¼šåŠ¨æ€è®¡ç®—å›¾', fontsize=14, weight='bold')
    ax1.text(0.5, 0.9, 'PyTorch ç¤ºä¾‹ä»£ç :', transform=ax1.transAxes, 
            fontsize=12, weight='bold')
    
    code_pytorch = '''import torch

x = torch.tensor(2.0, requires_grad=True)
y = torch.tensor(3.0, requires_grad=True)

# åŠ¨æ€æ„å»ºè®¡ç®—å›¾
z = x**2 + 2*x*y + y**2

# åå‘ä¼ æ’­
z.backward()

print(f"âˆ‚z/âˆ‚x = {x.grad}")
print(f"âˆ‚z/âˆ‚y = {y.grad}")'''
    
    ax1.text(0.05, 0.05, code_pytorch, transform=ax1.transAxes,
            fontsize=9, family='monospace',
            bbox=dict(boxstyle="round", facecolor='lightblue', alpha=0.7))
    
    ax1.text(0.5, 0.35, 'ç‰¹ç‚¹ï¼š\nâ€¢ çµæ´»ï¼Œæ˜“è°ƒè¯•\nâ€¢ æ”¯æŒåŠ¨æ€æ§åˆ¶æµ\nâ€¢ PythonåŸç”Ÿ',
            transform=ax1.transAxes, ha='center',
            bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.5))
    ax1.axis('off')
    
    # TensorFlowé£æ ¼
    ax2.set_title('TensorFlowé£æ ¼ï¼šé™æ€è®¡ç®—å›¾', fontsize=14, weight='bold')
    ax2.text(0.5, 0.9, 'TensorFlow 1.x ç¤ºä¾‹ä»£ç :', transform=ax2.transAxes,
            fontsize=12, weight='bold')
    
    code_tf = '''import tensorflow as tf

# å®šä¹‰è®¡ç®—å›¾
x = tf.placeholder(tf.float32)
y = tf.placeholder(tf.float32)
z = x**2 + 2*x*y + y**2

# è®¡ç®—æ¢¯åº¦
grad_x = tf.gradients(z, x)
grad_y = tf.gradients(z, y)

# è¿è¡Œä¼šè¯
with tf.Session() as sess:
    gx, gy = sess.run([grad_x, grad_y], 
                      feed_dict={x: 2.0, y: 3.0})'''
    
    ax2.text(0.05, 0.05, code_tf, transform=ax2.transAxes,
            fontsize=9, family='monospace',
            bbox=dict(boxstyle="round", facecolor='lightcoral', alpha=0.7))
    
    ax2.text(0.5, 0.35, 'ç‰¹ç‚¹ï¼š\nâ€¢ ä¼˜åŒ–æœºä¼šå¤š\nâ€¢ éƒ¨ç½²å‹å¥½\nâ€¢ éœ€è¦ç¼–è¯‘æ­¥éª¤',
            transform=ax2.transAxes, ha='center',
            bbox=dict(boxstyle="round", facecolor='lightyellow', alpha=0.5))
    ax2.axis('off')
    
    # JAXé£æ ¼
    ax3.set_title('JAXé£æ ¼ï¼šå‡½æ•°å¼è‡ªåŠ¨å¾®åˆ†', fontsize=14, weight='bold')
    ax3.text(0.5, 0.9, 'JAX ç¤ºä¾‹ä»£ç :', transform=ax3.transAxes,
            fontsize=12, weight='bold')
    
    code_jax = '''import jax
import jax.numpy as jnp

def f(x, y):
    return x**2 + 2*x*y + y**2

# è‡ªåŠ¨è·å–æ¢¯åº¦å‡½æ•°
grad_f = jax.grad(f, argnums=(0, 1))

# è®¡ç®—æ¢¯åº¦
grad_x, grad_y = grad_f(2.0, 3.0)

# JITç¼–è¯‘åŠ é€Ÿ
fast_grad_f = jax.jit(grad_f)'''
    
    ax3.text(0.05, 0.05, code_jax, transform=ax3.transAxes,
            fontsize=9, family='monospace',
            bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.7))
    
    ax3.text(0.5, 0.35, 'ç‰¹ç‚¹ï¼š\nâ€¢ å‡½æ•°å¼ç¼–ç¨‹\nâ€¢ JITç¼–è¯‘\nâ€¢ æ˜“äºç»„åˆå˜æ¢',
            transform=ax3.transAxes, ha='center',
            bbox=dict(boxstyle="round", facecolor='lightblue', alpha=0.5))
    ax3.axis('off')
    
    # æ€§èƒ½å¯¹æ¯”
    ax4.set_title('ä¸åŒåœºæ™¯ä¸‹çš„æ€§èƒ½å¯¹æ¯”', fontsize=14, weight='bold')
    
    scenarios = ['å°æ¨¡å‹\nè®­ç»ƒ', 'å¤§æ¨¡å‹\nè®­ç»ƒ', 'åŠ¨æ€\næ¨¡å‹', 'éƒ¨ç½²\næ¨ç†']
    pytorch_scores = [9, 8, 10, 6]
    tf_scores = [7, 9, 5, 10]
    jax_scores = [8, 10, 7, 8]
    
    x = np.arange(len(scenarios))
    width = 0.25
    
    bars1 = ax4.bar(x - width, pytorch_scores, width, label='PyTorch',
                     color='#EE4C2C', alpha=0.7)
    bars2 = ax4.bar(x, tf_scores, width, label='TensorFlow',
                     color='#FF6F00', alpha=0.7)
    bars3 = ax4.bar(x + width, jax_scores, width, label='JAX',
                     color='#00897B', alpha=0.7)
    
    ax4.set_ylabel('æ€§èƒ½è¯„åˆ†')
    ax4.set_xticks(x)
    ax4.set_xticklabels(scenarios)
    ax4.legend()
    ax4.grid(True, alpha=0.3, axis='y')
    ax4.set_ylim(0, 11)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ¯ æ¡†æ¶é€‰æ‹©å»ºè®®ï¼š")
    print("1. PyTorchï¼šç ”ç©¶å’ŒåŸå‹å¼€å‘é¦–é€‰")
    print("2. TensorFlowï¼šç”Ÿäº§éƒ¨ç½²çš„æˆç†Ÿé€‰æ‹©")
    print("3. JAXï¼šé«˜æ€§èƒ½ç§‘å­¦è®¡ç®—")

æ¡†æ¶è‡ªåŠ¨å¾®åˆ†å¯¹æ¯”()
```

#### ğŸ› å¸¸è§é™·é˜±ä¸ä¼˜åŒ–

```python
def è‡ªåŠ¨å¾®åˆ†é™·é˜±():
    """å±•ç¤ºè‡ªåŠ¨å¾®åˆ†çš„å¸¸è§é™·é˜±å’Œä¼˜åŒ–æŠ€å·§"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # é™·é˜±1ï¼šæ¢¯åº¦ç´¯ç§¯
    ax1.set_title('é™·é˜±1ï¼šæ¢¯åº¦ç´¯ç§¯', fontsize=14, weight='bold')
    ax1.text(0.5, 0.85, 'âŒ é”™è¯¯ç¤ºä¾‹', transform=ax1.transAxes,
            fontsize=12, weight='bold', color='red', ha='center')
    
    wrong_code = '''# æ¢¯åº¦ä¼šç´¯ç§¯ï¼
for epoch in range(3):
    loss = model(x)
    loss.backward()
    # x.grad: [1, 2, 3] ç´¯ç§¯!'''
    
    ax1.text(0.05, 0.55, wrong_code, transform=ax1.transAxes,
            fontsize=10, family='monospace',
            bbox=dict(boxstyle="round", facecolor='lightcoral', alpha=0.7))
    
    ax1.text(0.5, 0.35, 'âœ… æ­£ç¡®åšæ³•', transform=ax1.transAxes,
            fontsize=12, weight='bold', color='green', ha='center')
    
    right_code = '''# æ¯æ¬¡æ¸…é›¶æ¢¯åº¦
for epoch in range(3):
    optimizer.zero_grad()  # æ¸…é›¶ï¼
    loss = model(x)
    loss.backward()'''
    
    ax1.text(0.05, 0.05, right_code, transform=ax1.transAxes,
            fontsize=10, family='monospace',
            bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.7))
    ax1.axis('off')
    
    # é™·é˜±2ï¼šåŸåœ°æ“ä½œ
    ax2.set_title('é™·é˜±2ï¼šåŸåœ°æ“ä½œç ´åè®¡ç®—å›¾', fontsize=14, weight='bold')
    ax2.text(0.5, 0.85, 'âŒ é”™è¯¯ç¤ºä¾‹', transform=ax2.transAxes,
            fontsize=12, weight='bold', color='red', ha='center')
    
    inplace_wrong = '''# åŸåœ°æ“ä½œä¼šç ´åè®¡ç®—å›¾
x = torch.tensor([1., 2.], requires_grad=True)
y = x * 2
x[0] = 3  # é”™è¯¯ï¼ç ´åäº†è®¡ç®—å›¾
z = y.sum()
z.backward()  # RuntimeError!'''
    
    ax2.text(0.05, 0.5, inplace_wrong, transform=ax2.transAxes,
            fontsize=9, family='monospace',
            bbox=dict(boxstyle="round", facecolor='lightcoral', alpha=0.7))
    
    ax2.text(0.5, 0.3, 'âœ… ä½¿ç”¨.dataæˆ–.detach()', transform=ax2.transAxes,
            fontsize=12, weight='bold', color='green', ha='center')
    ax2.axis('off')
    
    # é™·é˜±3ï¼šæ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸
    ax3.set_title('é™·é˜±3ï¼šæ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸', fontsize=14, weight='bold')
    
    # æ¨¡æ‹Ÿæ¢¯åº¦åœ¨æ·±åº¦ç½‘ç»œä¸­çš„ä¼ æ’­
    depths = np.arange(1, 21)
    gradient_vanish = 0.5 ** depths  # æ¯å±‚æ¢¯åº¦ç¼©å°ä¸€åŠ
    gradient_explode = 1.5 ** depths  # æ¯å±‚æ¢¯åº¦æ”¾å¤§1.5å€
    
    ax3.semilogy(depths, gradient_vanish, 'b-o', label='æ¢¯åº¦æ¶ˆå¤± (Ã—0.5)', 
                 markersize=6)
    ax3.semilogy(depths, gradient_explode, 'r-o', label='æ¢¯åº¦çˆ†ç‚¸ (Ã—1.5)', 
                 markersize=6)
    ax3.axhline(y=1, color='green', linestyle='--', label='ç†æƒ³æ¢¯åº¦')
    
    ax3.fill_between(depths, 0.1, 10, alpha=0.2, color='green', label='å¥åº·èŒƒå›´')
    
    ax3.set_xlabel('ç½‘ç»œæ·±åº¦ï¼ˆå±‚æ•°ï¼‰')
    ax3.set_ylabel('æ¢¯åº¦å¤§å°ï¼ˆå¯¹æ•°å°ºåº¦ï¼‰')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # ä¼˜åŒ–æŠ€å·§
    ax4.set_title('ä¼˜åŒ–æŠ€å·§ï¼šæ£€æŸ¥ç‚¹ï¼ˆCheckpointingï¼‰', fontsize=14, weight='bold')
    ax4.set_xlim(0, 10)
    ax4.set_ylim(0, 10)
    ax4.axis('off')
    
    # ç”»å†…å­˜ä½¿ç”¨å¯¹æ¯”
    # æ™®é€šæ–¹å¼
    ax4.text(2.5, 8, 'æ™®é€šåå‘ä¼ æ’­', ha='center', fontsize=12, weight='bold')
    for i in range(5):
        rect = Rectangle((0.5 + i*0.8, 6), 0.7, 1, 
                        facecolor='lightcoral', edgecolor='black')
        ax4.add_patch(rect)
        ax4.text(0.85 + i*0.8, 6.5, f'L{i+1}', ha='center', fontsize=9)
    ax4.text(2.5, 5.5, 'å†…å­˜ï¼šO(n)', ha='center', fontsize=10, color='red')
    
    # Checkpointingæ–¹å¼
    ax4.text(2.5, 4, 'Gradient Checkpointing', ha='center', fontsize=12, weight='bold')
    for i in range(5):
        if i % 2 == 0:  # åªä¿å­˜éƒ¨åˆ†å±‚
            color = 'lightgreen'
        else:
            color = 'lightgray'
        rect = Rectangle((0.5 + i*0.8, 2), 0.7, 1,
                        facecolor=color, edgecolor='black')
        ax4.add_patch(rect)
        ax4.text(0.85 + i*0.8, 2.5, f'L{i+1}', ha='center', fontsize=9)
    ax4.text(2.5, 1.5, 'å†…å­˜ï¼šO(âˆšn)', ha='center', fontsize=10, color='green')
    
    # è¯´æ˜
    ax4.text(7, 6, 'â€¢ å­˜å‚¨æ‰€æœ‰æ¿€æ´»å€¼\nâ€¢ å†…å­˜å ç”¨å¤§\nâ€¢ é€Ÿåº¦å¿«',
            fontsize=10, bbox=dict(boxstyle="round", facecolor='lightcoral', alpha=0.5))
    ax4.text(7, 2, 'â€¢ åªå­˜å‚¨éƒ¨åˆ†æ¿€æ´»å€¼\nâ€¢ éœ€è¦æ—¶é‡æ–°è®¡ç®—\nâ€¢ çœå†…å­˜ï¼Œæ…¢ä¸€ç‚¹',
            fontsize=10, bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.5))
    
    plt.tight_layout()
    plt.show()
    
    print("âš ï¸ è‡ªåŠ¨å¾®åˆ†æ³¨æ„äº‹é¡¹ï¼š")
    print("1. è®°å¾—æ¸…é›¶æ¢¯åº¦ï¼ˆzero_gradï¼‰")
    print("2. é¿å…åŸåœ°æ“ä½œ")
    print("3. ç›‘æ§æ¢¯åº¦å¤§å°ï¼Œé˜²æ­¢æ¶ˆå¤±/çˆ†ç‚¸")
    print("4. å¤§æ¨¡å‹ä½¿ç”¨gradient checkpointingèŠ‚çœå†…å­˜")

è‡ªåŠ¨å¾®åˆ†é™·é˜±()
```

#### ğŸ¯ é«˜çº§è¯é¢˜ï¼šé«˜é˜¶å¯¼æ•°å’Œå‘é‡åŒ–

```python
def é«˜çº§è‡ªåŠ¨å¾®åˆ†():
    """å±•ç¤ºè‡ªåŠ¨å¾®åˆ†çš„é«˜çº§ç‰¹æ€§"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    
    # é«˜é˜¶å¯¼æ•°
    ax1.set_title('é«˜é˜¶å¯¼æ•°ï¼šHessiançŸ©é˜µ', fontsize=14, weight='bold')
    ax1.set_xlim(-3, 3)
    ax1.set_ylim(-3, 3)
    
    # ç”»ä¸€ä¸ªäºŒç»´å‡½æ•°çš„ç­‰é«˜çº¿
    x = np.linspace(-3, 3, 100)
    y = np.linspace(-3, 3, 100)
    X, Y = np.meshgrid(x, y)
    Z = X**2 + Y**2 + 0.5*X*Y  # ç®€å•çš„äºŒæ¬¡å‡½æ•°
    
    contour = ax1.contour(X, Y, Z, levels=20, cmap='viridis')
    ax1.clabel(contour, inline=True, fontsize=8)
    
    # åœ¨æŸç‚¹è®¡ç®—Hessian
    x0, y0 = 1.0, 0.5
    ax1.plot(x0, y0, 'ro', markersize=10)
    
    # HessiançŸ©é˜µ
    H = np.array([[2, 0.5], [0.5, 2]])  # å¯¹äºè¿™ä¸ªå‡½æ•°æ˜¯å¸¸æ•°
    
    # ç”»Hessiançš„ç‰¹å¾å‘é‡
    eigenvalues, eigenvectors = np.linalg.eig(H)
    for i in range(2):
        vec = eigenvectors[:, i]
        scale = 1.0 / np.sqrt(eigenvalues[i])
        ax1.arrow(x0, y0, vec[0]*scale, vec[1]*scale,
                 head_width=0.1, head_length=0.1, 
                 fc='red', ec='red', linewidth=2)
    
    ax1.set_xlabel('x')
    ax1.set_ylabel('y')
    ax1.grid(True, alpha=0.3)
    
    # æ·»åŠ Hessianä¿¡æ¯
    ax1.text(-2, 2.5, f'Hessian at ({x0}, {y0}):\n' + 
                      f'H = [{H[0,0]:.1f}  {H[0,1]:.1f}]\n' +
                      f'    [{H[1,0]:.1f}  {H[1,1]:.1f}]',
            fontsize=10, bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # å‘é‡åŒ–æ¢¯åº¦è®¡ç®—
    ax2.set_title('å‘é‡åŒ–ï¼šæ‰¹é‡æ¢¯åº¦è®¡ç®—', fontsize=14, weight='bold')
    ax2.axis('off')
    
    # ç¤ºä¾‹ä»£ç 
    vectorized_code = '''# å‘é‡åŒ–æ¢¯åº¦è®¡ç®—
import torch
from torch.func import vmap, grad

def loss_fn(params, x, y):
    """å•ä¸ªæ ·æœ¬çš„æŸå¤±"""
    return ((params @ x - y) ** 2).sum()

# æ‰¹é‡æ•°æ®
batch_size = 1000
params = torch.randn(10, 5, requires_grad=True)
X = torch.randn(batch_size, 5)
Y = torch.randn(batch_size, 10)

# æ–¹æ³•1ï¼šå¾ªç¯è®¡ç®—ï¼ˆæ…¢ï¼‰
grads_loop = []
for i in range(batch_size):
    g = grad(loss_fn)(params, X[i], Y[i])
    grads_loop.append(g)

# æ–¹æ³•2ï¼šå‘é‡åŒ–è®¡ç®—ï¼ˆå¿«ï¼‰
grad_fn = vmap(grad(loss_fn), in_dims=(None, 0, 0))
grads_vmap = grad_fn(params, X, Y)

# é€Ÿåº¦æå‡ï¼š10-100å€ï¼'''
    
    ax2.text(0.05, 0.5, vectorized_code, transform=ax2.transAxes,
            fontsize=10, family='monospace', va='center',
            bbox=dict(boxstyle="round", facecolor='lightblue', alpha=0.7))
    
    # æ€§èƒ½å¯¹æ¯”
    ax2.text(0.5, 0.15, 'æ€§èƒ½å¯¹æ¯”ï¼š\nå¾ªç¯: O(n) é¡ºåºæ‰§è¡Œ\nvmap: O(1) å¹¶è¡Œæ‰§è¡Œ',
            transform=ax2.transAxes, ha='center', fontsize=12,
            bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.5))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸš€ é«˜çº§ç‰¹æ€§ï¼š")
    print("1. é«˜é˜¶å¯¼æ•°ï¼šä¼˜åŒ–ç®—æ³•ï¼ˆç‰›é¡¿æ³•ï¼‰éœ€è¦")
    print("2. å‘é‡åŒ–æ¢¯åº¦ï¼šå¤§å¹…æå‡æ‰¹å¤„ç†æ•ˆç‡")
    print("3. æ··åˆç²¾åº¦ï¼šè‡ªåŠ¨å¤„ç†float16/32è½¬æ¢")

é«˜çº§è‡ªåŠ¨å¾®åˆ†()
```

#### ğŸ“ æœ¬ç« å°ç»“

è‡ªåŠ¨å¾®åˆ†æ˜¯æ·±åº¦å­¦ä¹ çš„åŸºçŸ³æŠ€æœ¯ï¼Œå®ƒè®©å¤æ‚çš„æ¢¯åº¦è®¡ç®—å˜å¾—ç®€å•è€Œé«˜æ•ˆï¼š

1. **æ ¸å¿ƒåŸç†**ï¼š
   - è®¡ç®—å›¾è®°å½•è¿ç®—è¿‡ç¨‹
   - é“¾å¼æ³•åˆ™è®¡ç®—æ¢¯åº¦
   - å‰å‘ä¼ æ’­å»ºå›¾ï¼Œåå‘ä¼ æ’­æ±‚å¯¼

2. **å®ç°æ–¹å¼**ï¼š
   - åŠ¨æ€å›¾ï¼šçµæ´»ä½†å¼€é”€å¤§ï¼ˆPyTorchï¼‰
   - é™æ€å›¾ï¼šé«˜æ•ˆä½†ä¸çµæ´»ï¼ˆTensorFlow 1.xï¼‰
   - å‡½æ•°å¼ï¼šä¼˜é›…ä¸”å¯ç»„åˆï¼ˆJAXï¼‰

3. **å¸¸è§é™·é˜±**ï¼š
   - æ¢¯åº¦ç´¯ç§¯é—®é¢˜
   - åŸåœ°æ“ä½œç ´åè®¡ç®—å›¾
   - æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸
   - å†…å­˜å ç”¨è¿‡å¤§

4. **ä¼˜åŒ–æŠ€å·§**ï¼š
   - Gradient checkpointing
   - æ··åˆç²¾åº¦è®­ç»ƒ
   - å‘é‡åŒ–è®¡ç®—
   - JITç¼–è¯‘

#### ğŸ’¡ å®ç”¨å»ºè®®

1. **è°ƒè¯•æŠ€å·§**ï¼š
   - ä½¿ç”¨`retain_graph=True`è°ƒè¯•
   - æ‰“å°æ¢¯åº¦æ£€æŸ¥æ­£ç¡®æ€§
   - å¯è§†åŒ–è®¡ç®—å›¾ç»“æ„

2. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - é¿å…ä¸å¿…è¦çš„æ¢¯åº¦è®¡ç®—
   - ä½¿ç”¨`no_grad()`ä¸Šä¸‹æ–‡
   - æ‰¹é‡æ“ä½œè€Œéå¾ªç¯

3. **æ¡†æ¶é€‰æ‹©**ï¼š
   - ç ”ç©¶ç”¨PyTorch
   - ç”Ÿäº§ç”¨TensorFlow
   - æ€§èƒ½æ•æ„Ÿç”¨JAX

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆè‡ªåŠ¨å¾®åˆ†æ¯”æ•°å€¼å¾®åˆ†å’Œç¬¦å·å¾®åˆ†æ›´é€‚åˆæ·±åº¦å­¦ä¹ ï¼Ÿ
2. åŠ¨æ€å›¾å’Œé™æ€å›¾å„æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ
3. å¦‚ä½•æ£€æµ‹å’Œè§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Ÿ

ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†è¿›å…¥è¯­è¨€æ¨¡å‹çš„ä¸–ç•Œï¼Œå­¦ä¹ ä»ç»Ÿè®¡è¯­è¨€æ¨¡å‹åˆ°ç¥ç»è¯­è¨€æ¨¡å‹çš„æ¼”è¿›å†ç¨‹ã€‚

### ç¬¬12ç« ï¼šä»ç»Ÿè®¡è¯­è¨€æ¨¡å‹åˆ°ç¥ç»è¯­è¨€æ¨¡å‹

#### ğŸ¯ æœ¬ç« å¯¼è¯»

æƒ³è±¡ä½ åœ¨ç©ä¸€ä¸ªå¡«è¯æ¸¸æˆï¼š

"ä»Šå¤©å¤©æ°”çœŸ____"

ä½ çš„å¤§è„‘ä¼šè‡ªåŠ¨å†’å‡º"å¥½"ã€"å†·"ã€"çƒ­"è¿™äº›è¯ã€‚ä½†ä¸ºä»€ä¹ˆä¸æ˜¯"è‹¹æœ"ã€"è·‘æ­¥"å‘¢ï¼Ÿ

è¿™å°±æ˜¯è¯­è¨€æ¨¡å‹è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ï¼š**é¢„æµ‹ä¸‹ä¸€ä¸ªè¯**ã€‚ä»æœ€æ—©çš„æ•°æ•°ç®—æ¦‚ç‡ï¼Œåˆ°ä»Šå¤©çš„ChatGPTï¼Œè¯­è¨€æ¨¡å‹ç»å†äº†ä¸€åœºé©å‘½æ€§çš„æ¼”å˜ã€‚

è®©æˆ‘ä»¬ä¸€èµ·å›é¡¾è¿™æ®µç²¾å½©çš„å†å²ï¼Œçœ‹çœ‹AIæ˜¯å¦‚ä½•ä¸€æ­¥æ­¥å­¦ä¼š"è¯´è¯"çš„ã€‚

#### ğŸ“Š ä»€ä¹ˆæ˜¯è¯­è¨€æ¨¡å‹ï¼Ÿ

```python
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict, Counter
import math
import seaborn as sns

def è¯­è¨€æ¨¡å‹åŸºç¡€æ¦‚å¿µ():
    """å±•ç¤ºè¯­è¨€æ¨¡å‹çš„åŸºæœ¬æ¦‚å¿µ"""
    
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
    
    # 1. è¯­è¨€æ¨¡å‹çš„ä»»åŠ¡
    ax1.set_title('è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒä»»åŠ¡', fontsize=14, weight='bold')
    ax1.set_xlim(0, 10)
    ax1.set_ylim(0, 10)
    ax1.axis('off')
    
    # è¾“å…¥åºåˆ—
    words = ['æˆ‘', 'çˆ±', 'åƒ', '?']
    x_positions = [2, 3.5, 5, 6.5]
    
    for i, (word, x) in enumerate(zip(words, x_positions)):
        if word == '?':
            color = 'lightcoral'
            edge_style = '--'
        else:
            color = 'lightblue'
            edge_style = '-'
        
        rect = plt.Rectangle((x-0.4, 7), 0.8, 1, 
                           facecolor=color, edgecolor='black',
                           linestyle=edge_style, linewidth=2)
        ax1.add_patch(rect)
        ax1.text(x, 7.5, word, ha='center', va='center', fontsize=12)
    
    # å€™é€‰è¯å’Œæ¦‚ç‡
    candidates = ['è‹¹æœ', 'é¥­', 'æ°´æœ', 'è¥¿ç“œ', 'è‚‰']
    probs = [0.35, 0.30, 0.20, 0.10, 0.05]
    y_start = 5
    
    for i, (word, prob) in enumerate(zip(candidates, probs)):
        y = y_start - i * 0.8
        
        # æ¦‚ç‡æ¡
        bar_width = prob * 3
        rect = plt.Rectangle((7, y-0.25), bar_width, 0.5,
                           facecolor='lightgreen', edgecolor='black')
        ax1.add_patch(rect)
        
        ax1.text(6.8, y, word, ha='right', va='center', fontsize=10)
        ax1.text(7.1 + bar_width, y, f'{prob:.0%}', 
                ha='left', va='center', fontsize=9)
    
    ax1.arrow(6.8, 7.5, 0.5, 0, head_width=0.2, head_length=0.1,
             fc='red', ec='red')
    ax1.text(4, 9, 'P(ä¸‹ä¸€ä¸ªè¯|ä¹‹å‰çš„è¯) = ?', fontsize=12, 
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # 2. æ¦‚ç‡é“¾
    ax2.set_title('å¥å­çš„æ¦‚ç‡åˆ†è§£', fontsize=14, weight='bold')
    ax2.set_xlim(0, 10)
    ax2.set_ylim(0, 10)
    ax2.axis('off')
    
    # å±•ç¤ºæ¦‚ç‡é“¾å¼åˆ†è§£
    sentence = "æˆ‘ çˆ± å­¦ä¹  AI"
    ax2.text(5, 8.5, f'P("{sentence}") = ?', ha='center', fontsize=12,
            bbox=dict(boxstyle="round", facecolor='lightblue'))
    
    # åˆ†è§£æ­¥éª¤
    steps = [
        'P(æˆ‘) Ã—',
        'P(çˆ±|æˆ‘) Ã—',
        'P(å­¦ä¹ |æˆ‘,çˆ±) Ã—',
        'P(AI|æˆ‘,çˆ±,å­¦ä¹ )'
    ]
    
    y_pos = 6.5
    for i, step in enumerate(steps):
        ax2.text(5, y_pos - i*0.8, step, ha='center', fontsize=11)
        if i < len(steps) - 1:
            ax2.arrow(5, y_pos - i*0.8 - 0.2, 0, -0.3,
                     head_width=0.1, head_length=0.05, fc='gray', ec='gray')
    
    # ç¤ºä¾‹è®¡ç®—
    ax2.text(5, 2, '= 0.1 Ã— 0.3 Ã— 0.4 Ã— 0.6 = 0.0072', 
            ha='center', fontsize=11, color='green',
            bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.5))
    
    # 3. å›°æƒ‘åº¦
    ax3.set_title('å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰', fontsize=14, weight='bold')
    
    # ä¸¤ä¸ªæ¨¡å‹çš„å›°æƒ‘åº¦å¯¹æ¯”
    models = ['æ¨¡å‹A', 'æ¨¡å‹B']
    perplexities = [150, 50]
    colors = ['lightcoral', 'lightgreen']
    
    bars = ax3.bar(models, perplexities, color=colors, edgecolor='black', linewidth=2)
    ax3.set_ylabel('å›°æƒ‘åº¦')
    ax3.set_ylim(0, 200)
    
    # æ ‡æ³¨
    for bar, ppl in zip(bars, perplexities):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2, height + 5,
                f'PPL={ppl}', ha='center', va='bottom', fontsize=11)
    
    # è§£é‡Š
    ax3.text(0.5, 0.95, 'å›°æƒ‘åº¦ = å¹³å‡æ¯ä¸ªè¯çš„é€‰æ‹©æ•°\nè¶Šä½è¶Šå¥½ï¼',
            transform=ax3.transAxes, ha='center', va='top',
            fontsize=10, bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    ax3.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ“ è¯­è¨€æ¨¡å‹çš„å®šä¹‰ï¼š")
    print("1. ç»™å®šå‰æ–‡ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒ")
    print("2. å¯ä»¥è®¡ç®—ä»»æ„æ–‡æœ¬åºåˆ—çš„æ¦‚ç‡")
    print("3. å›°æƒ‘åº¦æ˜¯è¯„ä»·æŒ‡æ ‡ï¼Œè¡¨ç¤ºæ¨¡å‹çš„ä¸ç¡®å®šæ€§")

è¯­è¨€æ¨¡å‹åŸºç¡€æ¦‚å¿µ()
```

#### ğŸ² N-gramï¼šç»Ÿè®¡è¯­è¨€æ¨¡å‹çš„å·…å³°

```python
class NGramLanguageModel:
    """å®ç°ä¸€ä¸ªN-gramè¯­è¨€æ¨¡å‹"""
    
    def __init__(self, n=2):
        self.n = n
        self.counts = defaultdict(Counter)
        self.vocab = set(['<s>', '</s>'])  # å¼€å§‹å’Œç»“æŸæ ‡è®°
        
    def train(self, sentences):
        """è®­ç»ƒN-gramæ¨¡å‹"""
        for sentence in sentences:
            # æ·»åŠ å¼€å§‹å’Œç»“æŸæ ‡è®°
            tokens = ['<s>'] * (self.n - 1) + sentence.split() + ['</s>']
            self.vocab.update(tokens)
            
            # ç»Ÿè®¡n-gram
            for i in range(len(tokens) - self.n + 1):
                context = tuple(tokens[i:i+self.n-1])
                next_word = tokens[i+self.n-1]
                self.counts[context][next_word] += 1
    
    def predict_next(self, context):
        """é¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒ"""
        context = tuple(context.split()[-self.n+1:])  # åªä¿ç•™æœ€è¿‘çš„n-1ä¸ªè¯
        
        if context not in self.counts:
            # æœªè§è¿‡çš„ä¸Šä¸‹æ–‡ï¼Œè¿”å›å‡åŒ€åˆ†å¸ƒ
            return {word: 1/len(self.vocab) for word in self.vocab}
        
        # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
        word_counts = self.counts[context]
        total = sum(word_counts.values())
        
        return {word: count/total for word, count in word_counts.items()}
    
    def generate(self, start_words="", max_length=20):
        """ç”Ÿæˆæ–‡æœ¬"""
        tokens = start_words.split() if start_words else []
        
        # æ·»åŠ å¼€å§‹æ ‡è®°
        tokens = ['<s>'] * (self.n - 1) + tokens
        
        for _ in range(max_length):
            context = tuple(tokens[-self.n+1:])
            probs = self.predict_next(' '.join(context))
            
            # æŒ‰æ¦‚ç‡é‡‡æ ·
            words = list(probs.keys())
            weights = list(probs.values())
            next_word = np.random.choice(words, p=weights)
            
            if next_word == '</s>':
                break
                
            tokens.append(next_word)
        
        # å»æ‰å¼€å§‹æ ‡è®°
        return ' '.join(tokens[self.n-1:])

def N_gramæ¨¡å‹æ¼”ç¤º():
    """æ¼”ç¤ºN-gramæ¨¡å‹çš„å·¥ä½œåŸç†"""
    
    # è®­ç»ƒæ•°æ®
    sentences = [
        "æˆ‘ çˆ± åƒ è‹¹æœ",
        "æˆ‘ çˆ± åƒ é¦™è•‰",
        "ä»– çˆ± åƒ è‹¹æœ",
        "æˆ‘ å–œæ¬¢ å­¦ä¹  AI",
        "ä»– å–œæ¬¢ å­¦ä¹  æ•°å­¦",
        "ä»Šå¤© å¤©æ°” å¾ˆ å¥½",
        "ä»Šå¤© å¤©æ°” ä¸ é”™"
    ]
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. Unigramæ¨¡å‹
    ax1.set_title('Unigramæ¨¡å‹ï¼ˆn=1ï¼‰', fontsize=14, weight='bold')
    
    unigram = NGramLanguageModel(n=1)
    unigram.train(sentences)
    
    # ç»Ÿè®¡è¯é¢‘
    all_words = []
    for sent in sentences:
        all_words.extend(sent.split())
    word_counts = Counter(all_words)
    
    # ç»˜åˆ¶è¯é¢‘
    words, counts = zip(*word_counts.most_common(10))
    ax1.bar(words, counts, color='lightblue', edgecolor='black')
    ax1.set_xlabel('è¯')
    ax1.set_ylabel('é¢‘ç‡')
    ax1.tick_params(axis='x', rotation=45)
    
    # 2. Bigramæ¨¡å‹
    ax2.set_title('Bigramæ¨¡å‹ï¼ˆn=2ï¼‰', fontsize=14, weight='bold')
    
    bigram = NGramLanguageModel(n=2)
    bigram.train(sentences)
    
    # å±•ç¤ºæ¡ä»¶æ¦‚ç‡
    context = "æˆ‘"
    probs = bigram.predict_next(context)
    
    # åªæ˜¾ç¤ºæ¦‚ç‡>0çš„è¯
    filtered_probs = {k: v for k, v in probs.items() if v > 0 and k not in ['<s>', '</s>']}
    if filtered_probs:
        words = list(filtered_probs.keys())
        probs_values = list(filtered_probs.values())
        
        ax2.barh(words, probs_values, color='lightgreen', edgecolor='black')
        ax2.set_xlabel('æ¦‚ç‡')
        ax2.set_title(f'P(ä¸‹ä¸€ä¸ªè¯|"{context}")')
        
        for i, (word, prob) in enumerate(zip(words, probs_values)):
            ax2.text(prob + 0.01, i, f'{prob:.2f}', va='center')
    
    # 3. ä¸åŒnå€¼çš„æ•ˆæœ
    ax3.set_title('ä¸åŒnå€¼çš„æ•ˆæœ', fontsize=14, weight='bold')
    ax3.axis('off')
    
    n_values = [1, 2, 3, 4]
    y_pos = 0.9
    
    for n in n_values:
        model = NGramLanguageModel(n=n)
        model.train(sentences)
        
        # ç”Ÿæˆæ–‡æœ¬
        generated = model.generate(start_words="æˆ‘", max_length=10)
        
        ax3.text(0.1, y_pos, f'n={n}:', fontsize=12, weight='bold')
        ax3.text(0.25, y_pos, generated, fontsize=11,
                bbox=dict(boxstyle="round", facecolor='lightblue', alpha=0.5))
        
        y_pos -= 0.2
    
    # æ·»åŠ ä¼˜ç¼ºç‚¹
    ax3.text(0.5, 0.3, 'N-gramçš„æƒè¡¡ï¼š\n'
                       'â€¢ nâ†‘ï¼šæ›´å‡†ç¡®ï¼Œä½†æ•°æ®ç¨€ç–\n'
                       'â€¢ nâ†“ï¼šæ›´å¹³æ»‘ï¼Œä½†ä¸¢å¤±é•¿ç¨‹ä¾èµ–',
            transform=ax3.transAxes, ha='center',
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # 4. æ•°æ®ç¨€ç–é—®é¢˜
    ax4.set_title('æ•°æ®ç¨€ç–é—®é¢˜', fontsize=14, weight='bold')
    
    # è®¡ç®—ä¸åŒnå€¼çš„è¦†ç›–ç‡
    n_values = [1, 2, 3, 4, 5]
    coverage_rates = []
    vocab_sizes = []
    
    for n in n_values:
        model = NGramLanguageModel(n=n)
        model.train(sentences)
        
        # ç»Ÿè®¡çœ‹åˆ°çš„n-gramæ•°é‡
        total_ngrams = sum(len(counter) for counter in model.counts.values())
        # ç†è®ºå¯èƒ½çš„n-gramæ•°é‡
        vocab_size = len(model.vocab)
        possible_ngrams = vocab_size ** n
        
        coverage = min(total_ngrams / possible_ngrams * 100, 100)
        coverage_rates.append(coverage)
        vocab_sizes.append(possible_ngrams)
    
    ax4_twin = ax4.twinx()
    
    line1 = ax4.plot(n_values, coverage_rates, 'b-o', markersize=8, 
                     linewidth=2, label='è¦†ç›–ç‡')
    line2 = ax4_twin.semilogy(n_values, vocab_sizes, 'r-s', markersize=8,
                              linewidth=2, label='å¯èƒ½ç»„åˆæ•°')
    
    ax4.set_xlabel('nå€¼')
    ax4.set_ylabel('è¦†ç›–ç‡ (%)', color='blue')
    ax4_twin.set_ylabel('å¯èƒ½çš„n-gramæ•°', color='red')
    ax4.tick_params(axis='y', labelcolor='blue')
    ax4_twin.tick_params(axis='y', labelcolor='red')
    
    # åˆå¹¶å›¾ä¾‹
    lines = line1 + line2
    labels = [l.get_label() for l in lines]
    ax4.legend(lines, labels, loc='center right')
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ“Š N-gramæ¨¡å‹æ€»ç»“ï¼š")
    print("1. ç®€å•ç›´è§‚ï¼Œæ˜“äºå®ç°")
    print("2. nè¶Šå¤§ï¼Œä¸Šä¸‹æ–‡è¶Šä¸°å¯Œï¼Œä½†æ•°æ®ç¨€ç–")
    print("3. æ— æ³•æ•æ‰é•¿è·ç¦»ä¾èµ–")
    print("4. éœ€è¦å¹³æ»‘æŠ€æœ¯å¤„ç†æœªè§è¿‡çš„n-gram")

N_gramæ¨¡å‹æ¼”ç¤º()
```

#### ğŸ§  ç¥ç»è¯­è¨€æ¨¡å‹çš„è¯ç”Ÿ

```python
def ç¥ç»è¯­è¨€æ¨¡å‹æ¼”ç¤º():
    """å±•ç¤ºç¥ç»è¯­è¨€æ¨¡å‹çš„åŸç†"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. è¯åµŒå…¥çš„å¼•å…¥
    ax1.set_title('è¯åµŒå…¥ï¼šä»ç¦»æ•£åˆ°è¿ç»­', fontsize=14, weight='bold')
    ax1.set_xlim(-3, 3)
    ax1.set_ylim(-3, 3)
    
    # One-hotç¼–ç çš„é—®é¢˜
    words = ['çŒ«', 'ç‹—', 'æ±½è½¦', 'é£æœº', 'è€è™']
    # æ¨¡æ‹Ÿçš„2Dè¯åµŒå…¥
    embeddings = {
        'çŒ«': [1.2, 0.8],
        'ç‹—': [1.0, 0.9],
        'è€è™': [1.3, 0.7],
        'æ±½è½¦': [-1.5, 1.2],
        'é£æœº': [-1.3, 1.5]
    }
    
    # ç»˜åˆ¶è¯å‘é‡
    for word, (x, y) in embeddings.items():
        ax1.scatter(x, y, s=200, alpha=0.6)
        ax1.annotate(word, (x, y), xytext=(5, 5), 
                    textcoords='offset points', fontsize=12)
    
    # ç”»èšç±»åœˆ
    animal_center = [1.17, 0.8]
    vehicle_center = [-1.4, 1.35]
    
    circle1 = plt.Circle(animal_center, 0.5, color='lightblue', 
                        fill=True, alpha=0.3)
    circle2 = plt.Circle(vehicle_center, 0.5, color='lightgreen', 
                        fill=True, alpha=0.3)
    ax1.add_patch(circle1)
    ax1.add_patch(circle2)
    
    ax1.text(animal_center[0], animal_center[1]-0.7, 'åŠ¨ç‰©', 
            ha='center', fontsize=10, weight='bold')
    ax1.text(vehicle_center[0], vehicle_center[1]-0.7, 'äº¤é€šå·¥å…·', 
            ha='center', fontsize=10, weight='bold')
    
    ax1.set_xlabel('ç»´åº¦1')
    ax1.set_ylabel('ç»´åº¦2')
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=0, color='k', linestyle='-', alpha=0.3)
    ax1.axvline(x=0, color='k', linestyle='-', alpha=0.3)
    
    # 2. å‰é¦ˆç¥ç»è¯­è¨€æ¨¡å‹
    ax2.set_title('å‰é¦ˆç¥ç»è¯­è¨€æ¨¡å‹ï¼ˆBengio et al. 2003ï¼‰', fontsize=14, weight='bold')
    ax2.set_xlim(0, 10)
    ax2.set_ylim(0, 10)
    ax2.axis('off')
    
    # ç½‘ç»œç»“æ„
    # è¾“å…¥å±‚ï¼ˆ3ä¸ªè¯ï¼‰
    input_words = ['æˆ‘', 'çˆ±', 'åƒ']
    for i, word in enumerate(input_words):
        rect = plt.Rectangle((1, 7-i*1.5), 1, 0.8,
                           facecolor='lightblue', edgecolor='black', linewidth=2)
        ax2.add_patch(rect)
        ax2.text(1.5, 7.4-i*1.5, word, ha='center', va='center', fontsize=11)
    
    # åµŒå…¥å±‚
    ax2.text(3.5, 8, 'åµŒå…¥å±‚', ha='center', fontsize=10, weight='bold')
    for i in range(3):
        for j in range(4):  # 4ç»´åµŒå…¥
            circle = plt.Circle((3.5+j*0.3, 7-i*1.5), 0.1,
                              facecolor='lightgreen', edgecolor='black')
            ax2.add_patch(circle)
    
    # éšè—å±‚
    ax2.text(6, 8, 'éšè—å±‚', ha='center', fontsize=10, weight='bold')
    for i in range(5):
        circle = plt.Circle((6, 6.5-i*0.6), 0.2,
                          facecolor='lightyellow', edgecolor='black')
        ax2.add_patch(circle)
    
    # è¾“å‡ºå±‚
    ax2.text(8.5, 8, 'è¾“å‡ºå±‚', ha='center', fontsize=10, weight='bold')
    output_words = ['è‹¹æœ', 'é¦™è•‰', '...', 'è¥¿ç“œ']
    for i, word in enumerate(output_words):
        rect = plt.Rectangle((8, 6.5-i*0.8), 1, 0.6,
                           facecolor='lightcoral', edgecolor='black')
        ax2.add_patch(rect)
        ax2.text(8.5, 6.8-i*0.8, word, ha='center', va='center', fontsize=9)
    
    # ç”»è¿æ¥çº¿ï¼ˆç®€åŒ–ï¼‰
    # åµŒå…¥åˆ°éšè—
    ax2.arrow(4.7, 6, 1, 0, head_width=0.1, head_length=0.1,
             fc='gray', ec='gray', alpha=0.5)
    # éšè—åˆ°è¾“å‡º
    ax2.arrow(6.3, 5, 1.5, 0, head_width=0.1, head_length=0.1,
             fc='gray', ec='gray', alpha=0.5)
    
    # 3. RNNè¯­è¨€æ¨¡å‹
    ax3.set_title('RNNè¯­è¨€æ¨¡å‹ï¼šå¤„ç†å˜é•¿åºåˆ—', fontsize=14, weight='bold')
    ax3.set_xlim(0, 10)
    ax3.set_ylim(0, 10)
    ax3.axis('off')
    
    # RNNå±•å¼€å›¾
    words = ['æˆ‘', 'çˆ±', 'å­¦ä¹ ', 'AI']
    hidden_states = ['h0', 'h1', 'h2', 'h3']
    
    for i, (word, h) in enumerate(zip(words, hidden_states)):
        x = 1.5 + i * 2
        
        # è¾“å…¥
        rect = plt.Rectangle((x-0.4, 3), 0.8, 0.8,
                           facecolor='lightblue', edgecolor='black')
        ax3.add_patch(rect)
        ax3.text(x, 3.4, word, ha='center', va='center', fontsize=10)
        
        # éšè—çŠ¶æ€
        circle = plt.Circle((x, 5), 0.4, facecolor='lightgreen',
                          edgecolor='black', linewidth=2)
        ax3.add_patch(circle)
        ax3.text(x, 5, h, ha='center', va='center', fontsize=10)
        
        # è¾“å‡º
        rect = plt.Rectangle((x-0.4, 7), 0.8, 0.8,
                           facecolor='lightcoral', edgecolor='black')
        ax3.add_patch(rect)
        if i < len(words) - 1:
            ax3.text(x, 7.4, words[i+1], ha='center', va='center', fontsize=10)
        else:
            ax3.text(x, 7.4, '?', ha='center', va='center', fontsize=10)
        
        # è¿æ¥
        # è¾“å…¥åˆ°éšè—
        ax3.arrow(x, 3.8, 0, 0.7, head_width=0.1, head_length=0.05,
                 fc='blue', ec='blue')
        # éšè—åˆ°è¾“å‡º
        ax3.arrow(x, 5.5, 0, 1.3, head_width=0.1, head_length=0.05,
                 fc='red', ec='red')
        # éšè—åˆ°éšè—
        if i < len(words) - 1:
            ax3.arrow(x+0.4, 5, 1.2, 0, head_width=0.1, head_length=0.05,
                     fc='green', ec='green', linestyle='--')
    
    ax3.text(5, 1.5, 'æ—¶é—´å±•å¼€ â†’', ha='center', fontsize=12, weight='bold')
    
    # 4. å¯¹æ¯”ç»Ÿè®¡vsç¥ç»
    ax4.set_title('ç»Ÿè®¡æ¨¡å‹ vs ç¥ç»æ¨¡å‹', fontsize=14, weight='bold')
    ax4.axis('off')
    
    # å¯¹æ¯”è¡¨æ ¼
    comparison = [
        ['ç‰¹æ€§', 'ç»Ÿè®¡æ¨¡å‹(N-gram)', 'ç¥ç»æ¨¡å‹'],
        ['---', '---', '---'],
        ['å‚æ•°é‡', 'è¯è¡¨å¤§å°^n', 'å›ºå®šå¤§å°'],
        ['æ³›åŒ–èƒ½åŠ›', 'å·®ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰', 'å¥½ï¼ˆè¯­ä¹‰ç›¸ä¼¼ï¼‰'],
        ['é•¿ç¨‹ä¾èµ–', f'æœ€å¤š{3}ä¸ªè¯', 'ç†è®ºä¸Šæ— é™'],
        ['è®¡ç®—æ•ˆç‡', 'æŸ¥è¡¨O(1)', 'çŸ©é˜µè¿ç®—O(n)'],
        ['å¯è§£é‡Šæ€§', 'é«˜', 'ä½'],
        ['æ•°æ®éœ€æ±‚', 'ä¸­ç­‰', 'å¤§é‡']
    ]
    
    # ç»˜åˆ¶è¡¨æ ¼
    cell_height = 0.8
    cell_width = 3
    
    for i, row in enumerate(comparison):
        for j, cell in enumerate(row):
            x = 1 + j * cell_width
            y = 8 - i * cell_height
            
            # è¡¨å¤´ç‰¹æ®Šå¤„ç†
            if i == 0:
                color = 'lightgray'
                weight = 'bold'
            elif i == 1:
                continue
            elif j == 0:
                color = 'lightblue'
                weight = 'bold'
            else:
                color = 'white'
                weight = 'normal'
            
            if i != 1:  # è·³è¿‡åˆ†éš”çº¿
                rect = plt.Rectangle((x-cell_width/2, y-cell_height/2), 
                                   cell_width, cell_height,
                                   facecolor=color, edgecolor='black')
                ax4.add_patch(rect)
                ax4.text(x, y, cell, ha='center', va='center', 
                        fontsize=10, weight=weight)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ§  ç¥ç»è¯­è¨€æ¨¡å‹çš„é©å‘½ï¼š")
    print("1. è¯åµŒå…¥ï¼šç›¸ä¼¼çš„è¯æœ‰ç›¸ä¼¼çš„è¡¨ç¤º")
    print("2. å‚æ•°å…±äº«ï¼šä¸åŒä½ç½®å…±äº«æƒé‡")
    print("3. éçº¿æ€§ï¼šå¯ä»¥å­¦ä¹ å¤æ‚æ¨¡å¼")
    print("4. ç«¯åˆ°ç«¯ï¼šä»è¾“å…¥åˆ°è¾“å‡ºä¸€ä½“åŒ–å­¦ä¹ ")

ç¥ç»è¯­è¨€æ¨¡å‹æ¼”ç¤º()
```

#### ğŸš€ ä»RNNåˆ°Transformer

```python
def è¯­è¨€æ¨¡å‹æ¼”åŒ–å²():
    """å±•ç¤ºè¯­è¨€æ¨¡å‹çš„æ¼”åŒ–å†ç¨‹"""
    
    fig = plt.figure(figsize=(16, 10))
    ax = fig.add_subplot(111)
    ax.set_xlim(1950, 2030)
    ax.set_ylim(0, 10)
    ax.set_xlabel('å¹´ä»½', fontsize=12)
    ax.set_ylabel('æ¨¡å‹å¤æ‚åº¦/å½±å“åŠ›', fontsize=12)
    ax.set_title('è¯­è¨€æ¨¡å‹å‘å±•å²', fontsize=16, weight='bold')
    
    # é‡è¦é‡Œç¨‹ç¢‘
    milestones = [
        (1948, 1, 'Shannon\nä¿¡æ¯è®º', 'blue'),
        (1980, 2, 'N-gram\nç»Ÿè®¡æ¨¡å‹', 'green'),
        (2003, 3, 'ç¥ç»è¯­è¨€æ¨¡å‹\n(Bengio)', 'orange'),
        (2013, 4, 'Word2Vec\nè¯åµŒå…¥é©å‘½', 'red'),
        (2014, 5, 'RNN/LSTM\nåºåˆ—å»ºæ¨¡', 'purple'),
        (2017, 7, 'Transformer\næ³¨æ„åŠ›æœºåˆ¶', 'darkred'),
        (2018, 8, 'BERT\né¢„è®­ç»ƒæ—¶ä»£', 'darkblue'),
        (2020, 9, 'GPT-3\nå¤§æ¨¡å‹å…ƒå¹´', 'darkgreen'),
        (2023, 9.5, 'ChatGPT\nAIå¯¹è¯é©å‘½', 'black'),
    ]
    
    # ç»˜åˆ¶æ—¶é—´çº¿
    for year, impact, name, color in milestones:
        ax.scatter(year, impact, s=300, c=color, alpha=0.6, edgecolors='black', linewidth=2)
        ax.annotate(name, (year, impact), xytext=(0, 20), 
                   textcoords='offset points', ha='center', fontsize=10,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor=color, alpha=0.3))
    
    # è¿æ¥çº¿æ˜¾ç¤ºæ¼”åŒ–
    years = [m[0] for m in milestones]
    impacts = [m[1] for m in milestones]
    ax.plot(years, impacts, 'k--', alpha=0.3, linewidth=2)
    
    # æ·»åŠ æ—¶ä»£æ ‡æ³¨
    eras = [
        (1950, 1990, 0.5, 'è§„åˆ™æ—¶ä»£', 'lightblue'),
        (1990, 2010, 0.5, 'ç»Ÿè®¡æ—¶ä»£', 'lightgreen'),
        (2010, 2017, 0.5, 'æ·±åº¦å­¦ä¹ æ—¶ä»£', 'lightyellow'),
        (2017, 2030, 0.5, 'å¤§æ¨¡å‹æ—¶ä»£', 'lightcoral'),
    ]
    
    for start, end, y, name, color in eras:
        ax.axvspan(start, end, ymin=0, ymax=0.15, alpha=0.3, color=color)
        ax.text((start+end)/2, y, name, ha='center', fontsize=12, weight='bold')
    
    # æ·»åŠ å…³é”®åˆ›æ–°æ ‡æ³¨
    innovations = [
        (2013, 6, 'åˆ†å¸ƒå¼è¡¨ç¤º'),
        (2017, 6, 'è‡ªæ³¨æ„åŠ›'),
        (2018, 6, 'é¢„è®­ç»ƒ-å¾®è°ƒ'),
        (2020, 6, 'å°‘æ ·æœ¬å­¦ä¹ '),
    ]
    
    for year, y, innovation in innovations:
        ax.annotate(innovation, xy=(year, y), xytext=(year, y+1),
                   arrowprops=dict(arrowstyle='->', color='gray', alpha=0.5),
                   fontsize=9, ha='center', style='italic')
    
    ax.grid(True, alpha=0.3)
    ax.set_ylim(0, 11)
    
    plt.tight_layout()
    plt.show()
    
    # æ¨¡å‹å‚æ•°é‡å¯¹æ¯”
    fig2, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # å‚æ•°é‡å¢é•¿
    ax1.set_title('æ¨¡å‹å‚æ•°é‡æŒ‡æ•°å¢é•¿', fontsize=14, weight='bold')
    
    models = ['N-gram', 'NNLM\n(2003)', 'Word2Vec\n(2013)', 'LSTM\n(2015)', 
              'Transformer\n(2017)', 'BERT\n(2018)', 'GPT-2\n(2019)', 
              'GPT-3\n(2020)', 'GPT-4\n(2023)']
    params = [1e6, 1e7, 3e8, 5e8, 1e8, 3.4e8, 1.5e9, 175e9, 1.7e12]  # ä¼°è®¡å€¼
    
    ax1.semilogy(models, params, 'bo-', markersize=10, linewidth=2)
    ax1.set_ylabel('å‚æ•°é‡')
    ax1.set_xlabel('æ¨¡å‹')
    ax1.tick_params(axis='x', rotation=45)
    ax1.grid(True, alpha=0.3)
    
    # æ ‡æ³¨æ•°é‡çº§
    for i, (model, param) in enumerate(zip(models, params)):
        if param >= 1e12:
            label = f'{param/1e12:.1f}T'
        elif param >= 1e9:
            label = f'{param/1e9:.0f}B'
        elif param >= 1e6:
            label = f'{param/1e6:.0f}M'
        else:
            label = f'{param:.0f}'
        ax1.text(i, param*1.5, label, ha='center', fontsize=9)
    
    # æ€§èƒ½æå‡
    ax2.set_title('æ¨¡å‹èƒ½åŠ›çš„æå‡', fontsize=14, weight='bold')
    
    capabilities = ['è¯­æ³•ç†è§£', 'è¯­ä¹‰ç†è§£', 'å¸¸è¯†æ¨ç†', 'ä¸Šä¸‹æ–‡å­¦ä¹ ', 'åˆ›é€ ç”Ÿæˆ']
    ngram_scores = [30, 10, 5, 0, 0]
    rnn_scores = [70, 60, 30, 20, 10]
    transformer_scores = [95, 90, 80, 85, 70]
    
    x = np.arange(len(capabilities))
    width = 0.25
    
    ax2.bar(x - width, ngram_scores, width, label='N-gram', color='lightblue')
    ax2.bar(x, rnn_scores, width, label='RNN/LSTM', color='lightgreen')
    ax2.bar(x + width, transformer_scores, width, label='Transformer+', color='lightcoral')
    
    ax2.set_ylabel('èƒ½åŠ›å¾—åˆ†')
    ax2.set_xticks(x)
    ax2.set_xticklabels(capabilities, rotation=15, ha='right')
    ax2.legend()
    ax2.grid(True, alpha=0.3, axis='y')
    ax2.set_ylim(0, 100)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ“ˆ è¯­è¨€æ¨¡å‹æ¼”åŒ–çš„å…³é”®è¶‹åŠ¿ï¼š")
    print("1. ä»ç¦»æ•£åˆ°è¿ç»­ï¼šone-hot â†’ è¯åµŒå…¥")
    print("2. ä»å±€éƒ¨åˆ°å…¨å±€ï¼šn-gram â†’ è‡ªæ³¨æ„åŠ›")
    print("3. ä»ç‰¹å®šåˆ°é€šç”¨ï¼šä»»åŠ¡ä¸“ç”¨ â†’ é€šç”¨é¢„è®­ç»ƒ")
    print("4. ä»å°åˆ°å¤§ï¼šMB â†’ TBçº§å‚æ•°")

è¯­è¨€æ¨¡å‹æ¼”åŒ–å²()
```

#### ğŸ’¡ å®æˆ˜ï¼šæ„å»ºç®€å•çš„ç¥ç»è¯­è¨€æ¨¡å‹

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class SimpleNeuralLM(nn.Module):
    """ä¸€ä¸ªç®€å•çš„ç¥ç»è¯­è¨€æ¨¡å‹"""
    
    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256, n_layers=2):
        super(SimpleNeuralLM, self).__init__()
        
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, 
                           batch_first=True, dropout=0.2)
        self.fc = nn.Linear(hidden_dim, vocab_size)
        
    def forward(self, x, hidden=None):
        # x: [batch_size, seq_len]
        embedded = self.embedding(x)  # [batch_size, seq_len, embedding_dim]
        output, hidden = self.lstm(embedded, hidden)  # [batch_size, seq_len, hidden_dim]
        predictions = self.fc(output)  # [batch_size, seq_len, vocab_size]
        return predictions, hidden
    
    def generate(self, start_tokens, max_length=50, temperature=1.0):
        """ç”Ÿæˆæ–‡æœ¬"""
        self.eval()
        tokens = start_tokens
        hidden = None
        
        with torch.no_grad():
            for _ in range(max_length):
                # å‰å‘ä¼ æ’­
                input_tensor = torch.tensor([tokens[-10:]])  # åªçœ‹æœ€è¿‘10ä¸ªè¯
                output, hidden = self.forward(input_tensor, hidden)
                
                # è·å–æœ€åä¸€ä¸ªä½ç½®çš„è¾“å‡º
                logits = output[0, -1, :] / temperature
                probs = F.softmax(logits, dim=0)
                
                # é‡‡æ ·
                next_token = torch.multinomial(probs, 1).item()
                tokens.append(next_token)
                
                # å¦‚æœç”Ÿæˆäº†ç»“æŸç¬¦ï¼Œåœæ­¢
                if next_token == 2:  # å‡è®¾2æ˜¯</s>
                    break
        
        return tokens

def å¯¹æ¯”å®éªŒ():
    """å¯¹æ¯”N-gramå’Œç¥ç»è¯­è¨€æ¨¡å‹"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. æ³›åŒ–èƒ½åŠ›å¯¹æ¯”
    ax1.set_title('æ³›åŒ–èƒ½åŠ›ï¼šå¤„ç†æœªè§è¿‡çš„ç»„åˆ', fontsize=14, weight='bold')
    ax1.axis('off')
    
    # ç¤ºä¾‹
    seen_phrases = ["æˆ‘çˆ±åƒè‹¹æœ", "ä»–çˆ±åƒé¦™è•‰", "å¥¹å–œæ¬¢åƒæ©™å­"]
    unseen_phrase = "æˆ‘å–œæ¬¢åƒé¦™è•‰"
    
    y_pos = 0.9
    ax1.text(0.5, y_pos, 'è®­ç»ƒæ•°æ®ï¼š', transform=ax1.transAxes, 
            fontsize=12, weight='bold', ha='center')
    
    y_pos -= 0.1
    for phrase in seen_phrases:
        ax1.text(0.5, y_pos, phrase, transform=ax1.transAxes,
                fontsize=11, ha='center',
                bbox=dict(boxstyle="round", facecolor='lightblue', alpha=0.5))
        y_pos -= 0.08
    
    y_pos -= 0.05
    ax1.text(0.5, y_pos, 'æµ‹è¯•ï¼š' + unseen_phrase, transform=ax1.transAxes,
            fontsize=12, weight='bold', ha='center', color='red')
    
    y_pos -= 0.15
    ax1.text(0.25, y_pos, 'N-gram:\næœªè§è¿‡"æˆ‘å–œæ¬¢åƒ"\né¢„æµ‹å¤±è´¥âŒ', 
            transform=ax1.transAxes, fontsize=10, ha='center',
            bbox=dict(boxstyle="round", facecolor='lightcoral', alpha=0.5))
    
    ax1.text(0.75, y_pos, 'ç¥ç»æ¨¡å‹:\nç†è§£è¯­ä¹‰ç›¸ä¼¼æ€§\né¢„æµ‹æˆåŠŸâœ“', 
            transform=ax1.transAxes, fontsize=10, ha='center',
            bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.5))
    
    # 2. é•¿ç¨‹ä¾èµ–å¤„ç†
    ax2.set_title('é•¿ç¨‹ä¾èµ–ï¼šè®°ä½è¿œå¤„çš„ä¿¡æ¯', fontsize=14, weight='bold')
    
    sentence = "é‚£ä¸ªæ˜¨å¤©æˆ‘åœ¨å…¬å›­é‡Œé‡åˆ°çš„æˆ´ç€çº¢å¸½å­çš„å¥³å­©ä»Šå¤©åˆæ¥äº†"
    important_words = [(0, 2), (29, 31)]  # "é‚£ä¸ª"å’Œ"å¥³å­©"
    
    # å¯è§†åŒ–å¥å­
    char_positions = list(range(len(sentence)))
    char_heights = [1] * len(sentence)
    
    # N-gramè§†é‡ï¼ˆå‡è®¾trigramï¼‰
    ngram_window = 3
    ax2.bar(char_positions[:ngram_window], char_heights[:ngram_window], 
           color='lightblue', edgecolor='black', alpha=0.7, label='N-gramè§†é‡')
    ax2.bar(char_positions[ngram_window:], char_heights[ngram_window:], 
           color='lightgray', edgecolor='black', alpha=0.5)
    
    # æ ‡æ³¨é‡è¦è¯
    for start, end in important_words:
        ax2.bar(char_positions[start:end], char_heights[start:end], 
               color='red', edgecolor='black', alpha=0.8)
    
    ax2.set_ylim(0, 2)
    ax2.set_xlabel('å­—ç¬¦ä½ç½®')
    ax2.set_title('N-gramï¼šåªèƒ½çœ‹åˆ°å±€éƒ¨', fontsize=12)
    ax2.legend()
    
    # 3. å‚æ•°æ•ˆç‡
    ax3.set_title('å‚æ•°æ•ˆç‡å¯¹æ¯”', fontsize=14, weight='bold')
    
    vocab_sizes = [1000, 5000, 10000, 50000, 100000]
    ngram_params = [v**3 for v in vocab_sizes]  # trigram
    neural_params = [v * 128 + 128 * 256 + 256 * v for v in vocab_sizes]  # ç®€åŒ–è®¡ç®—
    
    ax3.loglog(vocab_sizes, ngram_params, 'b-o', markersize=8, 
              linewidth=2, label='N-gram (n=3)')
    ax3.loglog(vocab_sizes, neural_params, 'r-s', markersize=8,
              linewidth=2, label='ç¥ç»æ¨¡å‹')
    
    ax3.set_xlabel('è¯è¡¨å¤§å°')
    ax3.set_ylabel('å‚æ•°æ•°é‡')
    ax3.legend()
    ax3.grid(True, alpha=0.3, which="both")
    
    # æ ‡æ³¨å·®å¼‚
    for v, n, neural in zip(vocab_sizes[-2:], ngram_params[-2:], neural_params[-2:]):
        ratio = n / neural
        ax3.annotate(f'{ratio:.0f}x', xy=(v, n), xytext=(v*1.2, n),
                    arrowprops=dict(arrowstyle='->', color='gray'),
                    fontsize=9)
    
    # 4. å®é™…æ•ˆæœå±•ç¤º
    ax4.set_title('ç”Ÿæˆæ–‡æœ¬è´¨é‡å¯¹æ¯”', fontsize=14, weight='bold')
    ax4.axis('off')
    
    examples = [
        ('N-gramç”Ÿæˆï¼š', 'æˆ‘ çˆ± åƒ è‹¹æœ ã€‚ æˆ‘ çˆ± åƒ è‹¹æœ ã€‚ ä»– çˆ± åƒ', 'lightcoral'),
        ('ç¥ç»æ¨¡å‹ç”Ÿæˆï¼š', 'æˆ‘ çˆ± åƒ è‹¹æœ ï¼Œ ä½†æ˜¯ ä»Šå¤© æƒ³ å°è¯• ä¸€äº› æ–° çš„ æ°´æœ', 'lightgreen'),
    ]
    
    y_pos = 0.8
    for title, text, color in examples:
        ax4.text(0.1, y_pos, title, transform=ax4.transAxes,
                fontsize=12, weight='bold')
        ax4.text(0.1, y_pos-0.1, text, transform=ax4.transAxes,
                fontsize=11, style='italic',
                bbox=dict(boxstyle="round", facecolor=color, alpha=0.5))
        y_pos -= 0.3
    
    # è¯„ä»·
    ax4.text(0.5, 0.2, 'ç¥ç»æ¨¡å‹ä¼˜åŠ¿ï¼š\nâ€¢ æ›´è‡ªç„¶çš„è¯­è¨€\nâ€¢ æ›´å¥½çš„è¿è´¯æ€§\nâ€¢ æ›´å¼ºçš„åˆ›é€ åŠ›',
            transform=ax4.transAxes, ha='center',
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ”¬ å®éªŒç»“è®ºï¼š")
    print("1. ç¥ç»æ¨¡å‹åœ¨æ³›åŒ–èƒ½åŠ›ä¸Šè¿œè¶…N-gram")
    print("2. RNN/LSTMå¯ä»¥æ•æ‰ä»»æ„é•¿åº¦çš„ä¾èµ–")
    print("3. å‚æ•°æ•ˆç‡ï¼šç¥ç»æ¨¡å‹éšè¯è¡¨çº¿æ€§å¢é•¿ï¼ŒN-gramå‘ˆæŒ‡æ•°å¢é•¿")
    print("4. ç”Ÿæˆè´¨é‡ï¼šç¥ç»æ¨¡å‹æ›´è‡ªç„¶ã€è¿è´¯")

å¯¹æ¯”å®éªŒ()
```

#### ğŸ“ æœ¬ç« å°ç»“

ä»ç»Ÿè®¡è¯­è¨€æ¨¡å‹åˆ°ç¥ç»è¯­è¨€æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€æ¬¡èŒƒå¼è½¬å˜ï¼š

1. **æ ¸å¿ƒæ€æƒ³çš„è½¬å˜**ï¼š
   - ä»"æ•°æ•°"åˆ°"ç†è§£"
   - ä»ç¦»æ•£ç¬¦å·åˆ°è¿ç»­è¡¨ç¤º
   - ä»å±€éƒ¨ç‰¹å¾åˆ°å…¨å±€è¯­ä¹‰

2. **æŠ€æœ¯çªç ´**ï¼š
   - è¯åµŒå…¥ï¼šè®©è¯æœ‰äº†"æ„ä¹‰"
   - RNN/LSTMï¼šå¤„ç†å˜é•¿åºåˆ—
   - æ³¨æ„åŠ›æœºåˆ¶ï¼šçªç ´é•¿ç¨‹ä¾èµ–é™åˆ¶

3. **å‘å±•è¶‹åŠ¿**ï¼š
   - æ¨¡å‹è¶Šæ¥è¶Šå¤§
   - é¢„è®­ç»ƒæˆä¸ºæ ‡é…
   - ä»ä¸“ç”¨åˆ°é€šç”¨

4. **æœªæ¥å±•æœ›**ï¼š
   - æ›´é«˜æ•ˆçš„æ¶æ„
   - æ›´å¥½çš„å¯è§£é‡Šæ€§
   - æ›´å¼ºçš„æ¨ç†èƒ½åŠ›

#### ğŸ’¡ å®ç”¨å»ºè®®

1. **å­¦ä¹ è·¯å¾„**ï¼š
   - å…ˆç†è§£N-gramï¼Œæ‰“å¥½æ¦‚ç‡åŸºç¡€
   - æŒæ¡è¯åµŒå…¥ï¼Œç†è§£åˆ†å¸ƒå¼è¡¨ç¤º
   - å­¦ä¹ RNN/Transformeræ¶æ„

2. **å®è·µé¡¹ç›®**ï¼š
   - å®ç°ä¸€ä¸ªç®€å•çš„N-gramæ¨¡å‹
   - ç”¨PyTorchæ„å»ºå­—ç¬¦çº§è¯­è¨€æ¨¡å‹
   - å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹

3. **æ·±å…¥ç ”ç©¶**ï¼š
   - é˜…è¯»ç»å…¸è®ºæ–‡ï¼ˆBengio 2003, Mikolov 2013ï¼‰
   - äº†è§£æœ€æ–°è¿›å±•ï¼ˆGPT, BERTç³»åˆ—ï¼‰
   - å…³æ³¨æ•ˆç‡ä¼˜åŒ–æ–¹å‘

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆè¯´è¯åµŒå…¥æ˜¯æ·±åº¦å­¦ä¹ åœ¨NLPä¸­çš„ç¬¬ä¸€ä¸ªæ€æ‰‹çº§åº”ç”¨ï¼Ÿ
2. N-gramæ¨¡å‹åœ¨æŸäº›åœºæ™¯ä¸‹ä»ç„¶æœ‰ç”¨ï¼Œä½ èƒ½æƒ³åˆ°å“ªäº›ï¼Ÿ
3. ç¥ç»è¯­è¨€æ¨¡å‹çš„"ç†è§£"å’Œäººç±»çš„ç†è§£æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ

æ­å–œä½ å®Œæˆäº†ç¬¬ä¸€éƒ¨åˆ†çš„å­¦ä¹ ï¼ä¸‹ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨è¯­è¨€çš„è¡¨ç¤ºä¸ç¼–ç ï¼Œä»Tokenizationå¼€å§‹ï¼Œé€æ­¥ç†è§£ç°ä»£NLPçš„åŸºç¡€æŠ€æœ¯æ ˆã€‚

## ç¬¬äºŒéƒ¨åˆ†ï¼šè¯­è¨€çš„è¡¨ç¤ºä¸ç¼–ç 

### ç¬¬13ç« ï¼šTokenizationâ€”â€”æŠŠæ–‡æœ¬åˆ‡æˆå°å—

#### ğŸ¯ æœ¬ç« å¯¼è¯»

æƒ³è±¡ä½ è¦æ•™ä¸€ä¸ªå¤–æ˜Ÿäººè¯»ä¸­æ–‡ã€‚ä½ ä¼šæ€ä¹ˆå¼€å§‹ï¼Ÿ

"ä»Šå¤©å¤©æ°”çœŸå¥½" â†’ ä»Š/å¤©/å¤©/æ°”/çœŸ/å¥½ï¼Ÿè¿˜æ˜¯ ä»Šå¤©/å¤©æ°”/çœŸ/å¥½ï¼Ÿ

è¿™å°±æ˜¯Tokenizationï¼ˆåˆ†è¯ï¼‰è¦è§£å†³çš„é—®é¢˜ï¼š**å¦‚ä½•æŠŠè¿ç»­çš„æ–‡æœ¬åˆ‡åˆ†æˆæœºå™¨èƒ½ç†è§£çš„åŸºæœ¬å•å…ƒ**ã€‚

çœ‹ä¼¼ç®€å•çš„ä»»åŠ¡ï¼ŒèƒŒåå´éšè—ç€è¯­è¨€å¤„ç†çš„æ·±åˆ»æŒ‘æˆ˜ã€‚ä»æœ€æ—©çš„ç©ºæ ¼åˆ†è¯ï¼Œåˆ°ä»Šå¤©çš„å­è¯ç®—æ³•ï¼Œåˆ†è¯æŠ€æœ¯çš„æ¼”è¿›è§è¯äº†NLPçš„å‘å±•å†ç¨‹ã€‚

#### ğŸ”¤ ä¸ºä»€ä¹ˆéœ€è¦Tokenizationï¼Ÿ

```python
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from collections import Counter, defaultdict
import re

def ä¸ºä»€ä¹ˆéœ€è¦åˆ†è¯():
    """å±•ç¤ºåˆ†è¯çš„å¿…è¦æ€§"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. è®¡ç®—æœºvsäººç±»ç†è§£æ–‡æœ¬
    ax1.set_title('äººç±»vsè®¡ç®—æœºï¼šç†è§£æ–‡æœ¬çš„å·®å¼‚', fontsize=14, weight='bold')
    ax1.set_xlim(0, 10)
    ax1.set_ylim(0, 10)
    ax1.axis('off')
    
    # äººç±»è§†è§’
    ax1.text(2.5, 8, 'äººç±»è§†è§’', fontsize=12, weight='bold', ha='center')
    sentence_human = "æˆ‘çˆ±è‡ªç„¶è¯­è¨€å¤„ç†"
    ax1.text(2.5, 6.5, sentence_human, fontsize=14, ha='center',
            bbox=dict(boxstyle="round", facecolor='lightblue'))
    ax1.text(2.5, 5, 'ç›´æ¥ç†è§£æ•´ä½“å«ä¹‰', fontsize=10, ha='center', style='italic')
    
    # è®¡ç®—æœºè§†è§’
    ax1.text(7.5, 8, 'è®¡ç®—æœºè§†è§’', fontsize=12, weight='bold', ha='center')
    
    # å­—èŠ‚è¡¨ç¤º
    bytes_repr = sentence_human.encode('utf-8')
    byte_str = ' '.join([f'{b:02X}' for b in bytes_repr[:12]]) + '...'
    ax1.text(7.5, 6.5, byte_str, fontsize=10, ha='center', family='monospace',
            bbox=dict(boxstyle="round", facecolor='lightcoral'))
    ax1.text(7.5, 5, 'åªçœ‹åˆ°å­—èŠ‚åºåˆ—', fontsize=10, ha='center', style='italic')
    
    # ä¸­é—´çš„é—®å·
    ax1.text(5, 6.5, '?', fontsize=30, ha='center', color='red', weight='bold')
    ax1.arrow(3.5, 6.5, 1, 0, head_width=0.2, head_length=0.1, fc='gray', ec='gray')
    ax1.arrow(6.5, 6.5, -1, 0, head_width=0.2, head_length=0.1, fc='gray', ec='gray')
    
    ax1.text(5, 3, 'Tokenizationï¼šå°†æ–‡æœ¬è½¬æ¢ä¸º\nè®¡ç®—æœºå¯å¤„ç†çš„å•å…ƒ', 
            fontsize=12, ha='center', weight='bold',
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # 2. ä¸åŒè¯­è¨€çš„æŒ‘æˆ˜
    ax2.set_title('ä¸åŒè¯­è¨€çš„åˆ†è¯æŒ‘æˆ˜', fontsize=14, weight='bold')
    ax2.axis('off')
    
    languages = [
        ('è‹±è¯­', 'I love natural language processing', 'lightblue', 'ç©ºæ ¼å¤©ç„¶åˆ†éš”'),
        ('ä¸­æ–‡', 'æˆ‘çˆ±è‡ªç„¶è¯­è¨€å¤„ç†', 'lightgreen', 'æ²¡æœ‰ç©ºæ ¼åˆ†éš”'),
        ('æ—¥è¯­', 'ç§ã¯è‡ªç„¶è¨€èªå‡¦ç†ãŒå¥½ãã§ã™', 'lightcoral', 'æ··åˆæ–‡å­—ç³»ç»Ÿ'),
        ('å¾·è¯­', 'Natursprachverarbeitung', 'lightyellow', 'å¤åˆè¯é—®é¢˜')
    ]
    
    y_pos = 0.85
    for lang, text, color, challenge in languages:
        ax2.text(0.15, y_pos, f'{lang}ï¼š', fontsize=11, weight='bold',
                transform=ax2.transAxes)
        ax2.text(0.25, y_pos, text, fontsize=10,
                transform=ax2.transAxes,
                bbox=dict(boxstyle="round", facecolor=color, alpha=0.7))
        ax2.text(0.75, y_pos, challenge, fontsize=9, style='italic',
                transform=ax2.transAxes, color='red')
        y_pos -= 0.2
    
    # 3. è¯æ±‡é‡çˆ†ç‚¸é—®é¢˜
    ax3.set_title('è¯æ±‡é‡çˆ†ç‚¸é—®é¢˜', fontsize=14, weight='bold')
    
    # æ¨¡æ‹Ÿä¸åŒç²’åº¦çš„è¯æ±‡é‡
    granularities = ['å­—ç¬¦çº§', 'å­è¯çº§', 'è¯çº§', 'çŸ­è¯­çº§']
    vocab_sizes = [100, 10000, 100000, 1000000]
    colors = ['green', 'blue', 'orange', 'red']
    
    bars = ax3.bar(granularities, vocab_sizes, color=colors, alpha=0.7, edgecolor='black')
    ax3.set_ylabel('è¯æ±‡è¡¨å¤§å°')
    ax3.set_yscale('log')
    
    # æ ‡æ³¨ä¼˜ç¼ºç‚¹
    pros_cons = [
        ('å°è¯è¡¨\næ˜“å¤„ç†', 'è¯­ä¹‰å¼±'),
        ('å¹³è¡¡', 'ä¸»æµ'),
        ('è¯­ä¹‰å¼º', 'ç¨€ç–'),
        ('å¤ªå¤§', 'ä¸å®ç”¨')
    ]
    
    for bar, (pro, con) in zip(bars, pros_cons):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2, height * 1.5,
                pro, ha='center', va='bottom', fontsize=9, color='green')
        ax3.text(bar.get_x() + bar.get_width()/2, height * 0.5,
                con, ha='center', va='top', fontsize=9, color='red')
    
    ax3.grid(True, alpha=0.3, axis='y')
    
    # 4. OOVé—®é¢˜
    ax4.set_title('OOVï¼ˆæœªç™»å½•è¯ï¼‰é—®é¢˜', fontsize=14, weight='bold')
    ax4.axis('off')
    
    # è®­ç»ƒè¯æ±‡
    train_vocab = {'æˆ‘', 'çˆ±', 'åƒ', 'è‹¹æœ', 'é¦™è•‰', 'å­¦ä¹ ', 'AI'}
    
    # æµ‹è¯•å¥å­
    test_sentences = [
        ('æˆ‘çˆ±åƒæ¦´è²', ['æˆ‘', 'çˆ±', 'åƒ', '[UNK]']),
        ('æˆ‘åœ¨ç ”ç©¶GPT-4', ['æˆ‘', '[UNK]', '[UNK]', '[UNK]']),
        ('ä»–å–œæ¬¢ç¼–ç¨‹', ['[UNK]', '[UNK]', '[UNK]'])
    ]
    
    # å±•ç¤ºè¯æ±‡è¡¨
    ax4.text(0.2, 0.9, 'è®­ç»ƒè¯æ±‡è¡¨ï¼š', transform=ax4.transAxes, 
            fontsize=12, weight='bold')
    vocab_str = ', '.join(train_vocab)
    ax4.text(0.2, 0.83, vocab_str, transform=ax4.transAxes,
            fontsize=10, bbox=dict(boxstyle="round", facecolor='lightblue'))
    
    # å±•ç¤ºOOVé—®é¢˜
    ax4.text(0.2, 0.65, 'æµ‹è¯•æ—¶é‡åˆ°çš„é—®é¢˜ï¼š', transform=ax4.transAxes,
            fontsize=12, weight='bold')
    
    y_pos = 0.55
    for sent, tokens in test_sentences:
        ax4.text(0.2, y_pos, f'"{sent}" â†’', transform=ax4.transAxes, fontsize=10)
        
        x_pos = 0.5
        for token in tokens:
            if token == '[UNK]':
                color = 'lightcoral'
            else:
                color = 'lightgreen'
            ax4.text(x_pos, y_pos, token, transform=ax4.transAxes,
                    fontsize=10, bbox=dict(boxstyle="round", facecolor=color))
            x_pos += 0.1
        
        y_pos -= 0.12
    
    ax4.text(0.5, 0.15, 'OOVé—®é¢˜å¯¼è‡´ä¿¡æ¯ä¸¢å¤±ï¼', transform=ax4.transAxes,
            fontsize=12, ha='center', color='red', weight='bold',
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ“ Tokenizationçš„æ ¸å¿ƒæŒ‘æˆ˜ï¼š")
    print("1. å¦‚ä½•å®šä¹‰åˆé€‚çš„åŸºæœ¬å•å…ƒ")
    print("2. å¹³è¡¡è¯æ±‡è¡¨å¤§å°å’Œè¡¨è¾¾èƒ½åŠ›")
    print("3. å¤„ç†æœªè§è¿‡çš„è¯ï¼ˆOOVï¼‰")
    print("4. é€‚åº”ä¸åŒè¯­è¨€çš„ç‰¹ç‚¹")

ä¸ºä»€ä¹ˆéœ€è¦åˆ†è¯()
```

#### ğŸ”ª ä¼ ç»Ÿåˆ†è¯æ–¹æ³•

```python
class TraditionalTokenizers:
    """ä¼ ç»Ÿåˆ†è¯æ–¹æ³•çš„å®ç°"""
    
    @staticmethod
    def space_tokenize(text):
        """åŸºäºç©ºæ ¼çš„åˆ†è¯"""
        return text.split()
    
    @staticmethod
    def char_tokenize(text):
        """å­—ç¬¦çº§åˆ†è¯"""
        return list(text)
    
    @staticmethod
    def word_tokenize_english(text):
        """è‹±æ–‡è¯çº§åˆ†è¯ï¼ˆç®€å•ç‰ˆï¼‰"""
        # å¤„ç†æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'([.!?,;:])', r' \1 ', text)
        return text.split()
    
    @staticmethod
    def jieba_tokenize_chinese(text):
        """ä¸­æ–‡åˆ†è¯ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # ç®€åŒ–çš„æœ€å¤§åŒ¹é…ç®—æ³•
        vocab = {'æˆ‘', 'çˆ±', 'è‡ªç„¶', 'è¯­è¨€', 'å¤„ç†', 'è‡ªç„¶è¯­è¨€å¤„ç†', 
                'ä»Šå¤©', 'å¤©æ°”', 'å¾ˆå¥½', 'å­¦ä¹ '}
        
        result = []
        i = 0
        while i < len(text):
            # ä»æœ€é•¿çš„è¯å¼€å§‹åŒ¹é…
            for length in range(min(5, len(text)-i), 0, -1):
                word = text[i:i+length]
                if word in vocab or length == 1:
                    result.append(word)
                    i += length
                    break
        
        return result

def ä¼ ç»Ÿåˆ†è¯æ–¹æ³•å¯¹æ¯”():
    """å¯¹æ¯”ä¸åŒçš„ä¼ ç»Ÿåˆ†è¯æ–¹æ³•"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    tokenizers = TraditionalTokenizers()
    
    # 1. ç©ºæ ¼åˆ†è¯
    ax1.set_title('ç©ºæ ¼åˆ†è¯ï¼šæœ€ç®€å•ä½†æœ‰å±€é™', fontsize=14, weight='bold')
    ax1.axis('off')
    
    texts = [
        ("Hello world!", "ç®€å•æƒ…å†µâœ“"),
        ("It's a test.", "ç¼©å†™é—®é¢˜âŒ"),
        ("æˆ‘çˆ±Python", "ä¸­æ–‡å¤±æ•ˆâŒ"),
        ("New York City", "è¯ç»„é—®é¢˜âŒ")
    ]
    
    y_pos = 0.9
    for text, issue in texts:
        tokens = tokenizers.space_tokenize(text)
        
        ax1.text(0.1, y_pos, f'"{text}"', transform=ax1.transAxes, fontsize=11)
        ax1.text(0.4, y_pos, 'â†’', transform=ax1.transAxes, fontsize=11)
        ax1.text(0.45, y_pos, str(tokens), transform=ax1.transAxes, fontsize=10,
                bbox=dict(boxstyle="round", facecolor='lightblue'))
        ax1.text(0.8, y_pos, issue, transform=ax1.transAxes, fontsize=9,
                color='green' if 'âœ“' in issue else 'red')
        y_pos -= 0.15
    
    # 2. å­—ç¬¦çº§åˆ†è¯
    ax2.set_title('å­—ç¬¦çº§åˆ†è¯ï¼šé€šç”¨ä½†è¯­ä¹‰å¼±', fontsize=14, weight='bold')
    ax2.axis('off')
    
    text = "Hello ä¸–ç•Œ"
    char_tokens = tokenizers.char_tokenize(text)
    
    # å¯è§†åŒ–å­—ç¬¦åˆ†è¯
    y_center = 0.6
    x_start = 0.1
    
    for i, char in enumerate(char_tokens):
        x = x_start + i * 0.08
        
        # å­—ç¬¦æ¡†
        rect = patches.Rectangle((x, y_center-0.05), 0.07, 0.1,
                               linewidth=2, edgecolor='black',
                               facecolor='lightgreen',
                               transform=ax2.transAxes)
        ax2.add_patch(rect)
        ax2.text(x+0.035, y_center, char, transform=ax2.transAxes,
                ha='center', va='center', fontsize=12)
    
    # ä¼˜ç¼ºç‚¹
    ax2.text(0.5, 0.3, 'ä¼˜ç‚¹ï¼š\nâ€¢ è¯æ±‡è¡¨å°ï¼ˆ~100-200ï¼‰\nâ€¢ æ— OOVé—®é¢˜\nâ€¢ è·¨è¯­è¨€é€šç”¨',
            transform=ax2.transAxes, ha='center',
            bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.5))
    
    ax2.text(0.5, 0.1, 'ç¼ºç‚¹ï¼š\nâ€¢ åºåˆ—å¤ªé•¿\nâ€¢ è¯­ä¹‰ä¿¡æ¯å¼±\nâ€¢ è®¡ç®—æ•ˆç‡ä½',
            transform=ax2.transAxes, ha='center',
            bbox=dict(boxstyle="round", facecolor='lightcoral', alpha=0.5))
    
    # 3. ä¸­æ–‡åˆ†è¯æŒ‘æˆ˜
    ax3.set_title('ä¸­æ–‡åˆ†è¯çš„æ­§ä¹‰æ€§', fontsize=14, weight='bold')
    ax3.axis('off')
    
    # åˆ†è¯æ­§ä¹‰ç¤ºä¾‹
    ambiguous_text = "å—äº¬å¸‚é•¿æ±Ÿå¤§æ¡¥"
    
    segmentations = [
        ('å—äº¬å¸‚/é•¿æ±Ÿ/å¤§æ¡¥', 'å—äº¬å¸‚çš„é•¿æ±Ÿå¤§æ¡¥'),
        ('å—äº¬/å¸‚é•¿/æ±Ÿå¤§æ¡¥', 'å¸‚é•¿å«æ±Ÿå¤§æ¡¥ï¼Ÿ'),
        ('å—äº¬å¸‚/é•¿/æ±Ÿå¤§æ¡¥', 'é•¿çš„æ±Ÿå¤§æ¡¥ï¼Ÿ')
    ]
    
    ax3.text(0.5, 0.85, f'åŸæ–‡ï¼š"{ambiguous_text}"', 
            transform=ax3.transAxes, ha='center', fontsize=12, weight='bold')
    
    y_pos = 0.65
    for seg, interpretation in segmentations:
        ax3.text(0.2, y_pos, seg, transform=ax3.transAxes, fontsize=11,
                bbox=dict(boxstyle="round", facecolor='lightblue'))
        ax3.text(0.5, y_pos, 'â†’', transform=ax3.transAxes, fontsize=11)
        ax3.text(0.55, y_pos, interpretation, transform=ax3.transAxes,
                fontsize=10, style='italic')
        y_pos -= 0.15
    
    ax3.text(0.5, 0.15, 'åˆ†è¯æ­§ä¹‰éœ€è¦ä¸Šä¸‹æ–‡æ‰èƒ½è§£å†³ï¼',
            transform=ax3.transAxes, ha='center', fontsize=11,
            color='red', weight='bold')
    
    # 4. è¯é¢‘ç»Ÿè®¡çš„å½±å“
    ax4.set_title('åŸºäºè¯é¢‘çš„åˆ†è¯æ•ˆæœ', fontsize=14, weight='bold')
    
    # æ¨¡æ‹Ÿè¯é¢‘
    text = "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯"
    
    # ä¸åŒåˆ†è¯ç²’åº¦çš„è¯é¢‘
    word_freq = {
        'å­—ç¬¦çº§': {'è‡ª': 1, 'ç„¶': 1, 'è¯­': 1, 'è¨€': 1, 'å¤„': 1, 'ç†': 1},
        'è¯çº§': {'è‡ªç„¶è¯­è¨€å¤„ç†': 1, 'æ˜¯': 1, 'äººå·¥æ™ºèƒ½': 1, 'çš„': 1},
        'æ··åˆ': {'è‡ªç„¶': 1, 'è¯­è¨€': 1, 'å¤„ç†': 1, 'äººå·¥': 1, 'æ™ºèƒ½': 1}
    }
    
    x = np.arange(3)
    unique_tokens = [6, 4, 5]
    total_tokens = [13, 7, 9]
    
    width = 0.35
    ax4.bar(x - width/2, unique_tokens, width, label='ç‹¬ç‰¹è¯æ•°', color='lightblue')
    ax4.bar(x + width/2, total_tokens, width, label='æ€»è¯æ•°', color='lightgreen')
    
    ax4.set_xticks(x)
    ax4.set_xticklabels(['å­—ç¬¦çº§', 'è¯çº§', 'æ··åˆ'])
    ax4.set_ylabel('æ•°é‡')
    ax4.legend()
    ax4.grid(True, alpha=0.3, axis='y')
    
    # æ ‡æ³¨å‹ç¼©ç‡
    for i, (u, t) in enumerate(zip(unique_tokens, total_tokens)):
        ratio = t / 13  # åŸå§‹å­—ç¬¦æ•°
        ax4.text(i, t + 0.5, f'å‹ç¼©ç‡\n{ratio:.1f}x', ha='center', fontsize=9)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ”§ ä¼ ç»Ÿåˆ†è¯æ–¹æ³•æ€»ç»“ï¼š")
    print("1. ç©ºæ ¼åˆ†è¯ï¼šé€‚ç”¨äºè‹±æ–‡ç­‰æœ‰æ˜ç¡®åˆ†éš”çš„è¯­è¨€")
    print("2. å­—ç¬¦åˆ†è¯ï¼šé€šç”¨ä½†æŸå¤±è¯­ä¹‰ä¿¡æ¯")
    print("3. è¯å…¸åˆ†è¯ï¼šä¾èµ–è¯å…¸è´¨é‡ï¼Œæœ‰OOVé—®é¢˜")
    print("4. ç»Ÿè®¡åˆ†è¯ï¼šéœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®")

ä¼ ç»Ÿåˆ†è¯æ–¹æ³•å¯¹æ¯”()
```

#### ğŸ¯ å­è¯ç®—æ³•ï¼šç°ä»£åˆ†è¯çš„ä¸»æµ

```python
class BPETokenizer:
    """Byte Pair Encoding (BPE) åˆ†è¯å™¨å®ç°"""
    
    def __init__(self, vocab_size=1000):
        self.vocab_size = vocab_size
        self.word_freq = defaultdict(int)
        self.vocab = {}
        
    def train(self, texts):
        """è®­ç»ƒBPEæ¨¡å‹"""
        # 1. ç»Ÿè®¡è¯é¢‘
        for text in texts:
            words = text.split()
            for word in words:
                # æ·»åŠ ç»“æŸç¬¦ï¼Œé¿å…æ­§ä¹‰
                word = ' '.join(list(word)) + ' </w>'
                self.word_freq[word] += 1
        
        # 2. åˆå§‹åŒ–è¯æ±‡è¡¨ï¼ˆæ‰€æœ‰å­—ç¬¦ï¼‰
        self.vocab = self._get_base_vocab()
        
        # 3. è¿­ä»£åˆå¹¶æœ€é¢‘ç¹çš„ç›¸é‚»å¯¹
        num_merges = self.vocab_size - len(self.vocab)
        
        merges = []
        for i in range(num_merges):
            pairs = self._get_pairs()
            if not pairs:
                break
                
            # æ‰¾å‡ºæœ€é¢‘ç¹çš„pair
            most_frequent = max(pairs, key=pairs.get)
            merges.append(most_frequent)
            
            # åˆå¹¶
            self._merge_pair(most_frequent)
            
            # æ›´æ–°è¯æ±‡è¡¨
            new_token = ''.join(most_frequent)
            self.vocab[new_token] = len(self.vocab)
            
            if (i + 1) % 100 == 0:
                print(f"å®Œæˆ {i+1} æ¬¡åˆå¹¶")
        
        return merges
    
    def _get_base_vocab(self):
        """è·å–åŸºç¡€è¯æ±‡è¡¨ï¼ˆæ‰€æœ‰å­—ç¬¦ï¼‰"""
        vocab = {}
        for word, freq in self.word_freq.items():
            for char in word.split():
                if char not in vocab:
                    vocab[char] = len(vocab)
        return vocab
    
    def _get_pairs(self):
        """ç»Ÿè®¡æ‰€æœ‰ç›¸é‚»å¯¹çš„é¢‘ç‡"""
        pairs = defaultdict(int)
        
        for word, freq in self.word_freq.items():
            symbols = word.split()
            for i in range(len(symbols) - 1):
                pair = (symbols[i], symbols[i + 1])
                pairs[pair] += freq
                
        return pairs
    
    def _merge_pair(self, pair):
        """åˆå¹¶æŒ‡å®šçš„pair"""
        new_word_freq = {}
        bigram = ' '.join(pair)
        replacement = ''.join(pair)
        
        for word, freq in self.word_freq.items():
            new_word = word.replace(bigram, replacement)
            new_word_freq[new_word] = freq
            
        self.word_freq = new_word_freq

def BPEç®—æ³•æ¼”ç¤º():
    """æ¼”ç¤ºBPEç®—æ³•çš„å·¥ä½œåŸç†"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. BPEç®—æ³•æ­¥éª¤
    ax1.set_title('BPEç®—æ³•ï¼šè¿­ä»£åˆå¹¶æœ€é¢‘ç¹çš„å­—ç¬¦å¯¹', fontsize=14, weight='bold')
    ax1.axis('off')
    
    # åˆå§‹çŠ¶æ€
    initial_words = {
        'l o w </w>': 5,
        'l o w e r </w>': 2,
        'n e w e s t </w>': 6,
        'w i d e s t </w>': 3
    }
    
    ax1.text(0.1, 0.9, 'åˆå§‹çŠ¶æ€ï¼ˆå­—ç¬¦çº§ï¼‰ï¼š', transform=ax1.transAxes,
            fontsize=12, weight='bold')
    
    y_pos = 0.8
    for word, freq in list(initial_words.items())[:4]:
        ax1.text(0.1, y_pos, f'{word}', transform=ax1.transAxes,
                fontsize=10, family='monospace',
                bbox=dict(boxstyle="round", facecolor='lightblue'))
        ax1.text(0.5, y_pos, f'é¢‘ç‡: {freq}', transform=ax1.transAxes,
                fontsize=10)
        y_pos -= 0.1
    
    # åˆå¹¶è¿‡ç¨‹
    merges = [
        ('e s', 'es', 9),
        ('es t', 'est', 9),
        ('l o', 'lo', 7),
        ('lo w', 'low', 7),
    ]
    
    ax1.text(0.1, 0.35, 'åˆå¹¶è¿‡ç¨‹ï¼š', transform=ax1.transAxes,
            fontsize=12, weight='bold')
    
    y_pos = 0.25
    for i, (pair, merged, freq) in enumerate(merges[:3]):
        ax1.text(0.1, y_pos, f'{i+1}. {pair} â†’ {merged} (é¢‘ç‡:{freq})',
                transform=ax1.transAxes, fontsize=10,
                bbox=dict(boxstyle="round", facecolor='lightgreen'))
        y_pos -= 0.08
    
    # 2. è¯æ±‡è¡¨å¢é•¿
    ax2.set_title('è¯æ±‡è¡¨çš„å¢é•¿è¿‡ç¨‹', fontsize=14, weight='bold')
    
    # æ¨¡æ‹Ÿè¯æ±‡è¡¨å¢é•¿
    iterations = np.arange(0, 1000, 50)
    vocab_sizes = 256 + iterations  # åŸºç¡€å­—ç¬¦ + åˆå¹¶çš„å­è¯
    
    ax2.plot(iterations, vocab_sizes, 'b-', linewidth=2)
    ax2.fill_between(iterations, 256, vocab_sizes, alpha=0.3, color='lightblue')
    
    ax2.axhline(y=256, color='red', linestyle='--', label='åŸºç¡€å­—ç¬¦')
    ax2.text(500, 270, 'åŸºç¡€å­—ç¬¦ï¼ˆ256ï¼‰', ha='center', fontsize=10)
    
    ax2.set_xlabel('åˆå¹¶æ¬¡æ•°')
    ax2.set_ylabel('è¯æ±‡è¡¨å¤§å°')
    ax2.grid(True, alpha=0.3)
    
    # æ ‡æ³¨ä¸åŒé˜¶æ®µ
    stages = [(100, 'å¸¸è§äºŒå…ƒç»„'), (400, 'å¸¸è§è¯æ ¹'), (800, 'å¸¸è§å•è¯')]
    for x, stage in stages:
        ax2.annotate(stage, xy=(x, 256+x), xytext=(x, 256+x+100),
                    arrowprops=dict(arrowstyle='->', color='gray'),
                    fontsize=9, ha='center')
    
    # 3. åˆ†è¯ç¤ºä¾‹
    ax3.set_title('BPEåˆ†è¯æ•ˆæœå±•ç¤º', fontsize=14, weight='bold')
    ax3.axis('off')
    
    # åˆ†è¯ç¤ºä¾‹
    examples = [
        ('unhappiness', ['un', 'happ', 'iness'], 'è¯†åˆ«è¯ç¼€'),
        ('chatbot', ['chat', 'bot'], 'è¯†åˆ«å¤åˆè¯'),
        ('GPT-4', ['G', 'PT', '-', '4'], 'å¤„ç†ç‰¹æ®Šè¯'),
        ('ä»Šå¤©å¤©æ°”', ['ä»Š', 'å¤©', 'å¤©', 'æ°”'], 'ä¸­æ–‡å­—ç¬¦')
    ]
    
    y_pos = 0.85
    for word, tokens, note in examples:
        ax3.text(0.1, y_pos, word, transform=ax3.transAxes,
                fontsize=11, weight='bold')
        ax3.text(0.3, y_pos, 'â†’', transform=ax3.transAxes, fontsize=11)
        
        # ç»˜åˆ¶token
        x_pos = 0.35
        for token in tokens:
            ax3.text(x_pos, y_pos, token, transform=ax3.transAxes,
                    fontsize=10, bbox=dict(boxstyle="round", 
                    facecolor='lightgreen' if len(token) > 1 else 'lightblue'))
            x_pos += 0.1
        
        ax3.text(0.75, y_pos, note, transform=ax3.transAxes,
                fontsize=9, style='italic', color='gray')
        y_pos -= 0.15
    
    # 4. ä¸å…¶ä»–æ–¹æ³•å¯¹æ¯”
    ax4.set_title('ä¸åŒåˆ†è¯æ–¹æ³•çš„å¯¹æ¯”', fontsize=14, weight='bold')
    
    methods = ['å­—ç¬¦çº§', 'BPE', 'WordPiece', 'è¯çº§']
    
    # è¯„åˆ†ï¼ˆæ»¡åˆ†5ï¼‰
    vocab_size_score = [5, 4, 4, 1]  # è¯æ±‡è¡¨å¤§å°ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    oov_handling = [5, 4, 4, 1]      # OOVå¤„ç†èƒ½åŠ›
    semantic_score = [1, 3, 3, 5]    # è¯­ä¹‰ä¿æŒ
    efficiency = [2, 4, 4, 3]        # è®¡ç®—æ•ˆç‡
    
    # é›·è¾¾å›¾
    angles = np.linspace(0, 2*np.pi, 4, endpoint=False).tolist()
    angles += angles[:1]  # é—­åˆ
    
    ax4 = plt.subplot(224, projection='polar')
    
    # ç»˜åˆ¶æ¯ç§æ–¹æ³•
    colors = ['blue', 'green', 'orange', 'red']
    for i, method in enumerate(methods):
        values = [vocab_size_score[i], oov_handling[i], 
                 semantic_score[i], efficiency[i]]
        values += values[:1]  # é—­åˆ
        
        ax4.plot(angles, values, 'o-', linewidth=2, 
                label=method, color=colors[i])
        ax4.fill(angles, values, alpha=0.15, color=colors[i])
    
    ax4.set_xticks(angles[:-1])
    ax4.set_xticklabels(['è¯è¡¨å¤§å°', 'OOVå¤„ç†', 'è¯­ä¹‰ä¿æŒ', 'æ•ˆç‡'])
    ax4.set_ylim(0, 5)
    ax4.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
    ax4.grid(True)
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ¯ BPEç®—æ³•æ€»ç»“ï¼š")
    print("1. æ•°æ®é©±åŠ¨ï¼šä»æ•°æ®ä¸­å­¦ä¹ æœ€ä¼˜åˆ†è¯")
    print("2. å¹³è¡¡æ€§å¥½ï¼šåœ¨è¯æ±‡è¡¨å¤§å°å’Œè¡¨è¾¾èƒ½åŠ›é—´å–å¾—å¹³è¡¡")
    print("3. å¤„ç†OOVï¼šå¯ä»¥åˆ†è§£æœªè§è¿‡çš„è¯")
    print("4. è¯­è¨€æ— å…³ï¼šé€‚ç”¨äºå„ç§è¯­è¨€")

BPEç®—æ³•æ¼”ç¤º()
```

#### ğŸ”¥ ç°ä»£åˆ†è¯å™¨ï¼šä»WordPieceåˆ°SentencePiece

```python
def ç°ä»£åˆ†è¯å™¨å¯¹æ¯”():
    """å¯¹æ¯”ç°ä»£ä¸»æµåˆ†è¯å™¨"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. WordPieceç®—æ³•
    ax1.set_title('WordPieceï¼šBERTçš„é€‰æ‹©', fontsize=14, weight='bold')
    ax1.axis('off')
    
    # WordPieceç‰¹ç‚¹
    ax1.text(0.5, 0.9, 'WordPiece vs BPE', transform=ax1.transAxes,
            fontsize=12, weight='bold', ha='center')
    
    # å¯¹æ¯”è¡¨æ ¼
    comparison = [
        ['ç‰¹æ€§', 'BPE', 'WordPiece'],
        ['åˆå¹¶å‡†åˆ™', 'é¢‘ç‡æœ€é«˜', 'äº’ä¿¡æ¯æœ€å¤§'],
        ['è¯æ±‡æ ‡è®°', 'ç©ºæ ¼/</w>', '##å‰ç¼€'],
        ['åˆ†è¯æ–¹å‘', 'ä»å‰å¾€å', 'æœ€å¤§ä¼¼ç„¶'],
        ['ä»£è¡¨æ¨¡å‹', 'GPT/RoBERTa', 'BERT/ELECTRA']
    ]
    
    # ç»˜åˆ¶è¡¨æ ¼
    cell_height = 0.12
    cell_width = 0.3
    
    for i, row in enumerate(comparison):
        for j, cell in enumerate(row):
            x = 0.2 + j * cell_width
            y = 0.7 - i * cell_height
            
            if i == 0:
                color = 'lightgray'
                weight = 'bold'
            elif j == 0:
                color = 'lightblue'
                weight = 'bold'
            else:
                color = 'white'
                weight = 'normal'
            
            rect = patches.Rectangle((x-cell_width/2, y-cell_height/2), 
                                   cell_width, cell_height,
                                   facecolor=color, edgecolor='black',
                                   transform=ax1.transAxes)
            ax1.add_patch(rect)
            ax1.text(x, y, cell, transform=ax1.transAxes,
                    ha='center', va='center', fontsize=9, weight=weight)
    
    # WordPieceç¤ºä¾‹
    ax1.text(0.5, 0.15, 'ç¤ºä¾‹ï¼š"unhappiness" â†’ ["un", "##happy", "##ness"]',
            transform=ax1.transAxes, ha='center', fontsize=10,
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # 2. SentencePiece
    ax2.set_title('SentencePieceï¼šçœŸæ­£çš„ç«¯åˆ°ç«¯', fontsize=14, weight='bold')
    ax2.axis('off')
    
    # ç‰¹ç‚¹åˆ—è¡¨
    features = [
        ('1ï¸âƒ£', 'è¯­è¨€æ— å…³', 'ä¸éœ€è¦é¢„åˆ†è¯ï¼Œç›´æ¥å¤„ç†åŸå§‹æ–‡æœ¬'),
        ('2ï¸âƒ£', 'å¯é€†åˆ†è¯', 'å¯ä»¥å®Œç¾è¿˜åŸåŸå§‹æ–‡æœ¬'),
        ('3ï¸âƒ£', 'ç»Ÿä¸€å¤„ç†', 'ç©ºæ ¼ä¹Ÿä½œä¸ºç‰¹æ®Šå­—ç¬¦å¤„ç†'),
        ('4ï¸âƒ£', 'å¤šç§ç®—æ³•', 'æ”¯æŒBPEå’ŒUnigramè¯­è¨€æ¨¡å‹')
    ]
    
    y_pos = 0.85
    for emoji, feature, desc in features:
        ax2.text(0.1, y_pos, emoji, transform=ax2.transAxes,
                fontsize=16)
        ax2.text(0.2, y_pos, feature, transform=ax2.transAxes,
                fontsize=11, weight='bold')
        ax2.text(0.35, y_pos-0.03, desc, transform=ax2.transAxes,
                fontsize=9, style='italic', color='gray')
        y_pos -= 0.18
    
    # å¯é€†æ€§ç¤ºä¾‹
    ax2.text(0.5, 0.15, 'å¯é€†æ€§ç¤ºä¾‹ï¼š\n"Hello world" â†’ ["â–Hello", "â–world"] â†’ "Hello world"',
            transform=ax2.transAxes, ha='center', fontsize=10,
            bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.5))
    
    # 3. ä¸åŒæ¨¡å‹çš„åˆ†è¯å™¨é€‰æ‹©
    ax3.set_title('ä¸»æµæ¨¡å‹çš„åˆ†è¯å™¨é€‰æ‹©', fontsize=14, weight='bold')
    
    models = ['GPT-2', 'BERT', 'T5', 'LLaMA', 'ChatGPT']
    tokenizers = ['BPE', 'WordPiece', 'SentencePiece', 'SentencePiece', 'BPE']
    vocab_sizes = [50257, 30522, 32128, 32000, 100000]
    colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow', 'lightpink']
    
    y_pos = np.arange(len(models))
    bars = ax3.barh(y_pos, np.array(vocab_sizes)/1000, color=colors, edgecolor='black')
    
    ax3.set_yticks(y_pos)
    ax3.set_yticklabels(models)
    ax3.set_xlabel('è¯æ±‡è¡¨å¤§å° (K)')
    
    # æ ‡æ³¨åˆ†è¯å™¨ç±»å‹
    for i, (bar, tokenizer) in enumerate(zip(bars, tokenizers)):
        width = bar.get_width()
        ax3.text(width + 1, bar.get_y() + bar.get_height()/2,
                tokenizer, va='center', fontsize=9)
    
    ax3.grid(True, alpha=0.3, axis='x')
    
    # 4. å¤šè¯­è¨€å¤„ç†èƒ½åŠ›
    ax4.set_title('å¤šè¯­è¨€å¤„ç†èƒ½åŠ›å¯¹æ¯”', fontsize=14, weight='bold')
    
    # æµ‹è¯•å¥å­
    test_sentences = {
        'è‹±è¯­': 'Hello world',
        'ä¸­æ–‡': 'ä½ å¥½ä¸–ç•Œ',
        'æ—¥è¯­': 'ã“ã‚“ã«ã¡ã¯',
        'éŸ©è¯­': 'ì•ˆë…•í•˜ì„¸ìš”',
        'é˜¿æ‹‰ä¼¯è¯­': 'Ù…Ø±Ø­Ø¨Ø§',
        'è¡¨æƒ…': 'ğŸ˜€ğŸ‰'
    }
    
    # ä¸åŒåˆ†è¯å™¨çš„å¤„ç†ç»“æœï¼ˆç®€åŒ–å±•ç¤ºï¼‰
    results = {
        'å­—ç¬¦çº§': [2, 4, 5, 5, 5, 2],
        'BPE': [2, 4, 3, 4, 4, 2],
        'SentencePiece': [2, 2, 2, 2, 3, 1]
    }
    
    languages = list(test_sentences.keys())
    x = np.arange(len(languages))
    width = 0.25
    
    for i, (method, tokens) in enumerate(results.items()):
        ax4.bar(x + i*width, tokens, width, label=method)
    
    ax4.set_xlabel('è¯­è¨€')
    ax4.set_ylabel('Tokenæ•°é‡')
    ax4.set_xticks(x + width)
    ax4.set_xticklabels(languages, rotation=15)
    ax4.legend()
    ax4.grid(True, alpha=0.3, axis='y')
    
    # æ·»åŠ è¯´æ˜
    ax4.text(0.5, 0.95, 'Tokenæ•°è¶Šå°‘ï¼Œå‹ç¼©æ•ˆç‡è¶Šé«˜',
            transform=ax4.transAxes, ha='center', fontsize=9,
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ”¥ ç°ä»£åˆ†è¯å™¨ç‰¹ç‚¹ï¼š")
    print("1. WordPieceï¼šBERTç³»åˆ—çš„æ ‡é…ï¼Œä½¿ç”¨##æ ‡è®°")
    print("2. SentencePieceï¼šç«¯åˆ°ç«¯å¤„ç†ï¼Œæ”¯æŒå¤šè¯­è¨€")
    print("3. è¶‹åŠ¿ï¼šæ›´å¤§çš„è¯æ±‡è¡¨ï¼Œæ›´å¥½çš„å¤šè¯­è¨€æ”¯æŒ")
    print("4. é€‰æ‹©ï¼šæ ¹æ®æ¨¡å‹æ¶æ„å’Œåº”ç”¨åœºæ™¯é€‰æ‹©")

ç°ä»£åˆ†è¯å™¨å¯¹æ¯”()
```

#### ğŸ’» å®æˆ˜ï¼šå®ç°ä¸€ä¸ªç®€å•çš„BPEåˆ†è¯å™¨

```python
class SimpleBPE:
    """ç®€åŒ–ç‰ˆçš„BPEå®ç°"""
    
    def __init__(self):
        self.vocab = {}
        self.merges = []
        
    def train_from_text(self, text, num_merges=100):
        """ä»æ–‡æœ¬è®­ç»ƒBPE"""
        # 1. åˆå§‹åŒ–ï¼šå°†æ–‡æœ¬åˆ†å‰²æˆå­—ç¬¦
        word_freq = Counter(text.split())
        
        # å°†æ¯ä¸ªè¯åˆ†å‰²æˆå­—ç¬¦
        splits = {}
        for word, freq in word_freq.items():
            splits[' '.join(list(word) + ['</w>'])] = freq
        
        # 2. å­¦ä¹ åˆå¹¶è§„åˆ™
        for i in range(num_merges):
            pairs = self._count_pairs(splits)
            if not pairs:
                break
                
            # æ‰¾åˆ°æœ€é¢‘ç¹çš„pair
            best_pair = max(pairs, key=pairs.get)
            self.merges.append(best_pair)
            
            # æ‰§è¡Œåˆå¹¶
            splits = self._merge_pair(splits, best_pair)
            
            if (i + 1) % 10 == 0:
                print(f"Merge {i+1}: {best_pair} (freq: {pairs[best_pair]})")
        
        # 3. æ„å»ºè¯æ±‡è¡¨
        for word in splits:
            for subword in word.split():
                if subword not in self.vocab:
                    self.vocab[subword] = len(self.vocab)
        
        return self
    
    def _count_pairs(self, splits):
        """ç»Ÿè®¡æ‰€æœ‰ç›¸é‚»å­—ç¬¦å¯¹çš„é¢‘ç‡"""
        pairs = Counter()
        
        for word, freq in splits.items():
            symbols = word.split()
            for i in range(len(symbols) - 1):
                pairs[(symbols[i], symbols[i+1])] += freq
                
        return pairs
    
    def _merge_pair(self, splits, pair):
        """åˆå¹¶æŒ‡å®šçš„å­—ç¬¦å¯¹"""
        new_splits = {}
        bigram = ' '.join(pair)
        replacement = ''.join(pair)
        
        for word, freq in splits.items():
            new_word = word.replace(bigram, replacement)
            new_splits[new_word] = freq
            
        return new_splits
    
    def tokenize(self, text):
        """ä½¿ç”¨å­¦ä¹ çš„è§„åˆ™åˆ†è¯"""
        words = text.split()
        tokens = []
        
        for word in words:
            # åˆå§‹åŒ–ä¸ºå­—ç¬¦åºåˆ—
            word_tokens = list(word) + ['</w>']
            
            # åº”ç”¨åˆå¹¶è§„åˆ™
            for pair in self.merges:
                i = 0
                while i < len(word_tokens) - 1:
                    if (word_tokens[i], word_tokens[i+1]) == pair:
                        word_tokens = word_tokens[:i] + [''.join(pair)] + word_tokens[i+2:]
                    else:
                        i += 1
            
            tokens.extend(word_tokens)
            
        return tokens

def BPEå®æˆ˜æ¼”ç¤º():
    """æ¼”ç¤ºBPEçš„å®é™…ä½¿ç”¨"""
    
    # å‡†å¤‡è®­ç»ƒæ–‡æœ¬
    training_text = """
    machine learning is amazing
    deep learning is more amazing
    natural language processing is interesting
    machine translation is useful
    learning algorithms are important
    """
    
    # è®­ç»ƒBPE
    print("ğŸš€ å¼€å§‹è®­ç»ƒBPEæ¨¡å‹...")
    bpe = SimpleBPE()
    bpe.train_from_text(training_text, num_merges=20)
    
    print(f"\nğŸ“Š è¯æ±‡è¡¨å¤§å°: {len(bpe.vocab)}")
    print(f"ğŸ“ éƒ¨åˆ†è¯æ±‡: {list(bpe.vocab.keys())[:20]}")
    
    # æµ‹è¯•åˆ†è¯
    test_sentences = [
        "machine learning",
        "deep thinking",  # åŒ…å«OOVè¯
        "learning is fun"
    ]
    
    print("\nğŸ” åˆ†è¯æµ‹è¯•:")
    for sent in test_sentences:
        tokens = bpe.tokenize(sent)
        print(f"'{sent}' â†’ {tokens}")
    
    # å¯è§†åŒ–åˆå¹¶è¿‡ç¨‹
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # 1. æ˜¾ç¤ºå‰10ä¸ªåˆå¹¶
    ax1.set_title('BPEå­¦ä¹ çš„åˆå¹¶è§„åˆ™ï¼ˆå‰10ä¸ªï¼‰', fontsize=14, weight='bold')
    ax1.axis('off')
    
    y_pos = 0.9
    for i, (a, b) in enumerate(bpe.merges[:10]):
        merged = a + b
        ax1.text(0.1, y_pos, f"{i+1}.", transform=ax1.transAxes, fontsize=11)
        ax1.text(0.2, y_pos, f"'{a}' + '{b}'", transform=ax1.transAxes,
                fontsize=10, family='monospace',
                bbox=dict(boxstyle="round", facecolor='lightblue'))
        ax1.text(0.5, y_pos, "â†’", transform=ax1.transAxes, fontsize=11)
        ax1.text(0.55, y_pos, f"'{merged}'", transform=ax1.transAxes,
                fontsize=10, family='monospace',
                bbox=dict(boxstyle="round", facecolor='lightgreen'))
        y_pos -= 0.09
    
    # 2. åˆ†è¯æ•ˆæœå¯è§†åŒ–
    ax2.set_title('åˆ†è¯æ•ˆæœå±•ç¤º', fontsize=14, weight='bold')
    ax2.axis('off')
    
    # å±•ç¤ºä¸€ä¸ªå¥å­çš„åˆ†è¯è¿‡ç¨‹
    sentence = "learning"
    
    # åˆå§‹çŠ¶æ€
    initial = list(sentence) + ['</w>']
    ax2.text(0.5, 0.8, 'åˆå§‹çŠ¶æ€:', transform=ax2.transAxes,
            ha='center', fontsize=11, weight='bold')
    
    x_start = 0.3
    for i, char in enumerate(initial):
        ax2.text(x_start + i*0.05, 0.7, char, transform=ax2.transAxes,
                fontsize=10, family='monospace',
                bbox=dict(boxstyle="round", facecolor='lightcoral'))
    
    # åº”ç”¨åˆå¹¶å
    final_tokens = bpe.tokenize(sentence)
    ax2.text(0.5, 0.4, 'åˆå¹¶å:', transform=ax2.transAxes,
            ha='center', fontsize=11, weight='bold')
    
    x_start = 0.35 - len(final_tokens)*0.025
    for i, token in enumerate(final_tokens):
        color = 'lightgreen' if len(token) > 1 else 'lightblue'
        ax2.text(x_start + i*0.1, 0.3, token, transform=ax2.transAxes,
                fontsize=10, family='monospace',
                bbox=dict(boxstyle="round", facecolor=color))
    
    # è¯´æ˜
    ax2.text(0.5, 0.1, 'ç»¿è‰²=åˆå¹¶çš„å­è¯ï¼Œè“è‰²=å•å­—ç¬¦',
            transform=ax2.transAxes, ha='center', fontsize=9,
            style='italic', color='gray')
    
    plt.tight_layout()
    plt.show()

BPEå®æˆ˜æ¼”ç¤º()
```

#### ğŸ“ æœ¬ç« å°ç»“

Tokenizationçœ‹ä¼¼ç®€å•ï¼Œå®åˆ™æ˜¯NLPçš„åŸºç¡€ä¸­çš„åŸºç¡€ï¼š

1. **æ ¸å¿ƒæŒ‘æˆ˜**ï¼š
   - å¹³è¡¡è¯æ±‡è¡¨å¤§å°å’Œè¡¨è¾¾èƒ½åŠ›
   - å¤„ç†æœªè§è¿‡çš„è¯ï¼ˆOOVï¼‰
   - é€‚åº”ä¸åŒè¯­è¨€çš„ç‰¹ç‚¹
   - ä¿æŒè¯­ä¹‰ä¿¡æ¯

2. **æŠ€æœ¯æ¼”è¿›**ï¼š
   - åŸºäºè§„åˆ™ â†’ åŸºäºç»Ÿè®¡ â†’ åŸºäºå­¦ä¹ 
   - è¯çº§ â†’ å­—ç¬¦çº§ â†’ å­è¯çº§
   - è¯­è¨€ç›¸å…³ â†’ è¯­è¨€æ— å…³

3. **ç°ä»£æ–¹æ¡ˆ**ï¼š
   - BPEï¼šæ•°æ®é©±åŠ¨çš„å­è¯å­¦ä¹ 
   - WordPieceï¼šBERTçš„é€‰æ‹©
   - SentencePieceï¼šçœŸæ­£çš„ç«¯åˆ°ç«¯

4. **å®ç”¨å»ºè®®**ï¼š
   - è‹±æ–‡ï¼šBPEæˆ–WordPieceéƒ½ä¸é”™
   - ä¸­æ–‡ï¼šå­—ç¬¦çº§æˆ–SentencePiece
   - å¤šè¯­è¨€ï¼šSentencePieceæ˜¯é¦–é€‰
   - è¯æ±‡è¡¨å¤§å°ï¼šé€šå¸¸32K-100K

#### ğŸ’¡ ç»éªŒåˆ†äº«

1. **é€‰æ‹©åˆ†è¯å™¨æ—¶è€ƒè™‘**ï¼š
   - ç›®æ ‡è¯­è¨€çš„ç‰¹ç‚¹
   - ä¸‹æ¸¸ä»»åŠ¡çš„éœ€æ±‚
   - æ¨¡å‹å¤§å°çš„é™åˆ¶
   - è®­ç»ƒæ•°æ®çš„è§„æ¨¡

2. **å¸¸è§é™·é˜±**ï¼š
   - è®­ç»ƒå’Œæ¨ç†ä½¿ç”¨ä¸åŒçš„åˆ†è¯å™¨
   - å¿½è§†ç‰¹æ®Šå­—ç¬¦çš„å¤„ç†
   - è¯æ±‡è¡¨è¿‡å¤§å¯¼è‡´æ¨¡å‹è‡ƒè‚¿
   - æ²¡æœ‰å¤„ç†å¥½OOVé—®é¢˜

3. **ä¼˜åŒ–æŠ€å·§**ï¼š
   - é¢„å…ˆè®¡ç®—å¸¸ç”¨è¯çš„åˆ†è¯ç»“æœ
   - ä½¿ç”¨å¹¶è¡ŒåŒ–åŠ é€Ÿåˆ†è¯
   - é’ˆå¯¹ç‰¹å®šé¢†åŸŸå®šåˆ¶è¯æ±‡è¡¨

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆè¯´å­è¯åˆ†è¯æ˜¯"æ°åˆ°å¥½å¤„"çš„ç²’åº¦ï¼Ÿ
2. å¦‚æœè®©ä½ è®¾è®¡ä¸€ä¸ªè¡¨æƒ…ç¬¦å·çš„åˆ†è¯å™¨ï¼Œä½ ä¼šæ€ä¹ˆåšï¼Ÿ
3. æœªæ¥çš„åˆ†è¯æŠ€æœ¯å¯èƒ½ä¼šæœä»€ä¹ˆæ–¹å‘å‘å±•ï¼Ÿ

æ­å–œä½ ç†è§£äº†Tokenizationï¼ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨è¯åµŒå…¥æŠ€æœ¯ï¼Œçœ‹çœ‹å¦‚ä½•è®©æ¯ä¸ªtokenéƒ½æœ‰äº†"çµé­‚"ã€‚

### ç¬¬14ç« ï¼šè¯åµŒå…¥â€”â€”è®©è¯è¯­æœ‰äº†çµé­‚

#### ğŸ¯ æœ¬ç« å¯¼è¯»

è¿˜è®°å¾—å°æ—¶å€™å­¦è‹±è¯­å—ï¼Ÿè€å¸ˆè¯´catæ˜¯çŒ«ï¼Œdogæ˜¯ç‹—ã€‚ä½†catå’Œdogä¹‹é—´æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿå®ƒä»¬éƒ½æ˜¯åŠ¨ç‰©ï¼Œéƒ½æ˜¯å® ç‰©ï¼Œéƒ½æœ‰å››æ¡è…¿...

åœ¨è®¡ç®—æœºçœ‹æ¥ï¼Œ"cat"åªæ˜¯[0,0,1,0,0,...]è¿™æ ·çš„ç¼–ç ï¼Œ"dog"æ˜¯[0,0,0,1,0,...]ã€‚å®ƒä»¬ä¹‹é—´æ¯«æ— å…³ç³»ã€‚

è¿™å°±æ˜¯è¯åµŒå…¥ï¼ˆWord Embeddingï¼‰è¦è§£å†³çš„é—®é¢˜ï¼š**è®©è®¡ç®—æœºç†è§£è¯ä¸è¯ä¹‹é—´çš„å…³ç³»**ã€‚

ä»æ­¤ï¼Œæ¯ä¸ªè¯ä¸å†æ˜¯å†°å†·çš„ç¼–å·ï¼Œè€Œæ˜¯æœ‰äº†"ä½ç½®"ã€"æ–¹å‘"å’Œ"è·ç¦»"â€”â€”å°±åƒè¯è¯­æœ‰äº†çµé­‚ã€‚

#### ğŸ­ ä»One-hotåˆ°åˆ†å¸ƒå¼è¡¨ç¤º

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import matplotlib.patches as mpatches
from mpl_toolkits.mplot3d import Axes3D

def one_hotçš„é—®é¢˜():
    """å±•ç¤ºOne-hotç¼–ç çš„å±€é™æ€§"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. One-hotç¼–ç ç¤ºä¾‹
    ax1.set_title('One-hotç¼–ç ï¼šç¨€ç–ä¸”æ— è¯­ä¹‰', fontsize=14, weight='bold')
    
    words = ['çŒ«', 'ç‹—', 'æ±½è½¦', 'é£æœº', 'è‹¹æœ']
    vocab_size = len(words)
    
    # åˆ›å»ºone-hotçŸ©é˜µ
    one_hot_matrix = np.eye(vocab_size)
    
    # å¯è§†åŒ–
    im = ax1.imshow(one_hot_matrix, cmap='Blues', aspect='auto')
    ax1.set_xticks(range(vocab_size))
    ax1.set_xticklabels(words)
    ax1.set_yticks(range(vocab_size))
    ax1.set_yticklabels(words)
    ax1.set_xlabel('è¯æ±‡è¡¨')
    ax1.set_ylabel('One-hotå‘é‡')
    
    # æ·»åŠ æ•°å€¼
    for i in range(vocab_size):
        for j in range(vocab_size):
            text = ax1.text(j, i, f'{int(one_hot_matrix[i, j])}',
                           ha="center", va="center", color="black" if one_hot_matrix[i, j] == 0 else "white")
    
    # 2. è¯­ä¹‰å…³ç³»ç¼ºå¤±
    ax2.set_title('One-hotçš„é—®é¢˜ï¼šè¯ä¹‹é—´æ²¡æœ‰å…³ç³»', fontsize=14, weight='bold')
    ax2.axis('off')
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    similarity_results = []
    pairs = [('çŒ«', 'ç‹—'), ('çŒ«', 'æ±½è½¦'), ('æ±½è½¦', 'é£æœº')]
    
    y_pos = 0.8
    for w1, w2 in pairs:
        idx1, idx2 = words.index(w1), words.index(w2)
        vec1, vec2 = one_hot_matrix[idx1], one_hot_matrix[idx2]
        
        # ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
        
        ax2.text(0.2, y_pos, f'{w1} vs {w2}:', transform=ax2.transAxes, fontsize=12)
        ax2.text(0.5, y_pos, f'ç›¸ä¼¼åº¦ = {similarity:.1f}', transform=ax2.transAxes,
                fontsize=12, bbox=dict(boxstyle="round", facecolor='lightcoral'))
        
        # æœŸæœ›çš„å…³ç³»
        if w1 == 'çŒ«' and w2 == 'ç‹—':
            expected = "åº”è¯¥ç›¸ä¼¼ï¼ˆéƒ½æ˜¯åŠ¨ç‰©ï¼‰"
        elif w1 == 'æ±½è½¦' and w2 == 'é£æœº':
            expected = "åº”è¯¥ç›¸ä¼¼ï¼ˆéƒ½æ˜¯äº¤é€šå·¥å…·ï¼‰"
        else:
            expected = "åº”è¯¥ä¸ç›¸ä¼¼"
            
        ax2.text(0.7, y_pos, expected, transform=ax2.transAxes,
                fontsize=10, style='italic', color='gray')
        y_pos -= 0.2
    
    ax2.text(0.5, 0.15, 'æ‰€æœ‰è¯çš„ç›¸ä¼¼åº¦éƒ½æ˜¯0ï¼ğŸ˜±', transform=ax2.transAxes,
            ha='center', fontsize=14, color='red', weight='bold',
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # 3. ç»´åº¦è¯…å’’
    ax3.set_title('ç»´åº¦è¯…å’’ï¼šè¯æ±‡è¡¨æœ‰å¤šå¤§ï¼Œå‘é‡å°±æœ‰å¤šé•¿', fontsize=14, weight='bold')
    
    vocab_sizes = [100, 1000, 10000, 50000, 100000]
    memory_mb = [size * size * 4 / 1024 / 1024 for size in vocab_sizes]  # float32
    
    ax3.semilogy(vocab_sizes, memory_mb, 'ro-', markersize=10, linewidth=2)
    ax3.set_xlabel('è¯æ±‡è¡¨å¤§å°')
    ax3.set_ylabel('å­˜å‚¨ç©ºé—´ (MB)')
    ax3.grid(True, alpha=0.3)
    
    # æ ‡æ³¨
    for i, (size, mem) in enumerate(zip(vocab_sizes, memory_mb)):
        if mem < 1000:
            label = f'{mem:.1f}MB'
        else:
            label = f'{mem/1024:.1f}GB'
        ax3.annotate(label, xy=(size, mem), xytext=(10, 10),
                    textcoords='offset points', fontsize=9)
    
    ax3.text(0.5, 0.95, 'ä»…å­˜å‚¨è¯å‘é‡çŸ©é˜µï¼', transform=ax3.transAxes,
            ha='center', fontsize=10, color='red',
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # 4. åˆ†å¸ƒå¼è¡¨ç¤ºçš„ä¼˜åŠ¿
    ax4.set_title('åˆ†å¸ƒå¼è¡¨ç¤ºï¼šä½ç»´ç¨ å¯†æœ‰è¯­ä¹‰', fontsize=14, weight='bold')
    ax4.axis('off')
    
    # å¯¹æ¯”è¡¨æ ¼
    comparison = [
        ['ç‰¹æ€§', 'One-hot', 'è¯åµŒå…¥'],
        ['ç»´åº¦', 'è¯æ±‡è¡¨å¤§å°', 'é€šå¸¸50-300'],
        ['ç¨€ç–æ€§', 'æåº¦ç¨€ç–', 'ç¨ å¯†'],
        ['è¯­ä¹‰', 'æ— ', 'æœ‰'],
        ['ç›¸ä¼¼åº¦', 'å…¨æ˜¯0', 'æœ‰æ„ä¹‰'],
        ['å­˜å‚¨', 'O(VÂ²)', 'O(VÃ—d)'],
    ]
    
    # ç»˜åˆ¶è¡¨æ ¼
    cell_height = 0.12
    cell_width = 0.3
    
    for i, row in enumerate(comparison):
        for j, cell in enumerate(row):
            x = 0.2 + j * cell_width
            y = 0.8 - i * cell_height
            
            if i == 0:
                color = 'lightgray'
                weight = 'bold'
            elif j == 0:
                color = 'lightblue'
                weight = 'bold'
            elif j == 1:
                color = 'lightcoral' if i > 1 else 'white'
            else:
                color = 'lightgreen' if i > 1 else 'white'
                
            weight = weight if i == 0 or j == 0 else 'normal'
            
            rect = mpatches.Rectangle((x-cell_width/2, y-cell_height/2), 
                                    cell_width, cell_height,
                                    facecolor=color, edgecolor='black',
                                    transform=ax4.transAxes)
            ax4.add_patch(rect)
            ax4.text(x, y, cell, transform=ax4.transAxes,
                    ha='center', va='center', fontsize=10, weight=weight)
    
    ax4.text(0.5, 0.1, 'V=è¯æ±‡è¡¨å¤§å°ï¼Œd=åµŒå…¥ç»´åº¦',
            transform=ax4.transAxes, ha='center', fontsize=9,
            style='italic', color='gray')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ“Š One-hotç¼–ç çš„è‡´å‘½ç¼ºé™·ï¼š")
    print("1. ç»´åº¦çˆ†ç‚¸ï¼šè¯æ±‡è¡¨å¤šå¤§ï¼Œå‘é‡å°±å¤šé•¿")
    print("2. æåº¦ç¨€ç–ï¼šåªæœ‰ä¸€ä¸ª1ï¼Œå…¶ä½™éƒ½æ˜¯0")
    print("3. è¯­ä¹‰ç¼ºå¤±ï¼šæ— æ³•è¡¨è¾¾è¯ä¹‹é—´çš„å…³ç³»")
    print("4. è®¡ç®—ä½æ•ˆï¼šå¤§é‡æ— ç”¨çš„0å‚ä¸è®¡ç®—")

one_hotçš„é—®é¢˜()
```

#### ğŸ² Word2Vecï¼šè¯åµŒå…¥çš„é©å‘½

```python
class Word2VecDemo:
    """Word2Vecç®—æ³•æ¼”ç¤º"""
    
    def __init__(self):
        # æ¨¡æ‹Ÿçš„è¯åµŒå…¥
        self.word_vectors = {
            # åŠ¨ç‰©
            'çŒ«': np.array([0.8, 0.6, 0.1]),
            'ç‹—': np.array([0.7, 0.7, 0.1]),
            'è€è™': np.array([0.9, 0.5, 0.2]),
            'ç‹®å­': np.array([0.85, 0.55, 0.15]),
            
            # æ°´æœ
            'è‹¹æœ': np.array([-0.6, 0.8, 0.3]),
            'é¦™è•‰': np.array([-0.7, 0.7, 0.4]),
            'æ©™å­': np.array([-0.65, 0.75, 0.35]),
            
            # åŠ¨ä½œ
            'åƒ': np.array([0.1, -0.8, 0.5]),
            'ç¡': np.array([0.2, -0.7, 0.6]),
            'è·‘': np.array([0.15, -0.85, 0.4]),
            
            # åœ°ç‚¹
            'åŒ—äº¬': np.array([0.3, 0.2, -0.8]),
            'ä¸Šæµ·': np.array([0.4, 0.3, -0.7]),
            'ä¸­å›½': np.array([0.35, 0.25, -0.9]),
            'ç¾å›½': np.array([0.2, 0.4, -0.85]),
        }
    
    def cosine_similarity(self, word1, word2):
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        vec1 = self.word_vectors[word1]
        vec2 = self.word_vectors[word2]
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    
    def find_nearest(self, word, n=3):
        """æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è¯"""
        if word not in self.word_vectors:
            return []
        
        similarities = []
        for w in self.word_vectors:
            if w != word:
                sim = self.cosine_similarity(word, w)
                similarities.append((w, sim))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:n]
    
    def analogy(self, a, b, c):
        """è¯ç±»æ¯”ï¼šaä¹‹äºbï¼Œå¦‚åŒcä¹‹äºï¼Ÿ"""
        if a not in self.word_vectors or b not in self.word_vectors or c not in self.word_vectors:
            return None
        
        # è®¡ç®— b - a + c
        result_vec = self.word_vectors[b] - self.word_vectors[a] + self.word_vectors[c]
        
        # æ‰¾åˆ°æœ€æ¥è¿‘çš„è¯
        best_word = None
        best_sim = -1
        
        for word, vec in self.word_vectors.items():
            if word not in [a, b, c]:
                sim = np.dot(result_vec, vec) / (np.linalg.norm(result_vec) * np.linalg.norm(vec))
                if sim > best_sim:
                    best_sim = sim
                    best_word = word
        
        return best_word

def word2vecç®—æ³•åŸç†():
    """å±•ç¤ºWord2Vecçš„ä¸¤ç§ç®—æ³•"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. CBOWæ¨¡å‹
    ax1.set_title('CBOWï¼šç”¨ä¸Šä¸‹æ–‡é¢„æµ‹ä¸­å¿ƒè¯', fontsize=14, weight='bold')
    ax1.set_xlim(0, 10)
    ax1.set_ylim(0, 10)
    ax1.axis('off')
    
    # è¾“å…¥å¥å­
    sentence = "æˆ‘ å–œæ¬¢ åƒ è‹¹æœ å’Œ é¦™è•‰"
    words = sentence.split()
    center_idx = 3  # "è‹¹æœ"
    window_size = 2
    
    # ç»˜åˆ¶ä¸Šä¸‹æ–‡çª—å£
    y_pos = 8
    for i, word in enumerate(words):
        if abs(i - center_idx) <= window_size and i != center_idx:
            color = 'lightblue'
            box_style = 'round'
        elif i == center_idx:
            color = 'lightcoral'
            box_style = 'round,pad=0.3'
        else:
            color = 'lightgray'
            box_style = 'round'
        
        x_pos = 1 + i * 1.3
        ax1.text(x_pos, y_pos, word, ha='center', va='center',
                bbox=dict(boxstyle=box_style, facecolor=color),
                fontsize=11)
    
    # ç»˜åˆ¶CBOWç»“æ„
    # è¾“å…¥å±‚
    context_words = ['å–œæ¬¢', 'åƒ', 'å’Œ', 'é¦™è•‰']
    for i, word in enumerate(context_words):
        y = 5.5 - i * 0.8
        ax1.text(2, y, word, ha='center', va='center',
                bbox=dict(boxstyle="round", facecolor='lightblue'),
                fontsize=10)
        ax1.arrow(2.5, y, 1.5, 0, head_width=0.1, head_length=0.1,
                 fc='gray', ec='gray', alpha=0.5)
    
    # éšè—å±‚
    ax1.text(5, 4, 'å¹³å‡', ha='center', va='center',
            bbox=dict(boxstyle="circle,pad=0.3", facecolor='lightyellow'),
            fontsize=10, weight='bold')
    
    # è¾“å‡ºå±‚
    ax1.arrow(5.5, 4, 1.5, 0, head_width=0.1, head_length=0.1,
             fc='gray', ec='gray', alpha=0.5)
    ax1.text(8, 4, 'è‹¹æœ', ha='center', va='center',
            bbox=dict(boxstyle="round", facecolor='lightcoral'),
            fontsize=11, weight='bold')
    
    ax1.text(5, 1.5, 'CBOWï¼šContinuous Bag of Words',
            ha='center', fontsize=10, style='italic')
    
    # 2. Skip-gramæ¨¡å‹
    ax2.set_title('Skip-gramï¼šç”¨ä¸­å¿ƒè¯é¢„æµ‹ä¸Šä¸‹æ–‡', fontsize=14, weight='bold')
    ax2.set_xlim(0, 10)
    ax2.set_ylim(0, 10)
    ax2.axis('off')
    
    # åŒæ ·çš„å¥å­
    y_pos = 8
    for i, word in enumerate(words):
        if abs(i - center_idx) <= window_size and i != center_idx:
            color = 'lightgreen'
            box_style = 'round'
        elif i == center_idx:
            color = 'lightcoral'
            box_style = 'round,pad=0.3'
        else:
            color = 'lightgray'
            box_style = 'round'
        
        x_pos = 1 + i * 1.3
        ax2.text(x_pos, y_pos, word, ha='center', va='center',
                bbox=dict(boxstyle=box_style, facecolor=color),
                fontsize=11)
    
    # ç»˜åˆ¶Skip-gramç»“æ„
    # è¾“å…¥å±‚
    ax2.text(2, 4, 'è‹¹æœ', ha='center', va='center',
            bbox=dict(boxstyle="round", facecolor='lightcoral'),
            fontsize=11, weight='bold')
    
    # éšè—å±‚
    ax2.arrow(2.5, 4, 2, 0, head_width=0.1, head_length=0.1,
             fc='gray', ec='gray', alpha=0.5)
    ax2.text(5, 4, 'åµŒå…¥', ha='center', va='center',
            bbox=dict(boxstyle="circle,pad=0.3", facecolor='lightyellow'),
            fontsize=10, weight='bold')
    
    # è¾“å‡ºå±‚
    output_words = ['å–œæ¬¢', 'åƒ', 'å’Œ', 'é¦™è•‰']
    for i, word in enumerate(output_words):
        y = 5.5 - i * 0.8
        ax2.arrow(5.5, 4, 2, y-4, head_width=0.1, head_length=0.1,
                 fc='gray', ec='gray', alpha=0.5)
        ax2.text(8, y, word, ha='center', va='center',
                bbox=dict(boxstyle="round", facecolor='lightgreen'),
                fontsize=10)
    
    ax2.text(5, 1.5, 'Skip-gramï¼šè·³è¿‡ä¸­å¿ƒè¯é¢„æµ‹å‘¨å›´',
            ha='center', fontsize=10, style='italic')
    
    # 3. è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
    ax3.set_title('è®­ç»ƒè¿‡ç¨‹ï¼šæ¢¯åº¦ä¸‹é™ä¼˜åŒ–', fontsize=14, weight='bold')
    
    # æ¨¡æ‹Ÿè®­ç»ƒæŸå¤±
    epochs = np.arange(0, 100, 1)
    loss_cbow = 5 * np.exp(-epochs/20) + 0.5 + 0.1 * np.random.randn(100)
    loss_skipgram = 5.5 * np.exp(-epochs/25) + 0.4 + 0.1 * np.random.randn(100)
    
    ax3.plot(epochs, loss_cbow, 'b-', label='CBOW', linewidth=2, alpha=0.8)
    ax3.plot(epochs, loss_skipgram, 'r-', label='Skip-gram', linewidth=2, alpha=0.8)
    
    ax3.set_xlabel('è®­ç»ƒè½®æ¬¡')
    ax3.set_ylabel('æŸå¤±å€¼')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    ax3.text(0.6, 0.8, 'CBOWï¼šè®­ç»ƒå¿«ï¼Œé€‚åˆå¤§æ•°æ®',
            transform=ax3.transAxes, fontsize=9,
            bbox=dict(boxstyle="round", facecolor='lightblue', alpha=0.5))
    ax3.text(0.6, 0.7, 'Skip-gramï¼šæ•ˆæœå¥½ï¼Œé€‚åˆå°æ•°æ®',
            transform=ax3.transAxes, fontsize=9,
            bbox=dict(boxstyle="round", facecolor='lightcoral', alpha=0.5))
    
    # 4. è´Ÿé‡‡æ ·ä¼˜åŒ–
    ax4.set_title('è´Ÿé‡‡æ ·ï¼šè®©è®­ç»ƒæ›´é«˜æ•ˆ', fontsize=14, weight='bold')
    ax4.axis('off')
    
    # å±•ç¤ºè´Ÿé‡‡æ ·
    ax4.text(0.5, 0.9, 'åŸå§‹Softmaxé—®é¢˜', transform=ax4.transAxes,
            ha='center', fontsize=12, weight='bold')
    
    ax4.text(0.5, 0.8, 'éœ€è¦è®¡ç®—æ‰€æœ‰è¯çš„æ¦‚ç‡ï¼šO(V)', transform=ax4.transAxes,
            ha='center', fontsize=10,
            bbox=dict(boxstyle="round", facecolor='lightcoral'))
    
    ax4.text(0.5, 0.65, 'â†“', transform=ax4.transAxes,
            ha='center', fontsize=20)
    
    ax4.text(0.5, 0.5, 'è´Ÿé‡‡æ ·è§£å†³æ–¹æ¡ˆ', transform=ax4.transAxes,
            ha='center', fontsize=12, weight='bold')
    
    # æ­£è´Ÿæ ·æœ¬ç¤ºä¾‹
    ax4.text(0.2, 0.35, 'æ­£æ ·æœ¬ï¼š', transform=ax4.transAxes, fontsize=10)
    ax4.text(0.35, 0.35, '(è‹¹æœ, åƒ)', transform=ax4.transAxes,
            fontsize=10, bbox=dict(boxstyle="round", facecolor='lightgreen'))
    
    ax4.text(0.2, 0.25, 'è´Ÿæ ·æœ¬ï¼š', transform=ax4.transAxes, fontsize=10)
    negative_samples = ['(è‹¹æœ, è·‘)', '(è‹¹æœ, åŒ—äº¬)', '(è‹¹æœ, ç¡)']
    x_pos = 0.35
    for sample in negative_samples:
        ax4.text(x_pos, 0.25, sample, transform=ax4.transAxes,
                fontsize=9, bbox=dict(boxstyle="round", facecolor='lightgray'))
        x_pos += 0.15
    
    ax4.text(0.5, 0.1, 'åªéœ€è¦è®¡ç®—K+1ä¸ªæ ·æœ¬ï¼šO(K) << O(V)',
            transform=ax4.transAxes, ha='center', fontsize=10,
            bbox=dict(boxstyle="round", facecolor='lightgreen'))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ² Word2Vecçš„æ ¸å¿ƒæ€æƒ³ï¼š")
    print("1. åˆ†å¸ƒå‡è¯´ï¼šç›¸ä¼¼çš„è¯å‡ºç°åœ¨ç›¸ä¼¼çš„ä¸Šä¸‹æ–‡ä¸­")
    print("2. CBOWï¼šå¿«é€Ÿï¼Œé€‚åˆå¤§è§„æ¨¡è¯­æ–™")
    print("3. Skip-gramï¼šå‡†ç¡®ï¼Œé€‚åˆå°è§„æ¨¡è¯­æ–™")
    print("4. è´Ÿé‡‡æ ·ï¼šå°†Softmaxç®€åŒ–ä¸ºäºŒåˆ†ç±»")

word2vecç®—æ³•åŸç†()
```

#### ğŸŒŸ è¯åµŒå…¥çš„ç¥å¥‡æ€§è´¨

```python
def è¯åµŒå…¥æ€§è´¨æ¼”ç¤º():
    """å±•ç¤ºè¯åµŒå…¥çš„å„ç§æ€§è´¨"""
    
    fig = plt.figure(figsize=(16, 12))
    
    # åˆ›å»ºWord2Vecæ¼”ç¤ºå¯¹è±¡
    w2v = Word2VecDemo()
    
    # 1. 3Dè¯å‘é‡ç©ºé—´
    ax1 = fig.add_subplot(221, projection='3d')
    ax1.set_title('è¯å‘é‡çš„3Dç©ºé—´åˆ†å¸ƒ', fontsize=14, weight='bold')
    
    # ç»˜åˆ¶æ‰€æœ‰è¯å‘é‡
    categories = {
        'åŠ¨ç‰©': ['çŒ«', 'ç‹—', 'è€è™', 'ç‹®å­'],
        'æ°´æœ': ['è‹¹æœ', 'é¦™è•‰', 'æ©™å­'],
        'åŠ¨ä½œ': ['åƒ', 'ç¡', 'è·‘'],
        'åœ°ç‚¹': ['åŒ—äº¬', 'ä¸Šæµ·', 'ä¸­å›½', 'ç¾å›½']
    }
    
    colors = {'åŠ¨ç‰©': 'red', 'æ°´æœ': 'green', 'åŠ¨ä½œ': 'blue', 'åœ°ç‚¹': 'orange'}
    
    for category, words in categories.items():
        for word in words:
            vec = w2v.word_vectors[word]
            ax1.scatter(vec[0], vec[1], vec[2], c=colors[category], 
                       s=100, alpha=0.6, edgecolors='black')
            ax1.text(vec[0], vec[1], vec[2], word, fontsize=9)
    
    # æ·»åŠ å›¾ä¾‹
    handles = [mpatches.Patch(color=color, label=cat) 
              for cat, color in colors.items()]
    ax1.legend(handles=handles)
    
    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_zlabel('Z')
    
    # 2. ç›¸ä¼¼åº¦çƒ­åŠ›å›¾
    ax2 = fig.add_subplot(222)
    ax2.set_title('è¯ä¹‹é—´çš„ç›¸ä¼¼åº¦çƒ­åŠ›å›¾', fontsize=14, weight='bold')
    
    # é€‰æ‹©ä¸€äº›è¯
    selected_words = ['çŒ«', 'ç‹—', 'è‹¹æœ', 'é¦™è•‰', 'åƒ', 'åŒ—äº¬']
    n_words = len(selected_words)
    
    # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    similarity_matrix = np.zeros((n_words, n_words))
    for i, w1 in enumerate(selected_words):
        for j, w2 in enumerate(selected_words):
            if i == j:
                similarity_matrix[i, j] = 1.0
            else:
                similarity_matrix[i, j] = w2v.cosine_similarity(w1, w2)
    
    # ç»˜åˆ¶çƒ­åŠ›å›¾
    im = ax2.imshow(similarity_matrix, cmap='RdYlBu_r', aspect='auto', vmin=-1, vmax=1)
    ax2.set_xticks(range(n_words))
    ax2.set_xticklabels(selected_words, rotation=45)
    ax2.set_yticks(range(n_words))
    ax2.set_yticklabels(selected_words)
    
    # æ·»åŠ æ•°å€¼
    for i in range(n_words):
        for j in range(n_words):
            text = ax2.text(j, i, f'{similarity_matrix[i, j]:.2f}',
                           ha="center", va="center", fontsize=9)
    
    plt.colorbar(im, ax=ax2)
    
    # 3. è¯ç±»æ¯”å…³ç³»
    ax3 = fig.add_subplot(223)
    ax3.set_title('è¯ç±»æ¯”ï¼šå‘é‡è¿ç®—çš„é­”æ³•', fontsize=14, weight='bold')
    ax3.axis('off')
    
    # ç±»æ¯”ç¤ºä¾‹
    analogies = [
        ('çŒ«', 'ç‹—', 'è‹¹æœ', '?'),
        ('åŒ—äº¬', 'ä¸­å›½', 'ä¸Šæµ·', '?'),
        ('åƒ', 'è‹¹æœ', 'ç¡', '?')
    ]
    
    y_pos = 0.9
    for a, b, c, _ in analogies:
        result = w2v.analogy(a, b, c)
        
        # æ˜¾ç¤ºç±»æ¯”
        ax3.text(0.1, y_pos, f'{a} : {b} = {c} : ?', 
                transform=ax3.transAxes, fontsize=12)
        
        # å‘é‡è¿ç®—
        ax3.text(0.5, y_pos, f'{b} - {a} + {c} =', 
                transform=ax3.transAxes, fontsize=10, style='italic')
        
        # ç»“æœ
        ax3.text(0.75, y_pos, result if result else 'æ— ', 
                transform=ax3.transAxes, fontsize=12,
                bbox=dict(boxstyle="round", facecolor='lightgreen'))
        
        y_pos -= 0.25
    
    ax3.text(0.5, 0.1, 'è¯åµŒå…¥ä¿ç•™äº†è¯­ä¹‰å…³ç³»ï¼',
            transform=ax3.transAxes, ha='center', fontsize=12,
            color='red', weight='bold')
    
    # 4. æœ€è¿‘é‚»å±•ç¤º
    ax4 = fig.add_subplot(224)
    ax4.set_title('æ‰¾åˆ°è¯­ä¹‰ç›¸ä¼¼çš„è¯', fontsize=14, weight='bold')
    ax4.axis('off')
    
    # æŸ¥è¯¢è¯
    query_words = ['çŒ«', 'è‹¹æœ', 'åƒ', 'åŒ—äº¬']
    
    y_pos = 0.9
    for query in query_words:
        neighbors = w2v.find_nearest(query, n=3)
        
        ax4.text(0.1, y_pos, f'{query}:', 
                transform=ax4.transAxes, fontsize=12, weight='bold')
        
        x_pos = 0.25
        for word, sim in neighbors:
            ax4.text(x_pos, y_pos, f'{word}\n({sim:.2f})', 
                    transform=ax4.transAxes, fontsize=10,
                    bbox=dict(boxstyle="round", facecolor='lightblue'),
                    ha='center')
            x_pos += 0.15
        
        y_pos -= 0.2
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸŒŸ è¯åµŒå…¥çš„ç¥å¥‡æ€§è´¨ï¼š")
    print("1. è¯­ä¹‰èšç±»ï¼šç›¸ä¼¼çš„è¯èšé›†åœ¨ä¸€èµ·")
    print("2. çº¿æ€§å…³ç³»ï¼šking - man + woman â‰ˆ queen")
    print("3. è·ç¦»æœ‰æ„ä¹‰ï¼šä½™å¼¦ç›¸ä¼¼åº¦åæ˜ è¯­ä¹‰ç›¸ä¼¼æ€§")
    print("4. å¯è®¡ç®—æ€§ï¼šæ”¯æŒå„ç§å‘é‡è¿ç®—")

è¯åµŒå…¥æ€§è´¨æ¼”ç¤º()
```

#### ğŸ”§ å…¶ä»–è¯åµŒå…¥æ–¹æ³•

```python
def å…¶ä»–è¯åµŒå…¥æ–¹æ³•():
    """ä»‹ç»GloVeã€FastTextç­‰æ–¹æ³•"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. GloVeåŸç†
    ax1.set_title('GloVeï¼šå…¨å±€å‘é‡è¡¨ç¤º', fontsize=14, weight='bold')
    ax1.axis('off')
    
    # GloVeçš„æ ¸å¿ƒæ€æƒ³
    ax1.text(0.5, 0.9, 'GloVe = Global Vectors', 
            transform=ax1.transAxes, ha='center', fontsize=12, weight='bold')
    
    ax1.text(0.5, 0.75, 'æ ¸å¿ƒæ€æƒ³ï¼šç»“åˆå…¨å±€ç»Ÿè®¡ä¿¡æ¯', 
            transform=ax1.transAxes, ha='center', fontsize=11,
            bbox=dict(boxstyle="round", facecolor='lightblue'))
    
    # å…±ç°çŸ©é˜µç¤ºä¾‹
    ax1.text(0.1, 0.6, 'å…±ç°çŸ©é˜µXï¼š', transform=ax1.transAxes, fontsize=10)
    
    # ç®€åŒ–çš„å…±ç°çŸ©é˜µ
    cooc_matrix = np.array([
        [0, 10, 2, 8],
        [10, 0, 5, 2],
        [2, 5, 0, 3],
        [8, 2, 3, 0]
    ])
    words = ['çŒ«', 'ç‹—', 'åƒ', 'ç¡']
    
    # ç»˜åˆ¶çŸ©é˜µ
    for i in range(4):
        for j in range(4):
            x = 0.3 + j * 0.1
            y = 0.5 - i * 0.08
            color = 'white' if cooc_matrix[i, j] == 0 else 'lightgreen'
            ax1.text(x, y, str(cooc_matrix[i, j]), 
                    transform=ax1.transAxes, ha='center', va='center',
                    bbox=dict(boxstyle="square", facecolor=color, pad=0.3),
                    fontsize=9)
    
    # æ ‡ç­¾
    for i, word in enumerate(words):
        ax1.text(0.25, 0.5 - i * 0.08, word, 
                transform=ax1.transAxes, ha='right', fontsize=9)
        ax1.text(0.3 + i * 0.1, 0.58, word, 
                transform=ax1.transAxes, ha='center', fontsize=9)
    
    # ç›®æ ‡å‡½æ•°
    ax1.text(0.5, 0.2, r'J = Î£ f(Xij)(wiÂ·wj - log Xij)Â²',
            transform=ax1.transAxes, ha='center', fontsize=11,
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    ax1.text(0.5, 0.05, 'Word2Vecå…³æ³¨å±€éƒ¨ï¼ŒGloVeå…³æ³¨å…¨å±€',
            transform=ax1.transAxes, ha='center', fontsize=10,
            style='italic', color='gray')
    
    # 2. FastText
    ax2.set_title('FastTextï¼šå­è¯çº§åˆ«çš„åµŒå…¥', fontsize=14, weight='bold')
    ax2.axis('off')
    
    # FastTextç‰¹ç‚¹
    ax2.text(0.5, 0.85, 'FastText = Fast + Text', 
            transform=ax2.transAxes, ha='center', fontsize=12, weight='bold')
    
    # å­è¯åˆ†è§£ç¤ºä¾‹
    word = "unhappiness"
    subwords = ['<un', 'unh', 'nha', 'hap', 'app', 'ppi', 'pin', 'ine', 'nes', 'ess', 'ss>']
    
    ax2.text(0.1, 0.7, f'è¯ï¼š{word}', transform=ax2.transAxes, fontsize=11)
    ax2.text(0.1, 0.6, '3-gramå­è¯ï¼š', transform=ax2.transAxes, fontsize=10)
    
    # æ˜¾ç¤ºå­è¯
    x_pos = 0.1
    y_pos = 0.5
    for i, subword in enumerate(subwords):
        if i > 0 and i % 4 == 0:
            x_pos = 0.1
            y_pos -= 0.08
        
        ax2.text(x_pos, y_pos, subword, transform=ax2.transAxes,
                fontsize=9, bbox=dict(boxstyle="round", facecolor='lightgreen'))
        x_pos += 0.12
    
    # ä¼˜åŠ¿
    ax2.text(0.5, 0.25, 'ä¼˜åŠ¿ï¼š', transform=ax2.transAxes, 
            ha='center', fontsize=11, weight='bold')
    
    advantages = [
        'âœ“ å¤„ç†OOVè¯ï¼šé€šè¿‡å­è¯ç»„åˆ',
        'âœ“ å½¢æ€å­¦ä¿¡æ¯ï¼šå‰ç¼€ã€åç¼€',
        'âœ“ æ‹¼å†™ç›¸ä¼¼ï¼štypoå®¹é”™'
    ]
    
    y_pos = 0.15
    for adv in advantages:
        ax2.text(0.5, y_pos, adv, transform=ax2.transAxes,
                ha='center', fontsize=10)
        y_pos -= 0.05
    
    # 3. æ–¹æ³•å¯¹æ¯”
    ax3.set_title('ä¸åŒè¯åµŒå…¥æ–¹æ³•å¯¹æ¯”', fontsize=14, weight='bold')
    
    methods = ['Word2Vec', 'GloVe', 'FastText', 'BERT*']
    
    # å„é¡¹æŒ‡æ ‡è¯„åˆ†ï¼ˆæ»¡åˆ†5ï¼‰
    speed = [4, 3, 4, 1]
    oov_handling = [1, 1, 5, 3]
    context = [3, 3, 3, 5]
    multilingual = [2, 2, 4, 5]
    
    x = np.arange(len(methods))
    width = 0.2
    
    ax3.bar(x - 1.5*width, speed, width, label='è®­ç»ƒé€Ÿåº¦', color='lightblue')
    ax3.bar(x - 0.5*width, oov_handling, width, label='OOVå¤„ç†', color='lightgreen')
    ax3.bar(x + 0.5*width, context, width, label='ä¸Šä¸‹æ–‡ç†è§£', color='lightcoral')
    ax3.bar(x + 1.5*width, multilingual, width, label='å¤šè¯­è¨€', color='lightyellow')
    
    ax3.set_xlabel('æ–¹æ³•')
    ax3.set_ylabel('è¯„åˆ†')
    ax3.set_xticks(x)
    ax3.set_xticklabels(methods)
    ax3.legend()
    ax3.grid(True, alpha=0.3, axis='y')
    
    ax3.text(0.5, 0.95, '*BERTæ˜¯ä¸Šä¸‹æ–‡ç›¸å…³çš„è¯åµŒå…¥',
            transform=ax3.transAxes, ha='center', fontsize=9,
            style='italic', color='gray')
    
    # 4. è¯„ä¼°æ–¹æ³•
    ax4.set_title('è¯åµŒå…¥è´¨é‡è¯„ä¼°', fontsize=14, weight='bold')
    ax4.axis('off')
    
    # è¯„ä¼°ä»»åŠ¡
    tasks = [
        ('è¯ç›¸ä¼¼åº¦', 'SimLex-999', 'äººå·¥æ ‡æ³¨çš„è¯å¯¹ç›¸ä¼¼åº¦'),
        ('è¯ç±»æ¯”', 'Google Analogy', 'A:B = C:Dç±»æ¯”ä»»åŠ¡'),
        ('ä¸‹æ¸¸ä»»åŠ¡', 'NER/æƒ…æ„Ÿåˆ†æ', 'åœ¨å…·ä½“ä»»åŠ¡ä¸Šçš„è¡¨ç°'),
    ]
    
    y_pos = 0.8
    for task, dataset, desc in tasks:
        # ä»»åŠ¡å
        ax4.text(0.1, y_pos, task, transform=ax4.transAxes,
                fontsize=11, weight='bold')
        
        # æ•°æ®é›†
        ax4.text(0.3, y_pos, dataset, transform=ax4.transAxes,
                fontsize=10, bbox=dict(boxstyle="round", facecolor='lightblue'))
        
        # æè¿°
        ax4.text(0.5, y_pos, desc, transform=ax4.transAxes,
                fontsize=9, style='italic', color='gray')
        
        y_pos -= 0.2
    
    # ç¤ºä¾‹è¯„åˆ†
    ax4.text(0.5, 0.15, 'å…¸å‹è¯„åˆ†ï¼šWord2Vec(70%) < GloVe(75%) < FastText(78%)',
            transform=ax4.transAxes, ha='center', fontsize=10,
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ”§ å„ç§è¯åµŒå…¥æ–¹æ³•æ€»ç»“ï¼š")
    print("1. Word2Vecï¼šå¼€åˆ›æ€§å·¥ä½œï¼Œç®€å•é«˜æ•ˆ")
    print("2. GloVeï¼šç»“åˆå…¨å±€ç»Ÿè®¡ï¼Œæ€§èƒ½ç¨³å®š")
    print("3. FastTextï¼šå­è¯å»ºæ¨¡ï¼Œå¤„ç†OOV")
    print("4. è¶‹åŠ¿ï¼šä»é™æ€åˆ°åŠ¨æ€ï¼Œä»è¯çº§åˆ°å­è¯çº§")

å…¶ä»–è¯åµŒå…¥æ–¹æ³•()
```

#### ğŸ’» å®æˆ˜ï¼šè®­ç»ƒè‡ªå·±çš„è¯åµŒå…¥

```python
import torch
import torch.nn as nn
import torch.optim as optim

class SimpleWord2Vec(nn.Module):
    """ç®€åŒ–çš„Word2Vecå®ç°ï¼ˆSkip-gramï¼‰"""
    
    def __init__(self, vocab_size, embedding_dim):
        super(SimpleWord2Vec, self).__init__()
        
        # è¾“å…¥åµŒå…¥å±‚ï¼ˆä¸­å¿ƒè¯ï¼‰
        self.in_embed = nn.Embedding(vocab_size, embedding_dim)
        # è¾“å‡ºåµŒå…¥å±‚ï¼ˆä¸Šä¸‹æ–‡è¯ï¼‰
        self.out_embed = nn.Embedding(vocab_size, embedding_dim)
        
        # åˆå§‹åŒ–
        self.in_embed.weight.data.uniform_(-0.1, 0.1)
        self.out_embed.weight.data.uniform_(-0.1, 0.1)
    
    def forward(self, center_words, context_words, negative_words):
        """
        center_words: ä¸­å¿ƒè¯ç´¢å¼• [batch_size]
        context_words: æ­£æ ·æœ¬ï¼ˆä¸Šä¸‹æ–‡è¯ï¼‰ç´¢å¼• [batch_size]
        negative_words: è´Ÿæ ·æœ¬ç´¢å¼• [batch_size, n_negative]
        """
        batch_size = center_words.size(0)
        
        # è·å–åµŒå…¥
        center_embeds = self.in_embed(center_words)  # [batch_size, embedding_dim]
        context_embeds = self.out_embed(context_words)  # [batch_size, embedding_dim]
        neg_embeds = self.out_embed(negative_words)  # [batch_size, n_negative, embedding_dim]
        
        # æ­£æ ·æœ¬å¾—åˆ†
        pos_score = torch.sum(center_embeds * context_embeds, dim=1)  # [batch_size]
        pos_score = torch.sigmoid(pos_score)
        
        # è´Ÿæ ·æœ¬å¾—åˆ†
        neg_score = torch.bmm(neg_embeds, center_embeds.unsqueeze(2)).squeeze()  # [batch_size, n_negative]
        neg_score = torch.sigmoid(-neg_score)
        
        # è®¡ç®—æŸå¤±
        pos_loss = -torch.log(pos_score).mean()
        neg_loss = -torch.log(neg_score).mean()
        
        return pos_loss + neg_loss
    
    def get_embedding(self, word_idx):
        """è·å–è¯åµŒå…¥"""
        return self.in_embed.weight[word_idx].detach().numpy()

def è®­ç»ƒè¯åµŒå…¥æ¼”ç¤º():
    """æ¼”ç¤ºè®­ç»ƒè¿‡ç¨‹"""
    
    # å‡†å¤‡æ•°æ®
    sentences = [
        "æˆ‘ å–œæ¬¢ åƒ è‹¹æœ",
        "æˆ‘ å–œæ¬¢ åƒ é¦™è•‰",
        "çŒ« å–œæ¬¢ åƒ é±¼",
        "ç‹— å–œæ¬¢ åƒ è‚‰",
        "ä»– å–œæ¬¢ å­¦ä¹  ç¼–ç¨‹",
        "å¥¹ å–œæ¬¢ å­¦ä¹  è‹±è¯­"
    ]
    
    # æ„å»ºè¯æ±‡è¡¨
    vocab = set()
    for sent in sentences:
        vocab.update(sent.split())
    vocab = list(vocab)
    word2idx = {word: idx for idx, word in enumerate(vocab)}
    idx2word = {idx: word for word, idx in word2idx.items()}
    
    print(f"è¯æ±‡è¡¨å¤§å°: {len(vocab)}")
    print(f"è¯æ±‡è¡¨: {vocab[:10]}...")
    
    # è®­ç»ƒå‚æ•°
    vocab_size = len(vocab)
    embedding_dim = 10
    window_size = 2
    n_negative = 3
    
    # åˆ›å»ºæ¨¡å‹
    model = SimpleWord2Vec(vocab_size, embedding_dim)
    optimizer = optim.Adam(model.parameters(), lr=0.01)
    
    # ç”Ÿæˆè®­ç»ƒæ ·æœ¬
    training_pairs = []
    for sent in sentences:
        words = sent.split()
        indices = [word2idx[w] for w in words]
        
        for i, center_idx in enumerate(indices):
            # è·å–ä¸Šä¸‹æ–‡è¯
            for j in range(max(0, i-window_size), min(len(indices), i+window_size+1)):
                if i != j:
                    training_pairs.append((center_idx, indices[j]))
    
    print(f"\nè®­ç»ƒæ ·æœ¬æ•°: {len(training_pairs)}")
    
    # è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # 1. æŸå¤±æ›²çº¿
    ax1.set_title('è®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14, weight='bold')
    
    losses = []
    n_epochs = 50
    
    for epoch in range(n_epochs):
        epoch_loss = 0
        
        for center, context in training_pairs:
            # å‡†å¤‡æ•°æ®
            center_tensor = torch.tensor([center])
            context_tensor = torch.tensor([context])
            
            # éšæœºè´Ÿé‡‡æ ·
            negative_indices = []
            while len(negative_indices) < n_negative:
                neg_idx = np.random.randint(0, vocab_size)
                if neg_idx != center and neg_idx != context:
                    negative_indices.append(neg_idx)
            negative_tensor = torch.tensor([negative_indices])
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            loss = model(center_tensor, context_tensor, negative_tensor)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
        
        avg_loss = epoch_loss / len(training_pairs)
        losses.append(avg_loss)
        
        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss:.4f}")
    
    ax1.plot(losses, 'b-', linewidth=2)
    ax1.set_xlabel('è®­ç»ƒè½®æ¬¡')
    ax1.set_ylabel('æŸå¤±å€¼')
    ax1.grid(True, alpha=0.3)
    
    # 2. å­¦åˆ°çš„è¯åµŒå…¥å¯è§†åŒ–ï¼ˆ2DæŠ•å½±ï¼‰
    ax2.set_title('å­¦ä¹ åˆ°çš„è¯åµŒå…¥ï¼ˆ2DæŠ•å½±ï¼‰', fontsize=14, weight='bold')
    
    # è·å–æ‰€æœ‰è¯åµŒå…¥
    embeddings = []
    words = []
    for word, idx in word2idx.items():
        embedding = model.get_embedding(idx)
        embeddings.append(embedding)
        words.append(word)
    
    embeddings = np.array(embeddings)
    
    # PCAé™ç»´åˆ°2D
    pca = PCA(n_components=2)
    embeddings_2d = pca.fit_transform(embeddings)
    
    # ç»˜åˆ¶
    ax2.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.6, s=100)
    
    for i, word in enumerate(words):
        ax2.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]),
                    xytext=(5, 5), textcoords='offset points', fontsize=11)
    
    ax2.set_xlabel('PCAç»´åº¦1')
    ax2.set_ylabel('PCAç»´åº¦2')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # æµ‹è¯•ç›¸ä¼¼åº¦
    print("\nğŸ” è¯ç›¸ä¼¼åº¦æµ‹è¯•:")
    test_words = ['æˆ‘', 'åƒ', 'è‹¹æœ']
    
    for test_word in test_words:
        if test_word in word2idx:
            test_idx = word2idx[test_word]
            test_embedding = model.get_embedding(test_idx)
            
            # è®¡ç®—ä¸å…¶ä»–è¯çš„ç›¸ä¼¼åº¦
            similarities = []
            for word, idx in word2idx.items():
                if word != test_word:
                    other_embedding = model.get_embedding(idx)
                    sim = np.dot(test_embedding, other_embedding) / (
                        np.linalg.norm(test_embedding) * np.linalg.norm(other_embedding))
                    similarities.append((word, sim))
            
            # æ’åºå¹¶æ˜¾ç¤ºå‰3ä¸ª
            similarities.sort(key=lambda x: x[1], reverse=True)
            print(f"\n'{test_word}'æœ€ç›¸ä¼¼çš„è¯:")
            for word, sim in similarities[:3]:
                print(f"  {word}: {sim:.3f}")

è®­ç»ƒè¯åµŒå…¥æ¼”ç¤º()
```

#### ğŸ“ æœ¬ç« å°ç»“

è¯åµŒå…¥æ˜¯æ·±åº¦å­¦ä¹ åœ¨NLPé¢†åŸŸçš„ç¬¬ä¸€ä¸ªæ€æ‰‹çº§åº”ç”¨ï¼š

1. **æ ¸å¿ƒåˆ›æ–°**ï¼š
   - ä»ç¦»æ•£åˆ°è¿ç»­ï¼šone-hot â†’ ç¨ å¯†å‘é‡
   - ä»ç‹¬ç«‹åˆ°ç›¸å…³ï¼šå­¤ç«‹çš„è¯ â†’ è¯­ä¹‰ç©ºé—´
   - ä»ç¬¦å·åˆ°è®¡ç®—ï¼šæ— æ³•è¿ç®— â†’ å‘é‡è¿ç®—

2. **ä¸»è¦æ–¹æ³•**ï¼š
   - Word2Vecï¼šCBOWå’ŒSkip-gram
   - GloVeï¼šç»“åˆå…¨å±€ç»Ÿè®¡ä¿¡æ¯
   - FastTextï¼šå¼•å…¥å­è¯ä¿¡æ¯
   - ä¸Šä¸‹æ–‡ç›¸å…³ï¼šELMoã€BERTï¼ˆåç»­ç« èŠ‚ï¼‰

3. **å…³é”®æ€§è´¨**ï¼š
   - è¯­ä¹‰ç›¸ä¼¼æ€§ï¼šç›¸ä¼¼çš„è¯è·ç¦»è¿‘
   - çº¿æ€§å…³ç³»ï¼šæ”¯æŒç±»æ¯”æ¨ç†
   - å¯ç»„åˆæ€§ï¼šçŸ­è¯­çš„è¯­ä¹‰ç»„åˆ

4. **å®é™…åº”ç”¨**ï¼š
   - ä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„è¾“å…¥ç‰¹å¾
   - è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
   - ä¿¡æ¯æ£€ç´¢å’Œæ¨è
   - è·¨è¯­è¨€æ˜ å°„

#### ğŸ’¡ å®ç”¨å»ºè®®

1. **é€‰æ‹©æŒ‡å—**ï¼š
   - é€šç”¨åœºæ™¯ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„Word2Vecæˆ–GloVe
   - å¤šè¯­è¨€/OOVå¤šï¼šä½¿ç”¨FastText
   - ç‰¹å®šé¢†åŸŸï¼šåœ¨é¢†åŸŸè¯­æ–™ä¸Šè®­ç»ƒ
   - è¿½æ±‚æ•ˆæœï¼šä½¿ç”¨BERTç­‰ä¸Šä¸‹æ–‡æ¨¡å‹

2. **è®­ç»ƒæŠ€å·§**ï¼š
   - è¯­æ–™è¦è¶³å¤Ÿå¤§ï¼ˆè‡³å°‘ç™¾ä¸‡è¯ï¼‰
   - åˆç†è®¾ç½®çª—å£å¤§å°ï¼ˆé€šå¸¸5-10ï¼‰
   - ä½¿ç”¨è´Ÿé‡‡æ ·åŠ é€Ÿè®­ç»ƒ
   - é€‚å½“çš„åµŒå…¥ç»´åº¦ï¼ˆ50-300ï¼‰

3. **å¸¸è§é—®é¢˜**ï¼š
   - è¯é¢‘ä¸å¹³è¡¡ï¼šä½¿ç”¨å­é‡‡æ ·
   - OOVé—®é¢˜ï¼šä½¿ç”¨FastTextæˆ–å­—ç¬¦çº§æ¨¡å‹
   - å¤šä¹‰è¯ï¼šè€ƒè™‘ä¸Šä¸‹æ–‡ç›¸å…³æ¨¡å‹

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆè¯´"è¯åµŒå…¥è®©NLPè¿›å…¥äº†æ·±åº¦å­¦ä¹ æ—¶ä»£"ï¼Ÿ
2. Word2Vecçš„Skip-gramä¸ºä»€ä¹ˆæ¯”CBOWæ•ˆæœå¥½ï¼Ÿ
3. å¦‚ä½•è¯„ä¼°è¯åµŒå…¥çš„è´¨é‡ï¼Ÿæœ‰å“ªäº›æŒ‡æ ‡ï¼Ÿ
4. é™æ€è¯åµŒå…¥çš„æœ€å¤§å±€é™æ˜¯ä»€ä¹ˆï¼Ÿ

æ­å–œä½ æŒæ¡äº†è¯åµŒå…¥æŠ€æœ¯ï¼ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†å­¦ä¹ ä½ç½®ç¼–ç ï¼Œçœ‹çœ‹å¦‚ä½•è®©æ¨¡å‹ç†è§£è¯çš„é¡ºåºã€‚

### ç¬¬15ç« ï¼šä½ç½®ç¼–ç â€”â€”è®©æ¨¡å‹ç†è§£é¡ºåº

#### ğŸ¯ æœ¬ç« å¯¼è¯»

è¯•ç€è¯»è¿™ä¸¤ä¸ªå¥å­ï¼š

1. "æˆ‘çˆ±ä½ "
2. "ä½ çˆ±æˆ‘"

åŒæ ·çš„ä¸‰ä¸ªå­—ï¼Œé¡ºåºä¸€å˜ï¼Œæ„æ€å®Œå…¨ä¸åŒã€‚ä½†å¯¹è®¡ç®—æœºæ¥è¯´ï¼Œå¦‚æœåªçœ‹è¯åµŒå…¥ï¼Œè¿™ä¸¤å¥è¯æ˜¯ä¸€æ ·çš„ï¼

è¿™å°±æ˜¯ä½ç½®ç¼–ç ï¼ˆPosition Encodingï¼‰è¦è§£å†³çš„é—®é¢˜ï¼š**è®©æ¨¡å‹çŸ¥é“æ¯ä¸ªè¯åœ¨å¥å­ä¸­çš„ä½ç½®**ã€‚

å°±åƒç»™æ¯ä¸ªæ¼”å‘˜å‘å·ç ç‰Œï¼Œè®©ä»–ä»¬çŸ¥é“è‡ªå·±è¯¥ç«™åœ¨èˆå°çš„ä»€ä¹ˆä½ç½®ã€‚

#### ğŸ“ ä¸ºä»€ä¹ˆéœ€è¦ä½ç½®ä¿¡æ¯ï¼Ÿ

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle, FancyBboxPatch, Circle
import matplotlib.patches as mpatches
from mpl_toolkits.mplot3d import Axes3D

def ä¸ºä»€ä¹ˆéœ€è¦ä½ç½®ç¼–ç ():
    """å±•ç¤ºä½ç½®ä¿¡æ¯çš„é‡è¦æ€§"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. è¯åºæ”¹å˜æ„æ€
    ax1.set_title('è¯åºå†³å®šè¯­ä¹‰', fontsize=14, weight='bold')
    ax1.set_xlim(0, 10)
    ax1.set_ylim(0, 10)
    ax1.axis('off')
    
    # ä¸¤ä¸ªå¥å­
    sentences = [
        ("ç‹—å’¬äºº", ["ç‹—", "å’¬", "äºº"]),
        ("äººå’¬ç‹—", ["äºº", "å’¬", "ç‹—"])
    ]
    
    y_positions = [7, 4]
    for (sent, words), y in zip(sentences, y_positions):
        # å¥å­æ ‡é¢˜
        ax1.text(1, y+1.5, sent, fontsize=12, weight='bold')
        
        # ç”»è¯
        for i, word in enumerate(words):
            x = 2 + i * 2
            # è¯æ¡†
            rect = FancyBboxPatch((x-0.4, y-0.4), 0.8, 0.8,
                                 boxstyle="round,pad=0.1",
                                 facecolor='lightblue', edgecolor='black')
            ax1.add_patch(rect)
            ax1.text(x, y, word, ha='center', va='center', fontsize=11)
            
            # ä½ç½®æ ‡å·
            ax1.text(x, y-0.8, f'ä½ç½®{i+1}', ha='center', fontsize=9, 
                    color='gray', style='italic')
    
    # è¯´æ˜
    ax1.text(5, 1, 'åŒæ ·çš„è¯ï¼Œä¸åŒçš„é¡ºåºï¼Œå®Œå…¨ä¸åŒçš„æ„æ€ï¼',
            ha='center', fontsize=11, color='red', weight='bold',
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # 2. Transformerçš„é—®é¢˜
    ax2.set_title('Transformerçš„"å¤±å¿†ç—‡"', fontsize=14, weight='bold')
    ax2.axis('off')
    
    # Self-Attentionç¤ºæ„
    ax2.text(0.5, 0.9, 'Self-Attentionè®¡ç®—', transform=ax2.transAxes,
            ha='center', fontsize=12, weight='bold')
    
    # è¾“å…¥åºåˆ—
    words = ["æˆ‘", "çˆ±", "å­¦ä¹ ", "AI"]
    colors = ['lightcoral', 'lightgreen', 'lightblue', 'lightyellow']
    
    # ç”»è¾“å…¥
    y_input = 0.7
    for i, (word, color) in enumerate(zip(words, colors)):
        x = 0.2 + i * 0.2
        ax2.text(x, y_input, word, transform=ax2.transAxes,
                ha='center', va='center', fontsize=10,
                bbox=dict(boxstyle="round", facecolor=color))
    
    # ç”»Attention
    ax2.text(0.5, 0.5, 'Attention\n(åªçœ‹å†…å®¹ç›¸ä¼¼åº¦)', 
            transform=ax2.transAxes, ha='center', va='center',
            fontsize=10, bbox=dict(boxstyle="round", facecolor='lightgray'))
    
    # ç”»è¾“å‡º
    y_output = 0.3
    ax2.text(0.5, y_output, 'ï¼Ÿï¼Ÿï¼Ÿ', transform=ax2.transAxes,
            ha='center', va='center', fontsize=12, color='red')
    
    # é—®é¢˜è¯´æ˜
    ax2.text(0.5, 0.1, 'Attentionæ˜¯æ’åˆ—ä¸å˜çš„ï¼ˆPermutation Invariantï¼‰\n'
                      'æ‰“ä¹±è¾“å…¥é¡ºåºï¼Œè¾“å‡ºå®Œå…¨ä¸€æ ·ï¼',
            transform=ax2.transAxes, ha='center', fontsize=10,
            color='red', bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # 3. RNN vs Transformer
    ax3.set_title('RNN vs Transformerï¼šä½ç½®ä¿¡æ¯å¤„ç†', fontsize=14, weight='bold')
    ax3.axis('off')
    
    # RNNéƒ¨åˆ†
    ax3.text(0.25, 0.9, 'RNN', transform=ax3.transAxes,
            ha='center', fontsize=12, weight='bold')
    
    # RNNåºåˆ—å¤„ç†
    y_rnn = 0.7
    for i in range(4):
        x = 0.1 + i * 0.08
        # ç”»çŠ¶æ€
        circle = Circle((x, y_rnn), 0.03, transform=ax3.transAxes,
                      facecolor='lightblue', edgecolor='black')
        ax3.add_patch(circle)
        
        if i < 3:
            # ç”»ç®­å¤´
            ax3.arrow(x + 0.03, y_rnn, 0.04, 0, transform=ax3.transAxes,
                     head_width=0.02, head_length=0.01, fc='gray', ec='gray')
    
    ax3.text(0.25, 0.55, 'âœ“ å¤©ç„¶æœ‰åº\nâœ— ä¸²è¡Œè®¡ç®—',
            transform=ax3.transAxes, ha='center', fontsize=9,
            bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.5))
    
    # Transformeréƒ¨åˆ†
    ax3.text(0.75, 0.9, 'Transformer', transform=ax3.transAxes,
            ha='center', fontsize=12, weight='bold')
    
    # Transformerå¹¶è¡Œå¤„ç†
    y_trans = 0.7
    for i in range(4):
        x = 0.6 + i * 0.08
        rect = Rectangle((x-0.025, y_trans-0.025), 0.05, 0.05,
                       transform=ax3.transAxes,
                       facecolor='lightcoral', edgecolor='black')
        ax3.add_patch(rect)
    
    # åŒå‘ç®­å¤´è¡¨ç¤ºå…¨è¿æ¥
    ax3.annotate('', xy=(0.85, y_trans), xytext=(0.6, y_trans),
                transform=ax3.transAxes,
                arrowprops=dict(arrowstyle='<->', color='gray'))
    
    ax3.text(0.75, 0.55, 'âœ“ å¹¶è¡Œè®¡ç®—\nâœ— æ— ä½ç½®ä¿¡æ¯',
            transform=ax3.transAxes, ha='center', fontsize=9,
            bbox=dict(boxstyle="round", facecolor='lightcoral', alpha=0.5))
    
    # è§£å†³æ–¹æ¡ˆ
    ax3.text(0.5, 0.3, 'â†“', transform=ax3.transAxes,
            ha='center', fontsize=20)
    ax3.text(0.5, 0.15, 'ä½ç½®ç¼–ç ï¼šç»™Transformerè£…ä¸Š"GPS"',
            transform=ax3.transAxes, ha='center', fontsize=11,
            weight='bold', bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # 4. ä½ç½®ç¼–ç çš„æ•ˆæœ
    ax4.set_title('åŠ å…¥ä½ç½®ç¼–ç åçš„æ•ˆæœ', fontsize=14, weight='bold')
    
    # æ¨¡æ‹Ÿæ³¨æ„åŠ›æƒé‡çŸ©é˜µ
    attention_no_pe = np.array([
        [0.25, 0.25, 0.25, 0.25],
        [0.25, 0.25, 0.25, 0.25],
        [0.25, 0.25, 0.25, 0.25],
        [0.25, 0.25, 0.25, 0.25]
    ])
    
    attention_with_pe = np.array([
        [0.4, 0.3, 0.2, 0.1],
        [0.3, 0.4, 0.3, 0.0],
        [0.2, 0.3, 0.4, 0.1],
        [0.1, 0.0, 0.1, 0.8]
    ])
    
    # ç»˜åˆ¶ä¸¤ä¸ªæ³¨æ„åŠ›çŸ©é˜µ
    im1 = ax4.imshow(attention_no_pe, cmap='Blues', aspect='auto',
                     extent=[0, 4, 8, 4])
    im2 = ax4.imshow(attention_with_pe, cmap='Reds', aspect='auto',
                     extent=[5, 9, 8, 4])
    
    ax4.text(2, 3.5, 'æ— ä½ç½®ç¼–ç ', ha='center', fontsize=10, weight='bold')
    ax4.text(7, 3.5, 'æœ‰ä½ç½®ç¼–ç ', ha='center', fontsize=10, weight='bold')
    
    ax4.text(2, 2.5, '(å‡åŒ€åˆ†å¸ƒ)', ha='center', fontsize=9, style='italic')
    ax4.text(7, 2.5, '(å±€éƒ¨æ€§æ¨¡å¼)', ha='center', fontsize=9, style='italic')
    
    ax4.set_xlim(0, 9)
    ax4.set_ylim(2, 9)
    ax4.axis('off')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ“ ä½ç½®ç¼–ç çš„å¿…è¦æ€§ï¼š")
    print("1. è¯­è¨€æ˜¯æœ‰åºçš„ï¼šè¯åºå†³å®šè¯­ä¹‰")
    print("2. Transformeræ˜¯æ— åºçš„ï¼šéœ€è¦é¢å¤–çš„ä½ç½®ä¿¡æ¯")
    print("3. ä½ç½®ç¼–ç ï¼šå°†ä½ç½®ä¿¡æ¯æ³¨å…¥åˆ°æ¨¡å‹ä¸­")
    print("4. æ•ˆæœï¼šè®©æ¨¡å‹èƒ½å¤ŸåŒºåˆ†ä¸åŒä½ç½®çš„ç›¸åŒè¯")

ä¸ºä»€ä¹ˆéœ€è¦ä½ç½®ç¼–ç ()
```

#### ğŸ”¢ ç»å¯¹ä½ç½®ç¼–ç 

```python
def æ­£å¼¦ä½ç½®ç¼–ç ():
    """å±•ç¤ºç»å…¸çš„æ­£å¼¦ä½ç½®ç¼–ç """
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. æ­£å¼¦ç¼–ç å…¬å¼
    ax1.set_title('æ­£å¼¦ä½ç½®ç¼–ç å…¬å¼', fontsize=14, weight='bold')
    ax1.axis('off')
    
    # å…¬å¼å±•ç¤º
    ax1.text(0.5, 0.8, 'PE(pos, 2i) = sin(pos / 10000^(2i/d))',
            transform=ax1.transAxes, ha='center', fontsize=12,
            bbox=dict(boxstyle="round", facecolor='lightblue'))
    
    ax1.text(0.5, 0.6, 'PE(pos, 2i+1) = cos(pos / 10000^(2i/d))',
            transform=ax1.transAxes, ha='center', fontsize=12,
            bbox=dict(boxstyle="round", facecolor='lightgreen'))
    
    # å‚æ•°è¯´æ˜
    params = [
        ('pos', 'ä½ç½®ç´¢å¼• (0, 1, 2, ...)'),
        ('i', 'ç»´åº¦ç´¢å¼•'),
        ('d', 'æ¨¡å‹ç»´åº¦ (å¦‚512)'),
    ]
    
    y_pos = 0.4
    for param, desc in params:
        ax1.text(0.3, y_pos, f'{param}:', transform=ax1.transAxes,
                fontsize=11, weight='bold')
        ax1.text(0.4, y_pos, desc, transform=ax1.transAxes,
                fontsize=10, style='italic')
        y_pos -= 0.1
    
    # 2. ä½ç½®ç¼–ç å¯è§†åŒ–
    ax2.set_title('ä½ç½®ç¼–ç çš„"æŒ‡çº¹"', fontsize=14, weight='bold')
    
    # ç”Ÿæˆä½ç½®ç¼–ç 
    max_len = 50
    d_model = 128
    
    def get_positional_encoding(max_len, d_model):
        pe = np.zeros((max_len, d_model))
        position = np.arange(0, max_len).reshape(-1, 1)
        
        div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))
        
        pe[:, 0::2] = np.sin(position * div_term)
        pe[:, 1::2] = np.cos(position * div_term)
        
        return pe
    
    pe = get_positional_encoding(max_len, d_model)
    
    # ç»˜åˆ¶çƒ­åŠ›å›¾
    im = ax2.imshow(pe.T, cmap='RdBu_r', aspect='auto')
    ax2.set_xlabel('ä½ç½®')
    ax2.set_ylabel('ç¼–ç ç»´åº¦')
    ax2.set_xlim(0, 50)
    
    # æ ‡æ³¨
    ax2.text(25, -5, 'æ¯ä¸ªä½ç½®éƒ½æœ‰ç‹¬ç‰¹çš„"æŒ‡çº¹"', 
            ha='center', fontsize=10, style='italic')
    
    plt.colorbar(im, ax=ax2)
    
    # 3. ä¸åŒç»´åº¦çš„å‘¨æœŸæ€§
    ax3.set_title('ä¸åŒç»´åº¦çš„æ³¢é•¿', fontsize=14, weight='bold')
    
    positions = np.arange(0, 100)
    
    # é€‰æ‹©å‡ ä¸ªç»´åº¦å±•ç¤º
    dims = [0, 10, 20, 40]
    colors = ['red', 'green', 'blue', 'orange']
    
    for dim, color in zip(dims, colors):
        if dim % 2 == 0:
            values = np.sin(positions / np.power(10000, dim / d_model))
        else:
            values = np.cos(positions / np.power(10000, (dim-1) / d_model))
        
        ax3.plot(positions, values, color=color, label=f'ç»´åº¦{dim}',
                alpha=0.8, linewidth=2)
    
    ax3.set_xlabel('ä½ç½®')
    ax3.set_ylabel('ç¼–ç å€¼')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    ax3.text(0.5, 0.95, 'ä½ç»´åº¦=é«˜é¢‘ï¼Œé«˜ç»´åº¦=ä½é¢‘',
            transform=ax3.transAxes, ha='center', fontsize=10,
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # 4. ä½ç½®ç¼–ç çš„æ€§è´¨
    ax4.set_title('æ­£å¼¦ç¼–ç çš„ä¼˜è‰¯æ€§è´¨', fontsize=14, weight='bold')
    ax4.axis('off')
    
    # æ€§è´¨åˆ—è¡¨
    properties = [
        ('1ï¸âƒ£ ç¡®å®šæ€§', 'ç›¸åŒä½ç½®æ€»æ˜¯å¾—åˆ°ç›¸åŒç¼–ç '),
        ('2ï¸âƒ£ å”¯ä¸€æ€§', 'ä¸åŒä½ç½®çš„ç¼–ç ä¸åŒ'),
        ('3ï¸âƒ£ æœ‰ç•Œæ€§', 'ç¼–ç å€¼åœ¨[-1, 1]ä¹‹é—´'),
        ('4ï¸âƒ£ å¹³æ»‘æ€§', 'ç›¸é‚»ä½ç½®çš„ç¼–ç ç›¸ä¼¼'),
        ('5ï¸âƒ£ å¯æ‰©å±•', 'å¯ä»¥å¤„ç†è®­ç»ƒæ—¶æœªè§è¿‡çš„é•¿åº¦')
    ]
    
    y_pos = 0.85
    for emoji, prop, desc in properties:
        ax4.text(0.1, y_pos, emoji, transform=ax4.transAxes, fontsize=16)
        ax4.text(0.2, y_pos, prop, transform=ax4.transAxes,
                fontsize=11, weight='bold')
        ax4.text(0.35, y_pos-0.02, desc, transform=ax4.transAxes,
                fontsize=9, style='italic', color='gray')
        y_pos -= 0.15
    
    # ç›¸å¯¹ä½ç½®æ€§è´¨
    ax4.text(0.5, 0.15, 'ç‰¹æ®Šæ€§è´¨ï¼šPE(pos+k) å¯ä»¥è¡¨ç¤ºä¸º PE(pos) çš„çº¿æ€§å˜æ¢',
            transform=ax4.transAxes, ha='center', fontsize=10,
            weight='bold', color='red',
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ”¢ æ­£å¼¦ä½ç½®ç¼–ç çš„è®¾è®¡æ™ºæ…§ï¼š")
    print("1. ä½¿ç”¨ä¸åŒé¢‘ç‡çš„æ­£å¼¦æ³¢ç¼–ç ä¸åŒç»´åº¦")
    print("2. ä½ç»´é«˜é¢‘æ•æ‰å±€éƒ¨ä¿¡æ¯ï¼Œé«˜ç»´ä½é¢‘æ•æ‰å…¨å±€ä¿¡æ¯")
    print("3. æ­£å¼¦å‡½æ•°çš„å‘¨æœŸæ€§ä½¿å¾—ç›¸å¯¹ä½ç½®è®¡ç®—æˆä¸ºå¯èƒ½")
    print("4. å€¼åŸŸæœ‰ç•Œï¼Œä¸ä¼šdominateè¯åµŒå…¥")

æ­£å¼¦ä½ç½®ç¼–ç ()
```

#### ğŸ”„ ç›¸å¯¹ä½ç½®ç¼–ç 

```python
def ç›¸å¯¹ä½ç½®ç¼–ç æ¼”ç¤º():
    """å±•ç¤ºç›¸å¯¹ä½ç½®ç¼–ç çš„æ¦‚å¿µ"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. ç»å¯¹ vs ç›¸å¯¹
    ax1.set_title('ç»å¯¹ä½ç½® vs ç›¸å¯¹ä½ç½®', fontsize=14, weight='bold')
    ax1.set_xlim(0, 10)
    ax1.set_ylim(0, 10)
    ax1.axis('off')
    
    # ç»å¯¹ä½ç½®ç¤ºä¾‹
    words_abs = ["æˆ‘", "çˆ±", "å­¦ä¹ ", "AI"]
    y_abs = 7
    
    ax1.text(5, 8.5, 'ç»å¯¹ä½ç½®ç¼–ç ', ha='center', fontsize=12, weight='bold')
    for i, word in enumerate(words_abs):
        x = 1.5 + i * 2
        # è¯æ¡†
        rect = FancyBboxPatch((x-0.4, y_abs-0.4), 0.8, 0.8,
                             boxstyle="round,pad=0.1",
                             facecolor='lightblue', edgecolor='black')
        ax1.add_patch(rect)
        ax1.text(x, y_abs, word, ha='center', va='center', fontsize=11)
        # ç»å¯¹ä½ç½®
        ax1.text(x, y_abs-0.8, f'Pos={i}', ha='center', fontsize=9,
                color='blue', weight='bold')
    
    # ç›¸å¯¹ä½ç½®ç¤ºä¾‹
    y_rel = 4
    ax1.text(5, 5.5, 'ç›¸å¯¹ä½ç½®ç¼–ç ', ha='center', fontsize=12, weight='bold')
    
    # ç”»ä¸­å¿ƒè¯
    center_idx = 1  # "çˆ±"
    for i, word in enumerate(words_abs):
        x = 1.5 + i * 2
        if i == center_idx:
            color = 'lightcoral'
        else:
            color = 'lightgreen'
        
        rect = FancyBboxPatch((x-0.4, y_rel-0.4), 0.8, 0.8,
                             boxstyle="round,pad=0.1",
                             facecolor=color, edgecolor='black')
        ax1.add_patch(rect)
        ax1.text(x, y_rel, word, ha='center', va='center', fontsize=11)
        
        # ç›¸å¯¹ä½ç½®
        rel_pos = i - center_idx
        ax1.text(x, y_rel-0.8, f'Rel={rel_pos:+d}', ha='center', fontsize=9,
                color='green', weight='bold')
    
    # è¯´æ˜
    ax1.text(5, 1.5, 'ç›¸å¯¹ä½ç½®ï¼šåªå…³å¿ƒè¯ä¸è¯ä¹‹é—´çš„è·ç¦»',
            ha='center', fontsize=10, style='italic',
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    # 2. ç›¸å¯¹ä½ç½®çŸ©é˜µ
    ax2.set_title('ç›¸å¯¹ä½ç½®çŸ©é˜µ', fontsize=14, weight='bold')
    
    # ç”Ÿæˆç›¸å¯¹ä½ç½®çŸ©é˜µ
    seq_len = 6
    rel_pos_matrix = np.zeros((seq_len, seq_len))
    
    for i in range(seq_len):
        for j in range(seq_len):
            rel_pos_matrix[i, j] = j - i
    
    # ç»˜åˆ¶
    im = ax2.imshow(rel_pos_matrix, cmap='RdBu_r', vmin=-5, vmax=5)
    
    # æ·»åŠ æ•°å€¼
    for i in range(seq_len):
        for j in range(seq_len):
            text = ax2.text(j, i, f'{int(rel_pos_matrix[i, j]):+d}',
                           ha="center", va="center", fontsize=10)
    
    ax2.set_xlabel('Token j')
    ax2.set_ylabel('Token i')
    ax2.set_title('ç›¸å¯¹ä½ç½® = j - i', fontsize=11)
    
    plt.colorbar(im, ax=ax2)
    
    # 3. ç›¸å¯¹ä½ç½®çš„ä¼˜åŠ¿
    ax3.set_title('ä¸ºä»€ä¹ˆä½¿ç”¨ç›¸å¯¹ä½ç½®ï¼Ÿ', fontsize=14, weight='bold')
    ax3.axis('off')
    
    # å¹³ç§»ä¸å˜æ€§ç¤ºä¾‹
    ax3.text(0.5, 0.9, 'å¹³ç§»ä¸å˜æ€§', transform=ax3.transAxes,
            ha='center', fontsize=12, weight='bold')
    
    # ä¸¤ä¸ªå¥å­
    sent1 = ["ç‹—", "è¿½", "çŒ«"]
    sent2 = ["æ˜¨å¤©", "ç‹—", "è¿½", "çŒ«", "äº†"]
    
    y1, y2 = 0.7, 0.5
    
    # ç¬¬ä¸€ä¸ªå¥å­
    ax3.text(0.1, y1, 'å¥å­1:', transform=ax3.transAxes, fontsize=10)
    for i, word in enumerate(sent1):
        x = 0.25 + i * 0.08
        ax3.text(x, y1, word, transform=ax3.transAxes,
                ha='center', fontsize=9,
                bbox=dict(boxstyle="round", facecolor='lightblue'))
    
    # ç¬¬äºŒä¸ªå¥å­
    ax3.text(0.1, y2, 'å¥å­2:', transform=ax3.transAxes, fontsize=10)
    for i, word in enumerate(sent2):
        x = 0.25 + i * 0.08
        if word in sent1:
            color = 'lightblue'
        else:
            color = 'lightgray'
        ax3.text(x, y2, word, transform=ax3.transAxes,
                ha='center', fontsize=9,
                bbox=dict(boxstyle="round", facecolor=color))
    
    # è¯´æ˜
    ax3.text(0.5, 0.3, '"ç‹—è¿½çŒ«"çš„ç›¸å¯¹ä½ç½®å…³ç³»ä¿æŒä¸å˜ï¼',
            transform=ax3.transAxes, ha='center', fontsize=10,
            color='green', weight='bold',
            bbox=dict(boxstyle="round", facecolor='lightgreen', alpha=0.3))
    
    # 4. ä¸åŒçš„ç›¸å¯¹ä½ç½®ç¼–ç æ–¹æ³•
    ax4.set_title('ç›¸å¯¹ä½ç½®ç¼–ç çš„å®ç°æ–¹å¼', fontsize=14, weight='bold')
    ax4.axis('off')
    
    methods = [
        ('T5é£æ ¼', 'ä½¿ç”¨å¯å­¦ä¹ çš„ç›¸å¯¹ä½ç½®åç½®', 'lightblue'),
        ('ALiBi', 'çº¿æ€§è¡°å‡çš„æ³¨æ„åŠ›åç½®', 'lightgreen'),
        ('RoPE', 'æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆå¤æ•°åŸŸï¼‰', 'lightcoral'),
        ('ç›¸å¯¹ä½ç½®åµŒå…¥', 'ç±»ä¼¼ç»å¯¹ä½ç½®ä½†ä½¿ç”¨ç›¸å¯¹ç´¢å¼•', 'lightyellow')
    ]
    
    y_pos = 0.85
    for method, desc, color in methods:
        # æ–¹æ³•å
        ax4.text(0.1, y_pos, method, transform=ax4.transAxes,
                fontsize=11, weight='bold',
                bbox=dict(boxstyle="round", facecolor=color))
        
        # æè¿°
        ax4.text(0.3, y_pos, desc, transform=ax4.transAxes,
                fontsize=10, style='italic')
        
        y_pos -= 0.18
    
    # æ€»ç»“
    ax4.text(0.5, 0.15, 'ç›¸å¯¹ä½ç½®ç¼–ç å·²æˆä¸ºå¤§æ¨¡å‹çš„ä¸»æµé€‰æ‹©',
            transform=ax4.transAxes, ha='center', fontsize=11,
            color='red', weight='bold')
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ”„ ç›¸å¯¹ä½ç½®ç¼–ç çš„ä¼˜åŠ¿ï¼š")
    print("1. å¹³ç§»ä¸å˜æ€§ï¼šå…³æ³¨çš„æ˜¯è¯ä¹‹é—´çš„ç›¸å¯¹å…³ç³»")
    print("2. æ›´å¥½çš„æ³›åŒ–ï¼šå¯ä»¥å¤„ç†ä»»æ„é•¿åº¦çš„åºåˆ—")
    print("3. æ›´ç¬¦åˆç›´è§‰ï¼šè¯­è¨€ç†è§£ä¸»è¦ä¾èµ–å±€éƒ¨å…³ç³»")
    print("4. å‚æ•°æ•ˆç‡ï¼šç›¸å¯¹ä½ç½®çš„ç§ç±»æœ‰é™")

ç›¸å¯¹ä½ç½®ç¼–ç æ¼”ç¤º()
```

#### ğŸŒ€ æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰

```python
def æ—‹è½¬ä½ç½®ç¼–ç è¯¦è§£():
    """è¯¦ç»†è§£é‡ŠRoPEçš„åŸç†"""
    
    fig = plt.figure(figsize=(16, 12))
    
    # 1. å¤æ•°è¡¨ç¤º
    ax1 = fig.add_subplot(221)
    ax1.set_title('RoPEçš„æ ¸å¿ƒï¼šå¤æ•°æ—‹è½¬', fontsize=14, weight='bold')
    
    # ç”»å•ä½åœ†
    theta = np.linspace(0, 2*np.pi, 100)
    ax1.plot(np.cos(theta), np.sin(theta), 'k-', alpha=0.3)
    
    # ç”»å‘é‡æ—‹è½¬
    angles = [0, np.pi/4, np.pi/2]
    colors = ['red', 'green', 'blue']
    labels = ['ä½ç½®0', 'ä½ç½®1', 'ä½ç½®2']
    
    for angle, color, label in zip(angles, colors, labels):
        x, y = np.cos(angle), np.sin(angle)
        ax1.arrow(0, 0, x*0.8, y*0.8, head_width=0.05, head_length=0.05,
                 fc=color, ec=color, linewidth=2)
        ax1.text(x*1.1, y*1.1, label, ha='center', va='center',
                color=color, fontsize=10, weight='bold')
    
    ax1.set_xlim(-1.5, 1.5)
    ax1.set_ylim(-1.5, 1.5)
    ax1.set_aspect('equal')
    ax1.grid(True, alpha=0.3)
    ax1.set_xlabel('å®éƒ¨')
    ax1.set_ylabel('è™šéƒ¨')
    
    # 2. æ—‹è½¬çŸ©é˜µ
    ax2 = fig.add_subplot(222)
    ax2.set_title('ä½ç½®mçš„æ—‹è½¬çŸ©é˜µ', fontsize=14, weight='bold')
    ax2.axis('off')
    
    # æ˜¾ç¤ºæ—‹è½¬çŸ©é˜µ
    ax2.text(0.5, 0.8, r'R_m = \begin{bmatrix} \cos(m\theta) & -\sin(m\theta) \\ \sin(m\theta) & \cos(m\theta) \end{bmatrix}',
            transform=ax2.transAxes, ha='center', fontsize=14,
            bbox=dict(boxstyle="round", facecolor='lightblue'))
    
    # åº”ç”¨è¯´æ˜
    ax2.text(0.5, 0.5, 'å°†è¯åµŒå…¥çš„æ¯ä¸¤ä¸ªç»´åº¦ä½œä¸ºä¸€ä¸ªå¤æ•°',
            transform=ax2.transAxes, ha='center', fontsize=11)
    ax2.text(0.5, 0.4, 'æ ¹æ®ä½ç½®mæ—‹è½¬ç›¸åº”çš„è§’åº¦mÎ¸',
            transform=ax2.transAxes, ha='center', fontsize=11)
    
    # é¢‘ç‡è¯´æ˜
    ax2.text(0.5, 0.2, r'Î¸_i = 10000^{-2i/d}',
            transform=ax2.transAxes, ha='center', fontsize=12,
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    ax2.text(0.5, 0.1, 'ä¸åŒç»´åº¦å¯¹ä½¿ç”¨ä¸åŒçš„æ—‹è½¬é¢‘ç‡',
            transform=ax2.transAxes, ha='center', fontsize=10,
            style='italic', color='gray')
    
    # 3. RoPEçš„æ•ˆæœ
    ax3 = fig.add_subplot(223)
    ax3.set_title('RoPEç¼–ç æ•ˆæœå¯è§†åŒ–', fontsize=14, weight='bold')
    
    # ç”ŸæˆRoPEç¼–ç 
    seq_len = 20
    d_model = 64
    
    def rope_encoding(seq_len, d_model):
        position = np.arange(seq_len).reshape(-1, 1)
        dims = np.arange(0, d_model, 2)
        
        theta = 1.0 / np.power(10000, dims / d_model)
        angles = position * theta
        
        # åˆ›å»ºæ—‹è½¬ç¼–ç 
        rope = np.zeros((seq_len, d_model))
        rope[:, 0::2] = np.cos(angles)
        rope[:, 1::2] = np.sin(angles)
        
        return rope
    
    rope = rope_encoding(seq_len, d_model)
    
    # ç»˜åˆ¶
    im = ax3.imshow(rope.T, cmap='RdBu_r', aspect='auto')
    ax3.set_xlabel('ä½ç½®')
    ax3.set_ylabel('ç»´åº¦')
    ax3.set_title('æ¯ä¸ªä½ç½®çš„æ—‹è½¬æ¨¡å¼', fontsize=11)
    plt.colorbar(im, ax=ax3)
    
    # 4. ç›¸å¯¹ä½ç½®è®¡ç®—
    ax4 = fig.add_subplot(224)
    ax4.set_title('RoPEçš„ç›¸å¯¹ä½ç½®æ€§è´¨', fontsize=14, weight='bold')
    ax4.axis('off')
    
    # å±•ç¤ºç›¸å¯¹ä½ç½®è®¡ç®—
    ax4.text(0.5, 0.85, 'å…³é”®æ€§è´¨ï¼šå†…ç§¯åªä¾èµ–ç›¸å¯¹ä½ç½®', 
            transform=ax4.transAxes, ha='center', fontsize=12, weight='bold')
    
    # æ•°å­¦æ¨å¯¼
    ax4.text(0.5, 0.7, 'q_m Â· k_n = q Â· k Â· cos((m-n)Î¸)',
            transform=ax4.transAxes, ha='center', fontsize=12,
            bbox=dict(boxstyle="round", facecolor='lightgreen'))
    
    # è§£é‡Š
    explanations = [
        'q_m = R_m Â· q ï¼ˆæŸ¥è¯¢å‘é‡æ—‹è½¬mè§’åº¦ï¼‰',
        'k_n = R_n Â· k ï¼ˆé”®å‘é‡æ—‹è½¬nè§’åº¦ï¼‰',
        'å†…ç§¯ç»“æœåªä¸(m-n)æœ‰å…³ï¼'
    ]
    
    y_pos = 0.5
    for exp in explanations:
        ax4.text(0.5, y_pos, exp, transform=ax4.transAxes,
                ha='center', fontsize=10)
        y_pos -= 0.1
    
    # ä¼˜åŠ¿æ€»ç»“
    ax4.text(0.5, 0.15, 'RoPEä¼˜åŠ¿ï¼šé«˜æ•ˆã€å¤–æ¨æ€§å¥½ã€æ— éœ€é¢å¤–å‚æ•°',
            transform=ax4.transAxes, ha='center', fontsize=11,
            color='red', weight='bold',
            bbox=dict(boxstyle="round", facecolor='lightyellow'))
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸŒ€ RoPEçš„åˆ›æ–°ä¹‹å¤„ï¼š")
    print("1. ä½¿ç”¨å¤æ•°æ—‹è½¬ç¼–ç ä½ç½®ä¿¡æ¯")
    print("2. å¤©ç„¶å…·æœ‰ç›¸å¯¹ä½ç½®æ€§è´¨")
    print("3. å¯ä»¥å¤–æ¨åˆ°è®­ç»ƒæ—¶æœªè§è¿‡çš„é•¿åº¦")
    print("4. è®¡ç®—é«˜æ•ˆï¼Œæ˜“äºå®ç°")

æ—‹è½¬ä½ç½®ç¼–ç è¯¦è§£()
```

#### ğŸ’» å®æˆ˜ï¼šå®ç°ä½ç½®ç¼–ç 

```python
import torch
import torch.nn as nn

class PositionalEncoding(nn.Module):
    """å®ç°å„ç§ä½ç½®ç¼–ç """
    
    def __init__(self, d_model, max_len=5000, encoding_type='sinusoidal'):
        super(PositionalEncoding, self).__init__()
        self.d_model = d_model
        self.encoding_type = encoding_type
        
        if encoding_type == 'sinusoidal':
            # æ­£å¼¦ä½ç½®ç¼–ç 
            pe = torch.zeros(max_len, d_model)
            position = torch.arange(0, max_len).unsqueeze(1).float()
            
            div_term = torch.exp(torch.arange(0, d_model, 2).float() *
                               -(torch.log(torch.tensor(10000.0)) / d_model))
            
            pe[:, 0::2] = torch.sin(position * div_term)
            pe[:, 1::2] = torch.cos(position * div_term)
            
            self.register_buffer('pe', pe.unsqueeze(0))
            
        elif encoding_type == 'learnable':
            # å¯å­¦ä¹ çš„ä½ç½®ç¼–ç 
            self.pe = nn.Parameter(torch.randn(1, max_len, d_model))
    
    def forward(self, x):
        """
        x: [batch_size, seq_len, d_model]
        """
        seq_len = x.size(1)
        
        if self.encoding_type == 'sinusoidal':
            return x + self.pe[:, :seq_len, :]
        elif self.encoding_type == 'learnable':
            return x + self.pe[:, :seq_len, :]

class RotaryPositionalEncoding(nn.Module):
    """æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰çš„ç®€åŒ–å®ç°"""
    
    def __init__(self, d_model, max_len=5000):
        super(RotaryPositionalEncoding, self).__init__()
        self.d_model = d_model
        
        # è®¡ç®—é¢‘ç‡
        inv_freq = 1.0 / (10000 ** (torch.arange(0, d_model, 2).float() / d_model))
        self.register_buffer('inv_freq', inv_freq)
        
        # é¢„è®¡ç®—coså’Œsin
        position = torch.arange(0, max_len).float()
        freqs = torch.einsum('i,j->ij', position, inv_freq)
        
        self.register_buffer('cos_cached', freqs.cos())
        self.register_buffer('sin_cached', freqs.sin())
    
    def apply_rotary_pos_emb(self, x, cos, sin):
        """åº”ç”¨æ—‹è½¬"""
        # x: [batch_size, seq_len, d_model]
        d_model = x.shape[-1]
        
        # åˆ†æˆä¸¤åŠ
        x1 = x[..., :d_model//2]
        x2 = x[..., d_model//2:]
        
        # æ—‹è½¬
        return torch.cat([
            x1 * cos - x2 * sin,
            x1 * sin + x2 * cos
        ], dim=-1)
    
    def forward(self, x):
        seq_len = x.size(1)
        
        cos = self.cos_cached[:seq_len].unsqueeze(0)  # [1, seq_len, d_model//2]
        sin = self.sin_cached[:seq_len].unsqueeze(0)
        
        return self.apply_rotary_pos_emb(x, cos, sin)

def ä½ç½®ç¼–ç å®æˆ˜():
    """æ¼”ç¤ºä¸åŒä½ç½®ç¼–ç çš„æ•ˆæœ"""
    
    # å‚æ•°è®¾ç½®
    batch_size = 2
    seq_len = 10
    d_model = 64
    
    # åˆ›å»ºè¾“å…¥
    x = torch.randn(batch_size, seq_len, d_model)
    
    # 1. æµ‹è¯•æ­£å¼¦ä½ç½®ç¼–ç 
    print("ğŸ”¢ æ­£å¼¦ä½ç½®ç¼–ç æµ‹è¯•:")
    sin_pe = PositionalEncoding(d_model, encoding_type='sinusoidal')
    x_sin = sin_pe(x)
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {x_sin.shape}")
    print(f"ä½ç½®ç¼–ç èŒƒå›´: [{sin_pe.pe.min():.3f}, {sin_pe.pe.max():.3f}]")
    
    # 2. æµ‹è¯•å¯å­¦ä¹ ä½ç½®ç¼–ç 
    print("\nğŸ“š å¯å­¦ä¹ ä½ç½®ç¼–ç æµ‹è¯•:")
    learn_pe = PositionalEncoding(d_model, encoding_type='learnable')
    x_learn = learn_pe(x)
    print(f"å‚æ•°æ•°é‡: {learn_pe.pe.numel()}")
    print(f"å‚æ•°å½¢çŠ¶: {learn_pe.pe.shape}")
    
    # 3. æµ‹è¯•RoPE
    print("\nğŸŒ€ RoPEæµ‹è¯•:")
    rope = RotaryPositionalEncoding(d_model)
    x_rope = rope(x)
    print(f"è¾“å‡ºå½¢çŠ¶: {x_rope.shape}")
    
    # å¯è§†åŒ–å¯¹æ¯”
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
    
    # æ­£å¼¦ç¼–ç 
    ax1.set_title('æ­£å¼¦ä½ç½®ç¼–ç ', fontsize=14, weight='bold')
    im1 = ax1.imshow(sin_pe.pe[0, :20, :32].numpy(), cmap='RdBu_r', aspect='auto')
    ax1.set_xlabel('ç»´åº¦')
    ax1.set_ylabel('ä½ç½®')
    plt.colorbar(im1, ax=ax1)
    
    # å¯å­¦ä¹ ç¼–ç 
    ax2.set_title('å¯å­¦ä¹ ä½ç½®ç¼–ç ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰', fontsize=14, weight='bold')
    im2 = ax2.imshow(learn_pe.pe[0, :20, :32].detach().numpy(), 
                     cmap='RdBu_r', aspect='auto')
    ax2.set_xlabel('ç»´åº¦')
    ax2.set_ylabel('ä½ç½®')
    plt.colorbar(im2, ax=ax2)
    
    # RoPEçš„coséƒ¨åˆ†
    ax3.set_title('RoPE (coséƒ¨åˆ†)', fontsize=14, weight='bold')
    im3 = ax3.imshow(rope.cos_cached[:20, :16].numpy(), 
                     cmap='RdBu_r', aspect='auto')
    ax3.set_xlabel('é¢‘ç‡ç»´åº¦')
    ax3.set_ylabel('ä½ç½®')
    plt.colorbar(im3, ax=ax3)
    
    plt.tight_layout()
    plt.show()
    
    # æ€§èƒ½å¯¹æ¯”
    print("\nâš¡ æ€§èƒ½å¯¹æ¯”:")
    import time
    
    # æ­£å¼¦ç¼–ç æ—¶é—´
    start = time.time()
    for _ in range(100):
        _ = sin_pe(x)
    sin_time = time.time() - start
    
    # RoPEæ—¶é—´
    start = time.time()
    for _ in range(100):
        _ = rope(x)
    rope_time = time.time() - start
    
    print(f"æ­£å¼¦ç¼–ç : {sin_time:.4f}ç§’")
    print(f"RoPE: {rope_time:.4f}ç§’")
    print(f"é€Ÿåº¦æ¯”: {sin_time/rope_time:.2f}x")

ä½ç½®ç¼–ç å®æˆ˜()
```

#### ğŸ“ æœ¬ç« å°ç»“

ä½ç½®ç¼–ç æ˜¯Transformerèƒ½å¤Ÿç†è§£åºåˆ—çš„å…³é”®ï¼š

1. **ä¸ºä»€ä¹ˆéœ€è¦**ï¼š
   - Self-Attentionæ˜¯æ’åˆ—ä¸å˜çš„
   - è¯­è¨€çš„æ„ä¹‰ä¾èµ–äºè¯åº
   - éœ€è¦æ˜¾å¼æ³¨å…¥ä½ç½®ä¿¡æ¯

2. **ä¸»è¦æ–¹æ³•**ï¼š
   - **ç»å¯¹ä½ç½®ç¼–ç **ï¼š
     - æ­£å¼¦ç¼–ç ï¼šç»å…¸ã€æ— å‚æ•°ã€å¯å¤–æ¨
     - å¯å­¦ä¹ ç¼–ç ï¼šçµæ´»ä½†éœ€è¦è®­ç»ƒ
   - **ç›¸å¯¹ä½ç½®ç¼–ç **ï¼š
     - T5é£æ ¼ï¼šå¯å­¦ä¹ çš„ç›¸å¯¹åç½®
     - ALiBiï¼šçº¿æ€§è¡°å‡åç½®
     - RoPEï¼šæ—‹è½¬ç¼–ç ï¼Œå…¼å…·æ•ˆç‡å’Œæ•ˆæœ

3. **å‘å±•è¶‹åŠ¿**ï¼š
   - ä»ç»å¯¹åˆ°ç›¸å¯¹
   - ä»åŠ æ³•åˆ°ä¹˜æ³•ï¼ˆæ—‹è½¬ï¼‰
   - ä»å›ºå®šåˆ°è‡ªé€‚åº”

4. **é€‰æ‹©å»ºè®®**ï¼š
   - çŸ­åºåˆ—ï¼šæ­£å¼¦ç¼–ç ç®€å•æœ‰æ•ˆ
   - é•¿åºåˆ—ï¼šRoPEæˆ–ALiBi
   - éœ€è¦å¤–æ¨ï¼šé¿å…å¯å­¦ä¹ ç¼–ç 

#### ğŸ’¡ å®ç”¨æŠ€å·§

1. **å®ç°è¦ç‚¹**ï¼š
   - ä½ç½®ç¼–ç åº”è¯¥ä¸è¯åµŒå…¥åŒä¸€é‡çº§
   - æ³¨æ„æ•°å€¼ç¨³å®šæ€§ï¼ˆé¿å…è¿‡å¤§çš„ä½ç½®å€¼ï¼‰
   - è€ƒè™‘åºåˆ—é•¿åº¦çš„å¤–æ¨éœ€æ±‚

2. **è°ƒè¯•æŠ€å·§**ï¼š
   - å¯è§†åŒ–ä½ç½®ç¼–ç çŸ©é˜µ
   - æ£€æŸ¥æ³¨æ„åŠ›æ¨¡å¼æ˜¯å¦åˆç†
   - æµ‹è¯•ä¸åŒé•¿åº¦çš„æ³›åŒ–èƒ½åŠ›

3. **å¸¸è§é—®é¢˜**ï¼š
   - ä½ç½®ç¼–ç è¿‡å¤§ï¼šä¼šæ©ç›–è¯åµŒå…¥ä¿¡æ¯
   - å¤–æ¨å¤±è´¥ï¼šè®­ç»ƒå’Œæ¨ç†é•¿åº¦å·®å¼‚å¤ªå¤§
   - ç›¸å¯¹ä½ç½®æº¢å‡ºï¼šéœ€è¦æˆªæ–­æˆ–ä½¿ç”¨å¯¹æ•°æ¡¶

#### ğŸ¤” æ€è€ƒé¢˜

1. ä¸ºä»€ä¹ˆæ­£å¼¦ä½ç½®ç¼–ç è¦ç”¨ä¸åŒçš„é¢‘ç‡ï¼Ÿ
2. RoPEä¸ºä»€ä¹ˆèƒ½å¤Ÿè‡ªç„¶åœ°ç¼–ç ç›¸å¯¹ä½ç½®ï¼Ÿ
3. å¦‚æœåºåˆ—å¾ˆé•¿ï¼ˆæ¯”å¦‚100kï¼‰ï¼Œè¯¥é€‰æ‹©ä»€ä¹ˆä½ç½®ç¼–ç ï¼Ÿ
4. ä½ç½®ç¼–ç æ˜¯å¦å¯ä»¥å®Œå…¨è¢«æ³¨æ„åŠ›æœºåˆ¶å­¦ä¹ åˆ°ï¼Ÿ

æ­å–œä½ æŒæ¡äº†ä½ç½®ç¼–ç ï¼ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ³¨æ„åŠ›æœºåˆ¶ï¼Œçœ‹çœ‹Transformerçš„æ ¸å¿ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

--- 